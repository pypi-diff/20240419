# Comparing `tmp/cid-cmd-0.2.9.tar.gz` & `tmp/cid_cmd-0.3.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "cid-cmd-0.2.9.tar", last modified: Mon Jan 16 18:21:08 2023, max compression
+gzip compressed data, was "cid_cmd-0.3.0.tar", last modified: Fri Apr 19 13:08:15 2024, max compression
```

## Comparing `cid-cmd-0.2.9.tar` & `cid_cmd-0.3.0.tar`

### file list

```diff
@@ -1,131 +1,156 @@
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.810700 cid-cmd-0.2.9/
--rw-r--r--   0 runner    (1001) docker     (123)      927 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/LICENSE
--rw-r--r--   0 runner    (1001) docker     (123)       97 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (123)     6903 2023-01-16 18:21:08.810700 cid-cmd-0.2.9/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)     6224 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/README.md
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/
--rw-r--r--   0 runner    (1001) docker     (123)       77 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)       23 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/_version.py
--rw-r--r--   0 runner    (1001) docker     (123)     1590 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/base.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/builtin/
--rw-r--r--   0 runner    (1001) docker     (123)       28 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/builtin/core/
--rw-r--r--   0 runner    (1001) docker     (123)       41 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/builtin/core/data/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.794700 cid-cmd-0.2.9/cid/builtin/core/data/datasets/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/
--rw-r--r--   0 runner    (1001) docker     (123)     2700 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/compute.json
--rw-r--r--   0 runner    (1001) docker     (123)     2893 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/ec2_running_cost.json
--rw-r--r--   0 runner    (1001) docker     (123)     3777 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/s3_view.json
--rw-r--r--   0 runner    (1001) docker     (123)     8825 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/summary_view.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/builtin/core/data/datasets/co/
--rw-r--r--   0 runner    (1001) docker     (123)     8130 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/co/dataset.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/
--rw-r--r--   0 runner    (1001) docker     (123)     3353 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_ebs_snap.json
--rw-r--r--   0 runner    (1001) docker     (123)     5069 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_ebs_storage_all.json
--rw-r--r--   0 runner    (1001) docker     (123)    20317 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_instance_all.json
--rw-r--r--   0 runner    (1001) docker     (123)    11136 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_s3_storage_all.json
--rw-r--r--   0 runner    (1001) docker     (123)    15008 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_tracker.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/builtin/core/data/datasets/shared/
--rw-r--r--   0 runner    (1001) docker     (123)    33424 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/shared/customer_all.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.802700 cid-cmd-0.2.9/cid/builtin/core/data/datasets/tao/
--rw-r--r--   0 runner    (1001) docker     (123)    67579 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/tao/dataset.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.802700 cid-cmd-0.2.9/cid/builtin/core/data/datasets/trends/
--rw-r--r--   0 runner    (1001) docker     (123)     2142 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/trends/daily_anomaly_detection.json
--rw-r--r--   0 runner    (1001) docker     (123)     2156 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/trends/monthly_anomaly_detection.json
--rw-r--r--   0 runner    (1001) docker     (123)     4681 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/datasets/trends/monthly_bill_by_account.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.802700 cid-cmd-0.2.9/cid/builtin/core/data/permissions/
--rw-r--r--   0 runner    (1001) docker     (123)      375 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/permissions/dashboard_permissions.json
--rw-r--r--   0 runner    (1001) docker     (123)      165 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/permissions/dashboard_permissions_namespace.json
--rw-r--r--   0 runner    (1001) docker     (123)      409 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/permissions/data_set_permissions.json
--rw-r--r--   0 runner    (1001) docker     (123)      289 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/permissions/data_source_permissions.json
--rw-r--r--   0 runner    (1001) docker     (123)      431 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/permissions/folder_permissions.json
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.798700 cid-cmd-0.2.9/cid/builtin/core/data/queries/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.802700 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/
--rw-r--r--   0 runner    (1001) docker     (123)     2264 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/compute_savings_plan_eligible_spend.sql
--rw-r--r--   0 runner    (1001) docker     (123)     1488 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ec2_running_cost.sql
--rw-r--r--   0 runner    (1001) docker     (123)     1471 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ec2_running_cost_ri.sql
--rw-r--r--   0 runner    (1001) docker     (123)     1474 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ec2_running_cost_sp.sql
--rw-r--r--   0 runner    (1001) docker     (123)     1459 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ec2_running_cost_sp_ri.sql
--rw-r--r--   0 runner    (1001) docker     (123)     2942 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ri_sp_mapping.sql
--rw-r--r--   0 runner    (1001) docker     (123)     2519 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ri_sp_mapping_ri.sql
--rw-r--r--   0 runner    (1001) docker     (123)     2537 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ri_sp_mapping_sp.sql
--rw-r--r--   0 runner    (1001) docker     (123)     2450 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ri_sp_mapping_sp_ri.sql
--rw-r--r--   0 runner    (1001) docker     (123)     1594 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/s3.sql
--rw-r--r--   0 runner    (1001) docker     (123)     5771 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/summary_view.sql
--rw-r--r--   0 runner    (1001) docker     (123)     5515 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/summary_view_ri.sql
--rw-r--r--   0 runner    (1001) docker     (123)     5571 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/summary_view_sp.sql
--rw-r--r--   0 runner    (1001) docker     (123)     5582 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/summary_view_sp_ri.sql
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.802700 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/
--rw-r--r--   0 runner    (1001) docker     (123)      323 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/all_options.sql
--rw-r--r--   0 runner    (1001) docker     (123)    14711 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/auto_scale.json
--rw-r--r--   0 runner    (1001) docker     (123)    26157 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/auto_scale_options.sql
--rw-r--r--   0 runner    (1001) docker     (123)     8850 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/ebs_volume.json
--rw-r--r--   0 runner    (1001) docker     (123)    22589 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/ebs_volume_options.sql
--rw-r--r--   0 runner    (1001) docker     (123)    18754 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/ec2_instance.json
--rw-r--r--   0 runner    (1001) docker     (123)    27437 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/ec2_instance_options.sql
--rw-r--r--   0 runner    (1001) docker     (123)     8029 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/lambda.json
--rw-r--r--   0 runner    (1001) docker     (123)    14694 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/co/lambda_options.sql
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.806700 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/
--rw-r--r--   0 runner    (1001) docker     (123)     9735 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/first_kpi_instance_mapping_view.sql
--rw-r--r--   0 runner    (1001) docker     (123)     3187 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_ebs_snap_view.sql
--rw-r--r--   0 runner    (1001) docker     (123)     6192 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_ebs_storage_view.sql
--rw-r--r--   0 runner    (1001) docker     (123)    23793 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_instance_all_view.sql
--rw-r--r--   0 runner    (1001) docker     (123)    22987 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRI.sql
--rw-r--r--   0 runner    (1001) docker     (123)    21969 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRISP.sql
--rw-r--r--   0 runner    (1001) docker     (123)    22847 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noSP.sql
--rw-r--r--   0 runner    (1001) docker     (123)    11256 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_s3_storage_view.sql
--rw-r--r--   0 runner    (1001) docker     (123)     8479 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/last_kpi_tracker_view.sql
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.806700 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/
--rw-r--r--   0 runner    (1001) docker     (123)      164 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/account_map.sql
--rw-r--r--   0 runner    (1001) docker     (123)      462 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/account_map_dummy.sql
--rw-r--r--   0 runner    (1001) docker     (123)      592 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/aws_accounts.sql
--rw-r--r--   0 runner    (1001) docker     (123)     1772 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/aws_regions.sql
--rw-r--r--   0 runner    (1001) docker     (123)     6455 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/aws_service_category_map.sql
--rw-r--r--   0 runner    (1001) docker     (123)      220 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/business_units_map.sql
--rw-r--r--   0 runner    (1001) docker     (123)      245 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/payer_account_name_map.sql
--rw-r--r--   0 runner    (1001) docker     (123)   142433 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/ta_descriptions.sql
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.806700 cid-cmd-0.2.9/cid/builtin/core/data/queries/tao/
--rw-r--r--   0 runner    (1001) docker     (123)    35595 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/tao/glue_table.json
--rw-r--r--   0 runner    (1001) docker     (123)     5890 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/tao/ta_org_view.sql
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.806700 cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/
--rw-r--r--   0 runner    (1001) docker     (123)      680 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/daily_anomaly_detection.sql
--rw-r--r--   0 runner    (1001) docker     (123)      695 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_anomaly_detection.sql
--rw-r--r--   0 runner    (1001) docker     (123)     1881 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_bill_by_account.sql
--rw-r--r--   0 runner    (1001) docker     (123)     2244 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_bill_by_account_ri.sql
--rw-r--r--   0 runner    (1001) docker     (123)     2304 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp.sql
--rw-r--r--   0 runner    (1001) docker     (123)     2544 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp_ri.sql
--rw-r--r--   0 runner    (1001) docker     (123)     9794 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/builtin/core/data/resources.yaml
--rw-r--r--   0 runner    (1001) docker     (123)     8675 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/cli.py
--rw-r--r--   0 runner    (1001) docker     (123)    60837 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/common.py
--rw-r--r--   0 runner    (1001) docker     (123)      193 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/exceptions.py
--rw-r--r--   0 runner    (1001) docker     (123)     7615 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/export.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.806700 cid-cmd-0.2.9/cid/helpers/
--rw-r--r--   0 runner    (1001) docker     (123)      294 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    11776 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/account_map.py
--rw-r--r--   0 runner    (1001) docker     (123)    16999 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/athena.py
--rw-r--r--   0 runner    (1001) docker     (123)     5328 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/cur.py
--rw-r--r--   0 runner    (1001) docker     (123)      991 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/glue.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.806700 cid-cmd-0.2.9/cid/helpers/quicksight/
--rw-r--r--   0 runner    (1001) docker     (123)    49795 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/quicksight/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     6021 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/quicksight/dashboard.py
--rw-r--r--   0 runner    (1001) docker     (123)     1244 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/quicksight/dataset.py
--rw-r--r--   0 runner    (1001) docker     (123)      938 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/quicksight/datasource.py
--rw-r--r--   0 runner    (1001) docker     (123)      497 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/quicksight/resource.py
--rw-r--r--   0 runner    (1001) docker     (123)     3156 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/helpers/quicksight/template.py
--rw-r--r--   0 runner    (1001) docker     (123)     2091 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/logger.py
--rw-r--r--   0 runner    (1001) docker     (123)     2932 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/plugin.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.810700 cid-cmd-0.2.9/cid/queries/
--rw-r--r--   0 runner    (1001) docker     (123)      274 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/queries/ahq-queries.json
--rw-r--r--   0 runner    (1001) docker     (123)      110 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/queries/ri_present.sql
--rw-r--r--   0 runner    (1001) docker     (123)      119 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/queries/sp_present.sql
--rw-r--r--   0 runner    (1001) docker     (123)     8458 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/cid/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-01-16 18:21:08.810700 cid-cmd-0.2.9/cid_cmd.egg-info/
--rw-r--r--   0 runner    (1001) docker     (123)     6903 2023-01-16 18:21:08.000000 cid-cmd-0.2.9/cid_cmd.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)     4813 2023-01-16 18:21:08.000000 cid-cmd-0.2.9/cid_cmd.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-01-16 18:21:08.000000 cid-cmd-0.2.9/cid_cmd.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (123)       80 2023-01-16 18:21:08.000000 cid-cmd-0.2.9/cid_cmd.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (123)       88 2023-01-16 18:21:08.000000 cid-cmd-0.2.9/cid_cmd.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (123)       43 2023-01-16 18:21:08.000000 cid-cmd-0.2.9/cid_cmd.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (123)       84 2023-01-16 18:20:59.000000 cid-cmd-0.2.9/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (123)     1065 2023-01-16 18:21:08.810700 cid-cmd-0.2.9/setup.cfg
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.367936 cid_cmd-0.3.0/
+-rw-r--r--   0 runner    (1001) docker     (127)      927 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (127)       97 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (127)     9475 2024-04-19 13:08:15.367936 cid_cmd-0.3.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)     8560 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/README.md
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.343936 cid_cmd-0.3.0/cid/
+-rw-r--r--   0 runner    (1001) docker     (127)       77 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)       22 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/_version.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1872 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/base.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.343936 cid_cmd-0.3.0/cid/builtin/
+-rw-r--r--   0 runner    (1001) docker     (127)       28 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.343936 cid_cmd-0.3.0/cid/builtin/core/
+-rw-r--r--   0 runner    (1001) docker     (127)       41 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.343936 cid_cmd-0.3.0/cid/builtin/core/data/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.339936 cid_cmd-0.3.0/cid/builtin/core/data/datasets/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.347936 cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/
+-rw-r--r--   0 runner    (1001) docker     (127)     2700 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/compute.json
+-rw-r--r--   0 runner    (1001) docker     (127)     2893 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/ec2_running_cost.json
+-rw-r--r--   0 runner    (1001) docker     (127)     3777 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/s3_view.json
+-rw-r--r--   0 runner    (1001) docker     (127)     8825 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/summary_view.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.347936 cid_cmd-0.3.0/cid/builtin/core/data/datasets/co/
+-rw-r--r--   0 runner    (1001) docker     (127)     9276 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/co/dataset.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.347936 cid_cmd-0.3.0/cid/builtin/core/data/datasets/cudos/
+-rw-r--r--   0 runner    (1001) docker     (127)     6223 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/cudos/hourly_view.json
+-rw-r--r--   0 runner    (1001) docker     (127)     8610 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/cudos/resource_view.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.347936 cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/
+-rw-r--r--   0 runner    (1001) docker     (127)     3353 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_ebs_snap.json
+-rw-r--r--   0 runner    (1001) docker     (127)     5069 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_ebs_storage_all.json
+-rw-r--r--   0 runner    (1001) docker     (127)    20695 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_instance_all.json
+-rw-r--r--   0 runner    (1001) docker     (127)    11136 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_s3_storage_all.json
+-rw-r--r--   0 runner    (1001) docker     (127)    15746 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_tracker.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.347936 cid_cmd-0.3.0/cid/builtin/core/data/datasets/shared/
+-rw-r--r--   0 runner    (1001) docker     (127)    30612 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/shared/customer_all.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.347936 cid_cmd-0.3.0/cid/builtin/core/data/datasets/tao/
+-rw-r--r--   0 runner    (1001) docker     (127)    69315 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/tao/dataset.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.347936 cid_cmd-0.3.0/cid/builtin/core/data/datasets/trends/
+-rw-r--r--   0 runner    (1001) docker     (127)     2142 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/trends/daily_anomaly_detection.json
+-rw-r--r--   0 runner    (1001) docker     (127)     2156 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/trends/monthly_anomaly_detection.json
+-rw-r--r--   0 runner    (1001) docker     (127)     4681 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/datasets/trends/monthly_bill_by_account.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.347936 cid_cmd-0.3.0/cid/builtin/core/data/permissions/
+-rw-r--r--   0 runner    (1001) docker     (127)      375 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/permissions/dashboard_permissions.json
+-rw-r--r--   0 runner    (1001) docker     (127)      165 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/permissions/dashboard_permissions_namespace.json
+-rw-r--r--   0 runner    (1001) docker     (127)      409 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/permissions/data_set_permissions.json
+-rw-r--r--   0 runner    (1001) docker     (127)      289 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/permissions/data_source_permissions.json
+-rw-r--r--   0 runner    (1001) docker     (127)      431 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/permissions/folder_permissions.json
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.339936 cid_cmd-0.3.0/cid/builtin/core/data/queries/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.351936 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/
+-rw-r--r--   0 runner    (1001) docker     (127)     2264 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/compute_savings_plan_eligible_spend.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1488 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ec2_running_cost.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1471 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ec2_running_cost_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1474 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ec2_running_cost_sp.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1459 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ec2_running_cost_sp_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2942 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ri_sp_mapping.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2519 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ri_sp_mapping_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2537 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ri_sp_mapping_sp.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     3134 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ri_sp_mapping_sp_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1594 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/s3.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     5808 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/summary_view.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     5533 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/summary_view_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     5589 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/summary_view_sp.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     5599 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/summary_view_sp_ri.sql
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.355936 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/
+-rw-r--r--   0 runner    (1001) docker     (127)      323 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/all_options.sql
+-rw-r--r--   0 runner    (1001) docker     (127)    14711 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/auto_scale.json
+-rw-r--r--   0 runner    (1001) docker     (127)    27919 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/auto_scale_options.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     9097 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/ebs_volume.json
+-rw-r--r--   0 runner    (1001) docker     (127)    22473 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/ebs_volume_options.sql
+-rw-r--r--   0 runner    (1001) docker     (127)    19144 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/ec2_instance.json
+-rw-r--r--   0 runner    (1001) docker     (127)    28308 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/ec2_instance_options.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     8029 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/lambda.json
+-rw-r--r--   0 runner    (1001) docker     (127)    15340 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/co/lambda_options.sql
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.355936 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/
+-rw-r--r--   0 runner    (1001) docker     (127)     1243 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/hourly_view.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1272 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/hourly_view_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1288 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/hourly_view_sp.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1366 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/hourly_view_sp_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1989 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/resource_view.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2019 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/resource_view_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2035 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/resource_view_sp.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2065 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/cudos/resource_view_sp_ri.sql
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.355936 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/
+-rw-r--r--   0 runner    (1001) docker     (127)    11145 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/first_kpi_instance_mapping_view.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     3187 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_ebs_snap_view.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     6192 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_ebs_storage_view.sql
+-rw-r--r--   0 runner    (1001) docker     (127)    24337 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_instance_all_view.sql
+-rw-r--r--   0 runner    (1001) docker     (127)    23573 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRI.sql
+-rw-r--r--   0 runner    (1001) docker     (127)    22559 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRISP.sql
+-rw-r--r--   0 runner    (1001) docker     (127)    23434 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noSP.sql
+-rw-r--r--   0 runner    (1001) docker     (127)    11256 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_s3_storage_view.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     9226 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/last_kpi_tracker_view.sql
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.359936 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/
+-rw-r--r--   0 runner    (1001) docker     (127)      260 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/account_map.sql
+-rw-r--r--   0 runner    (1001) docker     (127)      462 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/account_map_dummy.sql
+-rw-r--r--   0 runner    (1001) docker     (127)      592 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/aws_accounts.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2731 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/aws_regions.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     7282 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/aws_service_category_map.sql
+-rw-r--r--   0 runner    (1001) docker     (127)      220 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/business_units_map.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     5043 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/cur.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)      245 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/payer_account_name_map.sql
+-rw-r--r--   0 runner    (1001) docker     (127)   163373 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/ta_descriptions.sql
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.359936 cid_cmd-0.3.0/cid/builtin/core/data/queries/tao/
+-rw-r--r--   0 runner    (1001) docker     (127)    35595 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/tao/glue_table.json
+-rw-r--r--   0 runner    (1001) docker     (127)     5935 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/tao/ta_org_view.sql
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.359936 cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/
+-rw-r--r--   0 runner    (1001) docker     (127)      680 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/daily_anomaly_detection.sql
+-rw-r--r--   0 runner    (1001) docker     (127)      695 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_anomaly_detection.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     1881 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_bill_by_account.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2244 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_bill_by_account_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2304 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp.sql
+-rw-r--r--   0 runner    (1001) docker     (127)     2544 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp_ri.sql
+-rw-r--r--   0 runner    (1001) docker     (127)    18712 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/builtin/core/data/resources.yaml
+-rw-r--r--   0 runner    (1001) docker     (127)    12523 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/cli.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.359936 cid_cmd-0.3.0/cid/commands/
+-rw-r--r--   0 runner    (1001) docker     (127)       70 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/commands/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)      342 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/commands/command_base.py
+-rw-r--r--   0 runner    (1001) docker     (127)     5353 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/commands/init_qs.py
+-rw-r--r--   0 runner    (1001) docker     (127)    92373 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/common.py
+-rw-r--r--   0 runner    (1001) docker     (127)      193 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (127)    19919 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/export.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.363936 cid_cmd-0.3.0/cid/helpers/
+-rw-r--r--   0 runner    (1001) docker     (127)      588 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)    12580 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/account_map.py
+-rw-r--r--   0 runner    (1001) docker     (127)    22951 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/athena.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2711 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/csv2view.py
+-rw-r--r--   0 runner    (1001) docker     (127)     9850 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/cur.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2166 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/diff.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3377 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/glue.py
+-rw-r--r--   0 runner    (1001) docker     (127)    21978 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/iam.py
+-rw-r--r--   0 runner    (1001) docker     (127)      938 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/organizations.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.363936 cid_cmd-0.3.0/cid/helpers/quicksight/
+-rw-r--r--   0 runner    (1001) docker     (127)    68635 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/quicksight/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (127)     6731 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/quicksight/dashboard.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3173 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/quicksight/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (127)      938 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/quicksight/datasource.py
+-rw-r--r--   0 runner    (1001) docker     (127)      497 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/quicksight/resource.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3156 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/quicksight/template.py
+-rw-r--r--   0 runner    (1001) docker     (127)     1815 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/randtime.py
+-rw-r--r--   0 runner    (1001) docker     (127)     3302 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/s3.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2304 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/helpers/timezone.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2101 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/logger.py
+-rw-r--r--   0 runner    (1001) docker     (127)     2932 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/plugin.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.339936 cid_cmd-0.3.0/cid/test/
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.363936 cid_cmd-0.3.0/cid/test/python/
+-rw-r--r--   0 runner    (1001) docker     (127)      432 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/test/python/test_csv2view.py
+-rw-r--r--   0 runner    (1001) docker     (127)      453 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/test/python/test_isolated_parameters.py
+-rw-r--r--   0 runner    (1001) docker     (127)      588 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/test/python/test_merge.py
+-rw-r--r--   0 runner    (1001) docker     (127)    10836 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/cid/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-04-19 13:08:15.367936 cid_cmd-0.3.0/cid_cmd.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (127)     9475 2024-04-19 13:08:15.000000 cid_cmd-0.3.0/cid_cmd.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (127)     5677 2024-04-19 13:08:15.000000 cid_cmd-0.3.0/cid_cmd.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (127)        1 2024-04-19 13:08:15.000000 cid_cmd-0.3.0/cid_cmd.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       80 2024-04-19 13:08:15.000000 cid_cmd-0.3.0/cid_cmd.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       99 2024-04-19 13:08:15.000000 cid_cmd-0.3.0/cid_cmd.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       72 2024-04-19 13:08:15.000000 cid_cmd-0.3.0/cid_cmd.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (127)       85 2024-04-19 13:08:11.000000 cid_cmd-0.3.0/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (127)     1079 2024-04-19 13:08:15.367936 cid_cmd-0.3.0/setup.cfg
```

### Comparing `cid-cmd-0.2.9/LICENSE` & `cid_cmd-0.3.0/LICENSE`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/base.py` & `cid_cmd-0.3.0/cid/base.py`

 * *Files 8% similar despite different names*

```diff
@@ -18,14 +18,20 @@
         self.session = session
 
     @property
     def account_id(self) -> str:
         return self.awsIdentity.get('Account')
 
     @property
+    def domain(self) -> str:
+        if self.region.startswith('cn-'):
+            return 'amazonaws.cn'
+        return 'aws.amazon.com'
+
+    @property
     def awsIdentity(self) -> dict:
         if not self._awsIdentity:
             try:
                 sts = self.session.client('sts')
                 self.awsIdentity = sts.get_caller_identity()
             except Exception as e:
                 raise CidCritical(f'Authentication error: {e}')
@@ -40,14 +46,18 @@
         return self.session.region_name
 
     @property
     def region_name(self) -> str:
         return self.session.region_name
 
     @property
+    def partition(self) -> str:
+        return self.session.get_partition_for_region(region_name=self.region_name)
+
+    @property
     def session(self) -> Session:
         return self._session
 
     @session.setter
     def session(self, value):
         self._session = value
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/compute.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/compute.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/ec2_running_cost.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/ec2_running_cost.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/s3_view.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/s3_view.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/cid/summary_view.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/cid/summary_view.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/co/dataset.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/cudos/hourly_view.json`

 * *Files 15% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.6666666666666666%*

 * *Differences: {"'DataSetId'": "'78f4cc36-c46c-431b-91f0-c72e147d9bcb'",*

 * * "'LogicalTableMap'": "{replace: OrderedDict([('a34a38d8-7504-4aba-89e8-d038d5fb5706', "*

 * *                      "OrderedDict([('Alias', 'Intermediate Table'), ('DataTransforms', "*

 * *                      "[OrderedDict([('ProjectOperation', OrderedDict([('ProjectedColumns', "*

 * *                      "['product_code', 'service', 'operation', 'charge_type', 'usage_type', "*

 * *                      "'item_description', 'pricing_unit', 'region', 'pricing_term', " [â€¦]*

```diff
@@ -1,226 +1,178 @@
 {
-    "DataSetId": "compute_optimizer_all_options",
+    "DataSetId": "78f4cc36-c46c-431b-91f0-c72e147d9bcb",
     "ImportMode": "SPICE",
     "LogicalTableMap": {
-        "3ac94581-80b1-4ae5-a18f-af42ff4b61ad": {
-            "Alias": "business_units_map",
-            "Source": {
-                "PhysicalTableId": "5da8f118-fdc0-47ee-aaa0-b633cbf8f9c9"
-            }
-        },
-        "695b2749-bcfd-4923-afcc-e0db1252c9cc": {
+        "a34a38d8-7504-4aba-89e8-d038d5fb5706": {
             "Alias": "Intermediate Table",
             "DataTransforms": [
                 {
                     "ProjectOperation": {
                         "ProjectedColumns": [
-                            "lastrefreshtimestamp_utc",
-                            "accountid",
-                            "arn",
-                            "region",
+                            "product_code",
                             "service",
-                            "name",
-                            "module",
-                            "recommendationsourcetype",
-                            "finding",
-                            "reason",
-                            "lookbackperiodindays",
-                            "currentperformancerisk",
-                            "errorcode",
-                            "errormessage",
-                            "ressouce_details",
-                            "utilizationmetrics",
-                            "option_name",
-                            "option_from",
-                            "option_to",
-                            "currency",
-                            "monthlyprice",
-                            "hourlyprice",
-                            "estimatedmonthlysavings_value",
-                            "estimatedmonthly_ondemand_cost_change",
-                            "max_estimatedmonthlysavings_value_very_low",
-                            "max_estimatedmonthlysavings_value_low",
-                            "max_estimatedmonthlysavings_value_medium",
-                            "option_details",
+                            "operation",
+                            "charge_type",
+                            "usage_type",
+                            "item_description",
+                            "pricing_unit",
+                            "region",
+                            "pricing_term",
+                            "billing_period",
+                            "usage_date",
+                            "payer_account_id",
+                            "linked_account_id",
+                            "savings_plan_a_r_n",
+                            "reservation_a_r_n",
+                            "unblended_cost",
+                            "reservation_effective_cost",
+                            "savings_plan_effective_cost",
+                            "usage_quantity",
                             "account_id",
-                            "account_name",
-                            "bu"
-                        ]
-                    }
-                },
-                {
-                    "TagColumnOperation": {
-                        "ColumnName": "region",
-                        "Tags": [
-                            {
-                                "ColumnGeographicRole": "STATE"
-                            }
+                            "account_name"
                         ]
                     }
                 }
             ],
             "Source": {
                 "JoinInstruction": {
-                    "LeftOperand": "d46182de-be7b-4e56-926b-090ecb93df7d",
-                    "OnClause": "{accountid} = {account_id}",
-                    "RightOperand": "3ac94581-80b1-4ae5-a18f-af42ff4b61ad",
+                    "LeftOperand": "c08f9029-26ae-4a4c-91bc-ffad52dc67e3",
+                    "OnClause": "{linked_account_id} = {account_id}",
+                    "RightOperand": "dea38012-0b99-4729-bebb-fe071a8b5327",
                     "Type": "LEFT"
                 }
             }
         },
-        "d46182de-be7b-4e56-926b-090ecb93df7d": {
-            "Alias": "compute_optimizer_all_options",
+        "c08f9029-26ae-4a4c-91bc-ffad52dc67e3": {
+            "Alias": "hourly_view",
+            "DataTransforms": [
+                {
+                    "CastColumnTypeOperation": {
+                        "ColumnName": "reservation_effective_cost",
+                        "NewColumnType": "DECIMAL"
+                    }
+                },
+                {
+                    "CastColumnTypeOperation": {
+                        "ColumnName": "usage_quantity",
+                        "NewColumnType": "DECIMAL"
+                    }
+                }
+            ],
+            "Source": {
+                "PhysicalTableId": "e0c1051e-daef-4661-9554-42989b38effa"
+            }
+        },
+        "dea38012-0b99-4729-bebb-fe071a8b5327": {
+            "Alias": "account_map",
             "Source": {
-                "PhysicalTableId": "22291301-8e81-41bf-9270-56eb59692e55"
+                "PhysicalTableId": "d456be68-afcd-4dc9-a024-6e0cfe596eb9"
             }
         }
     },
-    "Name": "compute_optimizer_all_options",
+    "Name": "hourly_view",
     "Permissions": [],
     "PhysicalTableMap": {
-        "22291301-8e81-41bf-9270-56eb59692e55": {
+        "d456be68-afcd-4dc9-a024-6e0cfe596eb9": {
             "RelationalTable": {
-                "Catalog": "AwsDataCatalog",
                 "DataSourceArn": "${athena_datasource_arn}",
                 "InputColumns": [
                     {
-                        "Name": "errormessage",
+                        "Name": "account_id",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "ressouce_details",
+                        "Name": "account_name",
                         "Type": "STRING"
-                    },
+                    }
+                ],
+                "Name": "account_map",
+                "Schema": "${athena_database_name}"
+            }
+        },
+        "e0c1051e-daef-4661-9554-42989b38effa": {
+            "RelationalTable": {
+                "DataSourceArn": "${athena_datasource_arn}",
+                "InputColumns": [
                     {
-                        "Name": "reason",
+                        "Name": "product_code",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "utilizationmetrics",
+                        "Name": "service",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "option_details",
+                        "Name": "operation",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "option_name",
+                        "Name": "charge_type",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "estimatedmonthlysavings_value",
-                        "Type": "DECIMAL"
-                    },
-                    {
-                        "Name": "recommendationsourcetype",
+                        "Name": "usage_type",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "monthlyprice",
-                        "Type": "DECIMAL"
+                        "Name": "item_description",
+                        "Type": "STRING"
                     },
                     {
-                        "Name": "accountid",
+                        "Name": "pricing_unit",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "currency",
+                        "Name": "region",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "arn",
+                        "Name": "pricing_term",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "lastrefreshtimestamp_utc",
+                        "Name": "billing_period",
                         "Type": "DATETIME"
                     },
                     {
-                        "Name": "lookbackperiodindays",
-                        "Type": "STRING"
+                        "Name": "usage_date",
+                        "Type": "DATETIME"
                     },
                     {
-                        "Name": "errorcode",
+                        "Name": "payer_account_id",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "estimatedmonthly_ondemand_cost_change",
-                        "Type": "DECIMAL"
+                        "Name": "linked_account_id",
+                        "Type": "STRING"
                     },
                     {
-                        "Name": "module",
+                        "Name": "savings_plan_a_r_n",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "option_from",
+                        "Name": "reservation_a_r_n",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "max_estimatedmonthlysavings_value_medium",
+                        "Name": "unblended_cost",
                         "Type": "DECIMAL"
                     },
                     {
-                        "Name": "max_estimatedmonthlysavings_value_very_low",
+                        "Name": "reservation_effective_cost",
                         "Type": "DECIMAL"
                     },
                     {
-                        "Name": "finding",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "currentperformancerisk",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "hourlyprice",
+                        "Name": "savings_plan_effective_cost",
                         "Type": "DECIMAL"
                     },
                     {
-                        "Name": "service",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "name",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "option_to",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "region",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "max_estimatedmonthlysavings_value_low",
+                        "Name": "usage_quantity",
                         "Type": "DECIMAL"
                     }
                 ],
-                "Name": "compute_optimizer_all_options",
-                "Schema": "${athena_database_name}"
-            }
-        },
-        "5da8f118-fdc0-47ee-aaa0-b633cbf8f9c9": {
-            "RelationalTable": {
-                "Catalog": "AwsDataCatalog",
-                "DataSourceArn": "${athena_datasource_arn}",
-                "InputColumns": [
-                    {
-                        "Name": "account_id",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "account_name",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "bu",
-                        "Type": "STRING"
-                    }
-                ],
-                "Name": "business_units_map",
+                "Name": "hourly_view",
                 "Schema": "${athena_database_name}"
             }
         }
     }
 }
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_ebs_snap.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_ebs_snap.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_ebs_storage_all.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_ebs_storage_all.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_instance_all.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_instance_all.json`

 * *Files 0% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9999305555555557%*

 * *Differences: {"'LogicalTableMap'": "{'958b7222-e3e2-41ab-8093-6ba24c5e88a1': {'DataTransforms': {1: "*

 * *                      "{'ProjectOperation': {'ProjectedColumns': {insert: [(98, "*

 * *                      "'rds_oracle_cost'), (99, 'rds_sql_server_cost')]}}}}}}",*

 * * "'PhysicalTableMap'": "{'958b7222-e3e2-41ab-8093-6ba24c5e88a1': {'RelationalTable': "*

 * *                       "{'InputColumns': {insert: [(98, OrderedDict([('Name', 'rds_oracle_cost'), "*

 * *                       "('Type', 'DECIMAL')])), (99, OrderedDict([('Name', [â€¦]*

```diff
@@ -111,15 +111,17 @@
                             "dynamodb_ondemand_cost",
                             "dynamodb_commit_savings",
                             "dynamodb_commit_potential_savings",
                             "lambda_all_cost",
                             "lambda_usage_cost",
                             "lambda_graviton_eligible_cost",
                             "lambda_graviton_cost",
-                            "lambda_graviton_potential_savings"
+                            "lambda_graviton_potential_savings",
+                            "rds_oracle_cost",
+                            "rds_sql_server_cost"
                         ]
                     }
                 }
             ],
             "Source": {
                 "PhysicalTableId": "958b7222-e3e2-41ab-8093-6ba24c5e88a1"
             }
@@ -519,14 +521,22 @@
                     {
                         "Name": "lambda_graviton_cost",
                         "Type": "DECIMAL"
                     },
                     {
                         "Name": "lambda_graviton_potential_savings",
                         "Type": "DECIMAL"
+                    },
+                    {
+                        "Name": "rds_oracle_cost",
+                        "Type": "DECIMAL"
+                    },
+                    {
+                        "Name": "rds_sql_server_cost",
+                        "Type": "DECIMAL"
                     }
                 ],
                 "Name": "kpi_instance_all",
                 "Schema": "${athena_database_name}"
             }
         }
     }
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_s3_storage_all.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_s3_storage_all.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/kpi/kpi_tracker.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/kpi/kpi_tracker.json`

 * *Files 6% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9997653903903904%*

 * *Differences: {"'LogicalTableMap'": "{'ca597aad-1079-4c11-a5ac-7d9deb38132a': {'DataTransforms': {0: "*

 * *                      "{'ProjectOperation': {'ProjectedColumns': {insert: [(70, 'rds_license'), "*

 * *                      "(71, 'rds_no_license'), (72, 'rds_sql_server_cost'), (73, "*

 * *                      "'rds_oracle_cost')]}}}}}}",*

 * * "'PhysicalTableMap'": "{'ca597aad-1079-4c11-a5ac-7d9deb38132a': {'RelationalTable': "*

 * *                       "{'InputColumns': {insert: [(70, OrderedDict([('Name', 'rds_license'), "*

 * *         [â€¦]*

```diff
@@ -73,15 +73,19 @@
                             "sagemaker_all_cost",
                             "sagemaker_ondemand_cost",
                             "sagemaker_commit_potential_savings",
                             "sagemaker_commit_savings",
                             "lambda_all_cost",
                             "lambda_graviton_cost",
                             "lambda_graviton_eligible_cost",
-                            "lambda_graviton_potential_savings"
+                            "lambda_graviton_potential_savings",
+                            "rds_license",
+                            "rds_no_license",
+                            "rds_sql_server_cost",
+                            "rds_oracle_cost"
                         ]
                     }
                 }
             ],
             "Source": {
                 "PhysicalTableId": "ca597aad-1079-4c11-a5ac-7d9deb38132a"
             }
@@ -369,14 +373,30 @@
                     {
                         "Name": "lambda_graviton_eligible_cost",
                         "Type": "DECIMAL"
                     },
                     {
                         "Name": "lambda_graviton_potential_savings",
                         "Type": "DECIMAL"
+                    },
+                    {
+                        "Name": "rds_license",
+                        "Type": "INTEGER"
+                    },
+                    {
+                        "Name": "rds_no_license",
+                        "Type": "INTEGER"
+                    },
+                    {
+                        "Name": "rds_sql_server_cost",
+                        "Type": "DECIMAL"
+                    },
+                    {
+                        "Name": "rds_oracle_cost",
+                        "Type": "DECIMAL"
                     }
                 ],
                 "Name": "kpi_tracker",
                 "Schema": "${athena_database_name}"
             }
         }
     }
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/shared/customer_all.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/shared/customer_all.json`

 * *Files 4% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9998688142896858%*

 * *Differences: {"'LogicalTableMap'": "{'faad660a-8f70-4660-af84-8ab3c8a9474f': {'DataTransforms': {0: "*

 * *                      "{'ProjectOperation': {'ProjectedColumns': {delete: [208, 207, 206, 205, "*

 * *                      '199, 198, 197, 196, 195, 123, 122, 121, 120, 119, 118, 117, 116, 115]}}}}}}',*

 * * "'PhysicalTableMap'": "{'b163ad4b-f459-4b01-b2f3-54a168088640': {'RelationalTable': "*

 * *                       "{'InputColumns': {delete: [215, 171, 168, 147, 142, 125, 104, 97, 96, 89, "*

 * *                       '64, 43, 30, 24 [â€¦]*

```diff
@@ -131,23 +131,14 @@
                             "reservation_total_reserved_units",
                             "reservation_units_per_reservation",
                             "reservation_unused_amortized_upfront_fee_for_billing_period",
                             "reservation_unused_normalized_unit_quantity",
                             "reservation_unused_quantity",
                             "reservation_unused_recurring_fee",
                             "reservation_upfront_value",
-                            "resource_tags_aws_autoscaling_group_name",
-                            "resource_tags_aws_created_by",
-                            "resource_tags_aws_ec2spot_fleet_request_id",
-                            "resource_tags_user_cost_center",
-                            "resource_tags_user_department",
-                            "resource_tags_user_environment",
-                            "resource_tags_user_name",
-                            "resource_tags_user_workload",
-                            "resource_tags_user_workload_type",
                             "product_alarm_type",
                             "product_compute_family",
                             "product_compute_type",
                             "product_content_type",
                             "product_cputype",
                             "product_intel_avx2_available",
                             "product_intel_avx_available",
@@ -211,28 +202,19 @@
                             "product_standard_storage",
                             "product_steps",
                             "product_storage_type",
                             "product_traffic_direction",
                             "product_type",
                             "product_uservolume",
                             "pricing_currency",
-                            "resource_tags_user_application_department",
-                            "resource_tags_user_application",
-                            "cost_category_demo",
-                            "cost_category_env",
-                            "cost_category_team",
                             "product_cache_engine",
                             "product_describes",
                             "product_gets",
                             "product_ops_items",
                             "product_updates",
-                            "resource_tags_user_owner",
-                            "resource_tags_user_application_cost_center",
-                            "resource_tags_user_application_name",
-                            "resource_tags_user_application_owner",
                             "product_instances",
                             "product_request_description",
                             "product_request_type",
                             "product_input_mode",
                             "product_output_mode",
                             "product_instance",
                             "product_fee_code",
@@ -289,22 +271,14 @@
                 "DataSourceArn": "${athena_datasource_arn}",
                 "InputColumns": [
                     {
                         "Name": "product_updates",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_aws_ec2spot_fleet_request_id",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "resource_tags_user_application_department",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "year",
                         "Type": "STRING"
                     },
                     {
                         "Name": "bill_billing_period_end_date",
                         "Type": "DATETIME"
                     },
@@ -321,18 +295,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_storage",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_user_workload_type",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_content_type",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_finding_storage",
                         "Type": "STRING"
                     },
@@ -353,18 +323,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_maximum_extended_storage",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_user_name",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "savings_plan_used_commitment",
                         "Type": "DECIMAL"
                     },
                     {
                         "Name": "line_item_blended_cost",
                         "Type": "DECIMAL"
                     },
@@ -381,18 +347,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_physical_processor",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_user_workload",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_directory_type_description",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_from_location",
                         "Type": "STRING"
                     },
@@ -405,18 +367,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_memory",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_aws_created_by",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_capacitystatus",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_bundle_group",
                         "Type": "STRING"
                     },
@@ -457,18 +415,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_resource_type",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_user_application_cost_center",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_category",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_edition",
                         "Type": "STRING"
                     },
@@ -541,18 +495,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_software_included",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_user_application",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_request_description",
                         "Type": "STRING"
                     },
                     {
                         "Name": "line_item_availability_zone",
                         "Type": "STRING"
                     },
@@ -641,18 +591,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_group",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_user_department",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "line_item_currency_code",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_servicename",
                         "Type": "STRING"
                     },
@@ -669,22 +615,14 @@
                         "Type": "DECIMAL"
                     },
                     {
                         "Name": "reservation_end_time",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "cost_category_demo",
-                        "Type": "STRING"
-                    },
-                    {
-                        "Name": "resource_tags_user_owner",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_type",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_client_location",
                         "Type": "STRING"
                     },
@@ -701,18 +639,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "reservation_unused_quantity",
                         "Type": "DECIMAL"
                     },
                     {
-                        "Name": "resource_tags_aws_autoscaling_group_name",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_granularity",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_ratetype",
                         "Type": "STRING"
                     },
@@ -785,18 +719,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "reservation_upfront_value",
                         "Type": "DECIMAL"
                     },
                     {
-                        "Name": "resource_tags_user_environment",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_gpu_memory",
                         "Type": "STRING"
                     },
                     {
                         "Name": "line_item_operation",
                         "Type": "STRING"
                     },
@@ -853,18 +783,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "reservation_total_reserved_normalized_units",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_user_application_owner",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_compute_family",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_message_delivery_frequency",
                         "Type": "STRING"
                     },
@@ -873,18 +799,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "reservation_unused_normalized_unit_quantity",
                         "Type": "DECIMAL"
                     },
                     {
-                        "Name": "cost_category_env",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "reservation_unused_recurring_fee",
                         "Type": "DECIMAL"
                     },
                     {
                         "Name": "product_traffic_direction",
                         "Type": "STRING"
                     },
@@ -957,30 +879,22 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "savings_plan_total_commitment_to_date",
                         "Type": "DECIMAL"
                     },
                     {
-                        "Name": "resource_tags_user_cost_center",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "bill_bill_type",
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_output_mode",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "cost_category_team",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "bill_billing_period_start_date",
                         "Type": "DATETIME"
                     },
                     {
                         "Name": "product_operation",
                         "Type": "STRING"
                     },
@@ -1145,18 +1059,14 @@
                         "Type": "STRING"
                     },
                     {
                         "Name": "product_min_volume_size",
                         "Type": "STRING"
                     },
                     {
-                        "Name": "resource_tags_user_application_name",
-                        "Type": "STRING"
-                    },
-                    {
                         "Name": "product_free_query_types",
                         "Type": "STRING"
                     },
                     {
                         "Name": "pricing_unit",
                         "Type": "STRING"
                     }
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/tao/dataset.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/tao/dataset.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.999298633262449%*

 * *Differences: {"'LogicalTableMap'": "{'b5de237f-b599-407f-87ec-32024624ba65': {'DataTransforms': {5: "*

 * *                      "{'CreateColumnsOperation': {'Columns': {0: {'ColumnName': 'Resource Id', "*

 * *                      "'ColumnId': '88b4612e-f9b6-4fff-9e4a-32cdf90b9a86', 'Expression': "*

 * *                      "'concat({resourceid},{Account})'}}}}, 6: {'CreateColumnsOperation': "*

 * *                      "{'Columns': {0: {'ColumnName': 'Resource Name', 'ColumnId': "*

 * *                      '\'c32a279b-d728-4947-b6db-f122b7f [â€¦]*

```diff
@@ -46,61 +46,72 @@
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
-                                "ColumnId": "c32a279b-d728-4947-b6db-f122b7f5250f",
-                                "ColumnName": "Resource\u00a0Name",
-                                "Expression": "ifelse(\n{Check Name} = 'Idle Load Balancers', {load balancer name},\n{Check Name} = 'Amazon RDS Idle DB Instances', {db instance name},\n{Check Name} = 'Low Utilization Amazon EC2 Instances', {instance id},\n{Check Name} = 'Unassociated Elastic IP Addresses', {ip address},\n{Check Name} = 'Underutilized Amazon EBS Volumes', {volume id},\n{Check Name} = 'Underutilized Amazon Redshift Clusters', cluster,\n{Check Name} = 'Amazon EBS Public Snapshots', {volume id},\n{Check Name} = 'Amazon RDS Public Snapshots', {db instance or cluster id},\n{Check Name} = 'AWS Lambda Functions with High Error Rates', {function arn},\n{Check Name} = 'AWS Lambda Functions Using Deprecated Runtimes', {function arn},\ncheckid = 'Wxdfp4B1L1' OR checkid = 'Wxdfp4B1L2' OR checkid = 'Wxdfp4B1L3' OR checkid = 'Wxdfp4B1L4',{workload arn},\nresourceid\n)"
+                                "ColumnId": "bc17d09c-5a52-4e82-a166-925f8178166d",
+                                "ColumnName": "Account",
+                                "Expression": "ifelse(\n    accountname = '' OR isNull(accountname),\n    accountid,\n    concat(accountname,': ',accountid)\n    )"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
-                                "ColumnId": "a22e1199-f893-48d1-9066-e37c4c7d0f94",
-                                "ColumnName": "Datetime",
-                                "Expression": "epochDate(parseInt(timestamp))"
+                                "ColumnId": "88b4612e-f9b6-4fff-9e4a-32cdf90b9a86",
+                                "ColumnName": "Resource Id",
+                                "Expression": "concat({resourceid},{Account})"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
-                                "ColumnId": "bc17d09c-5a52-4e82-a166-925f8178166d",
-                                "ColumnName": "Account",
-                                "Expression": "ifelse(\n    accountname = '' OR isNull(accountname),\n    accountid,\n    concat(accountname,': ',accountid)\n    )"
+                                "ColumnId": "c32a279b-d728-4947-b6db-f122b7f5250f",
+                                "ColumnName": "Resource Name",
+                                "Expression": "ifelse(\n{Check Name} = 'Idle Load Balancers', {load balancer name},\n{Check Name} = 'Amazon RDS Idle DB Instances', {db instance name},\n{Check Name} = 'Low Utilization Amazon EC2 Instances', {instance id},\n{Check Name} = 'Unassociated Elastic IP Addresses', {ip address},\n{Check Name} = 'Underutilized Amazon EBS Volumes', {volume id},\n{Check Name} = 'Underutilized Amazon Redshift Clusters', cluster,\n{Check Name} = 'Amazon EBS Public Snapshots', {volume id},\n{Check Name} = 'Amazon RDS Public Snapshots', {db instance or cluster id},\n{Check Name} = 'AWS Lambda Functions with High Error Rates', {function arn},\n{Check Name} = 'AWS Lambda Functions Using Deprecated Runtimes', {function arn},\ncheckid = 'Wxdfp4B1L1' OR checkid = 'Wxdfp4B1L2' OR checkid = 'Wxdfp4B1L3' OR checkid = 'Wxdfp4B1L4',{workload arn},\n{Resource Id}\n)"
+                            }
+                        ]
+                    }
+                },
+                {
+                    "CreateColumnsOperation": {
+                        "Columns": [
+                            {
+                                "ColumnId": "a22e1199-f893-48d1-9066-e37c4c7d0f94",
+                                "ColumnName": "Datetime",
+                                "Expression": "epochDate(parseInt(timestamp))"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "b2d7393f-c258-45ce-aa35-e93bdd879652",
                                 "ColumnName": "First Check for Resource",
-                                "Expression": "minOver(Datetime, [{Resource\u00a0Name}],PRE_AGG)"
+                                "Expression": "minOver(Datetime, [{Resource Name}],PRE_AGG)"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "da58a4e8-1246-46a2-b1f2-416d33eb1d51",
                                 "ColumnName": "Last Check for Resource",
-                                "Expression": "ifelse(\ncategory = 'Cost Optimizing',\nmaxOver(Datetime, [{Resource\u00a0Name},{instance type}],PRE_AGG),\n{Check Name} = 'Amazon EBS Snapshots',\nmaxOver(Datetime, [{volume id},{Account},{snapshot age},{volume attachment}],PRE_AGG),\n{Check Name} = 'Amazon EC2 Availability Zone Balance',\nmaxOver(Datetime, [{Account},{region}, {instances in zone a},{instances in zone b},{instances in zone c},{instances in zone d},{instances in zone e},{instances in zone f}],PRE_AGG),\n\nmaxOver(Datetime, [{Resource\u00a0Name}],PRE_AGG)\n)\n"
+                                "Expression": "ifelse(\ncategory = 'Cost Optimizing',\nmaxOver(Datetime, [{Resource Id},{instance type}],PRE_AGG),\n{Check Name} = 'Amazon EBS Snapshots',\nmaxOver(Datetime, [{volume id},{Account},{snapshot age},{volume attachment}],PRE_AGG),\n{Check Name} = 'Amazon EC2 Availability Zone Balance',\nmaxOver(Datetime, [{Account},{region}, {instances in zone a},{instances in zone b},{instances in zone c},{instances in zone d},{instances in zone e},{instances in zone f}],PRE_AGG),\n\nmaxOver(Datetime, [{Resource Id}],PRE_AGG)\n)\n"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
@@ -114,15 +125,15 @@
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "f3f28fd1-5b05-48d4-8b73-54f7981213e4",
                                 "ColumnName": "Resource in Last Check",
-                                "Expression": "ifelse(dateDiff({Last Check for Resource},{Last Check for Account and CheckId}) >= 7, 'no', 'yes')"
+                                "Expression": "ifelse(dateDiff({Last Check for Resource},{Last Check for Account and CheckId}) >= 8, 'no', 'yes')"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
@@ -158,92 +169,92 @@
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "e351a4a5-1a61-4ee5-9927-69040296e120",
                                 "ColumnName": "Deprecation Date",
-                                "Expression": "maxOver(parseDate({deprecation date},'MM/dd/yyyy'),[{Resource\u00a0Name}],PRE_AGG)"
+                                "Expression": "maxOver(parseDate({deprecation date},'MM/dd/yyyy'),[{Resource Name}],PRE_AGG)"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "0108dd54-9ae3-447d-97d8-788894e6a8ae",
                                 "ColumnName": "Average Daily Invokes",
-                                "Expression": "maxOver(parseDecimal({average daily invokes}),[{Resource\u00a0Name}],PRE_AGG)"
+                                "Expression": "maxOver(parseDecimal({average daily invokes}),[{Resource Name}],PRE_AGG)"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "b9a05d2d-5997-4677-9ad4-73f1f0534210",
                                 "ColumnName": "Number of Days Low Utilization",
-                                "Expression": "maxOver(parseInt(replace({number of days low utilization}, ' days','')), [{Resource\u00a0Name}],PRE_AGG)"
+                                "Expression": "maxOver(parseInt(replace({number of days low utilization}, ' days','')), [{Resource Id}],PRE_AGG)"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "d04502b9-c9df-4ef0-a78d-a11771b5967f",
                                 "ColumnName": "14-Day Average CPU Utilization",
-                                "Expression": "maxOver(parseDecimal(replace({14-day average cpu utilization}, '%','')), [{Resource\u00a0Name}],PRE_AGG)"
+                                "Expression": "maxOver(parseDecimal(replace({14-day average cpu utilization}, '%','')), [{Resource Id}],PRE_AGG)"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "c059301f-0228-44be-b827-4337615995ac",
                                 "ColumnName": "14-Day Average Network I/O",
-                                "Expression": "maxOver(parseDecimal(replace({14-day average network i/o}, 'MB','')), [{Resource\u00a0Name}],PRE_AGG)"
+                                "Expression": "maxOver(parseDecimal(replace({14-day average network i/o}, 'MB','')), [{Resource Id}],PRE_AGG)"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "b6ea96d4-6a88-49ac-b24d-b12942c72fd4",
                                 "ColumnName": "Max Daily Error Rate",
-                                "Expression": "maxOver(parseDecimal({max daily error rate}),[{Resource\u00a0Name}],PRE_AGG)"
+                                "Expression": "maxOver(parseDecimal({max daily error rate}),[{Resource Id}],PRE_AGG)"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "ae799e1f-17d8-44dd-9374-f538a041200b",
                                 "ColumnName": "Date for Max Error Rate",
-                                "Expression": "maxOver(parseDate({date for max error rate},'MM/dd/yyyy'),[{Resource\u00a0Name}],PRE_AGG)\n"
+                                "Expression": "maxOver(parseDate({date for max error rate},'MM/dd/yyyy'),[{Resource Id}],PRE_AGG)\n"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
                             {
                                 "ColumnId": "e22c306a-1ef8-472e-9c98-0b487cf917c2",
                                 "ColumnName": "Average Daily Error Rate",
-                                "Expression": "maxOver(parseDecimal({average daily error rate}),[{Resource\u00a0Name}],PRE_AGG)\n"
+                                "Expression": "maxOver(parseDecimal({average daily error rate}),[{Resource Id}],PRE_AGG)\n"
                             }
                         ]
                     }
                 },
                 {
                     "CreateColumnsOperation": {
                         "Columns": [
@@ -373,14 +384,36 @@
                                 "ColumnName": "One Check Selected",
                                 "Expression": "distinctCountOver(checkid, [], PRE_AGG) = 1"
                             }
                         ]
                     }
                 },
                 {
+                    "CreateColumnsOperation": {
+                        "Columns": [
+                            {
+                                "ColumnId": "5334421f-d73e-4b5f-bdab-b7553553cc25",
+                                "ColumnName": "Estimated Monthly Savings",
+                                "Expression": "ifelse( maxOver(Datetime, [{Resource Id}] , PRE_AGG) = Datetime, {Estimated Monthly Savings Numeric}, null)\n"
+                            }
+                        ]
+                    }
+                },
+                {
+                    "CreateColumnsOperation": {
+                        "Columns": [
+                            {
+                                "ColumnId": "2f67fc2d-9c64-4f14-9d28-f962cad070d8",
+                                "ColumnName": "Estimated Monthly Savings Trend",
+                                "Expression": "ifelse( maxOver(Datetime, [resourceid,extract('MM', Datetime),extract('YYYY', Datetime)] , PRE_AGG) = Datetime, {Estimated Monthly Savings Numeric}, null)"
+                            }
+                        ]
+                    }
+                },
+                {
                     "ProjectOperation": {
                         "ProjectedColumns": [
                             "ip address",
                             "checkname",
                             "accountparentname",
                             "accountid",
                             "category",
@@ -616,15 +649,15 @@
                             "number of identified hris for security",
                             "number of hris resolved for cost optimization",
                             "total number of questions in cost optimization pillar",
                             "number of questions answered for cost optimization",
                             "number of identified hris for cost optimization",
                             "cluster name",
                             "Check Name",
-                            "Resource\u00a0Name",
+                            "Resource Name",
                             "Datetime",
                             "First Check for Resource",
                             "Last Check for Resource",
                             "Account",
                             "Last Check for Account and CheckId",
                             "Resource in Last Check",
                             "Estimated Monthly Savings Numeric",
@@ -645,15 +678,18 @@
                             "Instance Count",
                             "S3 Storage (gb)",
                             "Data Transfer Out (GB)",
                             "Ratio of Transfer to Storage",
                             "Max Daily Median",
                             "Number of Days Over",
                             "DateTime is Last Check for Resource",
-                            "One Check Selected"
+                            "One Check Selected",
+                            "Resource Id",
+                            "Estimated Monthly Savings",
+                            "Estimated Monthly Savings Trend"
                         ]
                     }
                 }
             ],
             "Source": {
                 "PhysicalTableId": "b5de237f-b599-407f-87ec-32024624ba65"
             }
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/trends/daily_anomaly_detection.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/trends/daily_anomaly_detection.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/trends/monthly_anomaly_detection.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/trends/monthly_anomaly_detection.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/datasets/trends/monthly_bill_by_account.json` & `cid_cmd-0.3.0/cid/builtin/core/data/datasets/trends/monthly_bill_by_account.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/compute_savings_plan_eligible_spend.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/compute_savings_plan_eligible_spend.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ec2_running_cost.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ec2_running_cost.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ec2_running_cost_ri.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ec2_running_cost_ri.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ec2_running_cost_sp.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ec2_running_cost_sp.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ec2_running_cost_sp_ri.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ec2_running_cost_sp_ri.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ri_sp_mapping.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ri_sp_mapping.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ri_sp_mapping_ri.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ri_sp_mapping_ri.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ri_sp_mapping_sp.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ri_sp_mapping_sp.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/ri_sp_mapping_sp_ri.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/ri_sp_mapping_sp_ri.sql`

 * *Files 21% similar despite different names*

```diff
@@ -1,47 +1,35 @@
- CREATE OR REPLACE VIEW "ri_sp_mapping" AS 
- SELECT DISTINCT
-   "a"."billing_period_mapping"
- , "a"."payer_account_id_mapping"
- , "a"."ri_sp_arn_mapping"
- , "a"."ri_sp_end_date"
- , "b"."ri_sp_term"
- , "b"."ri_sp_offering"
- , "b"."ri_sp_payment"
-	
- FROM
-   ((
-    SELECT DISTINCT
-  "bill_billing_period_start_date" "billing_period_mapping"
- , "bill_payer_account_id" "payer_account_id_mapping"
- , CASE 
-     WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n" 
-     WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n"ELSE '' END "ri_sp_arn_mapping"
- , CASE 
-     WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN CAST(CAST(from_iso8601_timestamp("savings_plan_end_time") AS date) AS timestamp)
-     WHEN ("reservation_reservation_a_r_n" <> '' AND "reservation_end_time" <> '') THEN CAST(CAST(from_iso8601_timestamp("reservation_end_time") AS date) AS timestamp) ELSE NULL END "ri_sp_end_date"
-    FROM
-      "${cur_table_name}"
-    WHERE (("line_item_line_item_type" = 'RIFee') OR ("line_item_line_item_type" = 'SavingsPlanRecurringFee'))
-	
- )  a
- LEFT JOIN (
-    SELECT DISTINCT
-  "bill_billing_period_start_date" "billing_period_mapping"
- , "bill_payer_account_id" "payer_account_id_mapping"
- , CASE 
-     WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n" 
-     WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n"ELSE '' END "ri_sp_arn_mapping"
- , CASE 
-     WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_purchase_term" 
- WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_lease_contract_length"ELSE '' END "ri_sp_term"
- , CASE 
-     WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_offering_type" 
-     WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_offering_class" ELSE '' END "ri_sp_offering"
- , CASE 
-     WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_payment_option" 
-     WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_purchase_option"	ELSE '' END "ri_sp_Payment"
-    FROM
-      "${cur_table_name}"
-    WHERE (("line_item_line_item_type" = 'DiscountedUsage') OR ("line_item_line_item_type" = 'SavingsPlanCoveredUsage'))
-	
- )  b ON (("a"."ri_sp_arn_mapping" = "b"."ri_sp_arn_mapping") AND ("a"."billing_period_mapping" = "b"."billing_period_mapping") AND ("a"."payer_account_id_mapping" = "b"."payer_account_id_mapping")))
+CREATE OR REPLACE VIEW "ri_sp_mapping" AS 
+SELECT DISTINCT
+  "a"."billing_period_mapping"
+, "a"."payer_account_id_mapping"
+, "a"."ri_sp_arn_mapping"
+, "a"."ri_sp_end_date"
+, COALESCE("b"."ri_sp_term", "a"."ri_sp_term") "ri_sp_term"
+, COALESCE("b"."ri_sp_offering", "a"."ri_sp_offering") "ri_sp_offering"
+, COALESCE("b"."ri_sp_payment", "a"."ri_sp_payment") "ri_sp_payment"
+FROM
+  ((
+   SELECT DISTINCT
+     "bill_billing_period_start_date" "billing_period_mapping"
+   , "bill_payer_account_id" "payer_account_id_mapping"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n" WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n" ELSE '' END) "ri_sp_arn_mapping"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN CAST(CAST("from_iso8601_timestamp"("savings_plan_end_time") AS date) AS timestamp) WHEN (("reservation_reservation_a_r_n" <> '') AND ("reservation_end_time" <> '')) THEN CAST(CAST("from_iso8601_timestamp"("reservation_end_time") AS date) AS timestamp) ELSE null END) "ri_sp_end_date"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_purchase_term" WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_lease_contract_length" ELSE '' END) "ri_sp_term"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_offering_type" WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_offering_class" ELSE '' END) "ri_sp_offering"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_payment_option" WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_purchase_option" ELSE '' END) "ri_sp_Payment"
+   FROM
+     "${cur_table_name}"
+   WHERE (("line_item_line_item_type" = 'RIFee') OR ("line_item_line_item_type" = 'SavingsPlanRecurringFee'))
+)  a
+LEFT JOIN (
+   SELECT DISTINCT
+     "bill_billing_period_start_date" "billing_period_mapping"
+   , "bill_payer_account_id" "payer_account_id_mapping"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n" WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n" ELSE '' END) "ri_sp_arn_mapping"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_purchase_term" WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_lease_contract_length" ELSE '' END) "ri_sp_term"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_offering_type" WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_offering_class" ELSE '' END) "ri_sp_offering"
+   , (CASE WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_payment_option" WHEN ("reservation_reservation_a_r_n" <> '') THEN "pricing_purchase_option" ELSE '' END) "ri_sp_Payment"
+   FROM
+     "${cur_table_name}"
+   WHERE (("line_item_line_item_type" = 'DiscountedUsage') OR ("line_item_line_item_type" = 'SavingsPlanCoveredUsage'))
+)  b ON ((("a"."ri_sp_arn_mapping" = "b"."ri_sp_arn_mapping") AND ("a"."billing_period_mapping" = "b"."billing_period_mapping")) AND ("a"."payer_account_id_mapping" = "b"."payer_account_id_mapping")))
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/s3.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/s3.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/summary_view.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/summary_view.sql`

 * *Files 2% similar despite different names*

```diff
@@ -16,18 +16,18 @@
  ELSE 'non_usage' END "charge_category"
  , CASE
  -- WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN 'SavingsPlan'
  -- WHEN ("reservation_reservation_a_r_n" <> '') THEN 'Reserved'
      WHEN ("line_item_usage_type" LIKE '%Spot%') THEN 'Spot'
      ELSE 'OnDemand' END "purchase_option"
  ,CASE
-  WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n"
+ -- WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n"
  -- WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n"
-  WHEN ("line_item_line_item_type" = 'Usage') THEN ''
-  ELSE '' END "ri_sp_arn"
+  WHEN ("line_item_line_item_type" = 'Usage') THEN CAST('' AS varchar)
+  ELSE CAST('' AS varchar) END "ri_sp_arn"
  , "line_item_product_code" "product_code"
  , "product_product_name" "product_name"
  , CASE
      WHEN ("bill_billing_entity" = 'AWS Marketplace' AND "line_item_line_item_type" NOT LIKE '%Discount%') THEN "Product_Product_Name"
      WHEN ("product_servicecode" = '') THEN "line_item_product_code" ELSE "product_servicecode" END "service"
  , "product_product_family" "product_family"
  , "line_item_usage_type" "usage_type"
@@ -48,15 +48,15 @@
  , "product_group" "product_group"
  , "product_from_location" "product_from_location"
  , "product_to_location" "product_to_location"
  , "product_current_generation" "current_generation"
  , "line_item_legal_entity" "legal_entity"
  , "bill_billing_entity" "billing_entity"
  , "pricing_unit" "pricing_unit"
- , "count"(DISTINCT "Line_item_resource_id") "resource_id_count"
+ , "approx_distinct"("Line_item_resource_id") "resource_id_count"
  , sum(CASE
  -- WHEN ("line_item_line_item_type" = 'SavingsPlanCoveredUsage') THEN "line_item_usage_amount"
  -- WHEN ("line_item_line_item_type" = 'DiscountedUsage') THEN "line_item_usage_amount"
  WHEN ("line_item_line_item_type" = 'Usage') THEN "line_item_usage_amount"
  ELSE 0 END) "usage_quantity"
  , sum ("line_item_unblended_cost") "unblended_cost"
  , sum(CASE
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/summary_view_ri.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/summary_view_ri.sql`

 * *Files 1% similar despite different names*

```diff
@@ -16,15 +16,15 @@
  , CASE
  -- WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN 'SavingsPlan'
      WHEN ("reservation_reservation_a_r_n" <> '') THEN 'Reserved'
      WHEN ("line_item_usage_type" LIKE '%Spot%') THEN 'Spot'
      ELSE 'OnDemand' END "purchase_option"
  , CASE
  -- WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n"
-     WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n" ELSE '' END "ri_sp_arn"
+     WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n" ELSE CAST('' AS varchar) END "ri_sp_arn"
  , "line_item_product_code" "product_code"
  , "product_product_name" "product_name"
  , CASE
      WHEN ("bill_billing_entity" = 'AWS Marketplace' AND "line_item_line_item_type" NOT LIKE '%Discount%') THEN "Product_Product_Name"
      WHEN ("product_servicecode" = '') THEN "line_item_product_code" ELSE "product_servicecode" END "service"
  , "product_product_family" "product_family"
  , "line_item_usage_type" "usage_type"
@@ -45,15 +45,15 @@
  , "product_group" "product_group"
  , "product_from_location" "product_from_location"
  , "product_to_location" "product_to_location"
  , "product_current_generation" "current_generation"
  , "line_item_legal_entity" "legal_entity"
  , "bill_billing_entity" "billing_entity"
  , "pricing_unit" "pricing_unit"
- , "count"(DISTINCT "Line_item_resource_id") "resource_id_count"
+ , "approx_distinct"("Line_item_resource_id") "resource_id_count"
  , sum(CASE
  -- WHEN ("line_item_line_item_type" = 'SavingsPlanCoveredUsage') THEN "line_item_usage_amount"
      WHEN ("line_item_line_item_type" = 'DiscountedUsage') THEN "line_item_usage_amount"
      WHEN ("line_item_line_item_type" = 'Usage') THEN "line_item_usage_amount" ELSE 0 END) "usage_quantity"
  , sum ("line_item_unblended_cost") "unblended_cost"
  , sum(CASE
  -- WHEN ("line_item_line_item_type" = 'SavingsPlanCoveredUsage') THEN "savings_plan_savings_plan_effective_cost"
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/summary_view_sp.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/summary_view_sp.sql`

 * *Files 2% similar despite different names*

```diff
@@ -17,15 +17,15 @@
      WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN 'SavingsPlan'
      -- WHEN ("reservation_reservation_a_r_n" <> '') THEN 'Reserved'
      WHEN ("line_item_usage_type" LIKE '%Spot%') THEN 'Spot'
      ELSE 'OnDemand' END "purchase_option"
  , CASE
      WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n"
      -- WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n"
-     ELSE '' END "ri_sp_arn"
+     ELSE CAST('' AS varchar) END "ri_sp_arn"
  , "line_item_product_code" "product_code"
  , "product_product_name" "product_name"
  , CASE
      WHEN ("bill_billing_entity" = 'AWS Marketplace' AND "line_item_line_item_type" NOT LIKE '%Discount%') THEN "Product_Product_Name"
      WHEN ("product_servicecode" = '') THEN "line_item_product_code" ELSE "product_servicecode" END "service"
  , "product_product_family" "product_family"
  , "line_item_usage_type" "usage_type"
@@ -46,15 +46,15 @@
  , "product_group" "product_group"
  , "product_from_location" "product_from_location"
  , "product_to_location" "product_to_location"
  , "product_current_generation" "current_generation"
  , "line_item_legal_entity" "legal_entity"
  , "bill_billing_entity" "billing_entity"
  , "pricing_unit" "pricing_unit"
- , "count"(DISTINCT "Line_item_resource_id") "resource_id_count"
+ , "approx_distinct"("Line_item_resource_id") "resource_id_count"
  , sum(CASE
      WHEN ("line_item_line_item_type" = 'SavingsPlanCoveredUsage') THEN "line_item_usage_amount"
      -- WHEN ("line_item_line_item_type" = 'DiscountedUsage') THEN "line_item_usage_amount"
      WHEN ("line_item_line_item_type" = 'Usage') THEN "line_item_usage_amount" ELSE 0 END) "usage_quantity"
  , sum ("line_item_unblended_cost") "unblended_cost"
  , sum(CASE
      WHEN ("line_item_line_item_type" = 'SavingsPlanCoveredUsage') THEN "savings_plan_savings_plan_effective_cost"
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/cid/summary_view_sp_ri.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/cid/summary_view_sp_ri.sql`

 * *Files 1% similar despite different names*

```diff
@@ -16,15 +16,15 @@
   , CASE
       WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN 'SavingsPlan'
       WHEN ("reservation_reservation_a_r_n" <> '') THEN 'Reserved'
       WHEN ("line_item_usage_type" LIKE '%Spot%') THEN 'Spot'
       ELSE 'OnDemand' END "purchase_option"
   , CASE
       WHEN ("savings_plan_savings_plan_a_r_n" <> '') THEN "savings_plan_savings_plan_a_r_n"
-      WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n" ELSE '' END "ri_sp_arn"
+      WHEN ("reservation_reservation_a_r_n" <> '') THEN "reservation_reservation_a_r_n" ELSE CAST('' AS varchar) END "ri_sp_arn"
   , "line_item_product_code" "product_code"
   , "product_product_name" "product_name"
   , CASE
       WHEN ("bill_billing_entity" = 'AWS Marketplace' AND "line_item_line_item_type" NOT LIKE '%Discount%') THEN "Product_Product_Name"
       WHEN ("product_servicecode" = '') THEN "line_item_product_code" ELSE "product_servicecode" END "service"
   , "product_product_family" "product_family"
   , "line_item_usage_type" "usage_type"
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/co/auto_scale.json` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/co/auto_scale.json`

 * *Files 0% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9999719982078853%*

 * *Differences: {"'TableInput'": "{'StorageDescriptor': {'Columns': {86: {'Name': "*

 * *                 "'effectiverecommendationpreferencesinferredworkloadtypes'}, 87: {'Name': "*

 * *                 "'inferredworkloadtypes'}, 88: {'Name': "*

 * *                 "'recommendationoptions_1_migrationeffort'}, 89: {'Name': "*

 * *                 "'recommendationoptions_2_migrationeffort'}, 90: {'Name': "*

 * *                 "'recommendationoptions_3_migrationeffort'}, 91: {'Name': "*

 * *                 "'effectiverecommendationpreferencescpuvendo [â€¦]*

```diff
@@ -351,39 +351,39 @@
                     "Type": "string"
                 },
                 {
                     "Name": "recommendationoptions_3_estimatedmonthlysavings_value",
                     "Type": "string"
                 },
                 {
-                    "Name": "effectiverecommendationpreferencescpuvendorarchitectures",
+                    "Name": "effectiverecommendationpreferencesinferredworkloadtypes",
                     "Type": "string"
                 },
                 {
-                    "Name": "effectiverecommendationpreferencesenhancedinfrastructuremetrics",
+                    "Name": "inferredworkloadtypes",
                     "Type": "string"
                 },
                 {
-                    "Name": "effectiverecommendationpreferencesinferredworkloadtypes",
+                    "Name": "recommendationoptions_1_migrationeffort",
                     "Type": "string"
                 },
                 {
-                    "Name": "inferredworkloadtypes",
+                    "Name": "recommendationoptions_2_migrationeffort",
                     "Type": "string"
                 },
                 {
-                    "Name": "recommendationoptions_1_migrationeffort",
+                    "Name": "recommendationoptions_3_migrationeffort",
                     "Type": "string"
                 },
                 {
-                    "Name": "recommendationoptions_2_migrationeffort",
+                    "Name": "effectiverecommendationpreferencescpuvendorarchitectures",
                     "Type": "string"
                 },
                 {
-                    "Name": "recommendationoptions_3_migrationeffort",
+                    "Name": "effectiverecommendationpreferencesenhancedinfrastructuremetrics",
                     "Type": "string"
                 }
             ],
             "InputFormat": "org.apache.hadoop.mapred.TextInputFormat",
             "Location": "${s3FolderPath}",
             "NumberOfBuckets": -1,
             "OutputFormat": "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat",
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/co/auto_scale_options.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/co/ec2_instance_options.sql`

 * *Files 17% similar despite different names*

```diff
@@ -1,50 +1,61 @@
-CREATE OR REPLACE VIEW compute_optimizer_auto_scale_options AS
-
-SELECT * FROM (
-
-    SELECT
-
+CREATE OR REPLACE VIEW compute_optimizer_ec2_instance_options AS
+(
+   SELECT
      TRY("date_parse"(lastrefreshtimestamp_utc, '%Y-%m-%d %H:%i:%s')) lastrefreshtimestamp_utc
    , accountid accountid
-   , autoscalinggrouparn arn
-   , TRY("split_part"(autoscalinggrouparn, ':', 4)) region
-   , TRY("split_part"(autoscalinggrouparn, ':', 3)) service
-   , autoscalinggroupname name
-   , 'auto_scale' module
-   , 'auto_scale' recommendationsourcetype
+   , instancearn arn
+   , TRY("split_part"(instancearn, ':', 4)) region
+   , TRY("split_part"(instancearn, ':', 3)) service
+   , instancename name
+   , 'ec2_instance' module
+   , recommendationssources_1_recommendationsourcetype recommendationsourcetype
    , finding finding
-   , cast ('' as varchar) reason
+   , CONCAT(
+        (CASE WHEN (findingreasoncodes_iscpuoverprovisioned =               'true') THEN 'CPU-Over '               ELSE '' END),
+        (CASE WHEN (findingreasoncodes_iscpuunderprovisioned =              'true') THEN 'CPU-Under '              ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isdiskiopsoverprovisioned =          'true') THEN 'DiskIOPS-Over '          ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isdiskiopsunderprovisioned =         'true') THEN 'DiskIOPS-Under '         ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isdiskthroughputoverprovisioned =    'true') THEN 'DiskThroughput-Over '    ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isdiskthroughputunderprovisioned =   'true') THEN 'DiskThroughput-Under '   ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isebsiopsoverprovisioned =           'true') THEN 'EBSIOPS-Over '           ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isebsiopsunderprovisioned =          'true') THEN 'EBSIOPS-Under '          ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isebsthroughputoverprovisioned =     'true') THEN 'EBSThroughput-Over '     ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isebsthroughputunderprovisioned =    'true') THEN 'EBSThroughput-Under '    ELSE '' END),
+        (CASE WHEN (findingreasoncodes_ismemoryoverprovisioned =            'true') THEN 'Memory-Over '            ELSE '' END),
+        (CASE WHEN (findingreasoncodes_ismemoryunderprovisioned =           'true') THEN 'Memory-Under '           ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isnetworkbandwidthoverprovisioned =  'true') THEN 'NetworkBandwidth-Over '  ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isnetworkbandwidthunderprovisioned = 'true') THEN 'NetworkBandwidth-Under ' ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isnetworkppsoverprovisioned =        'true') THEN 'NetworkPPS-Over '        ELSE '' END),
+        (CASE WHEN (findingreasoncodes_isnetworkppsunderprovisioned =       'true') THEN 'NetworkPPS-Under '       ELSE '' END)
+    ) reason
    , lookbackperiodindays lookbackperiodindays
    , currentperformancerisk as currentperformancerisk
    , errorcode errorcode
    , errormessage errormessage
-   , CONCAT(
-        inferredworkloadtypes, ';',
-        effectiverecommendationpreferencesenhancedinfrastructuremetrics
-    ) ressouce_details
+   , CONCAT(effectiverecommendationpreferencesenhancedinfrastructuremetrics, ';',
+         inferredworkloadtypes, ';') ressouce_details
    , CONCAT(
          utilizationmetrics_disk_read_bytes_per_second_maximum, ';',
          utilizationmetrics_disk_read_ops_per_second_maximum, ';',
          utilizationmetrics_disk_write_bytes_per_second_maximum, ';',
          utilizationmetrics_disk_write_ops_per_second_maximum, ';',
          utilizationmetrics_ebs_read_bytes_per_second_maximum, ';',
          utilizationmetrics_ebs_read_ops_per_second_maximum, ';',
          utilizationmetrics_ebs_write_bytes_per_second_maximum, ';',
          utilizationmetrics_ebs_write_ops_per_second_maximum, ';',
          utilizationmetrics_network_in_bytes_per_second_maximum, ';',
          utilizationmetrics_network_out_bytes_per_second_maximum, ';',
          utilizationmetrics_network_packets_in_per_second_maximum, ';',
-         utilizationmetrics_network_packets_out_per_second_maximum, ';'
-     ) utilizationmetrics
+         utilizationmetrics_network_packets_out_per_second_maximum, ';') utilizationmetrics
    , 'Current' option_name
-   , currentconfiguration_instancetype option_from
+    , currentinstancetype option_from
    , '' option_to
    , recommendationoptions_1_estimatedmonthlysavings_currency currency
-   , TRY(CAST(current_ondemandprice AS double) * 730) monthlyprice
+   , TRY((CAST(current_ondemandprice AS double) * 730)) monthlyprice
    , TRY(CAST(current_ondemandprice AS double)) hourlyprice
    , 0E0 estimatedmonthlysavings_value
    , 0E0 estimatedmonthly_ondemand_cost_change
    , GREATEST(
        CASE WHEN((recommendationoptions_1_migrationeffort = ''
                OR recommendationoptions_1_migrationeffort = 'VeryLow' )
               AND recommendationoptions_1_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
@@ -85,75 +96,54 @@
                OR recommendationoptions_3_migrationeffort = 'VeryLow'
                OR recommendationoptions_3_migrationeffort = 'Low'
                OR recommendationoptions_3_migrationeffort = 'Medium'    )
               AND recommendationoptions_3_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double) ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium
 
    , CONCAT(
-         currentperformancerisk, ';',
-         currentconfiguration_instancetype, ';',
-         '', ';',
-         current_memory, ';',
-         current_vcpus, ';',
-         current_network, ';',
-         current_storage, ';',
-         '', ';',
-         utilizationmetrics_cpu_maximum, ';',
-         utilizationmetrics_memory_maximum, ';',
-         currentconfiguration_desiredcapacity, ';'
-
-       ) option_details
-
-    FROM
-        compute_optimizer_auto_scale_lines
-    WHERE
-        autoscalinggrouparn LIKE '%arn:%'
-
+        COALESCE(currentperformancerisk, 'na'), ';',
+        COALESCE(currentinstancetype, 'na'), ';',
+        COALESCE('', 'na'), ';',
+        COALESCE(current_memory, 'na'), ';',
+        COALESCE(current_vcpus, 'na'), ';',
+        COALESCE(current_network, 'na'), ';',
+        COALESCE(current_storage, 'na'), ';',
+        COALESCE('', 'na'), ';',
+        COALESCE(utilizationmetrics_cpu_maximum, 'na'), ';',
+        COALESCE(utilizationmetrics_memory_maximum, 'na'), ';'
+   ) option_details
+   , tags tags
+   FROM
+     compute_optimizer_ec2_instance_lines
+   WHERE (instancearn LIKE '%arn:%')
 UNION SELECT
-
      TRY("date_parse"(lastrefreshtimestamp_utc, '%Y-%m-%d %H:%i:%s')) lastrefreshtimestamp_utc
    , accountid accountid
-   , autoscalinggrouparn arn
-   , TRY("split_part"(autoscalinggrouparn, ':', 4)) region
-   , TRY("split_part"(autoscalinggrouparn, ':', 3)) service
-   , autoscalinggroupname name
-   , 'auto_scale' module
-   , 'auto_scale' recommendationsourcetype
+   , instancearn arn
+   , TRY("split_part"(instancearn, ':', 4)) region
+   , TRY("split_part"(instancearn, ':', 3)) service
+   , instancename name
+   , 'ec2_instance' module
+   , recommendationssources_1_recommendationsourcetype recommendationsourcetype
    , finding finding
    , '' reason
    , lookbackperiodindays lookbackperiodindays
    , currentperformancerisk as currentperformancerisk
    , errorcode errorcode
    , errormessage errormessage
-   , CONCAT(
-        inferredworkloadtypes, ';',
-        effectiverecommendationpreferencesenhancedinfrastructuremetrics
-    ) ressouce_details
-   , CONCAT(
-         utilizationmetrics_disk_read_bytes_per_second_maximum, ';',
-         utilizationmetrics_disk_read_ops_per_second_maximum, ';',
-         utilizationmetrics_disk_write_bytes_per_second_maximum, ';',
-         utilizationmetrics_disk_write_ops_per_second_maximum, ';',
-         utilizationmetrics_ebs_read_bytes_per_second_maximum, ';',
-         utilizationmetrics_ebs_read_ops_per_second_maximum, ';',
-         utilizationmetrics_ebs_write_bytes_per_second_maximum, ';',
-         utilizationmetrics_ebs_write_ops_per_second_maximum, ';',
-         utilizationmetrics_network_in_bytes_per_second_maximum, ';',
-         utilizationmetrics_network_out_bytes_per_second_maximum, ';',
-         utilizationmetrics_network_packets_in_per_second_maximum, ';',
-         utilizationmetrics_network_packets_out_per_second_maximum, ';'
-     ) utilizationmetrics
+   , '' ressouce_details
+   , '' utilizationmetrics
    , 'Option 1' option_name
-   , currentconfiguration_instancetype option_from
-   , recommendationoptions_1_configuration_instancetype option_to
+   , currentinstancetype option_from
+   , recommendationoptions_1_instancetype option_to
    , recommendationoptions_1_estimatedmonthlysavings_currency currency
-   , TRY(CAST(recommendationoptions_1_ondemandprice AS double) * 730) monthlyprice
+   , TRY((CAST(recommendationoptions_1_ondemandprice AS double) * 730)) monthlyprice
    , TRY(CAST(recommendationoptions_1_ondemandprice AS double)) hourlyprice
-   , TRY(CAST(recommendationoptions_1_estimatedmonthlysavings_value as double)) as estimatedmonthlysavings_value
-   , TRY((CAST(current_ondemandprice as double) - CAST(recommendationoptions_1_ondemandprice as double)) * 730) as estimatedmonthly_ondemand_cost_change
+   , TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value AS double) estimatedmonthlysavings_value
+   , TRY(((CAST(current_ondemandprice AS double) - CAST(recommendationoptions_1_ondemandprice AS double)) * 730)) estimatedmonthly_ondemand_cost_change
    , GREATEST(
        CASE WHEN((recommendationoptions_1_migrationeffort = ''
                OR recommendationoptions_1_migrationeffort = 'VeryLow' )
               AND recommendationoptions_1_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
        CASE WHEN((recommendationoptions_2_migrationeffort = ''
                OR recommendationoptions_2_migrationeffort = 'VeryLow' )
               AND recommendationoptions_2_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value as double) ELSE 0E0 END,
@@ -190,76 +180,61 @@
        CASE WHEN((recommendationoptions_3_migrationeffort = ''
                OR recommendationoptions_3_migrationeffort = 'VeryLow'
                OR recommendationoptions_3_migrationeffort = 'Low'
                OR recommendationoptions_3_migrationeffort = 'Medium'    )
               AND recommendationoptions_3_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double) ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium
    , CONCAT(
-         recommendationoptions_1_performancerisk, ';',
-         recommendationoptions_1_configuration_instancetype, ';',
-         recommendationoptions_1_migrationeffort, ';',
-         recommendationoptions_1_memory, ';',
-         recommendationoptions_1_vcpus, ';',
-         recommendationoptions_1_network, ';',
-         recommendationoptions_1_storage, ';',
-         '', ';', --platform diff
-         recommendationoptions_1_projectedutilizationmetrics_cpu_maximum, ';',
-         recommendationoptions_1_projectedutilizationmetrics_memory_maximum, ';',
-         recommendationoptions_1_configuration_desiredcapacity, ';'
-
-       ) option_details
-
-    FROM
-        compute_optimizer_auto_scale_lines
-    WHERE
-        autoscalinggrouparn LIKE '%arn:%'
-
-
+        COALESCE(recommendationoptions_1_performancerisk, 'na'), ';',
+        COALESCE(recommendationoptions_1_instancetype, 'na'), ';',
+        COALESCE(recommendationoptions_1_migrationeffort, 'na'), ';',
+        COALESCE(recommendationoptions_1_memory, 'na'), ';',
+        COALESCE(recommendationoptions_1_vcpus, 'na'), ';',
+        COALESCE(recommendationoptions_1_network, 'na'), ';',
+        COALESCE(recommendationoptions_1_storage, 'na'), ';',
+        CONCAT(
+           (CASE WHEN (COALESCE(recommendationoptions_1_platformdifferences_isarchitecturedifferent, 'na') = 'true') THEN 'Architecture ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_1_platformdifferences_ishypervisordifferent, 'na') = 'true') THEN 'Hypervisor ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_1_platformdifferences_isinstancestoreavailabilitydifferent, 'na') = 'true') THEN 'InstanceStoreAvailability ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_1_platformdifferences_isnetworkinterfacedifferent, 'na') = 'true') THEN 'NetworkInterface ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_1_platformdifferences_isstorageinterfacedifferent, 'na') = 'true') THEN 'StorageInterface ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_1_platformdifferences_isvirtualizationtypedifferent, 'na') = 'true') THEN 'VirtualizationType ' ELSE '' END)
+        ), ';',
+        COALESCE(recommendationoptions_1_projectedutilizationmetrics_cpu_maximum, 'na'), ';',
+        COALESCE(recommendationoptions_1_projectedutilizationmetrics_memory_maximum, 'na'), ';'
+   ) option_details
+   , tags tags
+   FROM
+     compute_optimizer_ec2_instance_lines
+   WHERE (instancearn LIKE '%arn:%')
 UNION SELECT
-
      TRY("date_parse"(lastrefreshtimestamp_utc, '%Y-%m-%d %H:%i:%s')) lastrefreshtimestamp_utc
    , accountid accountid
-   , autoscalinggrouparn arn
-   , TRY("split_part"(autoscalinggrouparn, ':', 4)) region
-   , TRY("split_part"(autoscalinggrouparn, ':', 3)) service
-   , autoscalinggroupname name
-   , 'auto_scale' module
-   , 'auto_scale' recommendationsourcetype
+   , instancearn arn
+   , TRY("split_part"(instancearn, ':', 4)) region
+   , TRY("split_part"(instancearn, ':', 3)) service
+   , instancename name
+   , 'ec2_instance' module
+   , recommendationssources_1_recommendationsourcetype recommendationsourcetype
    , finding finding
    , '' reason
    , lookbackperiodindays lookbackperiodindays
    , currentperformancerisk as currentperformancerisk
    , errorcode errorcode
    , errormessage errormessage
-   , CONCAT(
-        inferredworkloadtypes, ';',
-        effectiverecommendationpreferencesenhancedinfrastructuremetrics
-    ) ressouce_details
-   , CONCAT(
-         utilizationmetrics_disk_read_bytes_per_second_maximum, ';',
-         utilizationmetrics_disk_read_ops_per_second_maximum, ';',
-         utilizationmetrics_disk_write_bytes_per_second_maximum, ';',
-         utilizationmetrics_disk_write_ops_per_second_maximum, ';',
-         utilizationmetrics_ebs_read_bytes_per_second_maximum, ';',
-         utilizationmetrics_ebs_read_ops_per_second_maximum, ';',
-         utilizationmetrics_ebs_write_bytes_per_second_maximum, ';',
-         utilizationmetrics_ebs_write_ops_per_second_maximum, ';',
-         utilizationmetrics_network_in_bytes_per_second_maximum, ';',
-         utilizationmetrics_network_out_bytes_per_second_maximum, ';',
-         utilizationmetrics_network_packets_in_per_second_maximum, ';',
-         utilizationmetrics_network_packets_out_per_second_maximum, ';'
-     ) utilizationmetrics
+   , '' ressouce_details
+   , '' utilizationmetrics
    , 'Option 2' option_name
-   , currentconfiguration_instancetype option_from
-   , recommendationoptions_2_configuration_instancetype option_to
+   , currentinstancetype option_from
+   , recommendationoptions_2_instancetype option_to
    , recommendationoptions_2_estimatedmonthlysavings_currency currency
-   , TRY(CAST(recommendationoptions_2_ondemandprice AS double) * 730) monthlyprice
+   , TRY((CAST(recommendationoptions_2_ondemandprice AS double) * 730)) monthlyprice
    , TRY(CAST(recommendationoptions_2_ondemandprice AS double)) hourlyprice
-   , TRY(CAST(recommendationoptions_2_estimatedmonthlysavings_value as double)) as estimatedmonthlysavings_value
-   , TRY((CAST(current_ondemandprice as double) - CAST(recommendationoptions_2_ondemandprice as double)) * 730) as estimatedmonthly_ondemand_cost_change
+   , TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value AS double) estimatedmonthlysavings_value
+   , TRY(((CAST(current_ondemandprice AS double) - CAST(recommendationoptions_2_ondemandprice AS double)) * 730)) estimatedmonthly_ondemand_cost_change
    , GREATEST(
        CASE WHEN((recommendationoptions_1_migrationeffort = ''
                OR recommendationoptions_1_migrationeffort = 'VeryLow' )
               AND recommendationoptions_1_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
        CASE WHEN((recommendationoptions_2_migrationeffort = ''
                OR recommendationoptions_2_migrationeffort = 'VeryLow' )
               AND recommendationoptions_2_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value as double) ELSE 0E0 END,
@@ -295,79 +270,64 @@
               AND recommendationoptions_2_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value as double) ELSE 0E0 END,
        CASE WHEN((recommendationoptions_3_migrationeffort = ''
                OR recommendationoptions_3_migrationeffort = 'VeryLow'
                OR recommendationoptions_3_migrationeffort = 'Low'
                OR recommendationoptions_3_migrationeffort = 'Medium'    )
               AND recommendationoptions_3_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double) ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium
-
    , CONCAT(
-         recommendationoptions_2_performancerisk, ';',
-         recommendationoptions_2_configuration_instancetype, ';',
-         recommendationoptions_2_migrationeffort, ';',
-         recommendationoptions_2_memory, ';',
-         recommendationoptions_2_vcpus, ';',
-         recommendationoptions_2_network, ';',
-         recommendationoptions_2_storage, ';',
-         '', ';', --platform diff
-         recommendationoptions_2_projectedutilizationmetrics_cpu_maximum, ';',
-         recommendationoptions_2_projectedutilizationmetrics_memory_maximum, ';',
-         recommendationoptions_2_configuration_desiredcapacity, ';'
-
-       ) option_details
-
-    FROM
-        compute_optimizer_auto_scale_lines
-    WHERE
-        autoscalinggrouparn LIKE '%arn:%'
-    AND recommendationoptions_2_estimatedmonthlysavings_currency <> ''
-
+        COALESCE(recommendationoptions_2_performancerisk, 'na'), ';',
+        COALESCE(recommendationoptions_2_instancetype, 'na'), ';',
+        COALESCE(recommendationoptions_2_migrationeffort, 'na'), ';',
+        COALESCE(recommendationoptions_2_memory, 'na'), ';',
+        COALESCE(recommendationoptions_2_vcpus, 'na'), ';',
+        COALESCE(recommendationoptions_2_network, 'na'), ';',
+        COALESCE(recommendationoptions_2_storage, 'na'), ';',
+        CONCAT(
+           (CASE WHEN (COALESCE(recommendationoptions_2_platformdifferences_isarchitecturedifferent, 'na') = 'true') THEN 'Architecture ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_2_platformdifferences_ishypervisordifferent, 'na') = 'true') THEN 'Hypervisor ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_2_platformdifferences_isinstancestoreavailabilitydifferent, 'na') = 'true') THEN 'InstanceStoreAvailability ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_2_platformdifferences_isnetworkinterfacedifferent, 'na') = 'true') THEN 'NetworkInterface ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_2_platformdifferences_isstorageinterfacedifferent, 'na') = 'true') THEN 'StorageInterface ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_2_platformdifferences_isvirtualizationtypedifferent, 'na') = 'true') THEN 'VirtualizationType ' ELSE '' END)
+        ), ';',
+        COALESCE(recommendationoptions_2_projectedutilizationmetrics_cpu_maximum, 'na'), ';',
+        COALESCE(recommendationoptions_2_projectedutilizationmetrics_memory_maximum, 'na'), ';'
+   ) option_details
+   , tags as tags
+   FROM
+     compute_optimizer_ec2_instance_lines
+   WHERE (instancearn LIKE '%arn:%')
+   AND recommendationoptions_2_estimatedmonthlysavings_currency <> ''
 
 UNION SELECT
-
      TRY("date_parse"(lastrefreshtimestamp_utc, '%Y-%m-%d %H:%i:%s')) lastrefreshtimestamp_utc
    , accountid accountid
-   , autoscalinggrouparn arn
-   , TRY("split_part"(autoscalinggrouparn, ':', 4)) region
-   , TRY("split_part"(autoscalinggrouparn, ':', 3)) service
-   , autoscalinggroupname name
-   , 'auto_scale' module
-   , 'auto_scale' recommendationsourcetype
+   , instancearn arn
+   , TRY("split_part"(instancearn, ':', 4)) region
+   , TRY("split_part"(instancearn, ':', 3)) service
+   , instancename name
+   , 'ec2_instance' module
+   , recommendationssources_1_recommendationsourcetype recommendationsourcetype
    , finding finding
    , '' reason
    , lookbackperiodindays lookbackperiodindays
    , currentperformancerisk as currentperformancerisk
    , errorcode errorcode
    , errormessage errormessage
-   , CONCAT(
-        inferredworkloadtypes, ';',
-        effectiverecommendationpreferencesenhancedinfrastructuremetrics
-    ) ressouce_details
-   , CONCAT(
-         utilizationmetrics_disk_read_bytes_per_second_maximum, ';',
-         utilizationmetrics_disk_read_ops_per_second_maximum, ';',
-         utilizationmetrics_disk_write_bytes_per_second_maximum, ';',
-         utilizationmetrics_disk_write_ops_per_second_maximum, ';',
-         utilizationmetrics_ebs_read_bytes_per_second_maximum, ';',
-         utilizationmetrics_ebs_read_ops_per_second_maximum, ';',
-         utilizationmetrics_ebs_write_bytes_per_second_maximum, ';',
-         utilizationmetrics_ebs_write_ops_per_second_maximum, ';',
-         utilizationmetrics_network_in_bytes_per_second_maximum, ';',
-         utilizationmetrics_network_out_bytes_per_second_maximum, ';',
-         utilizationmetrics_network_packets_in_per_second_maximum, ';',
-         utilizationmetrics_network_packets_out_per_second_maximum, ';'
-     ) utilizationmetrics
+   , '' ressouce_details
+   , '' utilizationmetrics
    , 'Option 3' option_name
-   , currentconfiguration_instancetype option_from
-   , recommendationoptions_3_configuration_instancetype option_to
+   , currentinstancetype option_from
+   , recommendationoptions_3_instancetype option_to
    , recommendationoptions_3_estimatedmonthlysavings_currency currency
-   , TRY(CAST(recommendationoptions_3_ondemandprice AS double) * 730) monthlyprice
+   , TRY((CAST(recommendationoptions_3_ondemandprice AS double) * 730)) monthlyprice
    , TRY(CAST(recommendationoptions_3_ondemandprice AS double)) hourlyprice
-   , TRY(CAST(recommendationoptions_3_estimatedmonthlysavings_value as double)) as estimatedmonthlysavings_value
-   , TRY((CAST(current_ondemandprice as double) - CAST(recommendationoptions_3_ondemandprice as double)) * 730) as estimatedmonthly_ondemand_cost_change
+   , TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value AS double) estimatedmonthlysavings_value
+   , TRY(((CAST(current_ondemandprice AS double) - CAST(recommendationoptions_3_ondemandprice AS double)) * 730)) estimatedmonthly_ondemand_cost_change
    , GREATEST(
        CASE WHEN((recommendationoptions_1_migrationeffort = ''
                OR recommendationoptions_1_migrationeffort = 'VeryLow' )
               AND recommendationoptions_1_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
        CASE WHEN((recommendationoptions_2_migrationeffort = ''
                OR recommendationoptions_2_migrationeffort = 'VeryLow' )
               AND recommendationoptions_2_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value as double) ELSE 0E0 END,
@@ -404,27 +364,32 @@
        CASE WHEN((recommendationoptions_3_migrationeffort = ''
                OR recommendationoptions_3_migrationeffort = 'VeryLow'
                OR recommendationoptions_3_migrationeffort = 'Low'
                OR recommendationoptions_3_migrationeffort = 'Medium'    )
               AND recommendationoptions_3_estimatedmonthlysavings_currency != '') THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double) ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium
    , CONCAT(
-         recommendationoptions_3_performancerisk, ';',
-         recommendationoptions_3_configuration_instancetype, ';',
-         recommendationoptions_3_migrationeffort, ';',
-         recommendationoptions_3_memory, ';',
-         recommendationoptions_3_vcpus, ';',
-         recommendationoptions_3_network, ';',
-         recommendationoptions_3_storage, ';',
-         '', ';', --platform diff
-         recommendationoptions_3_projectedutilizationmetrics_cpu_maximum, ';',
-         recommendationoptions_3_projectedutilizationmetrics_memory_maximum, ';',
-         recommendationoptions_3_configuration_desiredcapacity, ';'
-
-       ) option_details
+        COALESCE(recommendationoptions_3_performancerisk, 'na'), ';',
+        COALESCE(recommendationoptions_3_instancetype, 'na'), ';',
+        COALESCE(recommendationoptions_3_migrationeffort, 'na'), ';',
+        COALESCE(recommendationoptions_3_memory, 'na'), ';',
+        COALESCE(recommendationoptions_3_vcpus, 'na'), ';',
+        COALESCE(recommendationoptions_3_network, 'na'), ';',
+        COALESCE(recommendationoptions_3_storage, 'na'), ';',
+        CONCAT(
+           (CASE WHEN (COALESCE(recommendationoptions_3_platformdifferences_isarchitecturedifferent, 'na') = 'true') THEN 'Architecture ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_3_platformdifferences_ishypervisordifferent, 'na') = 'true') THEN 'Hypervisor ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_3_platformdifferences_isinstancestoreavailabilitydifferent, 'na') = 'true') THEN 'InstanceStoreAvailability ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_3_platformdifferences_isnetworkinterfacedifferent, 'na') = 'true') THEN 'NetworkInterface ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_3_platformdifferences_isstorageinterfacedifferent, 'na') = 'true') THEN 'StorageInterface ' ELSE '' END),
+           (CASE WHEN (COALESCE(recommendationoptions_3_platformdifferences_isvirtualizationtypedifferent, 'na') = 'true') THEN 'VirtualizationType ' ELSE '' END)
+        ), ';',
+        COALESCE(recommendationoptions_3_projectedutilizationmetrics_cpu_maximum, 'na'), ';',
+        COALESCE(recommendationoptions_3_projectedutilizationmetrics_memory_maximum, 'na'), ';'
+   ) option_details
+   , tags tags
+   FROM
+     compute_optimizer_ec2_instance_lines
+   WHERE (instancearn LIKE '%arn:%')
+     AND recommendationoptions_3_estimatedmonthlysavings_currency <> ''
 
-    FROM
-        compute_optimizer_auto_scale_lines
-    WHERE
-        autoscalinggrouparn LIKE '%arn:%'
-    AND recommendationoptions_3_estimatedmonthlysavings_currency <> ''
 )
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/co/ebs_volume.json` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/co/ebs_volume.json`

 * *Files 1% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9999458874458874%*

 * *Differences: {"'TableInput'": "{'StorageDescriptor': {'Columns': {insert: [(53, OrderedDict([('Name', "*

 * *                 "'currentConfiguration_rootVolume'), ('Type', 'string')])), (54, "*

 * *                 "OrderedDict([('Name', 'tags'), ('Type', 'string')]))]}}}"}*

```diff
@@ -217,14 +217,22 @@
                 {
                     "Name": "recommendationoptions_3_estimatedmonthlysavings_currency",
                     "Type": "string"
                 },
                 {
                     "Name": "recommendationoptions_3_estimatedmonthlysavings_value",
                     "Type": "string"
+                },
+                {
+                    "Name": "currentConfiguration_rootVolume",
+                    "Type": "string"
+                },
+                {
+                    "Name": "tags",
+                    "Type": "string"
                 }
             ],
             "InputFormat": "org.apache.hadoop.mapred.TextInputFormat",
             "Location": "${s3FolderPath}",
             "NumberOfBuckets": -1,
             "OutputFormat": "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat",
             "Parameters": {},
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/co/ebs_volume_options.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/co/ebs_volume_options.sql`

 * *Files 6% similar despite different names*

```diff
@@ -5,31 +5,31 @@
     volumearn as arn,
     try(split_part(volumearn, ':', 4)) as region,
     try(split_part(volumearn, ':', 3)) as service,
     try(split_part(volumearn, ':', 7)) as name,
     'ebs_volume' as module,
     'ebs_volume' as recommendationsourcetype,
     finding as finding,
-    cast ('' as varchar) as reason,
+    cast (NULL as varchar(1)) as reason,
     lookbackperiodindays as lookbackperiodindays,
     currentperformancerisk as currentperformancerisk,
     errorcode as errorcode,
     errormessage as errormessage,
-    cast ('' as varchar) as ressouce_details,
+    cast (NULL as varchar(1)) as ressouce_details,
 
     CONCAT(
         utilizationmetrics_volumereadopspersecondmaximum, ';',
         utilizationmetrics_volumewriteopspersecondmaximum, ';',
         utilizationmetrics_volumereadbytespersecondmaximum, ';',
         utilizationmetrics_volumewritebytespersecondmaximum, ';'
     ) as utilizationmetrics,
 
     'Current' as option_name,
     currentconfiguration_volumetype as option_from,
-    cast ('' as varchar) as option_to,
+    cast (NULL as varchar(1)) as option_to,
     recommendationoptions_1_estimatedmonthlysavings_currency as currency,
     try_cast(current_monthlyprice as double) as monthlyprice,
     try(cast(current_monthlyprice as double) / 730  ) as hourlyprice,
     0.0 as estimatedmonthlysavings_value,
     0.0 as estimatedmonthly_ondemand_cost_change,
 
     GREATEST(
@@ -63,22 +63,23 @@
              ELSE 0E0 END,
         CASE WHEN recommendationoptions_3_estimatedmonthlysavings_value != '' THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double)
              WHEN recommendationoptions_3_monthlyprice != ''                  THEN  try( cast(current_monthlyprice as double) - cast(recommendationoptions_3_monthlyprice as double) )
              ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium,
 
     CONCAT(
-        currentperformancerisk, ';', --  as performancerisk
-        currentconfiguration_volumetype, ';', --  as volumetype
-        currentconfiguration_volumesize, ';', --  as volumesize
-        currentconfiguration_volumebaselineiops, ';', --  as volumebaselineiops
-        currentconfiguration_volumebaselinethroughput, ';', --  as volumebaselinethroughput
-        currentconfiguration_volumeburstiops, ';', --  as volumeburstiops
-        currentconfiguration_volumeburstthroughput, ';' --  as volumeburstthroughput
-    ) as option_details
+        COALESCE(currentperformancerisk, 'na'), ';',
+        COALESCE(currentconfiguration_volumetype, 'na'), ';',
+        COALESCE(currentconfiguration_volumesize, 'na'), ';',
+        COALESCE(currentconfiguration_volumebaselineiops, 'na'), ';',
+        COALESCE(currentconfiguration_volumebaselinethroughput, 'na'), ';',
+        COALESCE(currentconfiguration_volumeburstiops, 'na'), ';',
+        COALESCE(currentconfiguration_volumeburstthroughput, 'na'), ';'
+    ) as option_details,
+    tags as tags
 
 FROM
     compute_optimizer_ebs_volume_lines
 WHERE
     volumearn LIKE '%arn:%'
 
 UNION SELECT
@@ -87,21 +88,21 @@
     volumearn as arn,
     try(split_part(volumearn, ':', 4)) as region,
     try(split_part(volumearn, ':', 3)) as service,
     try(split_part(volumearn, ':', 7)) as name,
     'ebs_volume' as module,
     'ebs_volume' as recommendationsourcetype,
     finding as finding,
-    cast ('' as varchar) as reason,
+    cast (NULL as varchar(1)) as reason,
     lookbackperiodindays as lookbackperiodindays,
     currentperformancerisk as currentperformancerisk,
     errorcode as errorcode,
     errormessage as errormessage,
-    cast ('' as varchar) as ressouce_details,
-    cast ('' as varchar) as utilizationmetrics,
+    cast (NULL as varchar(1)) as ressouce_details,
+    cast (NULL as varchar(1)) as utilizationmetrics,
 
     'Option 1' as option_name,
     currentconfiguration_volumetype as option_from,
     recommendationoptions_1_configuration_volumetype as option_to,
     recommendationoptions_1_estimatedmonthlysavings_currency as currency,
     try_cast(recommendationoptions_1_monthlyprice as double) as monthlyprice,
     try(cast(recommendationoptions_1_monthlyprice as double) / 730  ) as hourlyprice,
@@ -139,47 +140,49 @@
              ELSE 0E0 END,
         CASE WHEN recommendationoptions_3_estimatedmonthlysavings_value != '' THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double)
              WHEN recommendationoptions_3_monthlyprice != ''                  THEN  try( cast(current_monthlyprice as double) - cast(recommendationoptions_3_monthlyprice as double) )
              ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium,
 
     CONCAT(
-        recommendationoptions_1_performancerisk, ';', -- as performancerisk,
-        recommendationoptions_1_configuration_volumetype, ';', -- as volumetype,
-        recommendationoptions_1_configuration_volumesize, ';', -- as volumesize,
-        recommendationoptions_1_configuration_volumebaselineiops, ';', -- as volumebaselineiops,
-        recommendationoptions_1_configuration_volumebaselinethroughput, ';', -- as volumebaselinethroughput,
-        recommendationoptions_1_configuration_volumeburstiops, ';', -- as volumeburstiops,
-        recommendationoptions_1_configuration_volumeburstthroughput, ';' -- as volumeburstthroughput,
-    ) as option_details
+        COALESCE(recommendationoptions_1_performancerisk, 'na'), ';',
+        COALESCE(recommendationoptions_1_configuration_volumetype, 'na'), ';',
+        COALESCE(recommendationoptions_1_configuration_volumesize, 'na'), ';',
+        COALESCE(recommendationoptions_1_configuration_volumebaselineiops, 'na'), ';',
+        COALESCE(recommendationoptions_1_configuration_volumebaselinethroughput, 'na'), ';',
+        COALESCE(recommendationoptions_1_configuration_volumeburstiops, 'na'), ';',
+        COALESCE(recommendationoptions_1_configuration_volumeburstthroughput, 'na'), ';'
+    ) as option_details,
+
+    tags as tags
 
 FROM
     compute_optimizer_ebs_volume_lines
 WHERE
     volumearn LIKE '%arn:%'
-  AND recommendationoptions_1_estimatedmonthlysavings_currency <> ''
+  AND recommendationoptions_1_configuration_volumetype <> ''
 
 
 UNION SELECT
     TRY(date_parse(lastrefreshtimestamp_utc,'%Y-%m-%d %H:%i:%s')) as lastrefreshtimestamp_utc,
     accountid as accountid,
     volumearn as arn,
     try(split_part(volumearn, ':', 4)) as region,
     try(split_part(volumearn, ':', 3)) as service,
     try(split_part(volumearn, ':', 7)) as name,
     'ebs_volume' as module,
     'ebs_volume' as recommendationsourcetype,
     finding as finding,
-    cast ('' as varchar) as reason,
+    cast (NULL as varchar(1)) as reason,
     lookbackperiodindays as lookbackperiodindays,
     currentperformancerisk as currentperformancerisk,
     errorcode as errorcode,
     errormessage as errormessage,
-    cast ('' as varchar) as ressouce_details,
-    cast ('' as varchar) as utilizationmetrics,
+    cast (NULL as varchar(1)) as ressouce_details,
+    cast (NULL as varchar(1)) as utilizationmetrics,
 
     'Option 2' as option_name,
     currentconfiguration_volumetype as option_from,
     recommendationoptions_2_configuration_volumetype as option_to,
     recommendationoptions_2_estimatedmonthlysavings_currency as currency,
     try_cast(recommendationoptions_2_monthlyprice as double) as monthlyprice,
     try(cast(recommendationoptions_2_monthlyprice as double) / 730  ) as hourlyprice,
@@ -218,46 +221,48 @@
         CASE WHEN recommendationoptions_3_estimatedmonthlysavings_value != '' THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double)
              WHEN recommendationoptions_3_monthlyprice != ''                  THEN  try( cast(current_monthlyprice as double) - cast(recommendationoptions_3_monthlyprice as double) )
              ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium,
 
 
     CONCAT(
-        recommendationoptions_2_performancerisk, ';', -- as performancerisk,
-        recommendationoptions_2_configuration_volumetype, ';', -- as volumetype,
-        recommendationoptions_2_configuration_volumesize, ';', -- as volumesize,
-        recommendationoptions_2_configuration_volumebaselineiops, ';', -- as volumebaselineiops,
-        recommendationoptions_2_configuration_volumebaselinethroughput, ';', -- as volumebaselinethroughput,
-        recommendationoptions_2_configuration_volumeburstiops, ';', -- as volumeburstiops,
-        recommendationoptions_2_configuration_volumeburstthroughput, ';' -- as volumeburstthroughput,
-    ) as option_details
+        COALESCE(recommendationoptions_2_performancerisk, 'na'), ';',
+        COALESCE(recommendationoptions_2_configuration_volumetype, 'na'), ';',
+        COALESCE(recommendationoptions_2_configuration_volumesize, 'na'), ';',
+        COALESCE(recommendationoptions_2_configuration_volumebaselineiops, 'na'), ';',
+        COALESCE(recommendationoptions_2_configuration_volumebaselinethroughput, 'na'), ';',
+        COALESCE(recommendationoptions_2_configuration_volumeburstiops, 'na'), ';',
+        COALESCE(recommendationoptions_2_configuration_volumeburstthroughput, 'na'), ';'
+    ) as option_details,
+
+    tags as tags
 
 FROM
     compute_optimizer_ebs_volume_lines
 WHERE
     volumearn LIKE '%arn:%'
-  AND recommendationoptions_2_estimatedmonthlysavings_currency <> ''
+  AND recommendationoptions_2_configuration_volumetype <> ''
 
   UNION SELECT
     TRY(date_parse(lastrefreshtimestamp_utc,'%Y-%m-%d %H:%i:%s')) as lastrefreshtimestamp_utc,
     accountid as accountid,
     volumearn as arn,
     try(split_part(volumearn, ':', 4)) as region,
     try(split_part(volumearn, ':', 3)) as service,
     try(split_part(volumearn, ':', 7)) as name,
     'ebs_volume' as module,
     'ebs_volume' as recommendationsourcetype,
     finding as finding,
-    cast ('' as varchar) as reason,
+    cast (NULL as varchar(1)) as reason,
     lookbackperiodindays as lookbackperiodindays,
     currentperformancerisk as currentperformancerisk,
     errorcode as errorcode,
     errormessage as errormessage,
-    cast ('' as varchar) as ressouce_details,
-    cast ('' as varchar) as utilizationmetrics,
+    cast (NULL as varchar(1)) as ressouce_details,
+    cast (NULL as varchar(1)) as utilizationmetrics,
 
 
     'Option 3' as option_name,
     currentconfiguration_volumetype as option_from,
     recommendationoptions_3_configuration_volumetype as option_to,
     recommendationoptions_3_estimatedmonthlysavings_currency as currency,
     try_cast(recommendationoptions_3_monthlyprice as double) as monthlyprice,
@@ -296,22 +301,24 @@
              ELSE 0E0 END,
         CASE WHEN recommendationoptions_3_estimatedmonthlysavings_value != '' THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double)
              WHEN recommendationoptions_3_monthlyprice != ''                  THEN  try( cast(current_monthlyprice as double) - cast(recommendationoptions_3_monthlyprice as double) )
              ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium,
 
     CONCAT(
-        recommendationoptions_3_performancerisk, ';', -- as performancerisk,
-        recommendationoptions_3_configuration_volumetype, ';', -- as volumetype,
-        recommendationoptions_3_configuration_volumesize, ';', -- as volumesize,
-        recommendationoptions_3_configuration_volumebaselineiops, ';', -- as volumebaselineiops,
-        recommendationoptions_3_configuration_volumebaselinethroughput, ';', -- as volumebaselinethroughput,
-        recommendationoptions_3_configuration_volumeburstiops, ';', -- as volumeburstiops,
-        recommendationoptions_3_configuration_volumeburstthroughput, ';' -- as volumeburstthroughput,
-    ) as option_details
+        COALESCE(recommendationoptions_3_performancerisk, 'na'), ';',
+        COALESCE(recommendationoptions_3_configuration_volumetype, 'na'), ';',
+        COALESCE(recommendationoptions_3_configuration_volumesize, 'na'), ';',
+        COALESCE(recommendationoptions_3_configuration_volumebaselineiops, 'na'), ';',
+        COALESCE(recommendationoptions_3_configuration_volumebaselinethroughput, 'na'), ';',
+        COALESCE(recommendationoptions_3_configuration_volumeburstiops, 'na'), ';',
+        COALESCE(recommendationoptions_3_configuration_volumeburstthroughput, 'na'), ';'
+    ) as option_details,
+
+    tags as tags
 
 FROM
     compute_optimizer_ebs_volume_lines
 WHERE
     volumearn LIKE '%arn:%'
-  AND recommendationoptions_3_estimatedmonthlysavings_currency <> ''
-)
+  AND recommendationoptions_3_configuration_volumetype <> ''
+)
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/co/ec2_instance.json` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/co/ec2_instance.json`

 * *Files 0% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9999293154761905%*

 * *Differences: {"'TableInput'": "{'StorageDescriptor': {'Columns': {113: {'Name': "*

 * *                 "'recommendationoptions_2_migrationeffort'}, 114: {'Name': "*

 * *                 "'recommendationoptions_3_migrationeffort'}, 115: {'Name': "*

 * *                 "'effectiverecommendationpreferencescpuvendorarchitectures'}, 116: {'Name': "*

 * *                 "'effectiverecommendationpreferencesenhancedinfrastructuremetrics'}, 117: "*

 * *                 "{'Name': 'effectiverecommendationpreferencesexternalmetricssource'}, 118: "*

 * *      [â€¦]*

```diff
@@ -446,39 +446,51 @@
                     "Type": "string"
                 },
                 {
                     "Name": "recommendationoptions_3_estimatedmonthlysavings_value",
                     "Type": "string"
                 },
                 {
-                    "Name": "effectiverecommendationpreferencescpuvendorarchitectures",
+                    "Name": "effectiverecommendationpreferencesinferredworkloadtypes",
                     "Type": "string"
                 },
                 {
-                    "Name": "effectiverecommendationpreferencesenhancedinfrastructuremetrics",
+                    "Name": "inferredworkloadtypes",
                     "Type": "string"
                 },
                 {
-                    "Name": "effectiverecommendationpreferencesinferredworkloadtypes",
+                    "Name": "recommendationoptions_1_migrationeffort",
                     "Type": "string"
                 },
                 {
-                    "Name": "inferredworkloadtypes",
+                    "Name": "recommendationoptions_2_migrationeffort",
                     "Type": "string"
                 },
                 {
-                    "Name": "recommendationoptions_1_migrationeffort",
+                    "Name": "recommendationoptions_3_migrationeffort",
                     "Type": "string"
                 },
                 {
-                    "Name": "recommendationoptions_2_migrationeffort",
+                    "Name": "effectiverecommendationpreferencescpuvendorarchitectures",
                     "Type": "string"
                 },
                 {
-                    "Name": "recommendationoptions_3_migrationeffort",
+                    "Name": "effectiverecommendationpreferencesenhancedinfrastructuremetrics",
+                    "Type": "string"
+                },
+                {
+                    "Name": "effectiverecommendationpreferencesexternalmetricssource",
+                    "Type": "string"
+                },
+                {
+                    "Name": "instancestate",
+                    "Type": "string"
+                },
+                {
+                    "Name": "tags",
                     "Type": "string"
                 }
             ],
             "InputFormat": "org.apache.hadoop.mapred.TextInputFormat",
             "Location": "${s3FolderPath}",
             "NumberOfBuckets": -1,
             "OutputFormat": "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat",
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/co/lambda.json` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/co/lambda.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/co/lambda_options.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/co/lambda_options.sql`

 * *Files 8% similar despite different names*

```diff
@@ -14,30 +14,30 @@
         (CASE WHEN (findingreasoncodes_ismemoryoverprovisioned =  'true') THEN 'Memory-Over '      ELSE '' END),
         (CASE WHEN (findingreasoncodes_ismemoryunderprovisioned = 'true') THEN 'Memory-Under '     ELSE '' END),
         (CASE WHEN (findingreasoncodes_isinsufficientdata =       'true') THEN 'InsufficientData ' ELSE '' END),
         (CASE WHEN (findingreasoncodes_isinconclusive =           'true') THEN 'Inconclusive '     ELSE '' END)
     ) reason
    , lookbackperiodindays lookbackperiodindays
    , currentperformancerisk as currentperformancerisk
-   , cast(NULL as varchar) errorcode
-   , cast(NULL as varchar) errormessage
+   , cast(NULL as varchar(1)) errorcode
+   , cast(NULL as varchar(1)) errormessage
    , CONCAT(
          numberofinvocations , ';',
          current_costtotal , ';',
          currentconfiguration_timeout, ';',
          functionversion, ';') ressouce_details
    , CONCAT(
          utilizationmetrics_durationaverage, ';',
          utilizationmetrics_durationmaximum, ';',
          utilizationmetrics_memoryaverage, ';',
          utilizationmetrics_memorymaximum, ';'
     ) utilizationmetrics
    , 'Current' option_name
-    , cast(NULL as varchar) option_from
-   , cast(NULL as varchar) option_to
+   , cast(NULL as varchar(1)) option_from
+   , cast(NULL as varchar(1)) option_to
    , recommendationoptions_1_estimatedmonthlysavings_currency currency
    , try_cast(NULL as double) as monthlyprice
    , try_cast(NULL as double) as hourlyprice
    , 0E0 estimatedmonthlysavings_value
    , 0E0 estimatedmonthly_ondemand_cost_change
    , GREATEST(
         CASE WHEN recommendationoptions_1_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
@@ -52,46 +52,48 @@
    , GREATEST(
         CASE WHEN recommendationoptions_1_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
         CASE WHEN recommendationoptions_2_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value as double) ELSE 0E0 END,
         CASE WHEN recommendationoptions_3_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double) ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium
 
    , CONCAT(
-         currentperformancerisk, ';', -- '-'
-         currentconfiguration_memorysize, ';',
-         current_costaverage, ';',
-         current_costaverage, ';',
-         utilizationmetrics_durationaverage, ';',
-         '', ';',
-         utilizationmetrics_durationmaximum, ';'
+          COALESCE(currentperformancerisk, 'na'), ';',
+          COALESCE(currentconfiguration_memorysize, 'na'), ';',
+          COALESCE(current_costaverage, 'na'), ';',
+          COALESCE(current_costaverage, 'na'), ';',
+          COALESCE(utilizationmetrics_durationaverage, 'na'), ';',
+          '', ';',
+          COALESCE(utilizationmetrics_durationmaximum, 'na'), ';'
+      ) option_details
+
+   , cast('' as varchar(1)) as tags
 
-       ) option_details
    FROM
      compute_optimizer_lambda_lines
    WHERE (functionarn LIKE '%arn:%')
 UNION SELECT
      TRY(date_parse(lastrefreshtimestamp_utc, '%Y-%m-%d %H:%i:%s')) lastrefreshtimestamp_utc
    , accountid accountid
    , functionarn arn
    , TRY("split_part"(functionarn, ':', 4)) region
    , TRY("split_part"(functionarn, ':', 3)) service
    , TRY("split_part"(functionarn, ':', 7)) name
    , 'lambda' module
    , 'lambda' recommendationsourcetype
    , finding finding
-   , cast(NULL as varchar) reason
+   , cast(NULL as varchar(1)) reason
    , lookbackperiodindays lookbackperiodindays
    , currentperformancerisk as currentperformancerisk
-   , cast(NULL as varchar) errorcode
-   , cast(NULL as varchar) errormessage
-   , cast(NULL as varchar) ressouce_details
-   , cast(NULL as varchar) utilizationmetrics
+   , cast(NULL as varchar(1)) errorcode
+   , cast(NULL as varchar(1)) errormessage
+   , cast(NULL as varchar(1)) ressouce_details
+   , cast(NULL as varchar(1)) utilizationmetrics
    , 'Option 1' as option_name
-   , cast(NULL as varchar) option_from
-   , cast(NULL as varchar) option_to
+   , cast(NULL as varchar(1)) option_from
+   , cast(NULL as varchar(1)) option_to
    , recommendationoptions_1_estimatedmonthlysavings_currency currency
    , cast(NULL as double) monthlyprice
    , cast(NULL as double) hourlyprice
    , try_cast(recommendationoptions_1_estimatedmonthlysavings_value as double) as estimatedmonthlysavings_value
    , try_cast(recommendationoptions_1_estimatedmonthlysavings_value as double) as estimatedmonthly_ondemand_cost_change
    , GREATEST(
         CASE WHEN recommendationoptions_1_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
@@ -105,23 +107,23 @@
     ) as max_estimatedmonthlysavings_value_low
    , GREATEST(
         CASE WHEN recommendationoptions_1_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
         CASE WHEN recommendationoptions_2_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value as double) ELSE 0E0 END,
         CASE WHEN recommendationoptions_3_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double) ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium
    , CONCAT(
-         '', ';',  --no performance risk
-         recommendationoptions_1_configuration_memorysize, ';',
-         recommendationoptions_1_costlow, ';',
-         recommendationoptions_1_costhigh, ';',
-         recommendationoptions_1_projectedutilizationmetrics_durationexpected,
-         recommendationoptions_1_projectedutilizationmetrics_durationlowerbound, ';',
-         recommendationoptions_1_projectedutilizationmetrics_durationupperbound, ';'
-    ) option_details
-
+          '', ';',  --no performance risk
+          COALESCE(recommendationoptions_1_configuration_memorysize, 'na'), ';',
+          COALESCE(recommendationoptions_1_costlow, 'na'), ';',
+          COALESCE(recommendationoptions_1_costhigh, 'na'), ';',
+          COALESCE(recommendationoptions_1_projectedutilizationmetrics_durationexpected, 'na'), ';',
+          COALESCE(recommendationoptions_1_projectedutilizationmetrics_durationlowerbound, 'na'), ';',
+          COALESCE(recommendationoptions_1_projectedutilizationmetrics_durationupperbound, 'na'), ';'
+      ) option_details
+   , cast('' as varchar(1)) as tags
 
     FROM
         compute_optimizer_lambda_lines
     WHERE
         functionarn LIKE '%arn:%'
 
 UNION SELECT
@@ -130,24 +132,24 @@
    , functionarn arn
    , TRY("split_part"(functionarn, ':', 4)) region
    , TRY("split_part"(functionarn, ':', 3)) service
    , TRY("split_part"(functionarn, ':', 7)) name
    , 'lambda' module
    , 'lambda' recommendationsourcetype
    , finding finding
-   , cast(NULL as varchar) reason
+   , cast(NULL as varchar(1)) reason
    , lookbackperiodindays lookbackperiodindays
    , currentperformancerisk as currentperformancerisk
-   , cast(NULL as varchar) errorcode
-   , cast(NULL as varchar) errormessage
-   , cast(NULL as varchar) ressouce_details
-   , cast(NULL as varchar) utilizationmetrics
+   , cast(NULL as varchar(1)) errorcode
+   , cast(NULL as varchar(1)) errormessage
+   , cast(NULL as varchar(1)) ressouce_details
+   , cast(NULL as varchar(1)) utilizationmetrics
    , 'Option 2' as option_name
-   , cast(NULL as varchar) option_from
-   , cast(NULL as varchar) option_to
+   , cast(NULL as varchar(1)) option_from
+   , cast(NULL as varchar(1)) option_to
    , recommendationoptions_2_estimatedmonthlysavings_currency currency
    , cast(NULL as double) monthlyprice
    , cast(NULL as double) hourlyprice
    , try_cast(recommendationoptions_2_estimatedmonthlysavings_value as double) as estimatedmonthlysavings_value
    , try_cast(recommendationoptions_2_estimatedmonthlysavings_value as double) as estimatedmonthly_ondemand_cost_change
    , GREATEST(
         CASE WHEN recommendationoptions_1_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
@@ -161,22 +163,24 @@
     ) as max_estimatedmonthlysavings_value_low
    , GREATEST(
         CASE WHEN recommendationoptions_1_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
         CASE WHEN recommendationoptions_2_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value as double) ELSE 0E0 END,
         CASE WHEN recommendationoptions_3_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double) ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium
    , CONCAT(
-         '', ';',  --no performance risk
-         recommendationoptions_2_configuration_memorysize, ';',
-         recommendationoptions_2_costlow, ';',
-         recommendationoptions_2_costhigh, ';',
-         recommendationoptions_2_projectedutilizationmetrics_durationexpected,
-         recommendationoptions_2_projectedutilizationmetrics_durationlowerbound, ';',
-         recommendationoptions_2_projectedutilizationmetrics_durationupperbound, ';'
-    ) option_details
+          '', ';',  --no performance risk
+          COALESCE(recommendationoptions_2_configuration_memorysize, 'na'), ';',
+          COALESCE(recommendationoptions_2_costlow, 'na'), ';',
+          COALESCE(recommendationoptions_2_costhigh, 'na'), ';',
+          COALESCE(recommendationoptions_2_projectedutilizationmetrics_durationexpected, 'na'), ';',
+          COALESCE(recommendationoptions_2_projectedutilizationmetrics_durationlowerbound, 'na'), ';',
+          COALESCE(recommendationoptions_2_projectedutilizationmetrics_durationupperbound, 'na'), ';'
+      ) option_details
+   , cast('' as varchar(1)) as tags
+
 
 
     FROM
         compute_optimizer_lambda_lines
     WHERE
         functionarn LIKE '%arn:%'
        AND recommendationoptions_2_estimatedmonthlysavings_currency <> ''
@@ -188,24 +192,24 @@
    , functionarn arn
    , TRY("split_part"(functionarn, ':', 4)) region
    , TRY("split_part"(functionarn, ':', 3)) service
    , TRY("split_part"(functionarn, ':', 7)) name
    , 'lambda' module
    , 'lambda' recommendationsourcetype
    , finding finding
-   , cast(NULL as varchar) reason
+   , cast(NULL as varchar(1)) reason
    , lookbackperiodindays lookbackperiodindays
    , currentperformancerisk as currentperformancerisk
-   , cast(NULL as varchar) errorcode
-   , cast(NULL as varchar) errormessage
-   , cast(NULL as varchar) ressouce_details
-   , cast(NULL as varchar) utilizationmetrics
+   , cast(NULL as varchar(1)) errorcode
+   , cast(NULL as varchar(1)) errormessage
+   , cast(NULL as varchar(1)) ressouce_details
+   , cast(NULL as varchar(1)) utilizationmetrics
    , 'Option 3' as option_name
-   , cast(NULL as varchar) option_from
-   , cast(NULL as varchar) option_to
+   , cast(NULL as varchar(1)) option_from
+   , cast(NULL as varchar(1)) option_to
    , recommendationoptions_3_estimatedmonthlysavings_currency currency
    , cast(NULL as double) monthlyprice
    , cast(NULL as double) hourlyprice
    , try_cast(recommendationoptions_3_estimatedmonthlysavings_value as double) as estimatedmonthlysavings_value
    , try_cast(recommendationoptions_3_estimatedmonthlysavings_value as double) as estimatedmonthly_ondemand_cost_change
    , GREATEST(
         CASE WHEN recommendationoptions_1_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
@@ -219,24 +223,24 @@
     ) as max_estimatedmonthlysavings_value_low
    , GREATEST(
         CASE WHEN recommendationoptions_1_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_1_estimatedmonthlysavings_value as double) ELSE 0E0 END,
         CASE WHEN recommendationoptions_2_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_2_estimatedmonthlysavings_value as double) ELSE 0E0 END,
         CASE WHEN recommendationoptions_3_estimatedmonthlysavings_currency != '' THEN TRY_CAST(recommendationoptions_3_estimatedmonthlysavings_value as double) ELSE 0E0 END
     ) as max_estimatedmonthlysavings_value_medium
    , CONCAT(
-         '', ';',  --no performance risk
-         recommendationoptions_3_configuration_memorysize, ';',
-         recommendationoptions_3_costlow, ';',
-         recommendationoptions_3_costhigh, ';',
-         recommendationoptions_3_projectedutilizationmetrics_durationexpected,
-         recommendationoptions_3_projectedutilizationmetrics_durationlowerbound, ';',
-         recommendationoptions_3_projectedutilizationmetrics_durationupperbound, ';'
-    ) option_details
-
+          '', ';',  --no performance risk
+          COALESCE(recommendationoptions_3_configuration_memorysize, 'na'), ';',
+          COALESCE(recommendationoptions_3_costlow, 'na'), ';',
+          COALESCE(recommendationoptions_3_costhigh, 'na'), ';',
+          COALESCE(recommendationoptions_3_projectedutilizationmetrics_durationexpected, 'na'), ';',
+          COALESCE(recommendationoptions_3_projectedutilizationmetrics_durationlowerbound, 'na'), ';',
+          COALESCE(recommendationoptions_3_projectedutilizationmetrics_durationupperbound, 'na'), ';'
+      ) option_details
+   , cast(NULL as varchar(1)) as tags
 
     FROM
         compute_optimizer_lambda_lines
     WHERE
         functionarn LIKE '%arn:%'
        AND recommendationoptions_3_estimatedmonthlysavings_currency <> ''
 
-)
+)
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/first_kpi_instance_mapping_view.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/first_kpi_instance_mapping_view.sql`

 * *Files 12% similar despite different names*

```diff
@@ -1,149 +1,168 @@
 CREATE OR REPLACE VIEW kpi_instance_mapping AS 
 SELECT *
 FROM
   (
  VALUES 
- ROW ('a1', 'AmazonEC2', 'Current', 'Graviton', '', '', '', '')
-, ROW ('c1', 'AmazonEC2', 'Previous', 'Intel', 'c5', 'c5a', 'c6g', '')
-, ROW ('c3', 'AmazonEC2', 'Previous', 'Intel', 'c5', 'c5a', 'c6g', '')
-, ROW ('c4', 'AmazonEC2', 'Previous', 'Intel', 'c5', 'c5a', 'c6g', '')
-, ROW ('c5', 'AmazonEC2', 'Current', 'Intel', '', 'c5a', 'c6g', '')
-, ROW ('c5a', 'AmazonEC2', 'Current', 'AMD', '', '', 'c6g', '')
-, ROW ('c5ad', 'AmazonEC2', 'Current', 'AMD', '', '', 'c6gd', '')
+  ROW ('a1', 'AmazonEC2', 'Current', 'Graviton', '', '', '', '')
+, ROW ('c1', 'AmazonEC2', 'Previous', 'Intel','c6i','c6a','c7g', '')
+, ROW ('c3', 'AmazonEC2', 'Previous', 'Intel','c6i','c6a','c7g', '')
+, ROW ('c4', 'AmazonEC2', 'Previous', 'Intel','c6i','c6a','c7g', '')
+, ROW ('c5', 'AmazonEC2', 'Previous', 'Intel','c6i','c6a','c7g', '')
+, ROW ('c5a', 'AmazonEC2', 'Previous', 'AMD', '','c6a','c7g', '')
+, ROW ('c5ad', 'AmazonEC2', 'Current', 'AMD', '', 'c5ad', 'c6gd', '')
 , ROW ('c5d', 'AmazonEC2', 'Current', 'Intel', '', 'c5ad', 'c6gd', '')
-, ROW ('c5n', 'AmazonEC2', 'Current', 'Intel', '', '', 'c6gn', '')
-, ROW ('c6g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'c5')
+, ROW ('c5n', 'AmazonEC2', 'Current', 'Intel','c6in', '', 'c7gn', '')
+, ROW ('c6a', 'AmazonEC2', 'Current', 'AMD', '','c6a', '', '')
+, ROW ('c6g', 'AmazonEC2', 'Previous', 'Graviton', '', '','c7g', 'c5')
 , ROW ('c6gd', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'c5d')
-, ROW ('c6gn', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'c5n')
-, ROW ('cc2', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('cr1', 'AmazonEC2', 'Current', 'Intel', 'r5', '', '', '')
+, ROW ('c6gn', 'AmazonEC2', 'Previous', 'Graviton', '', '','c7gn', 'c5n')
+, ROW ('c6i', 'AmazonEC2', 'Current', 'Intel', '', 'c6a', 'c6g','c5')
+, ROW ('c6id', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('c6in', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('c7g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'c5')
+, ROW ('cc2', 'AmazonEC2', 'Current', 'Intel', 'c6i', 'c6a', 'c7g', '')
+, ROW ('cr1', 'AmazonEC2', 'Current', 'Intel', 'r6i', 'r6a', 'r7g', '')
 , ROW ('d2', 'AmazonEC2', 'Previous', 'Intel', 'd3', '', '', '')
 , ROW ('d3', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('d3en', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('dl1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('f1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('g2', 'AmazonEC2', 'Previous', 'Intel', 'g3', '', '', '')
-, ROW ('g3', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('g3s', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('g2', 'AmazonEC2', 'Previous', 'Intel','g5', '', '', '')
+, ROW ('g3', 'AmazonEC2', 'Previous', 'Intel','g5', '', '', '')
+, ROW ('g3s', 'AmazonEC2', 'Previous', 'Intel','g5', '', '', '')
 , ROW ('g4ad', 'AmazonEC2', 'Current', 'AMD', '', '', '', '')
 , ROW ('g4dn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('g5', 'AmazonEC2', 'Current', 'Intel', '', '', 'g5g', '')
+, ROW ('g5g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'g5')
 , ROW ('h1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('hs1', 'AmazonEC2', 'Current', 'Intel', 'd3', '', '', '')
 , ROW ('i2', 'AmazonEC2', 'Previous', 'Intel', 'i3', '', '', '')
 , ROW ('i3', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('i3en', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('i3p', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('inf1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('m1', 'AmazonEC2', 'Previous', 'Intel', 'm5', 'm5a', 'm6g', '')
-, ROW ('m2', 'AmazonEC2', 'Previous', 'Intel', 'm5', 'm5a', 'm6g', '')
-, ROW ('m3', 'AmazonEC2', 'Previous', 'Intel', 'm5', 'm5a', 'm6g', '')
-, ROW ('m4', 'AmazonEC2', 'Previous', 'Intel', 'm5', 'm5a', 'm6g', '')
-, ROW ('m5', 'AmazonEC2', 'Current', 'Intel', '', 'm5a', 'm6g', '')
-, ROW ('m5a', 'AmazonEC2', 'Current', 'AMD', '', '', 'm6g', '')
+, ROW ('i4g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', '')
+, ROW ('i4i', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('im4gn', 'AmazonEC2', 'Current', 'Graviton', '', '', '', '')
+, ROW ('inf1', 'AmazonEC2', 'Previous', 'Intel', '', '', '', '')
+, ROW ('inf2', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('is4gen', 'AmazonEC2', 'Current', 'Graviton', '', '', '', '')
+, ROW ('m1', 'AmazonEC2', 'Previous', 'Intel', 'm6i', 'm6a', 'm7g', '')
+, ROW ('m2', 'AmazonEC2', 'Previous', 'Intel', 'm6i', 'm6a', 'm7g', '')
+, ROW ('m3', 'AmazonEC2', 'Previous', 'Intel', 'm6i', 'm6a', 'm7g', '')
+, ROW ('m4', 'AmazonEC2', 'Previous', 'Intel', 'm6i', 'm6a', 'm7g', '')
+, ROW ('m5', 'AmazonEC2', 'Previous', 'Intel', 'm6i', 'm6a', 'm7g', '')
+, ROW ('m5a', 'AmazonEC2', 'Previous', 'AMD', 'm6i', 'm6a', 'm7g', '')
 , ROW ('m5ad', 'AmazonEC2', 'Current', 'AMD', '', '', 'm6gd', '')
-, ROW ('m5d', 'AmazonEC2', 'Current', 'Intel', '', 'm5a', 'm6gd', '')
-, ROW ('m5dn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('m5n', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('m5zn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('m6g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'm5')
+, ROW ('m5d', 'AmazonEC2', 'Previous', 'Intel', 'm6id', 'm6a', 'm6gd', '')
+, ROW ('m5dn', 'AmazonEC2', 'Previous', 'Intel', 'm6idn', '', '', '')
+, ROW ('m5n', 'AmazonEC2', 'Previous', 'Intel', 'm6in', '', '', '')
+, ROW ('m5zn', 'AmazonEC2', 'AmazonEC2', 'Intel', 'm6in', '', '', '')
+, ROW ('m6a', 'AmazonEC2', 'Current', 'AMD', '', '', 'm7g', '')
+, ROW ('m6g', 'AmazonEC2', 'Previous', 'Graviton', '', '','m7g', 'm5')
 , ROW ('m6gd', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'm5d')
-, ROW ('m6i', 'AmazonEC2', 'Current', 'Intel', '', '', 'm6g', '')
-, ROW ('mac1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('m6i', 'AmazonEC2', 'Current', 'Intel', '', '', 'm7g', '')
+, ROW ('m6idn', 'AmazonEC2', 'Current', 'Intel', '', '', 'm6gd', '')
+, ROW ('m6in', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('m7g', 'AmazonEC2', 'Current', 'Graviton', '', '', '','m6')
+, ROW ('mac1', 'AmazonEC2', 'Previous', 'Intel', '', '', '', '')
+, ROW ('mac2', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('p2', 'AmazonEC2', 'Previous', 'Intel', 'p3', '', '', '')
 , ROW ('p3', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('p3dn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('p4d', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('r3', 'AmazonEC2', 'Previous', 'Intel', 'r5', 'r5a', 'r6g', '')
-, ROW ('r4', 'AmazonEC2', 'Previous', 'Intel', 'r5', 'r5a', 'r6g', '')
-, ROW ('r5', 'AmazonEC2', 'Current', 'Intel', '', 'r5a', 'r6g', '')
-, ROW ('r5a', 'AmazonEC2', 'Current', 'AMD', '', '', 'r6g', '')
+, ROW ('r3', 'AmazonEC2', 'Previous', 'Intel', 'r6i', 'r6a', 'r7g', '')
+, ROW ('r4', 'AmazonEC2', 'Previous', 'Intel', 'r6i', 'r6a', 'r7g', '')
+, ROW ('r5', 'AmazonEC2', 'Previous', 'Intel', 'r6i', 'r6a', 'r6g', '')
+, ROW ('r5a', 'AmazonEC2', 'Previous', 'AMD', '', '', 'r7g', '')
 , ROW ('r5ad', 'AmazonEC2', 'Current', 'AMD', '', '', 'r6gd', '')
-, ROW ('r5b', 'AmazonEC2', 'Current', 'Intel', '', '', 'r6g', '')
-, ROW ('r5d', 'AmazonEC2', 'Current', 'Intel', '', 'r5ad', 'r6gd', '')
-, ROW ('r5dn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('r5n', 'AmazonEC2', 'Current', 'Intel', '', 'r5', 'r6g', '')
-, ROW ('r6g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'r5')
+, ROW ('r5b', 'AmazonEC2', 'Previous', 'Intel', '', '', '', '')
+, ROW ('r5d', 'AmazonEC2', 'Previous', 'Intel','r6id', 'r5ad', 'r6gd', '')
+, ROW ('r5dn', 'AmazonEC2', 'Current', 'Intel','r6idn', '', '', '')
+, ROW ('r5n', 'AmazonEC2', 'Previous', 'Intel','r6in', 'r5', 'r6g', '')
+, ROW ('r6a', 'AmazonEC2', 'Current', 'AMD', '', '', 'r7g', '')
+, ROW ('r6g', 'AmazonEC2', 'Previous', 'Graviton', '', '', '', 'r5')
 , ROW ('r6gd', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'r5')
+, ROW ('r6i', 'AmazonEC2', 'Current', 'Intel', '', 'r5a', 'r6g', '')
+, ROW ('r6id', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('r6idn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('r6in', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('r7g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', '')
 , ROW ('t1', 'AmazonEC2', 'Previous', 'Intel', 't3', 't3a', 't4g', '')
 , ROW ('t2', 'AmazonEC2', 'Previous', 'Intel', 't3', 't3a', 't4g', '')
 , ROW ('t3', 'AmazonEC2', 'Current', 'Intel', '', '', 't4g', '')
 , ROW ('t3a', 'AmazonEC2', 'Current', 'AMD', '', '', 't4g', '')
 , ROW ('t4g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 't3')
-, ROW ('x1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('x1e', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('z1d', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('x2gd', 'AmazonEC2', 'Current', 'Graviton', '', '', '', '')
-, ROW ('z1d', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('c6i', 'AmazonEC2', 'Current', 'Intel', '', 'c5a', 'c6g', '')
-, ROW ('dl1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('g5', 'AmazonEC2', 'Current', 'Intel', '', '', 'g5g', '')
-, ROW ('g5g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'g5')
-, ROW ('m6a', 'AmazonEC2', 'Current', 'AMD', '', '', 'm6g', '')
-, ROW ('mac2', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('r6i', 'AmazonEC2', 'Current', 'Intel', '', 'r5a', 'r6g', '')
 , ROW ('u-12tb1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('u-18tb1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('u-24tb1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('u-6tb1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('u-9tb1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('vt1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
-, ROW ('c7g', 'AmazonEC2', 'Current', 'Graviton', '', '', '', 'c5')
+, ROW ('x1', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('x1e', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('x2gd', 'AmazonEC2', 'Current', 'Graviton', '', '', '', '')
+, ROW ('x2idn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('x2iedn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('x2iezn', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
+, ROW ('z1d', 'AmazonEC2', 'Current', 'Intel', '', '', '', '')
 , ROW ('c1', 'AmazonElastiCache', 'Previous', 'Intel', '', '', '', '')
 , ROW ('m1', 'AmazonElastiCache', 'Previous', 'Intel', 'm5', '', 'm6g', '')
 , ROW ('m2', 'AmazonElastiCache', 'Previous', 'Intel', 'm5', '', 'm6g', '')
 , ROW ('m3', 'AmazonElastiCache', 'Previous', 'Intel', 'm5', '', 'm6g', '')
 , ROW ('m4', 'AmazonElastiCache', 'Previous', 'Intel', 'm5', '', 'm6g', '')
 , ROW ('m5', 'AmazonElastiCache', 'Current', 'Intel', '', '', 'm6g', '')
 , ROW ('m6g', 'AmazonElastiCache', 'Current', 'Graviton', '', '', '', 'm5')
 , ROW ('r3', 'AmazonElastiCache', 'Previous', 'Intel', 'r5', '', 'r6g', '')
 , ROW ('r4', 'AmazonElastiCache', 'Previous', 'Intel', 'r5', '', 'r6g', '')
 , ROW ('r5', 'AmazonElastiCache', 'Current', 'Intel', '', '', 'r6g', '')
 , ROW ('r6g', 'AmazonElastiCache', 'Current', 'Graviton', '', '', '', 'r5')
 , ROW ('r6gd', 'AmazonElastiCache', 'Current', 'Graviton', '', '', '', '')
 , ROW ('t1', 'AmazonElastiCache', 'Previous', 'Intel', 't3', '', 't4g', '')
 , ROW ('t2', 'AmazonElastiCache', 'Previous', 'Intel', 't3', '', 't4g', '')
-, ROW ('t4g', 'AmazonElastiCache', 'Current', 'Graviton', '', '', '', 't3')
 , ROW ('t3', 'AmazonElastiCache', 'Current', 'Intel', '', '', 't4g', '')
+, ROW ('t4g', 'AmazonElastiCache', 'Current', 'Graviton', '', '', '', 't3')
 , ROW ('c4', 'AmazonES', 'Previous', 'Intel', 'c5', '', 'c6g', '')
 , ROW ('c5', 'AmazonES', 'Current', 'Intel', '', '', 'c6g', '')
 , ROW ('c6g', 'AmazonES', 'Current', 'Graviton', '', '', '', 'c5')
 , ROW ('i2', 'AmazonES', 'Previous', 'Intel', 'i3', '', '', '')
 , ROW ('i3', 'AmazonES', 'Current', 'Intel', '', '', '', '')
 , ROW ('m3', 'AmazonES', 'Previous', 'Intel', 'm5', '', 'm6g', '')
 , ROW ('m4', 'AmazonES', 'Previous', 'Intel', 'm5', '', 'm6g', '')
 , ROW ('m5', 'AmazonES', 'Current', 'Intel', '', '', 'm6g', '')
 , ROW ('m6g', 'AmazonES', 'Current', 'Graviton', '', '', '', 'm5')
 , ROW ('r3', 'AmazonES', 'Previous', 'Intel', 'r5', '', 'r6g', '')
 , ROW ('r4', 'AmazonES', 'Previous', 'Intel', 'r5', '', 'r6g', '')
 , ROW ('r5', 'AmazonES', 'Current', 'Intel', '', '', 'r6g', '')
 , ROW ('r6g', 'AmazonES', 'Current', 'Graviton', '', '', '', 'r5')
+, ROW ('r6gd', 'AmazonES', 'Current', 'Graviton', '', '', '', 'r5')
 , ROW ('t2', 'AmazonES', 'Previous', 'Intel', 't3', '', '', '')
 , ROW ('t3', 'AmazonES', 'Current', 'Intel', '', '', '', '')
-, ROW ('r6gd', 'AmazonES', 'Current', 'Graviton', '', '', '', 'r5')
 , ROW ('cv11', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
-, ROW ('m1', 'AmazonRDS', 'Previous', 'Intel', 'm5', '', 'm6g', '')
-, ROW ('m2', 'AmazonRDS', 'Previous', 'Intel', 'm5', '', 'm6g', '')
-, ROW ('m3', 'AmazonRDS', 'Previous', 'Intel', 'm5', '', 'm6g', '')
-, ROW ('m4', 'AmazonRDS', 'Previous', 'Intel', 'm5', '', 'm6g', '')
+, ROW ('m1', 'AmazonRDS', 'Previous', 'Intel', 'm6i', '', 'm6g', '')
+, ROW ('m2', 'AmazonRDS', 'Previous', 'Intel', 'm6i', '', 'm6g', '')
+, ROW ('m3', 'AmazonRDS', 'Previous', 'Intel', 'm6i', '', 'm6g', '')
+, ROW ('m4', 'AmazonRDS', 'Previous', 'Intel', 'm6i', '', 'm6g', '')
 , ROW ('m5', 'AmazonRDS', 'Current', 'Intel', '', '', 'm6g', '')
 , ROW ('m5d', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
 , ROW ('m6g', 'AmazonRDS', 'Current', 'Graviton', '', '', '', 'm5')
 , ROW ('m6gd', 'AmazonRDS', 'Current', 'Graviton', '', '', '', '')
+, ROW ('m6i', 'AmazonRDS', 'Current', 'Intel', '', '', 'm6g', 'm5')
 , ROW ('mv11', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
-, ROW ('r3', 'AmazonRDS', 'Previous', 'Intel', 'r5', '', 'r6g', '')
-, ROW ('r4', 'AmazonRDS', 'Previous', 'Intel', 'r5', '', 'r6g', '')
+, ROW ('r3', 'AmazonRDS', 'Previous', 'Intel', 'r6i', '', 'r6g', 'r5')
+, ROW ('r4', 'AmazonRDS', 'Previous', 'Intel', 'r6i', '', 'r6g', 'r5')
 , ROW ('r5', 'AmazonRDS', 'Current', 'Intel', '', '', 'r6g', '')
 , ROW ('r5b', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
 , ROW ('r5d', 'AmazonRDS', 'Current', 'Intel', '', '', 'r6gd', '')
 , ROW ('r6g', 'AmazonRDS', 'Current', 'Graviton', '', '', '', 'r5')
 , ROW ('r6gd', 'AmazonRDS', 'Current', 'Graviton', '', '', '', 'r5d')
+, ROW ('r6i', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
 , ROW ('rv11', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
 , ROW ('t1', 'AmazonRDS', 'Previous', 'Intel', 't3', '', 't4g', '')
 , ROW ('t2', 'AmazonRDS', 'Previous', 'Intel', 't3', '', 't4g', '')
 , ROW ('t3', 'AmazonRDS', 'Current', 'Intel', '', '', 't4g', '')
 , ROW ('t4g', 'AmazonRDS', 'Current', 'Graviton', '', '', '', 't3')
 , ROW ('x1', 'AmazonRDS', 'Current', 'Intel', '', '', 'x2g', '')
 , ROW ('x1e', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
-, ROW ('z1d', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
 , ROW ('x2g', 'AmazonRDS', 'Current', 'Graviton', '', '', '', 'x1')
-
+, ROW ('z1d', 'AmazonRDS', 'Current', 'Intel', '', '', '', '')
 )  ignored_table_name (family, product, generation, instance_processor, latest_intel, latest_amd, latest_graviton, previous_intel)
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_ebs_snap_view.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_ebs_snap_view.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_ebs_storage_view.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_ebs_storage_view.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_instance_all_view.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_instance_all_view.sql`

 * *Files 1% similar despite different names*

```diff
@@ -93,15 +93,15 @@
 
 		   GROUP BY 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,17,18,19,20,21,22,23,24,25
 		   )
 		SELECT  
 			cur_all.*  
 		   , CASE 
 				WHEN (product_code = 'AmazonEC2' AND lower(platform) NOT LIKE '%window%') THEN latest_graviton 
-				WHEN (product_code = 'AmazonRDS' AND database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) THEN latest_graviton 
+				WHEN (product_code = 'AmazonRDS' AND database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) THEN latest_graviton 
 				WHEN (product_code = 'AmazonES') THEN latest_graviton
 				WHEN (product_code = 'AmazonElastiCache') THEN latest_graviton
 				END "latest_graviton"
 			,	latest_amd
 			, latest_intel
 			, generation
 			, instance_processor
@@ -160,39 +160,41 @@
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN (adjusted_amortized_cost * 5.5E-1) ELSE 0 END "ec2_spot_potential_savings"  /*Uses 55% savings estimate*/ 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option = 'Spot')) THEN (adjusted_amortized_cost -amortized_cost) ELSE 0 END "ec2_spot_savings" 		
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (generation IN ('Previous')) AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN (amortized_cost * 5E-2) ELSE 0 END "ec2_previous_generation_potential_savings"  /*Uses 5% savings estimate*/ 
 		   , CASE 
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 2E-1)
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor = 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_graviton_potential_savings"  /*Uses 20% savings estimate for intel and 10% for AMD*/ 				
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 2E-1)
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor = 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_graviton_potential_savings"  /*Uses 20% savings estimate for intel and 10% for AMD*/ 				
 		   , CASE 
 				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_amd <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_amd_potential_savings"  /*Uses 10% savings estimate for intel and 0% for Graviton*/
 /*RDS*/			
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '')) THEN adjusted_amortized_cost ELSE 0 END "rds_all_cost"	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN adjusted_amortized_cost ELSE 0 END "rds_ondemand_cost"				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND (adjusted_processor = 'Graviton')) THEN amortized_cost 
-				WHEN (("charge_type" = 'Usage') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) AND (adjusted_processor <> 'Graviton')  AND (latest_graviton <> '')) THEN amortized_cost ELSE 0 END "rds_graviton_eligible_cost"
+				WHEN (("charge_type" = 'Usage') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) AND (adjusted_processor <> 'Graviton')  AND (latest_graviton <> '')) THEN amortized_cost ELSE 0 END "rds_graviton_eligible_cost"
 		   , CASE 
-				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "rds_graviton_cost"
+				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "rds_graviton_cost"
 		   , CASE 
 				WHEN ("charge_type" NOT LIKE '%Usage%') THEN 0 
 				WHEN ("product_code" <> 'AmazonRDS') THEN 0 
 				WHEN (adjusted_processor = 'Graviton') THEN 0 
 				WHEN (latest_graviton = '') THEN 0 
-				WHEN ((latest_graviton <> '') AND purchase_option = 'OnDemand' AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL'))) THEN (amortized_cost * 1E-1) ELSE 0 END "rds_graviton_potential_savings"  /*Uses 10% savings estimate*/	
+				WHEN ((latest_graviton <> '') AND purchase_option = 'OnDemand' AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL'))) THEN (amortized_cost * 1E-1) ELSE 0 END "rds_graviton_potential_savings"  /*Uses 10% savings estimate*/	
 		   , CASE 
 				WHEN (("purchase_option" in ('Reserved','SavingsPlan')) AND ("product_code" = 'AmazonRDS')) THEN ("adjusted_amortized_cost" - "amortized_cost") ELSE 0 END "rds_commit_savings"	
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN (amortized_cost * 2E-1) ELSE 0 END "rds_commit_potential_savings"  /*Uses 20% savings estimate*/ 				
-				
+			, (CASE WHEN (((("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS')) AND ("instance_type" <> '')) AND (database_engine IN ('Oracle'))) THEN adjusted_amortized_cost ELSE 0 END) "rds_oracle_cost"
+			, (CASE WHEN (((("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS')) AND ("instance_type" <> '')) AND (database_engine IN ('SQL Server'))) THEN adjusted_amortized_cost ELSE 0 END) "rds_sql_server_cost"
+		
 /*ElastiCache*/			
 		   , CASE 
 				WHEN ("product_code" = 'AmazonElastiCache') THEN adjusted_amortized_cost ELSE 0 END "elasticache_all_cost"	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonElastiCache') AND ("instance_type" <> '')) THEN amortized_cost ELSE 0 END "elasticache_usage_cost"	 				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonElastiCache') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN adjusted_amortized_cost ELSE 0 END "elasticache_ondemand_cost"
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRI.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRI.sql`

 * *Files 2% similar despite different names*

```diff
@@ -89,15 +89,15 @@
 
 		   GROUP BY 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,17,18,19,20,21,22,23,24,25
 		   )
 		SELECT  
 			cur_all.*  
 		   , CASE 
 				WHEN (product_code = 'AmazonEC2' AND lower(platform) NOT LIKE '%window%') THEN latest_graviton 
-				WHEN (product_code = 'AmazonRDS' AND database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) THEN latest_graviton 
+				WHEN (product_code = 'AmazonRDS' AND database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) THEN latest_graviton 
 				WHEN (product_code = 'AmazonES') THEN latest_graviton
 				WHEN (product_code = 'AmazonElastiCache') THEN latest_graviton
 				END "latest_graviton"
 			,	latest_amd
 			, latest_intel
 			, generation
 			, instance_processor
@@ -134,15 +134,15 @@
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%')) THEN amortized_cost ELSE 0 END ec2_usage_cost	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option = 'Spot')) THEN adjusted_amortized_cost ELSE 0 END "ec2_spot_cost"				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (generation IN ('Previous')) AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN amortized_cost ELSE 0 END "ec2_previous_generation_cost"
 		   , CASE 
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%')
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') 
 				AND ((adjusted_processor = 'Graviton')
 				OR (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> ''))) 
 				 THEN amortized_cost ELSE 0 END "ec2_graviton_eligible_cost"
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "ec2_graviton_cost"
 		   , CASE 
 				WHEN adjusted_processor = 'Graviton' THEN 0
@@ -155,39 +155,41 @@
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN (adjusted_amortized_cost * 5.5E-1) ELSE 0 END "ec2_spot_potential_savings"  /*Uses 55% savings estimate*/ 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option = 'Spot')) THEN (adjusted_amortized_cost -amortized_cost) ELSE 0 END "ec2_spot_savings" 		
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (generation IN ('Previous')) AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN (amortized_cost * 5E-2) ELSE 0 END "ec2_previous_generation_potential_savings"  /*Uses 5% savings estimate*/ 
 		   , CASE 
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 2E-1)
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor = 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_graviton_potential_savings"  /*Uses 20% savings estimate for intel and 10% for AMD*/ 				
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 2E-1)
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor = 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_graviton_potential_savings"  /*Uses 20% savings estimate for intel and 10% for AMD*/ 				
 		   , CASE 
 				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_amd <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_amd_potential_savings"  /*Uses 10% savings estimate for intel and 0% for Graviton*/
 /*RDS*/			
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '')) THEN adjusted_amortized_cost ELSE 0 END "rds_all_cost"	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN adjusted_amortized_cost ELSE 0 END "rds_ondemand_cost"				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND (adjusted_processor = 'Graviton')) THEN amortized_cost 
-				WHEN (("charge_type" = 'Usage') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) AND (adjusted_processor <> 'Graviton')  AND (latest_graviton <> '')) THEN amortized_cost ELSE 0 END "rds_graviton_eligible_cost"
+				WHEN (("charge_type" = 'Usage') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) AND (adjusted_processor <> 'Graviton')  AND (latest_graviton <> '')) THEN amortized_cost ELSE 0 END "rds_graviton_eligible_cost"
 		   , CASE 
-				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "rds_graviton_cost"
+				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "rds_graviton_cost"
 		   , CASE 
 				WHEN ("charge_type" NOT LIKE '%Usage%') THEN 0 
 				WHEN ("product_code" <> 'AmazonRDS') THEN 0 
 				WHEN (adjusted_processor = 'Graviton') THEN 0 
 				WHEN (latest_graviton = '') THEN 0 
-				WHEN ((latest_graviton <> '') AND purchase_option = 'OnDemand' AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL'))) THEN (amortized_cost * 1E-1) ELSE 0 END "rds_graviton_potential_savings"  /*Uses 10% savings estimate*/	
+				WHEN ((latest_graviton <> '') AND purchase_option = 'OnDemand' AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL'))) THEN (amortized_cost * 1E-1) ELSE 0 END "rds_graviton_potential_savings"  /*Uses 10% savings estimate*/	
 		   , CASE 
 				WHEN (("purchase_option" in ('Reserved','SavingsPlan')) AND ("product_code" = 'AmazonRDS')) THEN ("adjusted_amortized_cost" - "amortized_cost") ELSE 0 END "rds_commit_savings"	
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN (amortized_cost * 2E-1) ELSE 0 END "rds_commit_potential_savings"  /*Uses 20% savings estimate*/ 				
-				
+			, (CASE WHEN (((("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS')) AND ("instance_type" <> '')) AND (database_engine IN ('Oracle'))) THEN adjusted_amortized_cost ELSE 0 END) "rds_oracle_cost"
+			, (CASE WHEN (((("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS')) AND ("instance_type" <> '')) AND (database_engine IN ('SQL Server'))) THEN adjusted_amortized_cost ELSE 0 END) "rds_sql_server_cost"
+	
 /*ElastiCache*/			
 		   , CASE 
 				WHEN ("product_code" = 'AmazonElastiCache') THEN adjusted_amortized_cost ELSE 0 END "elasticache_all_cost"	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonElastiCache') AND ("instance_type" <> '')) THEN amortized_cost ELSE 0 END "elasticache_usage_cost"	 				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonElastiCache') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN adjusted_amortized_cost ELSE 0 END "elasticache_ondemand_cost"
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRISP.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRISP.sql`

 * *Files 0% similar despite different names*

```diff
@@ -81,15 +81,15 @@
 
 		   GROUP BY 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,17,18,19,20,21,22,23,24,25
 		   )
 		SELECT  
 			cur_all.*  
 		   , CASE 
 				WHEN (product_code = 'AmazonEC2' AND lower(platform) NOT LIKE '%window%') THEN latest_graviton 
-				WHEN (product_code = 'AmazonRDS' AND database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) THEN latest_graviton 
+				WHEN (product_code = 'AmazonRDS' AND database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) THEN latest_graviton 
 				WHEN (product_code = 'AmazonES') THEN latest_graviton
 				WHEN (product_code = 'AmazonElastiCache') THEN latest_graviton
 				END "latest_graviton"
 			,	latest_amd
 			, latest_intel
 			, generation
 			, instance_processor
@@ -126,15 +126,15 @@
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%')) THEN amortized_cost ELSE 0 END ec2_usage_cost	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option = 'Spot')) THEN adjusted_amortized_cost ELSE 0 END "ec2_spot_cost"				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (generation IN ('Previous')) AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN amortized_cost ELSE 0 END "ec2_previous_generation_cost"
 		   , CASE 
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%')
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%')
 				AND ((adjusted_processor = 'Graviton')
 				OR (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> ''))) 
 				 THEN amortized_cost ELSE 0 END "ec2_graviton_eligible_cost"
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "ec2_graviton_cost"
 		   , CASE 
 				WHEN adjusted_processor = 'Graviton' THEN 0
@@ -147,38 +147,41 @@
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN (adjusted_amortized_cost * 5.5E-1) ELSE 0 END "ec2_spot_potential_savings"  /*Uses 55% savings estimate*/ 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option = 'Spot')) THEN (adjusted_amortized_cost -amortized_cost) ELSE 0 END "ec2_spot_savings" 		
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (generation IN ('Previous')) AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN (amortized_cost * 5E-2) ELSE 0 END "ec2_previous_generation_potential_savings"  /*Uses 5% savings estimate*/ 
 		   , CASE 
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 2E-1)
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor = 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_graviton_potential_savings"  /*Uses 20% savings estimate for intel and 10% for AMD*/ 				
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 2E-1)
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor = 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_graviton_potential_savings"  /*Uses 20% savings estimate for intel and 10% for AMD*/ 				
 		   , CASE 
 				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_amd <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_amd_potential_savings"  /*Uses 10% savings estimate for intel and 0% for Graviton*/
 /*RDS*/			
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '')) THEN adjusted_amortized_cost ELSE 0 END "rds_all_cost"	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN adjusted_amortized_cost ELSE 0 END "rds_ondemand_cost"				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND (adjusted_processor = 'Graviton')) THEN amortized_cost 
-				WHEN (("charge_type" = 'Usage') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) AND (adjusted_processor <> 'Graviton')  AND (latest_graviton <> '')) THEN amortized_cost ELSE 0 END "rds_graviton_eligible_cost"
+				WHEN (("charge_type" = 'Usage') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) AND (adjusted_processor <> 'Graviton')  AND (latest_graviton <> '')) THEN amortized_cost ELSE 0 END "rds_graviton_eligible_cost"
 		   , CASE 
-				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "rds_graviton_cost"
+				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "rds_graviton_cost"
 		   , CASE 
 				WHEN ("charge_type" NOT LIKE '%Usage%') THEN 0 
 				WHEN ("product_code" <> 'AmazonRDS') THEN 0 
 				WHEN (adjusted_processor = 'Graviton') THEN 0 
 				WHEN (latest_graviton = '') THEN 0 
-				WHEN ((latest_graviton <> '') AND purchase_option = 'OnDemand' AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL'))) THEN (amortized_cost * 1E-1) ELSE 0 END "rds_graviton_potential_savings"  /*Uses 10% savings estimate*/	
+				WHEN ((latest_graviton <> '') AND purchase_option = 'OnDemand' AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL'))) THEN (amortized_cost * 1E-1) ELSE 0 END "rds_graviton_potential_savings"  /*Uses 10% savings estimate*/	
 		   , CASE 
 				WHEN (("purchase_option" in ('Reserved','SavingsPlan')) AND ("product_code" = 'AmazonRDS')) THEN ("adjusted_amortized_cost" - "amortized_cost") ELSE 0 END "rds_commit_savings"	
 		   , CASE 
-				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN (amortized_cost * 2E-1) ELSE 0 END "rds_commit_potential_savings"  /*Uses 20% savings estimate*/ 				
+				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN (amortized_cost * 2E-1) ELSE 0 END "rds_commit_potential_savings"  /*Uses 20% savings estimate*/ 		
+			, (CASE WHEN (((("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS')) AND ("instance_type" <> '')) AND (database_engine IN ('Oracle'))) THEN adjusted_amortized_cost ELSE 0 END) "rds_oracle_cost"
+			, (CASE WHEN (((("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS')) AND ("instance_type" <> '')) AND (database_engine IN ('SQL Server'))) THEN adjusted_amortized_cost ELSE 0 END) "rds_sql_server_cost"
+			
 				
 /*ElastiCache*/			
 		   , CASE 
 				WHEN ("product_code" = 'AmazonElastiCache') THEN adjusted_amortized_cost ELSE 0 END "elasticache_all_cost"	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonElastiCache') AND ("instance_type" <> '')) THEN amortized_cost ELSE 0 END "elasticache_usage_cost"	 				
 		   , CASE
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noSP.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noSP.sql`

 * *Files 2% similar despite different names*

```diff
@@ -84,15 +84,15 @@
 
 		   GROUP BY 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,17,18,19,20,21,22,23,24,25
 		   )
 		SELECT  
 			cur_all.*  
 		   , CASE 
 				WHEN (product_code = 'AmazonEC2' AND lower(platform) NOT LIKE '%window%') THEN latest_graviton 
-				WHEN (product_code = 'AmazonRDS' AND database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) THEN latest_graviton 
+				WHEN (product_code = 'AmazonRDS' AND database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) THEN latest_graviton 
 				WHEN (product_code = 'AmazonES') THEN latest_graviton
 				WHEN (product_code = 'AmazonElastiCache') THEN latest_graviton
 				END "latest_graviton"
 			,	latest_amd
 			, latest_intel
 			, generation
 			, instance_processor
@@ -129,15 +129,15 @@
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%')) THEN amortized_cost ELSE 0 END ec2_usage_cost	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option = 'Spot')) THEN adjusted_amortized_cost ELSE 0 END "ec2_spot_cost"				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (generation IN ('Previous')) AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN amortized_cost ELSE 0 END "ec2_previous_generation_cost"
 		   , CASE 
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%')
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') 
 				AND ((adjusted_processor = 'Graviton')
 				OR (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> ''))) 
 				 THEN amortized_cost ELSE 0 END "ec2_graviton_eligible_cost"
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "ec2_graviton_cost"
 		   , CASE 
 				WHEN adjusted_processor = 'Graviton' THEN 0
@@ -150,39 +150,42 @@
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN (adjusted_amortized_cost * 5.5E-1) ELSE 0 END "ec2_spot_potential_savings"  /*Uses 55% savings estimate*/ 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (purchase_option = 'Spot')) THEN (adjusted_amortized_cost -amortized_cost) ELSE 0 END "ec2_spot_savings" 		
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (generation IN ('Previous')) AND (purchase_option <> 'Spot') AND (purchase_option <> 'Reserved') AND (savings_plan_offering_type NOT LIKE '%EC2%')) THEN (amortized_cost * 5E-2) ELSE 0 END "ec2_previous_generation_potential_savings"  /*Uses 5% savings estimate*/ 
 		   , CASE 
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 2E-1)
-				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor = 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_graviton_potential_savings"  /*Uses 20% savings estimate for intel and 10% for AMD*/ 				
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 2E-1)
+				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (lower(platform) NOT LIKE '%window%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_graviton <> '') AND adjusted_processor = 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_graviton_potential_savings"  /*Uses 20% savings estimate for intel and 10% for AMD*/ 				
 		   , CASE 
 				WHEN ("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonEC2') AND ("instance_type" <> '') AND ("operation" LIKE '%RunInstances%') AND (((purchase_option = 'OnDemand') OR (savings_plan_offering_type = 'ComputeSavingsPlans')) AND (adjusted_processor <> 'Graviton') AND (latest_amd <> '') AND adjusted_processor <> 'AMD') THEN (amortized_cost * 1E-1) ELSE 0 END "ec2_amd_potential_savings"  /*Uses 10% savings estimate for intel and 0% for Graviton*/
 /*RDS*/			
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '')) THEN adjusted_amortized_cost ELSE 0 END "rds_all_cost"	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN adjusted_amortized_cost ELSE 0 END "rds_ondemand_cost"				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND (adjusted_processor = 'Graviton')) THEN amortized_cost 
-				WHEN (("charge_type" = 'Usage') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) AND (adjusted_processor <> 'Graviton')  AND (latest_graviton <> '')) THEN amortized_cost ELSE 0 END "rds_graviton_eligible_cost"
+				WHEN (("charge_type" = 'Usage') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) AND (adjusted_processor <> 'Graviton')  AND (latest_graviton <> '')) THEN amortized_cost ELSE 0 END "rds_graviton_eligible_cost"
 		   , CASE 
-				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL')) AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "rds_graviton_cost"
+				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL')) AND (adjusted_processor = 'Graviton')) THEN amortized_cost ELSE 0 END "rds_graviton_cost"
 		   , CASE 
 				WHEN ("charge_type" NOT LIKE '%Usage%') THEN 0 
 				WHEN ("product_code" <> 'AmazonRDS') THEN 0 
 				WHEN (adjusted_processor = 'Graviton') THEN 0 
 				WHEN (latest_graviton = '') THEN 0 
-				WHEN ((latest_graviton <> '') AND purchase_option = 'OnDemand' AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL'))) THEN (amortized_cost * 1E-1) ELSE 0 END "rds_graviton_potential_savings"  /*Uses 10% savings estimate*/	
+				WHEN ((latest_graviton <> '') AND purchase_option = 'OnDemand' AND (database_engine in ('Aurora MySQL','Aurora PostgreSQL','MariaDB','PostgreSQL','MySQL'))) THEN (amortized_cost * 1E-1) ELSE 0 END "rds_graviton_potential_savings"  /*Uses 10% savings estimate*/	
 		   , CASE 
 				WHEN (("purchase_option" in ('Reserved','SavingsPlan')) AND ("product_code" = 'AmazonRDS')) THEN ("adjusted_amortized_cost" - "amortized_cost") ELSE 0 END "rds_commit_savings"	
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN (amortized_cost * 2E-1) ELSE 0 END "rds_commit_potential_savings"  /*Uses 20% savings estimate*/ 				
-				
+			, (CASE WHEN (((("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS')) AND ("instance_type" <> '')) AND (database_engine IN ('Oracle'))) THEN adjusted_amortized_cost ELSE 0 END) "rds_oracle_cost"
+			, (CASE WHEN (((("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonRDS')) AND ("instance_type" <> '')) AND (database_engine IN ('SQL Server'))) THEN adjusted_amortized_cost ELSE 0 END) "rds_sql_server_cost"
+	
+
 /*ElastiCache*/			
 		   , CASE 
 				WHEN ("product_code" = 'AmazonElastiCache') THEN adjusted_amortized_cost ELSE 0 END "elasticache_all_cost"	 
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonElastiCache') AND ("instance_type" <> '')) THEN amortized_cost ELSE 0 END "elasticache_usage_cost"	 				
 		   , CASE 
 				WHEN (("charge_type" LIKE '%Usage%') AND ("product_code" = 'AmazonElastiCache') AND ("instance_type" <> '') AND (purchase_option = 'OnDemand')) THEN adjusted_amortized_cost ELSE 0 END "elasticache_ondemand_cost"
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/kpi_s3_storage_view.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/kpi_s3_storage_view.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/kpi/last_kpi_tracker_view.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/kpi/last_kpi_tracker_view.sql`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-
 CREATE OR REPLACE VIEW kpi_tracker AS 
 SELECT DISTINCT
 spend_all.billing_period
 , spend_all.payer_account_id
 , spend_all.linked_account_id
 , account_map.*
 , spend_all.spend_all_cost			
@@ -66,28 +65,32 @@
 , instance_all.sagemaker_ondemand_cost
 , instance_all.sagemaker_commit_potential_savings
 , instance_all.sagemaker_commit_savings
 , instance_all.lambda_all_cost
 , instance_all.lambda_graviton_cost
 , instance_all.lambda_graviton_eligible_cost
 , instance_all.lambda_graviton_potential_savings
+, instance_all.rds_license
+, instance_all.rds_no_license
+, instance_all.rds_sql_server_cost
+, instance_all.rds_oracle_cost
 FROM
   (((((account_map
 LEFT JOIN (
    SELECT DISTINCT
      billing_period
    , payer_account_id
    , linked_account_id
    , "sum"(amortized_cost) "spend_all_cost"
    , "sum"(unblended_cost) "unblended_cost"
    FROM
      summary_view
    WHERE (CAST("concat"("year", '-', "month", '-01') AS date) >= ("date_trunc"('month', current_date) - INTERVAL  '3' MONTH))
    GROUP BY 1, 2, 3
-)  spend_all ON (spend_all.linked_account_id = account_id))
+)  spend_all ON (spend_all.linked_account_id = account_id) AND (spend_all.payer_account_id = payer_account_id))
 LEFT JOIN (
    SELECT DISTINCT
      billing_period
    , payer_account_id
    , linked_account_id
    , "sum"("ec2_all_cost") "ec2_all_cost"
    , "sum"("ec2_spot_cost") "ec2_spot_cost"
@@ -103,14 +106,16 @@
    , "sum"("rds_all_cost") "rds_all_cost"
    , "sum"("rds_ondemand_cost") "rds_ondemand_cost"
    , "sum"("rds_graviton_cost") "rds_graviton_cost"
    , "sum"("rds_graviton_eligible_cost") "rds_graviton_eligible_cost"
    , "sum"("rds_graviton_potential_savings") "rds_graviton_potential_savings"
    , "sum"("rds_commit_potential_savings") "rds_commit_potential_savings"
    , "sum"("rds_commit_savings") "rds_commit_savings"
+   , "sum"((CASE WHEN ("license_model" IN ('License included', 'Bring your own license')) THEN 1 ELSE 0 END)) "rds_license"
+   , "sum"((CASE WHEN ("license_model" LIKE 'No license required') THEN 1 ELSE 0 END)) "rds_no_license"
    , "sum"("elasticache_all_cost") "elasticache_all_cost"
    , "sum"("elasticache_ondemand_cost") "elasticache_ondemand_cost"
    , "sum"("elasticache_graviton_cost") "elasticache_graviton_cost"
    , "sum"("elasticache_graviton_eligible_cost") "elasticache_graviton_eligible_cost"
    , "sum"("elasticache_graviton_potential_savings") "elasticache_graviton_potential_savings"
    , "sum"("elasticache_commit_potential_savings") "elasticache_commit_potential_savings"
    , "sum"("elasticache_commit_savings") "elasticache_commit_savings"
@@ -138,50 +143,52 @@
    , "sum"("sagemaker_ondemand_cost") "sagemaker_ondemand_cost"
    , "sum"("sagemaker_commit_potential_savings") "sagemaker_commit_potential_savings"
    , "sum"("sagemaker_commit_savings") "sagemaker_commit_savings"
    , "sum"("lambda_all_cost") "lambda_all_cost"
    , "sum"("lambda_graviton_cost") "lambda_graviton_cost"
    , "sum"("lambda_graviton_eligible_cost") "lambda_graviton_eligible_cost"
    , "sum"("lambda_graviton_potential_savings") "lambda_graviton_potential_savings"
+   , "sum"("rds_sql_server_cost") "rds_sql_server_cost"
+   , "sum"("rds_oracle_cost") "rds_oracle_cost"
    FROM
      kpi_instance_all
    GROUP BY 1, 2, 3
-)  instance_all ON ((instance_all.linked_account_id = account_id) AND (instance_all.billing_period = spend_all.billing_period)))
+)  instance_all ON ((instance_all.linked_account_id = account_id) AND (instance_all.billing_period = spend_all.billing_period) AND (instance_all.payer_account_id = spend_all.payer_account_id)))
 LEFT JOIN (
    SELECT DISTINCT
      billing_period
    , payer_account_id
    , linked_account_id
    , "sum"("ebs_all_cost") "ebs_all_cost"   
    , "sum"("ebs_gp3_cost"+"ebs_gp2_cost") "ebs_gp_all_cost"
    , "sum"("ebs_gp3_cost") "ebs_gp3_cost"
    , "sum"("ebs_gp2_cost") "ebs_gp2_cost"
    , "sum"("ebs_gp3_potential_savings") "ebs_gp3_potential_savings"
    FROM
      kpi_ebs_storage_all
    GROUP BY 1, 2, 3
-)  ebs_all ON ((ebs_all.linked_account_id = account_id) AND (ebs_all.billing_period = spend_all.billing_period)))
+)  ebs_all ON ((ebs_all.linked_account_id = account_id) AND (ebs_all.billing_period = spend_all.billing_period) AND (ebs_all.payer_account_id = spend_all.payer_account_id)))
 LEFT JOIN (
    SELECT DISTINCT
      billing_period
    , payer_account_id
    , linked_account_id
    , "sum"("ebs_snapshots_under_1yr_cost") "ebs_snapshots_under_1yr_cost"
    , "sum"("ebs_snapshots_over_1yr_cost") "ebs_snapshots_over_1yr_cost"
    , "sum"("ebs_snapshot_cost") "ebs_snapshot_cost"
    FROM
      kpi_ebs_snap
    GROUP BY 1, 2, 3
-)  snap ON ((snap.linked_account_id = account_id) AND (snap.billing_period = spend_all.billing_period)))
+)  snap ON ((snap.linked_account_id = account_id) AND (snap.billing_period = spend_all.billing_period) AND (snap.payer_account_id = spend_all.payer_account_id)))
 LEFT JOIN (
    SELECT DISTINCT
      billing_period
    , payer_account_id
    , linked_account_id
    , "sum"("s3_all_storage_cost") "s3_all_storage_cost"
    , "sum"("s3_standard_storage_cost") "s3_standard_storage_cost"
    , "sum"("s3_standard_storage_potential_savings") "s3_standard_storage_potential_savings"
    FROM
      kpi_s3_storage_all
    GROUP BY 1, 2, 3
-)  s3_all ON ((s3_all.linked_account_id = account_id) AND (s3_all.billing_period = spend_all.billing_period)))
+)  s3_all ON ((s3_all.linked_account_id = account_id) AND (s3_all.billing_period = spend_all.billing_period) AND (s3_all.payer_account_id = spend_all.payer_account_id)))
 WHERE (spend_all.billing_period >= ("date_trunc"('month', current_timestamp) - INTERVAL  '3' MONTH))
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/aws_accounts.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/aws_accounts.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/aws_service_category_map.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/aws_service_category_map.sql`

 * *Files 6% similar despite different names*

```diff
@@ -2,14 +2,16 @@
 SELECT *
 FROM
   (
  VALUES
      ROW ('AmazonApiGateway', 'Networking & Content Delivery')
    , ROW ('AmazonAppStream', 'End User Computing')
    , ROW ('AmazonAthena', 'Analytics')
+   , ROW ('AmazonA2I', 'Machine Learning')
+   , ROW ('AmazonChime', 'Business Applications')
    , ROW ('AmazonCloudDirectory', 'Security, Identity & Compliance')
    , ROW ('AmazonCloudFront', 'Networking & Content Delivery')
    , ROW ('AmazonCloudSearch', 'Analytics')
    , ROW ('AmazonCloudWatch', 'Management & Governance')
    , ROW ('AmazonCognito', 'Security, Identity & Compliance')
    , ROW ('AmazonConnect', 'Customer Engagement')
    , ROW ('AmazonDAX', 'Database')
@@ -23,25 +25,27 @@
    , ROW ('AmazonEFS', 'Storage')
    , ROW ('AmazonEKS', 'Containers')
    , ROW ('AmazonElastiCache', 'Database')
    , ROW ('AmazonES', 'Analytics')
    , ROW ('AmazonETS', 'Media Services')
    , ROW ('AmazonForecast', 'Machine Learning')
    , ROW ('AmazonFSx', 'Storage')
+   , ROW ('AmazonGameLift', 'Game Tech')
    , ROW ('AmazonGlacier', 'Storage')
    , ROW ('AmazonGuardDuty', 'Security, Identity & Compliance')
    , ROW ('AmazonInspector', 'Security, Identity & Compliance')
    , ROW ('AmazonIVS', 'Media Services')
    , ROW ('AmazonKendra', 'Machine Learning')
    , ROW ('AmazonKinesis', 'Analytics')
    , ROW ('AmazonKinesisAnalytics', 'Analytics')
    , ROW ('AmazonKinesisFirehose', 'Analytics')
    , ROW ('AmazonKinesisVideo', 'Media Services')
    , ROW ('AmazonLex', 'Machine Learning')
    , ROW ('AmazonLightsail', 'Management & Governance')
+   , ROW ('AmazonLookoutEquipment', 'Machine Learning')
    , ROW ('AmazonMacie', 'Security, Identity & Compliance')
    , ROW ('AmazonManagedBlockchain', 'Blockchain')
    , ROW ('AmazonMCS', 'Management & Governance')
    , ROW ('AmazonML', 'Machine Learning')
    , ROW ('AmazonMQ', 'Application Integration')
    , ROW ('AmazonMSK', 'Analytics')
    , ROW ('AmazonNeptune', 'Database')
@@ -66,15 +70,16 @@
    , ROW ('AmazonTextract', 'Machine Learning')
    , ROW ('AmazonVPC', 'Networking & Content Delivery')
    , ROW ('AmazonWAM', 'End User Computing')
    , ROW ('AmazonWorkDocs', 'Business Applications')
    , ROW ('AmazonWorkMail', 'Business Applications')
    , ROW ('AmazonWorkSpaces', 'End User Computing')
    , ROW ('AppFlow', 'Application Integration')
-   , ROW ('AWSAmplify', 'Mobile')
+   , ROW ('AWSAppRunner', 'Compute')
+   , ROW ('AWSAmplify', 'Front-end Web & Mobile')
    , ROW ('AWSAppSync', 'Application Integration')
    , ROW ('AWSBackup', 'Storage')
    , ROW ('AWSBudgets', 'AWS Cost Management')
    , ROW ('AWSCertificateManager', 'Security, Identity & Compliance')
    , ROW ('AWSCloudFormation', 'Management & Governance')
    , ROW ('AWSCloudMap', 'Networking & Content Delivery')
    , ROW ('AWSCloudTrail', 'Management & Governance')
@@ -84,28 +89,29 @@
    , ROW ('AWSCodePipeline', 'Developer Tools')
    , ROW ('AWSConfig', 'Management & Governance')
    , ROW ('AWSCostExplorer', 'AWS Cost Management')
    , ROW ('AWSDatabaseMigrationSvc', 'Migration & Transfer')
    , ROW ('AWSDataSync', 'Migration & Transfer')
    , ROW ('AWSDataTransfer', 'Migration & Transfer')
    , ROW ('AWSDeveloperSupport', 'Support')
-   , ROW ('AWSDeviceFarm', 'Mobile')
+   , ROW ('AWSDeviceFarm', 'Front-end Web & Mobile')
    , ROW ('AWSDirectConnect', 'Networking & Content Delivery')
    , ROW ('AWSDirectoryService', 'Security, Identity & Compliance')
    , ROW ('AWSELB', 'Networking & Content Delivery')
    , ROW ('AWSElementalMediaConvert', 'Media Services')
    , ROW ('AWSElementalMediaLive', 'Media Services')
    , ROW ('AWSElementalMediaStore', 'Media Services')
    , ROW ('AWSEvents', 'Management & Governance')
    , ROW ('AWSGlobalAccelerator', 'Networking & Content Delivery')
    , ROW ('AWSGlue', 'Analytics')
    , ROW ('AWSGreengrass', 'Internet of Things')
    , ROW ('AWSIoT', 'Internet of Things')
    , ROW ('AWSIoT1Click', 'Internet of Things')
    , ROW ('AWSIoTAnalytics', 'Internet of Things')
+   , ROW ('AWSIoTEvents', 'Internet of Things')
    , ROW ('awskms', 'Security, Identity & Compliance')
    , ROW ('AWSLambda', 'Compute')
    , ROW ('AWSQueueService', 'Application Integration')
    , ROW ('AWSRoboMaker', 'Robotics')
    , ROW ('AWSSecretsManager', 'Security, Identity & Compliance')
    , ROW ('AWSSecurityHub', 'Security, Identity & Compliance')
    , ROW ('AWSServiceCatalog', 'Management & Governance')
@@ -128,8 +134,18 @@
    , ROW ('ElasticMapReduce', 'Analytics')
    , ROW ('IngestionServiceSnowball', 'Migration & Transfer')
    , ROW ('IoTDeviceDefender', 'Internet of Things')
    , ROW ('IoTDeviceManagement', 'Internet of Things')
    , ROW ('SnowballExtraDays', 'Migration & Transfer')
    , ROW ('transcribe', 'Machine Learning')
    , ROW ('translate', 'Machine Learning')
-)  ignored_table_name (line_item_product_code, aws_service_category)
+   , ROW ('OCBPremiumSupport', 'Customer Enablement')
+   , ROW ('ComputeSavingsPlans', 'Compute')
+   , ROW ('AmazonMWAA', 'Application Integration')
+   , ROW ('AmazonInspectorV2', 'Security, Identity & Compliance')
+   , ROW ('AWSFMS', 'Security, Identity & Compliance')
+   , ROW ('AWSFIS', 'Developer Tools')
+   , ROW ('AWSCloudShell', 'Developer Tools')
+   , ROW ('auditmanager', 'Security, Identity & Compliance')
+   , ROW ('AmazonLocationService', 'Front-end Web & Mobile')
+   , ROW ('AmazonTimestream', 'Database')
+)  ignored_table_name (line_item_product_code, aws_service_category)
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/shared/ta_descriptions.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/shared/ta_descriptions.sql`

 * *Files 12% similar despite different names*

```diff
@@ -1,269 +1,322 @@
 CREATE OR REPLACE VIEW "ta_descriptions" AS 
 SELECT *
 FROM
   (
- VALUES 
-  ROW ('Qch7DwouX1', 'en', 'Low Utilization Amazon EC2 Instances', 'Checks the Amazon Elastic Compute Cloud (Amazon EC2) instances that were running at any time during the last 14 days and alerts you if the daily CPU utilization was 10% or less and network I/O was 5 MB or less on 4 or more days. Running instances generate hourly usage charges. Although some scenarios can result in low utilization by design, you can often lower your costs by managing the number and size of your instances.')
-, ROW ('hjLMh88uM8', 'en', 'Idle Load Balancers', 'Checks your Elastic Load Balancing configuration for load balancers that are not actively used. Any load balancer that is configured accrues charges. If a load balancer has no associated back-end instances or if network traffic is severely limited, the load balancer is not being used effectively.')
-, ROW ('DAvU99Dc4C', 'en', 'Underutilized Amazon EBS Volumes', 'Checks Amazon Elastic Block Store (Amazon EBS) volume configurations and warns when volumes appear to be underused. Charges begin when a volume is created. If a volume remains unattached or has very low write activity (excluding boot volumes) for a period of time, the volume is probably not being used.')
-, ROW ('Z4AUBRNSmz', 'en', 'Unassociated Elastic IP Addresses', 'Checks for Elastic IP addresses (EIPs) that are not associated with a running Amazon Elastic Compute Cloud (Amazon EC2) instance. EIPs are static IP addresses designed for dynamic cloud computing. Unlike traditional static IP addresses, EIPs can mask the failure of an instance or Availability Zone by remapping a public IP address to another instance in your account. A nominal charge is imposed for an EIP that is not associated with a running instance.')
+VALUES 
+  ROW ('rSs93HQwa1', 'en', 'Amazon RDS Public Snapshots', 'Checks the permission settings for your Amazon Relational Database Service (Amazon RDS) DB snapshots and alerts you if any snapshots are marked as public. When you make a snapshot public, you give all AWS accounts and users access to all the data on the snapshot. If you want to share a snapshot with particular users or accounts, mark the snapshot as private, and then specify the user or accounts you want to share the snapshot data with. <h4 class=headerBodyStyle>Note</h4>: Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: The RDS  snapshot is marked as public.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Unless you are certain you want to share all the data in the snapshot with all AWS accounts and users, modify the permissions: mark the snapshot as private, and then specify the accounts that you want to give permissions to. For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ShareSnapshot.html" target="_blank">Sharing a DB Snapshot or DB Cluster Snapshot</a>. Note: For temporary technical reasons, items in this check cannot be excluded from view in the Trusted Advisor console.To modify permissions for your snapshots directly, you can use a runbook in the AWS Systems Manager console. For more information, see <a href="https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awssupport-modifyrdssnapshotpermission.html" target="_blank">AWSSupport-ModifyRDSSnapshotPermission</a>.<br/><br/> <h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_CommonTasks.BackupRestore.html" target="_blank">Backing Up and Restoring Amazon RDS DB Instances</a>')
+, ROW ('xSqX82fQu', 'en', 'ELB Security Groups', 'Checks for load balancers configured with a missing security group or a security group that allows access to ports that are not configured for the load balancer. If a security group associated with a load balancer is deleted, the load balancer does not work as expected. If a security group allows access to ports that are not configured for the load balancer, the risk of loss of data or malicious attacks increases. <br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: The inbound rules of an Amazon VPC security group associated with a load balancer allow access to ports that are not defined in the load balancers listener configuration. <br/>Red: A security group associated with a load balancer does not exist. <br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Configure the security group rules to restrict access to only those ports and protocols that are defined in the load balancer listener configuration, plus the ICMP protocol to support Path MTU Discovery. See <a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html">Listeners for Your Classic Load Balancer</a> and <a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html#elb-vpc-security-groups">Security Groups for Load Balancers in a VPC</a>.<br/>If a security group is missing, apply a new security group to the load balancer. Create security group rules that restrict access to only those ports and protocols that are defined in the load balancer listener configuration. See <a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html#elb-vpc-security-groups">Security Groups for Load Balancers in a VPC</a>. <br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html">Elastic Load Balancing User Guide</a> <br/><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-configure-load-balancer.html">Configure Your Classic Load Balancer</a>')
+, ROW ('aW7HH0l7J9', 'en', 'Auto Scaling Launch Configurations', 'Checks for usage that is more than 80% of the Auto Scaling Launch Configurations Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('dx3xfbjfMr', 'en', 'Route 53 Traffic Policies', 'Checks for usage that is more than 80% of the Route 53 Traffic Policies Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('gH5CC0e3J9', 'en', 'EBS Cold HDD (sc1) Volume Storage', 'Checks for usage that is more than 80% of the EBS Cold HDD (sc1) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('b73EEdD790', 'en', 'Amazon Route 53 Failover Resource Record Sets', 'Checks for Amazon Route 53 failover resource record sets that are misconfigured. When Amazon Route 53 health checks determine that the primary resource is unhealthy, Amazon Route 53 responds to queries with a secondary, backup resource record set. You must create correctly configured primary and secondary resource record sets for failover to work. Hosted zones created by AWS services wonâ€™t appear in your check results.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A primary failover resource record set does not have a corresponding secondary resource record set.<br/>Yellow: A secondary failover resource record set does not have a corresponding primary resource record set.<br/>Yellow: Primary and secondary resource record sets that have the same name are associated with the same health check.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>If a failover resource set is missing, create the corresponding resource record set; see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/creating-failover-rrsets.html" target="_blank">Creating Failover Resource Record Sets</a>.<br/>If your resource record sets are associated with the same health check, create separate health checks for each one; see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-creating-deleting.html" target="_blank">Creating, Updating, and Deleting Health Checks</a>.<br/><br/><h4 class=headerBodyStyle>Additional Information</h4><br/><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html" target="_blank">Amazon Route 53 Health Checks and DNS Failover</a>')
+, ROW ('N425c450f2', 'en', 'CloudFront Custom SSL Certificates in the IAM Certificate Store', 'Checks the SSL certificates for CloudFront alternate domain names in the IAM certificate store and alerts you if the certificate is expired, will soon expire, uses outdated encryption, or is not configured correctly for the distribution. When a custom certificate for an alternate domain name expires, browsers that display your CloudFront content might show a warning message about the security of your website. Certificates that are encrypted by using the SHA-1 hashing algorithm are being deprecated by web browsers such as Chrome and Firefox.  If a certificate doesnt contain any domain names that match either Origin Domain Name or the domain name in the Host header of viewer requests, CloudFront returns an HTTP status code 502 (bad gateway) to the user. For more information, see <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/SecureConnections.html#CNAMEsAndHTTPS" target="_blank">Using Alternate Domain Names and HTTPS</a>.')
+, ROW ('L4dfs2Q4C5', 'en', 'AWS Lambda Functions Using Deprecated Runtimes', 'Checks for Lambda functions that are configured to use a runtime that is approaching deprecation or is deprecated. Deprecated runtimes are not eligible for security updates or technical support.<br/><h4 class=headerBodyStyle>Notes:</h4>')
+, ROW ('L4dfs2Q4C6', 'en', 'AWS Lambda VPC-enabled Functions without Multi-AZ Redundancy', 'Checks for VPC-enabled Lambda functions that are vulnerable to service interruption in a single availability zone. It is recommended for VPC-enabled functions to be connected to multiple availability zones for high availability.<br/><h4 class=headerBodyStyle>Note:</h4> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A VPC-enabled Lambda function connected to subnets in a single Availability Zone.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>When configuring functions for access to your VPC, choose subnets in multiple Availability Zones to ensure high availability.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html" target="blank">Configuring a Lambda function to access resources in a VPC</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/security-resilience.html" target="blank">Resilience in AWS Lambda</a><br/>')
+, ROW ('cF171Db240', 'en', 'Amazon Route 53 Name Server Delegations', 'Checks for Amazon Route 53 hosted zones for which your domain registrar or DNS is not using the correct Route 53 name servers. When you create a hosted zone, Route 53 assigns a delegation set of four name servers. The names of these servers are ns-###.awsdns-##.com, .net, .org, and .co.uk, where ### and ## typically represent different numbers. Before Route 53 can route DNS queries for your domain, you must update your registrars name server configuration to remove the name servers that the registrar assigned and add all four name servers in the Route 53 delegation set. For maximum availability, you must add all four Route 53 name servers. Hosted zones created by AWS services wonâ€™t appear in your check results.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A hosted zone for which the registrar for your domain does not use all four of the Route 53 name servers in the delegation set.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Add or update name server records with your registrar or with the current DNS service for your domain to include all four of the name servers in your Route 53 delegation set. To find these values, see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/GetInfoAboutHostedZone.html" target="_blank">Getting the Name Servers for a Hosted Zone</a>. For information about adding or updating name server records, see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/creating-migrating.html" target="_blank">Creating and Migrating Domains and Subdomains to Amazon Route&nbsp;53</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/AboutHZWorkingWith.html" target="_blank">Working with Hosted Zones</a> <br/>')
+, ROW ('cG7HH0l7J9', 'en', 'EBS Magnetic (standard) Volume Storage', 'Checks for usage that is more than 80% of the EBS Magnetic (standard) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('sU7XX0l7J9', 'en', 'IAM Group', 'Checks for usage that is more than 80% of the IAM Group Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('N420c450f2', 'en', 'CloudFront Alternate Domain Names', 'Checks Amazon CloudFront distributions for alternate domain names (CNAMES) that have incorrectly configured DNS settings. If a CloudFront distribution includes alternate domain names, the DNS configuration for the domains must route DNS queries to that distribution.<br/><br/>Note: This check assumes Amazon Route 53 DNS and Amazon CloudFront distribution are configured in the same AWS account. As such the Alert list may include resources otherwise working as expected due to DNS setting outsides of this AWS account.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A CloudFront distribution includes alternate domain names, but the DNS configuration is not correctly set up with a CNAME record or an Amazon Route 53 alias resource record.<br/>Yellow: A CloudFront distribution includes alternate domain names, but Trusted Advisor could not evaluate the DNS configuration because there were too many redirects.<br/>Yellow: A CloudFront distribution includes alternate domain names, but Trusted Advisor could not evaluate the DNS configuration for some other reason, most likely because of a timeout.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Update the DNS configuration to route DNS queries to the CloudFront distribution; see <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html" target="_blank">Using Alternate Domain Names (CNAMEs)</a>. If youre using Amazon Route 53 as your DNS service, see <a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfront-distribution.html" target="_blank">Routing Traffic to an Amazon CloudFront Web Distribution by Using Your Domain Name</a>. If the check timed out, try refreshing the check.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html">Amazon CloudFront Developer Guide</a>')
+, ROW ('COr6dfpM04', 'en', 'Amazon EBS under-provisioned volumes', 'Checks the Amazon Elastic Block Storage (Amazon EBS) volumes that were running at any time during the lookback period. This check alerts you if any EBS volumes were under-provisioned for your workloads. Consistent high utilization can indicate optimized, steady performance, but can also indicate that an application does not have enough resources.<br/><br/><h4 class=headerBodyStyle>Source</h4><br/>AWS Compute Optimizer<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: An EBS Volume that was under-provisioned during the lookback period. To determine if a volume is under-provisioned, we consider all default CloudWatch metrics (including IOPS and throughput). The algorithm used to identify under-provisioned EBS volumes follows AWS best practices. The algorithm is updated when a new pattern has been identified.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider upsizing volumes that have high utilization.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/>For more information about this recommendation, see the <a href="https://docs.aws.amazon.com/console/awssupport/trusted-advisor/compute-optimizer" target="blank">Trusted Advisor documentation</a>.')
+, ROW ('COr6dfpM03', 'en', 'Amazon EBS over-provisioned volumes', 'Checks the Amazon Elastic Block Storage (Amazon EBS) volumes that were running at any time during the lookback period. This check alerts you if any EBS volumes were over-provisioned for your workloads. When you have over-provisioned volumes, youâ€™re paying for unused resources. Although some scenarios can result in low optimization by design, you can often lower your costs by changing the configuration of your EBS volumes. Estimated monthly savings are calculated by using the current usage rate for EBS volumes. Actual savings will vary if the volume isnâ€™t present for a full month.<br/><br/><h4 class=headerBodyStyle>Source</h4><br/>AWS Compute Optimizer<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: An EBS Volume that was over-provisioned during the lookback period. To determine if a volume is over-provisioned, we consider all default CloudWatch metrics (including IOPS and throughput). The algorithm used to identify over-provisioned EBS volumes follows AWS best practices. The algorithm is updated when a new pattern has been identified.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider downsizing volumes that have low utilization.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/>For more information about this recommendation, see the <a href="https://docs.aws.amazon.com/console/awssupport/trusted-advisor/compute-optimizer" target="blank">Trusted Advisor documentation.</a>.')
+, ROW ('jtlIMO3qZM', 'en', 'RDS Cluster Parameter Groups', 'Checks for usage that is more than 80% of the RDS Cluster Parameter Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('COr6dfpM06', 'en', 'AWS Lambda under-provisioned functions for memory size', 'Checks the AWS Lambda functions that were invoked at least once during the lookback period. This check alerts you if any of your Lambda functions were under-provisioned for memory size. When you have Lambda functions that are under-provisioned for memory size, these functions take longer time to complete.<br/><br/><h4 class=headerBodyStyle>Source</h4><br/>AWS Compute Optimizer<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A Lambda function that was under-provisioned for memory size during the lookback period. To determine if a Lambda function is under-provisioned, we consider all default CloudWatch metrics for that function. The algorithm used to identify under-provisioned Lambda functions for memory size follows AWS best practices. The algorithm is updated when a new pattern has been identified.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider increasing the memory size of your Lambda functions.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/>For more information about this recommendation, see the <a href="https://docs.aws.amazon.com/console/awssupport/trusted-advisor/compute-optimizer" target="blank">Trusted Advisor documentation</a>.')
+, ROW ('COr6dfpM05', 'en', 'AWS Lambda over-provisioned functions for memory size', 'Checks the AWS Lambda functions that were invoked at least once during the lookback period. This check alerts you if any of your Lambda functions were over-provisioned for memory size. When you have Lambda functions that are over-provisioned for memory sizes, youâ€™re paying for unused resources. Although some scenarios can result in low utilization by design, you can often lower your costs by changing the memory configuration of your Lambda functions. Estimated monthly savings are calculated by using the current usage rate for Lambda functions.<br/><br/><h4 class=headerBodyStyle>Source</h4><br/>AWS Compute Optimizer<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A Lambda function that was over-provisioned for memory size during the lookback period. To determine if a Lambda function is over-provisioned, we consider all default CloudWatch metrics for that function. The algorithm used to identify over-provisioned Lambda functions for memory size follows AWS best practices. The algorithm is updated when a new pattern has been identified.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider reducing the memory size of your Lambda functions.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/>For more information about this recommendation, see the <a href="https://docs.aws.amazon.com/console/awssupport/trusted-advisor/compute-optimizer" target="blank">Trusted Advisor documentation page</a>.')
+, ROW ('f2iK5R6Dep', 'en', 'Amazon RDS Multi-AZ', 'Checks for DB instances that are deployed in a single Availability Zone. Multi-AZ deployments enhance database availability by synchronously replicating to a standby instance in a different Availability Zone. During planned database maintenance or the failure of a DB instance or Availability Zone, Amazon RDS automatically fails over to the standby so that database operations can resume quickly without administrative intervention. Because Multi-AZ deployments for the SQL Server engine use a different mechanism for synchronization, this check does not examine SQL Server instances.')
+, ROW ('jEhCtdJKOY', 'en', 'RDS Subnets per Subnet Group', 'Checks for usage that is more than 80% of the RDS Subnets per Subnet Group Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('a2sEc6ILx', 'en', 'ELB Listener Security', 'Checks for load balancers with listeners that do not use recommended security configurations for encrypted communication. AWS recommends using a secure protocol (HTTPS or SSL), up-to-date security policies, and ciphers and protocols that are secure.<br/>When you use a secure protocol for a front-end connection (client to load balancer), the requests are encrypted between your clients and the load balancer, which is more secure.<br/>Elastic Load Balancing provides predefined security policies  with ciphers and protocols that adhere to AWS security best practices. New versions of predefined policies are released as new configurations become available. <br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A load balancer has no listener that uses a secure protocol (HTTPS or SSL). <br/>Yellow: A load balancer listener uses an outdated predefined SSL security policy. <br/>Yellow: A load balancer listener uses a cipher or protocol that is not recommended. <br/>Red: A load balancer listener uses an insecure cipher or protocol.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><ul><li>If the traffic to your load balancer must be secure, use either the HTTPS or the SSL protocol for the front-end connection.</li><li>Upgrade your load balancer to the latest version of the predefined SSL security policy.</li> <li>Use only the recommended ciphers and protocols.</li> </ul>For more information, see <a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-listener-config.html">Listener Configurations for Elastic Load Balancing</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/using-elb-listenerconfig-quickref.html">Listener Configurations Quick Reference</a><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/ssl-config-update.html">Update SSL Negotiation Configuration of Your Load Balancer</a><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-ssl-security-policy.html">SSL Negotiation Configurations for Elastic Load Balancing</a><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-security-policy-table.html">SSL Security Policy Table</a><br/>')
+, ROW ('ePs02jT06w', 'en', 'Amazon EBS Public Snapshots', 'Checks the permission settings for your Amazon Elastic Block Store (Amazon EBS) volume snapshots and alerts you if any snapshots are marked as public. When you make a snapshot public, you give all AWS accounts and users access to all the data on the snapshot. If you want to share a snapshot with particular users or accounts, mark the snapshot as private, and then specify the user or accounts you want to share the snapshot data with. <h4 class=headerBodyStyle>Note</h4>: Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: The EBS volume snapshot is marked as public.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Unless you are certain you want to share all the data in the snapshot with all AWS accounts and users, modify the permissions: mark the snapshot as private, and then specify the accounts that you want to give permissions to. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modifying-snapshot-permissions.html" target="_blank">Sharing an Amazon EBS Snapshot</a>. Note: For temporary technical reasons, items in this check cannot be excluded from view in the Trusted Advisor console.To modify permissions for your snapshots directly, you can use a runbook in the AWS Systems Manager console. For more information, see <a href="https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awssupport-modifyebssnapshotpermission.html" target="_blank">AWSSupport-ModifyEBSSnapshotPermission</a>.<br/><br/> <h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html" target="_blank">Amazon EBS Snapshots</a>')
+, ROW ('R365s2Qddf', 'en', 'Amazon S3 Bucket Versioning', 'Checks for Amazon Simple Storage Service buckets that do not have versioning enabled, or have versioning suspended. When versioning is enabled, you can easily recover from both unintended user actions and application failures. Versioning allows you to preserve, retrieve, and restore any version of any object stored in a bucket. You can use lifecycle rules to manage all versions of your objects as well as their associated costs by automatically archiving objects to the Glacier storage class or removing them after a specified time period. You can also choose to require multi-factor authentication (MFA) for any object deletions or configuration changes to your buckets. <br/><br/>Versioning cannot be disabled after it has been enabled, but it can be suspended, which prevents new versions of objects from being created. Using versioning can increase your costs for Amazon S3, because you pay for storage of multiple versions of an object.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Green: Versioning is enabled for the bucket.<br/>Yellow: Versioning is not enabled for the bucket.<br/>Yellow: Versioning is suspended for the bucket.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Enable bucket versioning on most buckets to prevent accidental deletion or overwriting. See <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html" target="_blank">Using Versioning</a> and <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/manage-versioning-examples.html" target="_blank">Enabling Versioning Programmatically</a>. <br/><br/>If bucket versioning is suspended, consider reenabling versioning. For information on working with objects in a versioning-suspended bucket, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/VersionSuspendedBehavior.html" target="_blank">Managing Objects in a Versioning-Suspended Bucket</a>.<br/><br/>When versioning is enabled or suspended, you can define lifecycle configuration rules to mark certain object versions as expired or to permanently remove unneeded object versions. For more information, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html" target="_blank">Object Lifecycle Management</a>. <br/><br/>MFA Delete requires additional authentication when the versioning status of the bucket is changed or when versions of an object are deleted. It requires the user to enter credentials and a code from an approved authentication device. For more information, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html#MultiFactorAuthenticationDelete" target="_blank">MFA Delete</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/AmazonS3/latest/UG/BucketOperations.html" target="_blank">Working with Buckets</a>')
+, ROW ('Wxdfp4B1L2', 'en', 'AWS Well-Architected high risk issues for performance efficiency', 'Checks for high risk issues (HRIs) for your workloads in the performance pillar. This check is based on your AWS-Well Architected reviews. Your check results depend on whether you completed the workload evaluation with AWS Well-Architected.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: At least one active high risk issue was identified in the performance pillar for AWS Well-Architected.')
+, ROW ('Wxdfp4B1L3', 'en', 'AWS Well-Architected high risk issues for security', 'Checks for high risk issues (HRIs) for your workloads in the security pillar. This check is based on your AWS-Well Architected reviews. Your check results depend on whether you completed the workload evaluation with AWS Well-Architected.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: At least one active high risk issue was identified in the security pillar for AWS Well-Architected.')
+, ROW ('8wIqYSt25K', 'en', 'ELB Network Load Balancers', 'Checks for usage that is more than 80% of the ELB Network Load Balancers Limit. Classic Load Balancers and Application Load Balancers have separate limits. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.<br/>')
+, ROW ('Wxdfp4B1L4', 'en', 'AWS Well-Architected high risk issues for reliability', 'Checks for high risk issues (HRIs) for your workloads in the Reliability pillar. This check is based on your AWS-Well Architected reviews. Your check results depend on whether you completed the workload evaluation with AWS Well-Architected.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: At least one active high risk issue was identified in the reliability pillar for AWS Well-Architected.')
+, ROW ('Wxdfp4B1L1', 'en', 'AWS Well-Architected high risk issues for cost optimization', 'Checks for high risk issues (HRIs) for your workloads in the cost optimization pillar. This check is based on your AWS-Well Architected reviews. Your check results depend on whether you completed the workload evaluation with AWS Well-Architected.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: At least one active high risk issue was identified in the cost optimization pillar for AWS Well-Architected.')
+, ROW ('opQPADkZvH', 'en', 'Amazon RDS Backups', 'Checks for automated backups of Amazon RDS DB instances. By default, backups are enabled with a retention period of 1 day. Backups reduce the risk of unexpected data loss and allow for point-in-time recovery.')
+, ROW ('L4dfs2Q3C2', 'en', 'AWS Lambda Functions with High Error Rates', 'Checks for Lambda functions with high error rates that may result in high cost. Lambda charges based on the number of requests and aggregate execution time for your function. Function errors may cause retries that incur additional charges.<br/><h4 class=headerBodyStyle>Note:</h4> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: Functions where > 10% of invocations end in error on any given day within the last 7 days.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider the following guidelines to reduce errors. Function errors include errors returned by the functions code and errors returned by the functions runtime. To help you troubleshoot Lambda errors, Lambda integrates with services like Amazon CloudWatch and AWS X-Ray. You can use a combination of logs, metrics, alarms, and X-ray tracing to quickly detect and identify issues in your function code, API, or other resources that support your application. For more information, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-monitoring.html" target="blank">Monitoring and troubleshooting Lambda applications</a>. For more information on handling errors with specific runtimes, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html" target="blank">Error handling and automatic retries in AWS Lambda</a>. For additional troubleshooting, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-troubleshooting.html" target="blank">Troubleshooting issues in Lambda</a>.You can also choose from an ecosystem of monitoring and observability tools provided by AWS Lambda partners. For additional information about Partners, see <a href="https://aws.amazon.com/lambda/partners/?partner-solutions-cards.sort-by=item.additionalFields.partnerNameLower&partner-solutions-cards.sort-order=asc" target="blank">AWS Lambda Partners</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html" target="blank">Error Handling and Automatic  Retries in AWS Lambda</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-monitoring.html" target="blank">Monitoring and Troubleshooting Lambda applications</a><br/><a href="https://aws.amazon.com/premiumsupport/knowledge-center/lambda-function-retry-timeout-sdk/" target="blank">Lambda Function Retry Timeout SDK</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-troubleshooting.html" target="blank">Troubleshooting  issues in Lambda</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_Errors" target="blank">API Invoke Errors</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/samples-errorprocessor.html" target="blank">Error Processor Sample Application for AWS Lambda</a><br/>')
+, ROW ('L4dfs2Q3C3', 'en', 'AWS Lambda Functions with Excessive Timeouts', 'Checks for Lambda functions with high timeout rates that may result in high cost. Lambda charges based on execution time for your function and number of requests for your function. Function timeouts result in function errors that may cause retries that incur additional request and execution time charges.<br/><h4 class=headerBodyStyle>Note:</h4> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: Functions where > 10% of invocations end in an error due to a timeout on any given day within the last 7 days.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Inspect function logging and X-ray traces to determine the contributor to the high function duration. Implement logging in your code at relevant parts, such as before or after API calls or database connections. By default, AWS SDK clients timeouts may be longer than the configured function duration. Adjust API and SDK connection clients to retry or fail within the function timeout. If the expected duration is longer than the configured timeout, you can increase the timeout setting for the function. For more information, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-monitoring.html" target="blank">Monitoring and troubleshooting Lambda applications</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-monitoring.html" target="blank">Monitoring and troubleshooting Lambda applications</a><br/><a href="https://aws.amazon.com/premiumsupport/knowledge-center/lambda-function-retry-timeout-sdk/" target="blank">Lambda Function Retry Timeout SDK</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/services-xray.html" target="blank">Using AWS Lambda with AWS X-Ray</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs.html" target="blank">Accessing Amazon CloudWatch logs for AWS Lambda</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/samples-errorprocessor.html" target="blank">Error Processor Sample Application for AWS Lambda</a><br/>')
+, ROW ('vjafUGJ9H0', 'en', 'AWS CloudTrail Logging', 'Checks for your use of AWS CloudTrail. CloudTrail provides increased visibility into activity in your AWS account by recording information about AWS API calls made on the account. You can use these logs to determine, for example, what actions a particular user has taken during a specified time period or which users have taken actions on a particular resource during a specified time period. Because CloudTrail delivers log files to an Amazon Simple Storage Service (Amazon S3) bucket, CloudTrail must have write permissions for the bucket. If a trail applies to all regions (the default when creating a new trail), the trail appears multiple times in the Trusted Advisor report.')
+, ROW ('7fuccf1Mx7', 'en', 'RDS Cluster Roles', 'Checks for usage that is more than 80% of the RDS Cluster Roles Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('ru4xfcdfMr', 'en', 'Route 53 Max Health Checks', 'Checks for usage that is more than 80% of the Route 53 Health Checks Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('dV84wpqRUs', 'en', 'RDS DB Manual Snapshots', 'Checks for usage that is more than 80% of the RDS DB Manual Snapshots Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('xuy7H1avtl', 'en', 'Amazon Aurora DB Instance Accessibility', 'Checks for cases where an Amazon Aurora DB cluster has both private and public instances. When your primary instance fails, a replica can be promoted to a primary instance. If that replica is private, users who have only public access would no longer be able to connect to the database after failover. Its best practice for all the DB instances in a cluster to have the same accessibility.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: The instances in an Aurora DB cluster have different accessibility (a mix of public and private).<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Modify the <h4 class=headerBodyStyle>Publicly Accessible</h4> setting of the instances in the DB cluster so that they are all either public or private. For details, see the instructions for MySQL instances at <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ModifyInstance.MySQL.html" target="_blank">Modifying a DB Instance Running the MySQL Database Engine</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Aurora.Managing.html#Aurora.Managing.FaultTolerance" target="_blank">Fault Tolerance for an Aurora DB Cluster</a>')
+, ROW ('0t121N1Ty3', 'en', 'AWS Direct Connect Connection Redundancy', 'Checks for regions that have only one AWS Direct Connect connection. Connectivity to your AWS resources should have two Direct Connect connections configured at all times to provide redundancy in case a device is unavailable.<br/><h4 class=headerBodyStyle>Note:</h4> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow:  The region has only one Direct Connect connection.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Configure an additional Direct Connect connection in this region to protect against device unavailability. For more information, see <a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Configure Redundant Connections with AWS Direct Connect</a>. To protect against site unavailability and add location redundancy, configure the additional Direct Connect connection to a different Direct Connect location.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Getting Started with AWS Direct Connect</a><br/><a target="_blank" href="https://aws.amazon.com/directconnect/faqs/">AWS Direct Connect FAQs</a> ')
+, ROW ('RH23stmM01', 'en', 'AWS Resilience Hub resilience scores', 'Checks if you have run an assessment for your applications in Resilience Hub. This check alerts you if your resilience scores are below a specific value. Results for this check are automatically refreshed once every day.<br/><br/><b>Alert Criteria</b><br/>Green: Your application has a resilience score of 70 or greater.')
+, ROW ('RH23stmM02', 'en', 'AWS Resilience Hub policy breached', 'Checks Resilience Hub for applications that dont meet the recovery time objective (RTO) and recovery point objective (RPO) that the policy defines. The check alerts you if your application doesnt meet the RTO and RPO objectives youve set for an application in Resilience Hub.<br/><br/><b>Alert Criteria</b><br/>Green: The application has a policy and meets the RTO and RPO objectives.')
+, ROW ('hc0dfs7601', 'en', 'AWS CloudHSM clusters running HSM instances in a single AZ', 'Checks your clusters that run HSM instances in a single Availability Zone (AZ). This check alerts you if your clusters are at risk of not having the most recent backup.<br/><br/><b>Alert Criteria</b><br/>Yellow: A CloudHSM cluster is running all HSM instances in a single Availability Zone for more than 1 hour.')
+, ROW ('DqdJqYeRm5', 'en', 'IAM Access Key Rotation', 'Checks for active IAM access keys that have not been rotated in the last 90 days.  When you rotate your access keys regularly, you reduce the chance that a compromised key could be used without your knowledge to access resources. For the purposes of this check, the last rotation date and time is when the access key was created or most recently activated. The access key number and date come from the <h4 class=headerBodyStyle>access_key_1_last_rotated</h4> and <h4 class=headerBodyStyle>access_key_2_last_rotated</h4> information in the most recent IAM credential report. Because the regeneration frequency of a credential report  is restricted, refreshing this check might not reflect recent changes (for details, see <a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html">Getting Credential Reports for Your AWS Account</a>).<br/>In order to create and rotate access keys, a user must have the appropriate permissions. For more information, see <a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_delegate-permissions_examples.html#creds-policies-credentials">Allow Users to Manage Their Own Passwords, Access Keys, and SSH Keys</a>.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Green: The access key is active and has been rotated in the last 90 days.<br/>Yellow: The access key is active and has been rotated in the last 2 years, but more than 90 days ago.<br/>Red: The access key is active and has not been rotated in the last 2 years.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Rotate access keys on a regular basis. See <a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_RotateAccessKey">Rotating Access Keys</a> and <a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html">Managing Access Keys for IAM Users</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">IAM Best Practices</a><br/><a target="_blank" href="https://blogs.aws.amazon.com/security/post/Tx15CIT22V4J8RP/How-to-rotate-access-keys-for-IAM-users">How to rotate access keys for IAM users</a> (AWS blog)')
+, ROW ('7DAFEmoDos', 'en', 'MFA on Root Account', 'Checks the root account and warns if multi-factor authentication (MFA) is not enabled. For increased security, we recommend that you protect your account by using MFA, which requires a user to enter a unique authentication code from their MFA hardware or virtual device when interacting with the AWS console and associated websites.')
+, ROW ('tfg86AVHAZ', 'en', 'Large Number of Rules in an EC2 Security Group', 'Checks each Amazon Elastic Compute Cloud (EC2) security group for an excessive number of rules. If a security group has a large number of rules, performance can be degraded.')
+, ROW ('kM7QQ0l7J9', 'en', 'VPC Internet Gateways', 'Checks for usage that is more than 80% of the VPC Internet Gateways Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
 , ROW ('HCP4007jGY', 'en', 'Security Groups - Specific Ports Unrestricted', 'Checks security groups for rules that allow unrestricted access (0.0.0.0/0) to specific ports. Unrestricted access increases opportunities for malicious activity (hacking, denial-of-service attacks, loss of data). The ports with highest risk are flagged red, and those with less risk are flagged yellow. Ports flagged green are typically used by applications that require unrestricted access, such as HTTP and SMTP.')
-, ROW ('1iG5NDGVre', 'en', 'Security Groups - Unrestricted Access', 'Checks security groups for rules that allow unrestricted access to a resource. Unrestricted access increases opportunities for malicious activity (hacking, denial-of-service attacks, loss of data).')
-, ROW ('zXCkfM1nI3', 'en', 'IAM Use', 'This check is intended to discourage the use of root access by checking for existence of at least one IAM user. You may ignore the alert if you are following the best practice of centralizing identities and configuring users in an <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html" target="_blank">external identity provider</a> or <a href="https://aws.amazon.com/single-sign-on/" target="_blank">AWS Single Sign-On</a>. ')
 , ROW ('Pfx0RwqBli', 'en', 'Amazon S3 Bucket Permissions', 'Checks buckets in Amazon Simple Storage Service (Amazon S3) that have open access permissions or allow access to any authenticated AWS user. Bucket permissions that grant List access can result in higher than expected charges if objects in the bucket are listed by unintended users at a high frequency. Bucket permissions that grant Upload/Delete access create potential security vulnerabilities by allowing users that to add, modify, or remove items in a bucket.')
-, ROW ('7DAFEmoDos', 'en', 'MFA on Root Account', 'Checks the root account and warns if multi-factor authentication (MFA) is not enabled. For increased security, we recommend that you protect your account by using MFA, which requires a user to enter a unique authentication code from their MFA hardware or virtual device when interacting with the AWS console and associated websites.')
-, ROW ('Yw2K9puPzl', 'en', 'IAM Password Policy', 'Checks the password policy for your account and warns when a password policy is not enabled, or if password content requirements have not been enabled. Password content requirements increase the overall security of your AWS environment by enforcing the creation of strong user passwords. When you create or change a password policy, the change is enforced immediately for new users but does not require existing users to change their passwords. ')
+, ROW ('Hs4Ma3G191', 'en', 'RDS cluster snapshots and database snapshots should be encrypted at rest', 'Checks if Amazon RDS cluster snapshots and database snapshots are encrypted.')
+, ROW ('Hs4Ma3G192', 'en', 'RDS DB Instances should prohibit public access, determined by the PubliclyAccessible configuration', 'Checks if RDS instances are publicly accessible by evaluating the publiclyAccessible field in the instance configuration item.')
+, ROW ('Hs4Ma3G193', 'en', 'RDS DB instances should have encryption at-rest enabled', 'Checks if storage encryption is enabled for your RDS DB instances.')
+, ROW ('Hs4Ma3G194', 'en', 'RDS snapshot should be private', 'Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public.')
+, ROW ('Hs4Ma3G195', 'en', 'CloudFront distributions should have origin access identity enabled', 'Checks if an Amazon CloudFront distribution with an Amazon S3 origin type has Origin Access Identity (OAI) configured. The check fails if the CloudFront distribution that is backed by Amazon S3 does not have OAI configured.')
+, ROW ('Hs4Ma3G196', 'en', 'AWS Config should be enabled', 'Checks if the Config service is enabled in the account for the local region and is recording all resources.')
+, ROW ('B913Ef6fb4', 'en', 'Amazon Route 53 Alias Resource Record Sets', 'Checks for resource record sets that can be changed to alias resource record sets to improve performance and save money. An alias resource record set routes DNS queries to an AWS resource (for example, an Elastic Load Balancing load balancer or an Amazon S3 bucket) or to another Route 53 resource record set. When you use alias resource record sets, Route 53 routes your DNS queries to AWS resources free of charge. Hosted zones created by AWS services wonâ€™t appear in your check results.')
+, ROW ('Hs4Ma3G197', 'en', 'Amazon Elasticsearch Service domains should have encryption at-rest enabled', 'Checks whether Amazon Elasticsearch Service domains have encryption at rest configuration enabled. This check fails if the EncryptionAtRestOptions field is not enabled.')
+, ROW ('Hs4Ma3G198', 'en', 'RDS DB instances should have deletion protection enabled', 'Checks if RDS DB instances have deletion protection enabled.')
+, ROW ('1iG5NDGVre', 'en', 'Security Groups - Unrestricted Access', 'Checks security groups for rules that allow unrestricted access to a resource. Unrestricted access increases opportunities for malicious activity (hacking, denial-of-service attacks, loss of data).')
+, ROW ('Hs4Ma3G190', 'en', 'RDS clusters should have deletion protection enabled', 'Checks if RDS clusters have deletion protection enabled.')
 , ROW ('nNauJisYIT', 'en', 'Amazon RDS Security Group Access Risk', 'Checks security group configurations for Amazon Relational Database Service (Amazon RDS) and warns when a security group rule might grant overly permissive access to your database. Recommended configuration for any security group rule is to allow access from specific Amazon Elastic Compute Cloud (Amazon EC2) security groups or from a specific IP address. Data for Amazon Relational Database Service (Amazon RDS) instances created in the Asia Pacific (Seoul) region (sa-east-1) is not available. We are working to fix this issue as soon as possible.')
-, ROW ('H7IgTzjTYb', 'en', 'Amazon EBS Snapshots', 'Checks the age of the snapshots for your Amazon Elastic Block Store (Amazon EBS) volumes (available or in-use). Even though Amazon EBS volumes are replicated, failures can occur. Snapshots are persisted to Amazon Simple Storage Service (Amazon S3) for durable storage and point-in-time recovery.')
+, ROW ('Hs4Ma3G188', 'en', 'GuardDuty should be enabled', 'Checks if Amazon GuardDuty is enabled in your AWS account and region.')
+, ROW ('Hs4Ma3G189', 'en', 'Enhanced monitoring should be configured for RDS DB instances', 'Checks if enhanced monitoring is enabled for your RDS DB instances.')
+, ROW ('1e93e4c0b5', 'en', 'Amazon EC2 Reserved Instance Lease Expiration', 'Checks for Amazon EC2 Reserved Instances that are scheduled to expire within the next 30 days or have expired in the preceding 30 days. Reserved Instances do not renew automatically; you can continue using an EC2 instance covered by the reservation without interruption, but you will be charged On-Demand rates. New Reserved Instances can have the same parameters as the expired ones, or you can purchase Reserved Instances with different parameters.<br/>The estimated monthly savings we show is the difference between the On-Demand and Reserved Instance rates for the same instance type.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: The Reserved Instance lease expires in less than 30 days.<br/>Yellow: The Reserved Instance lease expired in the preceding 30 days.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider purchasing a new Reserved Instance to replace the one that is nearing the end of its term. For more information, see <a href="https://aws.amazon.com/ec2/purchasing-options/reserved-instances/buyer/" target="_blank">How to Purchase Reserved Instances</a> and <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-concepts-buying.html" target="_blank">Buying Reserved Instances</a>.<br/><br/> <h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-on-demand-reserved-instances.html" target="_blank">Reserved Instances</a><br/><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html" target="_blank">Instance Types</a>')
+, ROW ('C056F80cR3', 'en', 'Amazon Route 53 High TTL Resource Record Sets', 'Checks for resource record sets that can benefit from having a lower time-to-live (TTL) value. TTL is the number of seconds that a resource record set is cached by DNS resolvers. When you specify a long TTL, DNS resolvers take longer to request updated DNS records, which can cause unnecessary delay in rerouting traffic (for example, when DNS Failover detects and responds to a failure of one of your endpoints). Hosted zones created by AWS services wonâ€™t appear in your check results.')
+, ROW ('6gtQddfEw6', 'en', 'DynamoDB Read Capacity', 'Checks for usage that is more than 80% of the DynamoDB Provisioned Throughput Limit for Reads per Account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G199', 'en', 'Database logging should be enabled', 'Checks if the following Amazon RDS logs are enabled and sent to CloudWatch Logs: Oracle: (Alert, Audit, Trace, Listener), PostgreSQL: (Postgresql, Upgrade), MySQL: (Audit, Error, General, SlowQuery), MariaDB: (Audit, Error, General, SlowQuery), SQL Server: (Error, Agent), Aurora: (Audit, Error, General, SlowQuery), Aurora-MySQL: (Audit, Error, General, SlowQuery), Aurora-PostgreSQL: (Postgresql).')
+, ROW ('XG0aXHpIEt', 'en', 'RDS DB Instances', 'Checks for usage that is more than 80% of the RDS DB Instances Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
 , ROW ('wuy7G1zxql', 'en', 'Amazon EC2 Availability Zone Balance', 'Checks the distribution of Amazon Elastic Compute Cloud (Amazon EC2) instances across Availability Zones in a region. Availability Zones are distinct locations that are designed to be insulated from failures in other Availability Zones and to provide inexpensive, low-latency network connectivity to other Availability Zones in the same region. By launching instances in multiple Availability Zones in the same region, you can help protect your applications from a single point of failure.')
-, ROW ('iqdCTZKCUp', 'en', 'Load Balancer Optimization', 'Checks your load balancer configuration. To help increase the level of fault tolerance in Amazon Elastic Compute Cloud (EC2) when using Elastic Load Balancing, we recommend running an equal number of instances across multiple Availability Zones in a region. A load balancer that is configured accrues charges, so this is a cost-optimization check as well.<br/><br/><b>Alert Criteria</b><br/>Yellow: A load balancer is enabled for a single Availability Zone.<br/>Yellow: A load balancer is enabled for an Availability Zone that has no active instances.<br/>Yellow: The Amazon EC2 instances that are registered with a load balancer are unevenly distributed across Availability Zones. (The difference between the highest and lowest instance counts in utilized Availability Zones is more than 1, and the difference is more than 20% of the highest count.)<br/><br/><b>Recommended Action</b><br/>Ensure that your load balancer points to active and healthy instances in at least two Availability Zones. For more information, see <a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/enable-disable-az.html#US_AddLBAvailabilityZone" target="_blank">Add Availability Zone</a>.<br/>If your load balancer is configured for an Availability Zone with no healthy instances, or if there is an imbalance of instances across the Availability Zones, determine if all the Availability Zones are necessary. Omit any unnecessary Availability Zones and ensure there is a balanced distribution of instances across the remaining Availability Zones. For more information, see <a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/enable-disable-az.html#US_ShrinkLBApp04" target="_blank">Remove Availability Zone</a>.<br/><br/><b>Additional Resources</b><br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#AZ-Region" target="_blank">Availability Zones and Regions</a><br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/UserScenarios.html" target="_blank">Managing Load Balancers</a><br/><a href="http://aws.amazon.com/articles/1636185810492479" target="_blank">Best Practices in Evaluating Elastic Load Balancing</a>')
-, ROW ('S45wrEXrLz', 'en', 'VPN Tunnel Redundancy', 'Checks the number of tunnels that are active for each of your VPNs. A VPN should have two tunnels configured at all times to provide redundancy in case of outage or planned maintenance of the devices at the AWS endpoint. For some hardware, only one tunnel is active at a time (see the <a href="http://docs.aws.amazon.com/AmazonVPC/latest/NetworkAdminGuide/Welcome.html" target="_blank">Amazon Virtual Private Cloud Network Administrator Guide</a>). If a VPN has no active tunnels, charges for the VPN might still apply.')
-, ROW ('ZRxQlPsb6c', 'en', 'High Utilization Amazon EC2 Instances', 'Checks the Amazon Elastic Compute Cloud (Amazon EC2) instances that were running at any time during the last 14 days and alerts you if the daily CPU utilization was more than 90% on 4 or more days. Consistent high utilization can indicate optimized, steady performance, but it can also indicate that an application does not have enough resources. To get daily CPU utilization data, download the report for this check.')
-, ROW ('8CNsSllI5v', 'en', 'Auto Scaling Group Resources', 'Checks the availability of resources associated with launch configurations and your Auto Scaling groups. Auto Scaling groups that point to unavailable resources cannot launch new Amazon Elastic Compute Cloud (Amazon EC2) instances. When properly configured, Auto Scaling causes the number of Amazon EC2 instances to increase seamlessly during demand spikes and decrease automatically during demand lulls. Auto Scaling groups and launch configurations that point to unavailable resources do not operate as intended.')
-, ROW ('opQPADkZvH', 'en', 'Amazon RDS Backups', 'Checks for automated backups of Amazon RDS DB instances. By default, backups are enabled with a retention period of 1 day. Backups reduce the risk of unexpected data loss and allow for point-in-time recovery.')
-, ROW ('f2iK5R6Dep', 'en', 'Amazon RDS Multi-AZ', 'Checks for DB instances that are deployed in a single Availability Zone. Multi-AZ deployments enhance database availability by synchronously replicating to a standby instance in a different Availability Zone. During planned database maintenance or the failure of a DB instance or Availability Zone, Amazon RDS automatically fails over to the standby so that database operations can resume quickly without administrative intervention. Because Multi-AZ deployments for the SQL Server engine use a different mechanism for synchronization, this check does not examine SQL Server instances.')
+, ROW ('Hs4Ma3G170', 'en', 'S3 Block Public Access setting should be enabled', 'Checks if the following public access block settings are configured from account level: ignorePublicAcls: True, blockPublicPolicy: True, blockPublicAcls: True, restrictPublicBuckets: True.')
+, ROW ('Hs4Ma3G171', 'en', 'S3 buckets should prohibit public read access', 'Checks if your S3 buckets allow public read access by evaluating the Block Public Access settings, the bucket policy, and the bucket access check list (ACL).')
+, ROW ('Hs4Ma3G172', 'en', 'S3 buckets should prohibit public write access', 'Checks if your S3 buckets allow public write access by evaluating the Block Public Access settings, the bucket policy, and the bucket access check list (ACL).')
+, ROW ('c1z7dfpz01', 'en', 'Amazon ECS service using a single AZ', 'Checks that your service configuration uses a single Availability Zone (AZ).')
+, ROW ('Hs4Ma3G173', 'en', 'S3 Block Public Access setting should be enabled at the bucket-level', 'Checks if Amazon S3 buckets have bucket level public access blocks applied. This check fails if any of the bucket level settings are set to "false" public: ignorePublicAcls, blockPublicPolicy, blockPublicAcls, restrictPublicBuckets.')
+, ROW ('c1z7dfpz02', 'en', 'Amazon ECS Multi-AZ placement strategy', 'Checks that your Amazon ECS service uses the spread placement strategy. This strategy distributes tasks across Availability Zones (AZs) in the same AWS Region and can help protect your applications from a single point of failure.')
+, ROW ('Hs4Ma3G174', 'en', 'CodeBuild GitHub or Bitbucket source repository URLs should use OAuth', 'Checks if the GitHub or Bitbucket source repository URL contains either personal access tokens or user name and password.')
+, ROW ('Hs4Ma3G175', 'en', 'CodeBuild project environment variables should not contain clear text credentials', 'Checks if the project contains environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.')
+, ROW ('Hs4Ma3G176', 'en', 'ACM certificates should be renewed after a specified time period', 'Checks if ACM Certificates in your account are marked for expiration within a specified time period. Certificates provided by ACM are automatically renewed. ACM does not automatically renew certificates that you import.')
 , ROW ('CLOG40CDO8', 'en', 'Auto Scaling Group Health Check', 'Examines the health check configuration for Auto Scaling groups. If Elastic Load Balancing is being used for an Auto Scaling group, the recommended configuration is to enable an Elastic Load Balancing health check. If an Elastic Load Balancing health check is not used, Auto Scaling can only act upon the health of the Amazon Elastic Compute Cloud (Amazon EC2) instance and not on the application that is running on the instance.')
-, ROW ('BueAdJ7NrP', 'en', 'Amazon S3 Bucket Logging', 'Checks the logging configuration of Amazon Simple Storage Service (Amazon S3) buckets. When server access logging is enabled, detailed access logs are delivered hourly to a bucket that you choose. An access log record contains details about each request, such as the request type, the resources specified in the request, and the time and date the request was processed. By default, bucket logging is not enabled; you should enable logging if you want to perform security audits or learn more about users and usage patterns.')
-, ROW ('PPkZrjsH2q', 'en', 'Amazon EBS Provisioned IOPS (SSD) Volume Attachment Configuration', 'Checks for Provisioned IOPS (SSD) volumes that are attached to an Amazon EBS-optimizable Amazon Elastic Compute Cloud (Amazon EC2) instance that is not EBS-optimized. Provisioned IOPS (SSD) volumes in the Amazon Elastic Block Store (Amazon EBS) are designed to deliver the expected performance only when they are attached to an EBS-optimized instance.')
-, ROW ('tfg86AVHAZ', 'en', 'Large Number of Rules in an EC2 Security Group', 'Checks each Amazon Elastic Compute Cloud (EC2) security group for an excessive number of rules. If a security group has a large number of rules, performance can be degraded.')
-, ROW ('j3DFqYTe29', 'en', 'Large Number of EC2 Security Group Rules Applied to an Instance', 'Checks for Amazon Elastic Compute Cloud (EC2) instances that have a large number of security group rules. Performance can be degraded if an instance has a large number of rules.')
-, ROW ('Ti39halfu8', 'en', 'Amazon RDS Idle DB Instances', 'Checks the configuration of your Amazon Relational Database Service (Amazon RDS) for any DB instances that appear to be idle. If a DB instance has not had a connection for a prolonged period of time, you can delete the instance to reduce costs. If persistent storage is needed for data on the instance, you can use lower-cost options such as taking and retaining a DB snapshot. Manually created DB snapshots are retained until you delete them.')
-, ROW ('B913Ef6fb4', 'en', 'Amazon Route 53 Alias Resource Record Sets', 'Checks for resource record sets that can be changed to alias resource record sets to improve performance and save money. An alias resource record set routes DNS queries to an AWS resource (for example, an Elastic Load Balancing load balancer or an Amazon S3 bucket) or to another Route 53 resource record set. When you use alias resource record sets, Route 53 routes your DNS queries to AWS resources free of charge. Hosted zones created by AWS services wonâ€™t appear in your check results.')
-, ROW ('cF171Db240', 'en', 'Amazon Route 53 Name Server Delegations', 'Checks for Amazon Route 53 hosted zones for which your domain registrar or DNS is not using the correct Route 53 name servers. When you create a hosted zone, Route 53 assigns a delegation set of four name servers. The names of these servers are ns-###.awsdns-##.com, .net, .org, and .co.uk, where ### and ## typically represent different numbers. Before Route 53 can route DNS queries for your domain, you must update your registrars name server configuration to remove the name servers that the registrar assigned and add all four name servers in the Route 53 delegation set. For maximum availability, you must add all four Route 53 name servers. Hosted zones created by AWS services wonâ€™t appear in your check results.<br/><br/><b>Alert Criteria</b><br/>Yellow: A hosted zone for which the registrar for your domain does not use all four of the Route 53 name servers in the delegation set.<br/><br/><b>Recommended Action</b><br/>Add or update name server records with your registrar or with the current DNS service for your domain to include all four of the name servers in your Route 53 delegation set. To find these values, see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/GetInfoAboutHostedZone.html" target="_blank">Getting the Name Servers for a Hosted Zone</a>. For information about adding or updating name server records, see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/creating-migrating.html" target="_blank">Creating and Migrating Domains and Subdomains to Amazon Route&nbsp;53</a>.<br/><br/><b>Additional Resources</b><br/><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/AboutHZWorkingWith.html" target="_blank">Working with Hosted Zones</a> <br/>')
-, ROW ('C056F80cR3', 'en', 'Amazon Route 53 High TTL Resource Record Sets', 'Checks for resource record sets that can benefit from having a lower time-to-live (TTL) value. TTL is the number of seconds that a resource record set is cached by DNS resolvers. When you specify a long TTL, DNS resolvers take longer to request updated DNS records, which can cause unnecessary delay in rerouting traffic (for example, when DNS Failover detects and responds to a failure of one of your endpoints). Hosted zones created by AWS services wonâ€™t appear in your check results.')
+, ROW ('aW9HH0l8J6', 'en', 'EC2-Classic Elastic IP Addresses', 'Checks for usage that is more than 80% of the EC2-Classic Elastic IP Addresses Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('wH7DD0l3J9', 'en', 'EBS Throughput Optimized HDD (st1) Volume Storage', 'Checks for usage that is more than 80% of the EBS Throughput Optimized HDD (st1) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('iK7OO0l7J9', 'en', 'ELB Classic Load Balancers', 'Checks for usage that is more than 80% of the ELB Classic Load Balancers. Application Load Balancers and Network Load Balancers have a separate limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.<br/>')
+, ROW ('DAvU99Dc4C', 'en', 'Underutilized Amazon EBS Volumes', 'Checks Amazon Elastic Block Store (Amazon EBS) volume configurations and warns when volumes appear to be underused. Charges begin when a volume is created. If a volume remains unattached or has very low write activity (excluding boot volumes) for a period of time, the volume is probably not being used.')
+, ROW ('pYW8UkYz2w', 'en', 'RDS Read Replicas per Master', 'Checks for usage that is more than 80% of the RDS Read Replicas per Master Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('pR7UU0l7J9', 'en', 'IAM Policies', 'Checks for usage that is more than 80% of the IAM Policies Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('eI7KK0l7J9', 'en', 'EBS Active Snapshots', 'Checks for usage that is more than 80% of the EBS Active Snapshots Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G166', 'en', 'An RDS event notifications subscription should be configured for critical cluster events', 'Checks if an Amazon RDS Event subscription for RDS clusters is configured to notify on event categories of both "maintenance" and "failure".')
+, ROW ('Hs4Ma3G167', 'en', 'S3 buckets should have server-side encryption enabled', 'Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-object requests without server side encryption.')
+, ROW ('Hs4Ma3G168', 'en', 'S3 buckets should require requests to use Secure Socket Layer', 'Checks if S3 buckets have policies that require requests to use Secure Socket Layer (SSL).')
+, ROW ('Hs4Ma3G169', 'en', 'S3 permissions granted to other AWS accounts in bucket policies should be restricted', 'Checks if the S3 bucket policy allows sensitive bucket-level or object-level actions from a principal in another AWS account. The check fails if any of the following actions are allowed in the S3 bucket policy for a principal in another AWS account: s3:DeleteBucketPolicy, s3:PutBucketAcl, s3:PutBucketPolicy, s3:PutObjectAcl, and s3:PutEncryptionConfiguration.')
+, ROW ('fW7HH0l7J9', 'en', 'Auto Scaling Groups', 'Checks for usage that is more than 80% of the Auto Scaling Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('P1jhKWEmLa', 'en', 'RDS Total Storage Quota', 'Checks for usage that is more than 80% of the RDS Total Storage Quota Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G180', 'en', 'Amazon Elasticsearch Service domain error logging to CloudWatch Logs should be enabled', 'Checks whether Amazon Elasticsearch Service domains are configured to send error logs to CloudWatch Logs.')
+, ROW ('Hs4Ma3G181', 'en', 'Classic Load Balancers with SSL/HTTPS listeners should use a certificate provided by AWS Certificate Manager', 'Checks if a Classic Load Balancer uses HTTPS/SSL certificates provided by AWS Certificate Manager. The check fails if a Classic Load Balancer that is configured with an HTTPS/SSL listener does not use a certificate provided by AWS Certificate Manager.')
+, ROW ('Hs4Ma3G182', 'en', 'Classic Load Balancer listeners should be configured with HTTPS or TLS termination', 'Checks if your Classic Load Balancer listeners are configured with HTTPS or TLS protocol for front-end (client to load balancer) connections. The check is applicable if a Classic Load Balancer has listeners. If your Classic Load Balancer does not have a listener configured, then the check does not report any findings.')
+, ROW ('1qazXsw23e', 'en', 'Amazon Relational Database Service (RDS) Reserved Instance Optimization', 'Checks your usage of RDS and provides recommendations on purchase of Reserved Instances to help reduce costs incurred from using RDS On-Demand. AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of Reserved Instance to purchase to maximize your savings. This check covers recommendations based on partial upfront payment option with 1-year or 3-year commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: Optimizing the purchase of RDS Reserved Instances can help reduce costs.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>See the <a href="http://console.aws.amazon.com/billing/home?/costexplorer#/costexplorer" target="_blank">Cost Explorer</a> page for more detailed recommendations, customization options (e.g. look-back period, payment option, etc.) and to purchase RDS Reserved Instances.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/>Information on RDS Reserved Instances and how they can save you money can be found <a href="http://aws.amazon.com/rds/reserved-instances/" target="_blank">here</a>.')
+, ROW ('Hs4Ma3G183', 'en', 'Application load balancer should be configured to drop http headers', 'This check evaluates AWS Application Load Balancers (ALB) to ensure they are configured to drop http headers. By default, ALBs are not configured to drop invalid http header values. This check evaluates all ALBs fails if the attribute value of routing.http.drop_invalid_header_fields.enabled is set to false.')
+, ROW ('Hs4Ma3G184', 'en', 'Application and Classic Load Balancers logging should be enabled', 'Checks if the Application Load Balancer and the Classic Load Balancer have logging enabled. The check fails if the access_logs.s3.enabled is false.')
+, ROW ('Hs4Ma3G185', 'en', 'IAM customer managed policies that you create should not allow wildcard actions for services', 'Checks if the IAM identity-based custom policies have Allow statements that grant permissions for all actions on a service. The check fails if any policy statement includes "Effect": "Allow" with "Action": "Service:".')
+, ROW ('Hs4Ma3G186', 'en', 'AWS WAF Classic Global Web ACL logging should be enabled', 'Checks if logging is enabled for a WAF global Web ACL. This check fails if logging is not enabled for the Web ACL.')
+, ROW ('Hs4Ma3G187', 'en', 'Connections to Amazon Elasticsearch Service domains should be encrypted using TLS 1.2', 'Checks whether connections to Amazon Elasticsearch Service domains are required to use TLS 1.2.  The check fails if the Amazon Elasticsearch Service domain TLSSecurityPolicy is not Policy-Min-TLS-1-2-2019-07.')
+, ROW ('12Fnkpl8Y5', 'en', 'Exposed Access Keys', 'Checks popular code repositories for access keys that have been exposed to the public and for irregular Amazon Elastic Compute Cloud (Amazon EC2) usage that could be the result of a compromised access key. An access key consists of an access key ID and the corresponding secret access key. Exposed access keys pose a security risk to your account and other users, could lead to excessive charges from unauthorized activity or abuse, and violate the <a target="_blank" href="https://aws.amazon.com/agreement/">AWS Customer Agreement</a>. If your access key is exposed, take immediate action to secure your account. To protect your account from excessive charges, AWS temporarily limits your ability to create certain AWS resources when exposed access keys are identified. This does not make your account secure; it only partially limits the unauthorized usage for which you could be charged. Note: This check does not guarantee the identification of exposed access keys or compromised EC2 instances. You are ultimately responsible for the safety and security of your access keys and AWS resources.   <br/><br/>If a deadline is shown for an access key, AWS may suspend your AWS account if the unauthorized usage is not stopped by that date. If you believe an alert is in error, <a href="https://console.aws.amazon.com/support/home?#/case/create?issueType=customer-service&serviceCode=customer-account&categoryCode=security" target="_blank">contact AWS Support</a>.<br/><br/>The information displayed in Trusted Advisor may not reflect the most recent state of your account. No exposed access keys are marked as resolved until all exposed access keys on the account have been resolved. This data synchronization can take up to one week.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: Potentially compromised - AWS has identified an access key ID and corresponding secret access key that have been exposed on the Internet and may have been compromised (used).<br/>Red: Exposed - AWS has identified an access key ID and corresponding secret access key that have been exposed on the Internet.<br/>Red: Suspected - Irregular Amazon EC2 usage indicates that an access key may have been compromised, but it has not been identified as exposed on the Internet.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Delete the affected access key as soon as possible. If the key is associated with an IAM user, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/ManagingCredentials.html" target="_blank">Managing Access Keys for IAM Users</a>.<br/><br/>Check your account for unauthorized usage. Log in to the <a href="https://console.aws.amazon.com/" target="_blank">AWS Management Console</a> and check each service console for suspicious resources. Pay special attention to running Amazon EC2 instances, Spot Instance requests, access keys, and IAM users. You can also check overall usage on the <a href="https://console.aws.amazon.com/billing/home#/" target="_blank">Billing & Cost Management Dashboard</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html" target="_blank">Best Practices for Managing AWS Access Keys</a><br/><a href="https://docs.aws.amazon.com/general/latest/gr/aws-security-audit-guide.html" target="_blank">AWS Security Audit Guidelines</a>')
+, ROW ('8CNsSllI5v', 'en', 'Auto Scaling Group Resources', 'Checks the availability of resources associated with launch configurations and your Auto Scaling groups. Auto Scaling groups that point to unavailable resources cannot launch new Amazon Elastic Compute Cloud (Amazon EC2) instances. When properly configured, Auto Scaling causes the number of Amazon EC2 instances to increase seamlessly during demand spikes and decrease automatically during demand lulls. Auto Scaling groups and launch configurations that point to unavailable resources do not operate as intended.')
 , ROW ('k3J2hns32g', 'en', 'Overutilized Amazon EBS Magnetic Volumes', 'Checks for Amazon Elastic Block Store (EBS) Magnetic volumes that are potentially overutilized and might benefit from a more efficient configuration. A Magnetic volume is designed for applications with moderate or bursty I/O requirements, and the IOPS rate is not guaranteed. It delivers approximately 100 IOPS on average, with a best-effort ability to burst to hundreds of IOPS. For consistently higher IOPS, you can use a Provisioned IOPS (SSD) volume. For bursty IOPS, you can use a General Purpose (SSD) volume. For more information, see <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html" target="_blank">Amazon EBS Volume Types</a>.')
-, ROW ('796d6f3D83', 'en', 'CloudFront Content Delivery Optimization', 'Checks for cases where data transfer from Amazon Simple Storage Service (Amazon S3) buckets could be accelerated by using Amazon CloudFront, the AWS global content delivery service. When you configure CloudFront to deliver your content, requests for your content are automatically routed to the nearest edge location where content is cached, so it can be delivered to your users with the best possible performance. A high ratio of data transferred out to the data stored in the bucket indicates that you could benefit from using Amazon CloudFront to deliver the data. ')
-, ROW ('51fC20e7I2', 'en', 'Amazon Route 53 Latency Resource Record Sets', 'Checks for Amazon Route 53 latency record sets that are configured inefficiently. To allow Amazon Route 53 to route queries to the region with the lowest network latency, you should create latency resource record sets for a particular domain name (such as example.com) in different regions. If you create only one latency resource record set for a domain name, all queries are routed to one region, and you pay extra for latency-based routing without getting the benefits. Hosted zones created by AWS services wonâ€™t appear in your check results.')
-, ROW ('c9D319e7sG', 'en', 'Amazon Route 53 MX Resource Record Sets and Sender Policy Framework', 'For each MX resource record set, checks that the TXT or SPF resource record set contains a valid SPF record. The record must start with "v=spf1". The SPF record specifies the servers that are authorized to send email for your domain, which helps detect and stop email address spoofing to reduce spam. Route 53 recommends that you use a TXT record instead of an SPF record. Trusted Advisor reports this check as green as long as each MX resource record set has at least one SPF or TXT record.<br/><br/><b>Alert Criteria</b><br/>Yellow: An MX resource record set doesnâ€™t have a TXT or SPF resource record that contains a valid SPF value.<br/><br/><b>Recommended Action</b><br/>For each MX resource record set, create a TXT resource record set that contains a valid SPF value. For more information, see <a href="http://www.open-spf.org/SPF_Record_Syntax" target="_blank">Sender Policy Framework: SPF Record Syntax</a> and <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/RRSchanges_console.html" target="_blank">Creating Resource Record Sets By Using the Amazon Route 53 Console</a>.<br/><br/><b>Additional Information</b><br/><a href="http://en.wikipedia.org/wiki/Sender_Policy_Framework" target="_blank">Sender Policy Framework</a> (Wikipedia)<br/><a href="http://en.wikipedia.org/wiki/MX_record" target="_blank">MX record</a> (Wikipedia)')
-, ROW ('b73EEdD790', 'en', 'Amazon Route 53 Failover Resource Record Sets', 'Checks for Amazon Route 53 failover resource record sets that are misconfigured. When Amazon Route 53 health checks determine that the primary resource is unhealthy, Amazon Route 53 responds to queries with a secondary, backup resource record set. You must create correctly configured primary and secondary resource record sets for failover to work. Hosted zones created by AWS services wonâ€™t appear in your check results.<br/><br/><b>Alert Criteria</b><br/>Yellow: A primary failover resource record set does not have a corresponding secondary resource record set.<br/>Yellow: A secondary failover resource record set does not have a corresponding primary resource record set.<br/>Yellow: Primary and secondary resource record sets that have the same name are associated with the same health check.<br/><br/><b>Recommended Action</b><br/>If a failover resource set is missing, create the corresponding resource record set; see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/creating-failover-rrsets.html" target="_blank">Creating Failover Resource Record Sets</a>.<br/>If your resource record sets are associated with the same health check, create separate health checks for each one; see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-creating-deleting.html" target="_blank">Creating, Updating, and Deleting Health Checks</a>.<br/><br/><b>Additional Information</b><br/><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html" target="_blank">Amazon Route 53 Health Checks and DNS Failover</a>')
-, ROW ('Cb877eB72b', 'en', 'Amazon Route 53 Deleted Health Checks', 'Checks for resource record sets that are associated with health checks that have been deleted. Amazon Route 53 does not prevent you from deleting a health check that is associated with one or more resource record sets. If you delete a health check without updating the associated resource record sets, the routing of DNS queries for your DNS failover configuration will not work as intended. Hosted zones created by AWS services wonâ€™t appear in your check results.<br/><br/><b>Alert Criteria</b><br/>Yellow: A resource record set is associated with a health check that has been deleted.<br/><br/><b>Recommended Action</b><br/>Create a new health check and associate it with the resource record set; see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-creating-deleting.html" target="_blank">Creating, Updating, and Deleting Health Checks</a> and <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-adding-to-rrsets.html" target="_blank">Adding Health Checks to Resource Record Sets</a>.<br/><br/><b>Additional Information</b><br/><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html" target="_blank">Amazon Route 53 Health Checks and DNS Failover</a><br/><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-simple-configs.html" target="_blank">How Health Checks Work in Simple Amazon Route 53 Configurations</a>')
-, ROW ('vjafUGJ9H0', 'en', 'AWS CloudTrail Logging', 'Checks for your use of AWS CloudTrail. CloudTrail provides increased visibility into activity in your AWS account by recording information about AWS API calls made on the account. You can use these logs to determine, for example, what actions a particular user has taken during a specified time period or which users have taken actions on a particular resource during a specified time period. Because CloudTrail delivers log files to an Amazon Simple Storage Service (Amazon S3) bucket, CloudTrail must have write permissions for the bucket. If a trail applies to all regions (the default when creating a new trail), the trail appears multiple times in the Trusted Advisor report.')
-, ROW ('a2sEc6ILx', 'en', 'ELB Listener Security', 'Checks for load balancers with listeners that do not use recommended security configurations for encrypted communication. AWS recommends using a secure protocol (HTTPS or SSL), up-to-date security policies, and ciphers and protocols that are secure.<br/>When you use a secure protocol for a front-end connection (client to load balancer), the requests are encrypted between your clients and the load balancer, which is more secure.<br/>Elastic Load Balancing provides predefined security policies  with ciphers and protocols that adhere to AWS security best practices. New versions of predefined policies are released as new configurations become available. <br/><br/><b>Alert Criteria</b><br/>Yellow: A load balancer has no listener that uses a secure protocol (HTTPS or SSL). <br/>Yellow: A load balancer listener uses an outdated predefined SSL security policy. <br/>Yellow: A load balancer listener uses a cipher or protocol that is not recommended. <br/>Red: A load balancer listener uses an insecure cipher or protocol.<br/><br/><b>Recommended Action</b><ul><li>If the traffic to your load balancer must be secure, use either the HTTPS or the SSL protocol for the front-end connection.</li><li>Upgrade your load balancer to the latest version of the predefined SSL security policy.</li> <li>Use only the recommended ciphers and protocols.</li> </ul>For more information, see <a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-listener-config.html">Listener Configurations for Elastic Load Balancing</a>.<br/><br/><b>Additional Resources</b><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/using-elb-listenerconfig-quickref.html">Listener Configurations Quick Reference</a><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/ssl-config-update.html">Update SSL Negotiation Configuration of Your Load Balancer</a><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-ssl-security-policy.html">SSL Negotiation Configurations for Elastic Load Balancing</a><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/elb-security-policy-table.html">SSL Security Policy Table</a><br/>')
-, ROW ('xSqX82fQu', 'en', 'ELB Security Groups', 'Checks for load balancers configured with a missing security group or a security group that allows access to ports that are not configured for the load balancer. If a security group associated with a load balancer is deleted, the load balancer does not work as expected. If a security group allows access to ports that are not configured for the load balancer, the risk of loss of data or malicious attacks increases. <br/><br/><b>Alert Criteria</b><br/>Yellow: The inbound rules of an Amazon VPC security group associated with a load balancer allow access to ports that are not defined in the load balancers listener configuration. <br/>Red: A security group associated with a load balancer does not exist. <br/><br/><b>Recommended Action</b><br/>Configure the security group rules to restrict access to only those ports and protocols that are defined in the load balancer listener configuration, plus the ICMP protocol to support Path MTU Discovery. See <a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html">Listeners for Your Classic Load Balancer</a> and <a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html#elb-vpc-security-groups">Security Groups for Load Balancers in a VPC</a>.<br/>If a security group is missing, apply a new security group to the load balancer. Create security group rules that restrict access to only those ports and protocols that are defined in the load balancer listener configuration. See <a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-security-groups.html#elb-vpc-security-groups">Security Groups for Load Balancers in a VPC</a>. <br/><br/><b>Additional Resources</b><br/><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html">Elastic Load Balancing User Guide</a> <br/><a target="_blank" href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-configure-load-balancer.html">Configure Your Classic Load Balancer</a>')
-, ROW ('xdeXZKIUy', 'en', 'ELB Cross-Zone Load Balancing', 'With Cross-zone load balancing turned off, there is a risk of service unavailability due to uneven distribution of traffic or backend overloading. This problem can occur when clients incorrectly cache DNS information, or when there are an unequal number of instances in each Availability Zone (for example, if you have taken down some instances for maintenance).<br/><br/><b>Alert Criteria</b><br/>Yellow: Cross-zone load balancing is not enabled for a load balancer.<br/><br/><b>Recommended Action</b><br/>Confirm that the Amazon EC2 instances registered with the load balancer are launched in multiple Availability Zones, and then enable cross-zone load balancing for the load balancer. For more information, see <a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#AZ-Region">Availability Zones and Regions</a> and <a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/enable-disable-crosszone-lb.html">Enable or Disable Cross-Zone Load Balancing for Your Load Balancer</a>.<br/><br/><b>Additional Resources</b><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#request-routing">Request Routing</a><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html">Elastic Load Balancing Concepts</a>')
-, ROW ('7qGXsKIUw', 'en', 'ELB Connection Draining', 'Checks for load balancers that do not have connection draining enabled. When connection draining is not enabled and you remove (deregister) an Amazon EC2 instance from a load balancer, the load balancer stops routing traffic to that instance and closes the connection. When connection draining is enabled, the load balancer stops sending new requests to the deregistered instance but keeps the connection open to serve active requests.<br/><br/><b>Alert Criteria</b><br/> Yellow: Connection draining is not enabled for a load balancer.<br/><br/> <b>Recommended Action</b><br/>Enable connection draining for the load balancer. For more information, see <a target="_blank" href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#conn-drain">Connection Draining</a> and <a target="_blank" href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/config-conn-drain.html">Enable or Disable Connection Draining for Your Load Balancer</a>.<br/><br/><b>Additional Resources</b><br/><a target="_blank" href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html">Elastic Load Balancing Concepts</a>')
+, ROW ('hjLMh88uM8', 'en', 'Idle Load Balancers', 'Checks your Elastic Load Balancing configuration for load balancers that are not actively used. Any load balancer that is configured accrues charges. If a load balancer has no associated back-end instances or if network traffic is severely limited, the load balancer is not being used effectively.')
+, ROW ('Hs4Ma3G177', 'en', 'Auto scaling groups associated with a load balancer should use load balancer health checks', 'Checks if your Auto Scaling groups that are associated with a load balancer are using Elastic Load Balancing health checks.')
+, ROW ('Hs4Ma3G178', 'en', 'Security groups should only allow unrestricted incoming traffic for authorized ports', 'Checks if the security groups allow unrestricted incoming traffic. The check fails if ports allow unrestricted traffic on ports other than 80 and 443, which are default values for parameter authorizedTcpPorts.')
+, ROW ('BueAdJ7NrP', 'en', 'Amazon S3 Bucket Logging', 'Checks the logging configuration of Amazon Simple Storage Service (Amazon S3) buckets. When server access logging is enabled, detailed access logs are delivered hourly to a bucket that you choose. An access log record contains details about each request, such as the request type, the resources specified in the request, and the time and date the request was processed. By default, bucket logging is not enabled; you should enable logging if you want to perform security audits or learn more about users and usage patterns.')
+, ROW ('Hs4Ma3G179', 'en', 'SNS topics should be encrypted at-rest using AWS KMS', 'Checks if an Amazon SNS topic is encrypted at rest using AWS KMS.')
+, ROW ('xdeXZKIUy', 'en', 'ELB Cross-Zone Load Balancing', 'With Cross-zone load balancing turned off, there is a risk of service unavailability due to uneven distribution of traffic or backend overloading. This problem can occur when clients incorrectly cache DNS information, or when there are an unequal number of instances in each Availability Zone (for example, if you have taken down some instances for maintenance).<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: Cross-zone load balancing is not enabled for a load balancer.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Confirm that the Amazon EC2 instances registered with the load balancer are launched in multiple Availability Zones, and then enable cross-zone load balancing for the load balancer. For more information, see <a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#AZ-Region">Availability Zones and Regions</a> and <a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/enable-disable-crosszone-lb.html">Enable or Disable Cross-Zone Load Balancing for Your Load Balancer</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#request-routing">Request Routing</a><br/><a target="_blank" href="https://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html">Elastic Load Balancing Concepts</a>')
+, ROW ('gW7HH0l7J9', 'en', 'CloudFormation Stacks', 'Checks for usage that is more than 80% of the CloudFormation Stacks Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('gI7MM0l7J2', 'en', 'EBS Provisioned IOPS SSD (io2) Volume Storage', 'Checks for usage that is more than 80% of the EBS Provisioned IOPS SSD (io2) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G270', 'en', 'EC2 Auto Scaling groups should use EC2 launch templates', 'Checks if an Amazon EC2 Auto Scaling group is created from an EC2 launch template. This check fails if an Amazon EC2 Auto Scaling group is not created with a launch template or if a launch template is not specified in a mixed instances policy.')
+, ROW ('Hs4Ma3G271', 'en', 'API Gateway routes should specify an authorization type', 'Checks if Amazon API Gateway routes have an authorization type. The check fails if the API Gateway route does not specify an authorization type')
+, ROW ('Hs4Ma3G150', 'en', 'Elasticsearch domains should encrypt data sent between nodes', 'Checks if Elasticsearch domains have node-to-node encryption enabled.')
+, ROW ('Hs4Ma3G272', 'en', 'Users should not have root access to SageMaker notebook instances', 'Checks if root access is turned off for Amazon SageMaker notebook instances. The check fails if root access is turned on for a SageMaker notebook instance.')
+, ROW ('Hs4Ma3G151', 'en', 'An RDS event notifications subscription should be configured for critical database parameter group events', 'Checks if an Amazon RDS Event subscription for RDS parameter groups is configured to notify on event category of "configuration change".')
+, ROW ('Hs4Ma3G273', 'en', 'Security contact information should be provided for an AWS account.', 'Checks if an Amazon Web Services (AWS) account has security contact information. The check fails if security contact information is not provided for the account.')
+, ROW ('Hs4Ma3G152', 'en', 'An RDS event notifications subscription should be configured for critical database instance events', 'Checks if an Amazon RDS Event subscription for RDS instances is configured to notify on event categories of both "maintenance", "configuration change", and "failure".')
+, ROW ('EM8b3yLRTr', 'en', 'ELB Application Load Balancers', 'Checks for usage that is more than 80% of the ELB Application Load Balancers Limit. Classic Load Balancers and Network Load Balancers have separate limits. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.<br/>')
+, ROW ('rT7WW0l7J9', 'en', 'IAM Server Certificates', 'Checks for usage that is more than 80% of the IAM Server Certificates Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G274', 'en', 'SageMaker notebook instances should be launched in a custom VPC', 'Checks if an Amazon SageMaker notebook instance is launched within a custom VPC. The check fails if a SageMaker notebook instance is not launched within a custom VPC.')
+, ROW ('Hs4Ma3G153', 'en', 'RDS instances should not use a database engine default port', 'Checks if RDS instances use the default port of that database engine.')
+, ROW ('Hs4Ma3G275', 'en', 'CloudFront distributions should not point to non-existent S3 origins', 'Checks if Amazon CloudFront distributions are pointing to non-existent S3 origins. The check fails for a CloudFront distribution if the origin is configured to point to a non-existent bucket. This check only applies to CloudFront distributions where an S3 bucket without static website hosting is the S3 origin.')
+, ROW ('Hs4Ma3G154', 'en', 'An RDS event notifications subscription should be configured for critical database security group events', 'Checks if an Amazon RDS Event subscription for RDS security groups is configured to notify on event categories of both "configuration change" and "failure".')
 , ROW ('N415c450f2', 'en', 'CloudFront Header Forwarding and Cache Hit Ratio', 'Checks the HTTP request headers that CloudFront currently receives from the client and forwards to your origin server. Some headers, such as Date or User-Agent, significantly reduce the cache hit ratio (the proportion of requests that are served from a CloudFront edge cache). This increases the load on your origin and reduces performance because CloudFront must forward more requests to your origin.')
-, ROW ('N425c450f2', 'en', 'CloudFront Custom SSL Certificates in the IAM Certificate Store', 'Checks the SSL certificates for CloudFront alternate domain names in the IAM certificate store and alerts you if the certificate is expired, will soon expire, uses outdated encryption, or is not configured correctly for the distribution. When a custom certificate for an alternate domain name expires, browsers that display your CloudFront content might show a warning message about the security of your website. Certificates that are encrypted by using the SHA-1 hashing algorithm are being deprecated by web browsers such as Chrome and Firefox.  If a certificate doesnt contain any domain names that match either Origin Domain Name or the domain name in the Host header of viewer requests, CloudFront returns an HTTP status code 502 (bad gateway) to the user. For more information, see <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/SecureConnections.html#CNAMEsAndHTTPS" target="_blank">Using Alternate Domain Names and HTTPS</a>.')
-, ROW ('N430c450f2', 'en', 'CloudFront SSL Certificate on the Origin Server', 'Checks your origin server for SSL certificates that are expired, about to expire, missing, or that use outdated encryption. If a certificate is expired, CloudFront responds to requests for your content with HTTP status code 502, Bad Gateway. Certificates that were encrypted by using the SHA-1 hashing algorithm are being deprecated by web browsers such as Chrome and Firefox. Depending on the number of SSL certificates that you have associated with your CloudFront distributions, this check might add a few cents per month to your bill with your web hosting provider, for example, AWS if youre using EC2 or ELB as the origin for your CloudFront distribution. This check does not validate your origin certificate chain or certificate authorities; you can check these in your CloudFront configuration. ')
-, ROW ('Bh2xRR2FGH', 'en', 'Amazon EC2 to EBS Throughput Optimization', 'Checks for Amazon EBS volumes whose performance might be affected by the maximum throughput capability of the Amazon EC2 instance they are attached to. To optimize performance, you should ensure that the maximum throughput of an EC2 instance is greater than the aggregate maximum throughput of the attached EBS volumes. This check computes the total EBS volume throughput for each five-minute period in the preceding day (UTC) for each EBS-optimized instance and alerts you if usage in more than half of those periods was greater than 95% of the maximum throughput of the EC2 instance.<br/><br/> <b>Alert Criteria</b><br/> Yellow: In the preceding day (UTC), the aggregate throughput (megabytes/sec) of the EBS volumes attached to the EC2 instance exceeded 95% of the published throughput between the instance and the EBS volumes more than 50% of time.<br/><br/> <b>Recommended Action</b><br/> Compare the maximum throughput of your EBS volumes (see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html" target="_blank">Amazon EBS Volume Types</a>) with the maximum throughput of the EC2 instance they are attached to (see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html#ebs-optimization-support" target="_blank">Instance Types That Support EBS Optimization</a>). Consider attaching your volumes to an instance that supports higher throughput to EBS for optimal performance.<br/><br/> <b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html" target="_blank">Amazon EBS Volume Types</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html" target="_blank">Amazon EBS-Optimized Instances</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html" target="_blank">Monitoring the Status of Your Volumes</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-attaching-volume.html" target="_blank">Attaching an Amazon EBS Volume to an Instance</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-detaching-volume.html" target="_blank">Detaching an Amazon EBS Volume from an Instance</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-volume.html" target="_blank">Deleting an Amazon EBS Volume</a> ')
-, ROW ('N420c450f2', 'en', 'CloudFront Alternate Domain Names', 'Checks Amazon CloudFront distributions for alternate domain names (CNAMES) that have incorrectly configured DNS settings. If a CloudFront distribution includes alternate domain names, the DNS configuration for the domains must route DNS queries to that distribution.<br/><br/>Note: This check assumes Amazon Route 53 DNS and Amazon CloudFront distribution are configured in the same AWS account. As such the Alert list may include resources otherwise working as expected due to DNS setting outsides of this AWS account.<br/><br/><b>Alert Criteria</b><br/>Yellow: A CloudFront distribution includes alternate domain names, but the DNS configuration is not correctly set up with a CNAME record or an Amazon Route 53 alias resource record.<br/>Yellow: A CloudFront distribution includes alternate domain names, but Trusted Advisor could not evaluate the DNS configuration because there were too many redirects.<br/>Yellow: A CloudFront distribution includes alternate domain names, but Trusted Advisor could not evaluate the DNS configuration for some other reason, most likely because of a timeout.<br/><br/><b>Recommended Action</b><br/>Update the DNS configuration to route DNS queries to the CloudFront distribution; see <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/CNAMEs.html" target="_blank">Using Alternate Domain Names (CNAMEs)</a>. If youre using Amazon Route 53 as your DNS service, see <a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfront-distribution.html" target="_blank">Routing Traffic to an Amazon CloudFront Web Distribution by Using Your Domain Name</a>. If the check timed out, try refreshing the check.<br/><br/><b>Additional Resources</b><br/><a target="_blank" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html">Amazon CloudFront Developer Guide</a>')
-, ROW ('DqdJqYeRm5', 'en', 'IAM Access Key Rotation', 'Checks for active IAM access keys that have not been rotated in the last 90 days.  When you rotate your access keys regularly, you reduce the chance that a compromised key could be used without your knowledge to access resources. For the purposes of this check, the last rotation date and time is when the access key was created or most recently activated. The access key number and date come from the <b>access_key_1_last_rotated</b> and <b>access_key_2_last_rotated</b> information in the most recent IAM credential report. Because the regeneration frequency of a credential report  is restricted, refreshing this check might not reflect recent changes (for details, see <a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_getting-report.html">Getting Credential Reports for Your AWS Account</a>).<br/>In order to create and rotate access keys, a user must have the appropriate permissions. For more information, see <a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_delegate-permissions_examples.html#creds-policies-credentials">Allow Users to Manage Their Own Passwords, Access Keys, and SSH Keys</a>.<br/><br/><b>Alert Criteria</b><br/>Green: The access key is active and has been rotated in the last 90 days.<br/>Yellow: The access key is active and has been rotated in the last 2 years, but more than 90 days ago.<br/>Red: The access key is active and has not been rotated in the last 2 years.<br/><br/><b>Recommended Action</b><br/>Rotate access keys on a regular basis. See <a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_RotateAccessKey">Rotating Access Keys</a> and <a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html">Managing Access Keys for IAM Users</a>.<br/><br/><b>Additional Resources</b><br/><a target="_blank" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html">IAM Best Practices</a><br/><a target="_blank" href="https://blogs.aws.amazon.com/security/post/Tx15CIT22V4J8RP/How-to-rotate-access-keys-for-IAM-users">How to rotate access keys for IAM users</a> (AWS blog)')
-, ROW ('12Fnkpl8Y5', 'en', 'Exposed Access Keys', 'Checks popular code repositories for access keys that have been exposed to the public and for irregular Amazon Elastic Compute Cloud (Amazon EC2) usage that could be the result of a compromised access key. An access key consists of an access key ID and the corresponding secret access key. Exposed access keys pose a security risk to your account and other users, could lead to excessive charges from unauthorized activity or abuse, and violate the <a target="_blank" href="https://aws.amazon.com/agreement/">AWS Customer Agreement</a>. If your access key is exposed, take immediate action to secure your account. To protect your account from excessive charges, AWS temporarily limits your ability to create certain AWS resources when exposed access keys are identified. This does not make your account secure; it only partially limits the unauthorized usage for which you could be charged. Note: This check does not guarantee the identification of exposed access keys or compromised EC2 instances. You are ultimately responsible for the safety and security of your access keys and AWS resources.   <br/><br/>If a deadline is shown for an access key, AWS may suspend your AWS account if the unauthorized usage is not stopped by that date. If you believe an alert is in error, <a href="https://console.aws.amazon.com/support/home?#/case/create?issueType=customer-service&serviceCode=customer-account&categoryCode=security" target="_blank">contact AWS Support</a>.<br/><br/>The information displayed in Trusted Advisor may not reflect the most recent state of your account. No exposed access keys are marked as resolved until all exposed access keys on the account have been resolved. This data synchronization can take up to one week.<br/><br/><b>Alert Criteria</b><br/>Red: Potentially compromised - AWS has identified an access key ID and corresponding secret access key that have been exposed on the Internet and may have been compromised (used).<br/>Red: Exposed - AWS has identified an access key ID and corresponding secret access key that have been exposed on the Internet.<br/>Red: Suspected - Irregular Amazon EC2 usage indicates that an access key may have been compromised, but it has not been identified as exposed on the Internet.<br/><br/><b>Recommended Action</b><br/>Delete the affected access key as soon as possible. If the key is associated with an IAM user, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/ManagingCredentials.html" target="_blank">Managing Access Keys for IAM Users</a>.<br/><br/>Check your account for unauthorized usage. Log in to the <a href="https://console.aws.amazon.com/" target="_blank">AWS Management Console</a> and check each service console for suspicious resources. Pay special attention to running Amazon EC2 instances, Spot Instance requests, access keys, and IAM users. You can also check overall usage on the <a href="https://console.aws.amazon.com/billing/home#/" target="_blank">Billing & Cost Management Dashboard</a>.<br/><br/><b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/general/latest/gr/aws-access-keys-best-practices.html" target="_blank">Best Practices for Managing AWS Access Keys</a><br/><a href="https://docs.aws.amazon.com/general/latest/gr/aws-security-audit-guide.html" target="_blank">AWS Security Audit Guidelines</a>')
-, ROW ('G31sQ1E9U', 'en', 'Underutilized Amazon Redshift Clusters', 'Checks your Amazon Redshift configuration for clusters that appear to be underutilized. If an Amazon Redshift cluster has not had a connection for a prolonged period of time or is using a low amount of CPU, you can use lower-cost options such as downsizing the cluster or shutting down the cluster and taking a final snapshot. Final snapshots are retained even after you delete your cluster.<br/><br/><b>Alert Criteria</b><br/>Yellow: A running cluster has not had a connection in the last 7 days.<br/>Yellow: A running cluster had less than 5% cluster-wide average CPU utilization for 99% of the last 7 days.<br/><br/><b>Recommended Action</b><br/>Consider shutting down the cluster and taking a final snapshot, or downsizing the cluster. See <a href="https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#rs-mgmt-shutdown-delete-cluster" target="_blank">Shutting Down and Deleting Clusters</a> and <a href="https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#cluster-resize-intro" target="_blank">Resizing a Cluster</a>.<br/><br/><b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/Welcome.html" target="_blank">Amazon CloudWatch Developer Guide</a>')
-, ROW ('1e93e4c0b5', 'en', 'Amazon EC2 Reserved Instance Lease Expiration', 'Checks for Amazon EC2 Reserved Instances that are scheduled to expire within the next 30 days or have expired in the preceding 30 days. Reserved Instances do not renew automatically; you can continue using an EC2 instance covered by the reservation without interruption, but you will be charged On-Demand rates. New Reserved Instances can have the same parameters as the expired ones, or you can purchase Reserved Instances with different parameters.<br/>The estimated monthly savings we show is the difference between the On-Demand and Reserved Instance rates for the same instance type.<br/><br/><b>Alert Criteria</b><br/>Yellow: The Reserved Instance lease expires in less than 30 days.<br/>Yellow: The Reserved Instance lease expired in the preceding 30 days.<br/><br/><b>Recommended Action</b><br/>Consider purchasing a new Reserved Instance to replace the one that is nearing the end of its term. For more information, see <a href="https://aws.amazon.com/ec2/purchasing-options/reserved-instances/buyer/" target="_blank">How to Purchase Reserved Instances</a> and <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-concepts-buying.html" target="_blank">Buying Reserved Instances</a>.<br/><br/> <b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-on-demand-reserved-instances.html" target="_blank">Reserved Instances</a><br/><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html" target="_blank">Instance Types</a>')
-, ROW ('R365s2Qddf', 'en', 'Amazon S3 Bucket Versioning', 'Checks for Amazon Simple Storage Service buckets that do not have versioning enabled, or have versioning suspended. When versioning is enabled, you can easily recover from both unintended user actions and application failures. Versioning allows you to preserve, retrieve, and restore any version of any object stored in a bucket. You can use lifecycle rules to manage all versions of your objects as well as their associated costs by automatically archiving objects to the Glacier storage class or removing them after a specified time period. You can also choose to require multi-factor authentication (MFA) for any object deletions or configuration changes to your buckets. <br/><br/>Versioning cannot be disabled after it has been enabled, but it can be suspended, which prevents new versions of objects from being created. Using versioning can increase your costs for Amazon S3, because you pay for storage of multiple versions of an object.<br/><br/><b>Alert Criteria</b><br/>Green: Versioning is enabled for the bucket.<br/>Yellow: Versioning is not enabled for the bucket.<br/>Yellow: Versioning is suspended for the bucket.<br/><br/><b>Recommended Action</b><br/>Enable bucket versioning on most buckets to prevent accidental deletion or overwriting. See <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html" target="_blank">Using Versioning</a> and <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/manage-versioning-examples.html" target="_blank">Enabling Versioning Programmatically</a>. <br/><br/>If bucket versioning is suspended, consider reenabling versioning. For information on working with objects in a versioning-suspended bucket, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/VersionSuspendedBehavior.html" target="_blank">Managing Objects in a Versioning-Suspended Bucket</a>.<br/><br/>When versioning is enabled or suspended, you can define lifecycle configuration rules to mark certain object versions as expired or to permanently remove unneeded object versions. For more information, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html" target="_blank">Object Lifecycle Management</a>. <br/><br/>MFA Delete requires additional authentication when the versioning status of the bucket is changed or when versions of an object are deleted. It requires the user to enter credentials and a code from an approved authentication device. For more information, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html#MultiFactorAuthenticationDelete" target="_blank">MFA Delete</a>.<br/><br/><b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/AmazonS3/latest/UG/BucketOperations.html" target="_blank">Working with Buckets</a>')
-, ROW ('0t121N1Ty3', 'en', 'AWS Direct Connect Connection Redundancy', 'Checks for regions that have only one AWS Direct Connect connection. Connectivity to your AWS resources should have two Direct Connect connections configured at all times to provide redundancy in case a device is unavailable.<br/><b>Note:</b> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><b>Alert Criteria</b><br/>Yellow:  The region has only one Direct Connect connection.<br/><br/><b>Recommended Action</b><br/>Configure an additional Direct Connect connection in this region to protect against device unavailability. For more information, see <a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Configure Redundant Connections with AWS Direct Connect</a>. To protect against site unavailability and add location redundancy, configure the additional Direct Connect connection to a different Direct Connect location.<br/><br/><b>Additional Resources</b><br/><a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Getting Started with AWS Direct Connect</a><br/><a target="_blank" href="https://aws.amazon.com/directconnect/faqs/">AWS Direct Connect FAQs</a> ')
-, ROW ('8M012Ph3U5', 'en', 'AWS Direct Connect Location Redundancy', 'Checks for regions with one or more AWS Direct Connect connections and only one AWS Direct Connect location. Connectivity to your AWS resources should have Direct Connect connections configured to different Direct Connect locations to provide redundancy in case a location is unavailable.<br/><b>Note:</b> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><b>Alert Criteria</b><br/>Yellow:  The Direct Connect connections in the region are not configured to different locations.<br/><br/><b>Recommended Action</b><br/>Configure a Direct Connect connection that uses a different Direct Connect location to protect against location unavailability. For more information, see <a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Getting Started with AWS Direct Connect</a>.<br/><br/><b>Additional Resources</b><br/><a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Getting Started with AWS Direct Connect</a><br/><a target="_blank" href="https://aws.amazon.com/directconnect/faqs/">AWS Direct Connect FAQs</a>')
-, ROW ('4g3Nt5M1Th', 'en', 'AWS Direct Connect Virtual Interface Redundancy', 'Checks for virtual private gateways with Direct Connect virtual interfaces (VIFs) that are not configured on at least two Direct Connect connections. Connectivity to your virtual private gateway should have multiple virtual interfaces configured across multiple Direct Connect connections and locations to provide redundancy in case a device or location is unavailable. <br/><b>Note:</b> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><b>Alert Criteria</b><br/>Yellow:  A virtual private gateway has less than two virtual interfaces, or the interfaces are not configured to multiple Direct Connect connections. <br/><br/><b>Recommended Action</b><br/>Configure at least two virtual interfaces that are configured to two Direct Connect connections to protect against device or location unavailability. See <a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getstarted.html#createvirtualinterface">Create a Virtual Interface.</a><br/><br/><b>Additional Resources</b><br/><a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Getting Started with AWS Direct Connect</a><br/><a target="_blank" href="https://aws.amazon.com/directconnect/faqs/">AWS Direct Connect FAQs</a> <br/><a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html">Working With AWS Direct Connect Virtual Interfaces</a>')
-, ROW ('xuy7H1avtl', 'en', 'Amazon Aurora DB Instance Accessibility', 'Checks for cases where an Amazon Aurora DB cluster has both private and public instances. When your primary instance fails, a replica can be promoted to a primary instance. If that replica is private, users who have only public access would no longer be able to connect to the database after failover. Its best practice for all the DB instances in a cluster to have the same accessibility.<br/><br/><b>Alert Criteria</b><br/>Yellow: The instances in an Aurora DB cluster have different accessibility (a mix of public and private).<br/><br/><b>Recommended Action</b><br/>Modify the <b>Publicly Accessible</b> setting of the instances in the DB cluster so that they are all either public or private. For details, see the instructions for MySQL instances at <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ModifyInstance.MySQL.html" target="_blank">Modifying a DB Instance Running the MySQL Database Engine</a>.<br/><br/><b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Aurora.Managing.html#Aurora.Managing.FaultTolerance" target="_blank">Fault Tolerance for an Aurora DB Cluster</a>')
-, ROW ('ePs02jT06w', 'en', 'Amazon EBS Public Snapshots', 'Checks the permission settings for your Amazon Elastic Block Store (Amazon EBS) volume snapshots and alerts you if any snapshots are marked as public. When you make a snapshot public, you give all AWS accounts and users access to all the data on the snapshot. If you want to share a snapshot with particular users or accounts, mark the snapshot as private, and then specify the user or accounts you want to share the snapshot data with. <b>Note</b>: Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><b>Alert Criteria</b><br/>Red: The EBS volume snapshot is marked as public.<br/><br/><b>Recommended Action</b><br/>Unless you are certain you want to share all the data in the snapshot with all AWS accounts and users, modify the permissions: mark the snapshot as private, and then specify the accounts that you want to give permissions to. For more information, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-modifying-snapshot-permissions.html" target="_blank">Sharing an Amazon EBS Snapshot</a>. Note: For temporary technical reasons, items in this check cannot be excluded from view in the Trusted Advisor console.To modify permissions for your snapshots directly, you can use a runbook in the AWS Systems Manager console. For more information, see <a href="https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awssupport-modifyebssnapshotpermission.html" target="_blank">AWSSupport-ModifyEBSSnapshotPermission</a>.<br/><br/> <b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html" target="_blank">Amazon EBS Snapshots</a>')
-, ROW ('rSs93HQwa1', 'en', 'Amazon RDS Public Snapshots', 'Checks the permission settings for your Amazon Relational Database Service (Amazon RDS) DB snapshots and alerts you if any snapshots are marked as public. When you make a snapshot public, you give all AWS accounts and users access to all the data on the snapshot. If you want to share a snapshot with particular users or accounts, mark the snapshot as private, and then specify the user or accounts you want to share the snapshot data with. <b>Note</b>: Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><b>Alert Criteria</b><br/>Red: The RDS  snapshot is marked as public.<br/><br/><b>Recommended Action</b><br/>Unless you are certain you want to share all the data in the snapshot with all AWS accounts and users, modify the permissions: mark the snapshot as private, and then specify the accounts that you want to give permissions to. For more information, see <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ShareSnapshot.html" target="_blank">Sharing a DB Snapshot or DB Cluster Snapshot</a>. Note: For temporary technical reasons, items in this check cannot be excluded from view in the Trusted Advisor console.To modify permissions for your snapshots directly, you can use a runbook in the AWS Systems Manager console. For more information, see <a href="https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awssupport-modifyrdssnapshotpermission.html" target="_blank">AWSSupport-ModifyRDSSnapshotPermission</a>.<br/><br/> <b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_CommonTasks.BackupRestore.html" target="_blank">Backing Up and Restoring Amazon RDS DB Instances</a>')
-, ROW ('0Xc6LMYG8P', 'en', 'EC2 On-Demand Instances', 'Checks for usage that is more than 80% of the EC2 On-Demand Instances Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('hJ7NN0l7J9', 'en', 'SES Daily Sending Quota', 'Checks for usage that is more than 80% of the SES Daily Sending Quota Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('tV7YY0l7J9', 'en', 'EBS Provisioned IOPS (SSD) Volume Aggregate IOPS', 'Checks for usage that is more than 80% of the EBS Provisioned IOPS (SSD) Volume Aggregate IOPS Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G265', 'en', 'A WAF Regional rule group should have at least one rule', 'Checks if a WAF Regional rule group has at least one rule. The check fails if no rules are present within a rule group.')
+, ROW ('Hs4Ma3G144', 'en', 'Unused IAM user credentials should be removed', 'Checks if your IAM users have passwords or active access keys that were not used within the previous 90 days.')
+, ROW ('iqdCTZKCUp', 'en', 'Load Balancer Optimization', 'Checks your load balancer configuration. To help increase the level of fault tolerance in Amazon Elastic Compute Cloud (EC2) when using Elastic Load Balancing, we recommend running an equal number of instances across multiple Availability Zones in a region. A load balancer that is configured accrues charges, so this is a cost-optimization check as well.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A load balancer is enabled for a single Availability Zone.<br/>Yellow: A load balancer is enabled for an Availability Zone that has no active instances.<br/>Yellow: The Amazon EC2 instances that are registered with a load balancer are unevenly distributed across Availability Zones. (The difference between the highest and lowest instance counts in utilized Availability Zones is more than 1, and the difference is more than 20% of the highest count.)<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Ensure that your load balancer points to active and healthy instances in at least two Availability Zones. For more information, see <a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/enable-disable-az.html#US_AddLBAvailabilityZone" target="_blank">Add Availability Zone</a>.<br/>If your load balancer is configured for an Availability Zone with no healthy instances, or if there is an imbalance of instances across the Availability Zones, determine if all the Availability Zones are necessary. Omit any unnecessary Availability Zones and ensure there is a balanced distribution of instances across the remaining Availability Zones. For more information, see <a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/enable-disable-az.html#US_ShrinkLBApp04" target="_blank">Remove Availability Zone</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#AZ-Region" target="_blank">Availability Zones and Regions</a><br/><a href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/UserScenarios.html" target="_blank">Managing Load Balancers</a><br/><a href="http://aws.amazon.com/articles/1636185810492479" target="_blank">Best Practices in Evaluating Elastic Load Balancing</a>')
 , ROW ('gI7MM0l7J9', 'en', 'EBS Provisioned IOPS SSD (io1) Volume Storage', 'Checks for usage that is more than 80% of the EBS Provisioned IOPS SSD (io1) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('eI7KK0l7J9', 'en', 'EBS Active Snapshots', 'Checks for usage that is more than 80% of the EBS Active Snapshots Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('dH7RR0l6J9', 'en', 'EBS General Purpose SSD (gp2) Volume Storage', 'Checks for usage that is more than 80% of the EBS General Purpose SSD (gp2) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('cG7HH0l7J9', 'en', 'EBS Magnetic (standard) Volume Storage', 'Checks for usage that is more than 80% of the EBS Magnetic (standard) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('aW9HH0l8J6', 'en', 'EC2-Classic Elastic IP Addresses', 'Checks for usage that is more than 80% of the EC2-Classic Elastic IP Addresses Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('iH7PP0l7J9', 'en', 'EC2 Reserved Instance Leases', 'Checks for usage that is more than 80% of the EC2 Reserved Instance Leases Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G266', 'en', 'A WAF Regional web ACL should have at least one rule or rule group', 'Checks if a WAF Regional web ACL contains any WAF rules or WAF rule groups. This check fails if a web ACL does not contain any WAF rules or rule groups.')
+, ROW ('Hs4Ma3G145', 'en', 'Amazon ECS task definitions should have secure networking modes and user definitions.', 'Checks if an Amazon ECS Task Definition with host networking mode has "privileged" or "user" container definitions. The check fails with host network mode and container definitions are privileged=false or empty and user=root or empty.')
+, ROW ('Ti39halfu8', 'en', 'Amazon RDS Idle DB Instances', 'Checks the configuration of your Amazon Relational Database Service (Amazon RDS) for any DB instances that appear to be idle. If a DB instance has not had a connection for a prolonged period of time, you can delete the instance to reduce costs. If persistent storage is needed for data on the instance, you can use lower-cost options such as taking and retaining a DB snapshot. Manually created DB snapshots are retained until you delete them.')
+, ROW ('Hs4Ma3G267', 'en', 'A WAF global rule should have at least one condition', 'Checks if a WAF global rule has at least one condition. This check fails if no conditions are present within a rule.')
+, ROW ('Hs4Ma3G146', 'en', 'ECS services should not have public IP addresses assigned to them automatically', 'Checks if ECS services are configured to automatically assign public IP addresses. This check fails if AssignPublicIP is ENABLED.')
+, ROW ('j3DFqYTe29', 'en', 'Large Number of EC2 Security Group Rules Applied to an Instance', 'Checks for Amazon Elastic Compute Cloud (EC2) instances that have a large number of security group rules. Performance can be degraded if an instance has a large number of rules.')
+, ROW ('Hs4Ma3G268', 'en', 'A WAF global rule group should have at least one rule', 'Checks if a WAF global rule group has at least one rule. The check fails if no rules are present within a rule group.')
+, ROW ('Hs4Ma3G147', 'en', 'Amazon Elasticsearch Service domains should be in a VPC', 'Checks whether Amazon Elasticsearch Service domains are in a VPC. It does not evaluate the VPC subnet routing configuration to determine public reachability. This check also does not check whether the Amazon OpenSearch Service resource-based policy permits public access by other accounts or external entities. You should ensure that Amazon Elasticsearch Service domains are not attached to public subnets. See Resource-based policies (https://docs.aws.amazon.com/opensearch-service/latest/developerguide/ac.html#ac-types-resource) in the Amazon OpenSearch Service (successor to Amazon Elasticsearch Service) Developer Guide. You should also ensure that your VPC is configured according to the recommended best practices. See Security best practices for your VPC (https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html) in the Amazon VPC User Guide.')
+, ROW ('Hs4Ma3G269', 'en', 'A WAF global web ACL should have at least one rule or rule group', 'Checks if a WAF global web ACL contains any WAF rules or WAF rule groups. This check fails if a web ACL does not contain any WAF rules or WAF rule groups.')
+, ROW ('Hs4Ma3G148', 'en', 'Elastic Beanstalk environments should have enhanced health reporting enabled', 'Checks if enhanced health reporting is enabled for your AWS Elastic Beanstalk environments.')
+, ROW ('1qw23er45t', 'en', 'Amazon Redshift Reserved Node Optimization', 'Checks your usage of Redshift and provides recommendations on purchase of Reserved Nodes to help reduce costs incurred from using Redshift On-Demand. AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of Reserved Nodes to purchase to maximize your savings. This check covers recommendations based on partial upfront payment option with 1-year or 3-year commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: Optimizing the purchase of Redshift Reserved Nodes can help reduce costs.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>See the <a href="https://console.aws.amazon.com/billing/home?/costexplorer#/costexplorer" target="_blank">Cost Explorer</a> page for more detailed recommendations, customization options (e.g. look-back period, payment option, etc.) and to purchase Redshift Reserved Nodes.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/>Information on Redshift Reserved Nodes and how they can save you money can be found <a href="http://docs.aws.amazon.com/redshift/latest/mgmt/purchase-reserved-node-instance.html" target="_blank">here</a>.')
+, ROW ('Hs4Ma3G149', 'en', 'Elastic Beanstalk managed platform updates should be enabled', 'Checks if managed platform updates are enabled for the AWS Elastic Beanstalk environment.')
+, ROW ('Cb877eB72b', 'en', 'Amazon Route 53 Deleted Health Checks', 'Checks for resource record sets that are associated with health checks that have been deleted. Amazon Route 53 does not prevent you from deleting a health check that is associated with one or more resource record sets. If you delete a health check without updating the associated resource record sets, the routing of DNS queries for your DNS failover configuration will not work as intended. Hosted zones created by AWS services wonâ€™t appear in your check results.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A resource record set is associated with a health check that has been deleted.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Create a new health check and associate it with the resource record set; see <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-creating-deleting.html" target="_blank">Creating, Updating, and Deleting Health Checks</a> and <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-adding-to-rrsets.html" target="_blank">Adding Health Checks to Resource Record Sets</a>.<br/><br/><h4 class=headerBodyStyle>Additional Information</h4><br/><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html" target="_blank">Amazon Route 53 Health Checks and DNS Failover</a><br/><a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-simple-configs.html" target="_blank">How Health Checks Work in Simple Amazon Route 53 Configurations</a>')
+, ROW ('Hs4Ma3G280', 'en', 'Application, Network and Gateway Load Balancers should span multiple Availability Zones', 'Checks if an Elastic Load Balancer V2 (Application, Network, or Gateway Load Balancer) has registered instances from multiple Availability Zones. The check fails if an Elastic Load Balancer V2 has instances registered in less than 2 Availability Zones.')
+, ROW ('796d6f3D83', 'en', 'CloudFront Content Delivery Optimization', 'Checks for cases where data transfer from Amazon Simple Storage Service (Amazon S3) buckets could be accelerated by using Amazon CloudFront, the AWS global content delivery service. When you configure CloudFront to deliver your content, requests for your content are automatically routed to the nearest edge location where content is cached, so it can be delivered to your users with the best possible performance. A high ratio of data transferred out to the data stored in the bucket indicates that you could benefit from using Amazon CloudFront to deliver the data. ')
+, ROW ('Hs4Ma3G160', 'en', 'IAM authentication should be configured for RDS instances', 'Checks if an RDS DB instance has IAM database authentication enabled.')
+, ROW ('Hs4Ma3G161', 'en', 'IAM authentication should be configured for RDS clusters', 'Checks if an RDS DB cluster has IAM database authentication enabled.')
+, ROW ('Hs4Ma3G162', 'en', 'RDS automatic minor version upgrades should be enabled', 'Checks if automatic minor version upgrades are enabled for the Amazon RDS database instance.')
+, ROW ('Hs4Ma3G163', 'en', 'RDS DB clusters should be configured to copy tags to snapshots', 'Checks if RDS DB clusters are configured to copy all tags to snapshots when the snapshots are created.')
+, ROW ('Hs4Ma3G164', 'en', 'RDS DB instances should be configured to copy tags to snapshots', 'Checks if RDS DB instances are configured to copy all tags to snapshots when the snapshots are created.')
+, ROW ('Hs4Ma3G165', 'en', 'RDS instances should be deployed in a VPC', 'Checks if an RDS instance is deployed in a VPC (EC2-VPC).')
+, ROW ('keAhfbH5yb', 'en', 'RDS Event Subscriptions', 'Checks for usage that is more than 80% of the RDS Event Subscriptions Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('c5ftjdfkMr', 'en', 'DynamoDB Write Capacity', 'Checks for usage that is more than 80% of the DynamoDB Provisioned Throughput Limit for Writes per Account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G276', 'en', 'A WAFV2 web ACL should have at least one rule or rule group', 'Checks if a WAFV2 web ACL contains at least one WAF rule or WAF rule group. The check fails if a web ACL does not contain any WAF rule or rule group.')
+, ROW ('Hs4Ma3G155', 'en', 'EC2 instances should be managed by AWS Systems Manager', 'Checks if the Amazon EC2 instances in your account are managed by AWS Systems Manager.')
+, ROW ('Cm24dfsM13', 'en', 'Amazon Comprehend Endpoint Access Risk', 'Checks the AWS Key Management Service (AWS KMS) key permissions for an endpoint where the underlying model was encrypted by using customer managed keys. If the customer managed key is disabled or the key policy was changed to alter the allowed permissions for Amazon Comprehend, the endpoint availability might be affected.<br/><h4 class=headerBodyStyle>Note:</h4> This check is automatically refreshed multiple times a day. It might take a few hours for the latest results to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: The customer managed key is disabled or the key policy was changed to alter the allowed permissions for Amazon Comprehend access.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>If the customer managed key was disabled, we recommend that you enable it. For more information, see <a href="https://docs.aws.amazon.com/kms/latest/developerguide/enabling-keys.html" target="blank">Enabling keys</a>. If the key policy was altered and you want to keep using the endpoint, we recommend that you update the KMS key policy. For more information, see <a href="https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying.html" target="blank">Changing a key policy</a>.')
+, ROW ('Hs4Ma3G277', 'en', 'EC2 launch templates should not assign public IPs to network interfaces', 'Checks if Amazon EC2 launch templates are configured to assign public IP addresses to network interfaces upon launch. The check fails if an EC2 launch template is configured to assign a public IP address to network interfaces or if there is at least one network interface that has a public IP address.')
+, ROW ('Hs4Ma3G156', 'en', 'EC2 instances managed by Systems Manager should have a patch compliance status of COMPLIANT after a patch installation', 'Checks if the compliance status of the Amazon EC2 Systems Manager patch compliance is COMPLIANT or NON_COMPLIANT after the patch installation on the instance. It only assesses instances that are managed by AWS Systems Manager Patch Manager.')
+, ROW ('ZRxQlPsb6c', 'en', 'High Utilization Amazon EC2 Instances', 'Checks the Amazon Elastic Compute Cloud (Amazon EC2) instances that were running at any time during the last 14 days and alerts you if the daily CPU utilization was more than 90% on 4 or more days. Consistent high utilization can indicate optimized, steady performance, but it can also indicate that an application does not have enough resources. To get daily CPU utilization data, download the report for this check.')
+, ROW ('Hs4Ma3G278', 'en', 'Access logging should be configured for API Gateway V2 Stages', 'Checks if Amazon API Gateway V2 stages have access logging configured. This check fails if access log settings arenâ€™t defined.')
+, ROW ('Hs4Ma3G157', 'en', 'EC2 instances managed by Systems Manager should have an association compliance status of COMPLIANT', 'Checks if the status of the AWS Systems Manager association compliance is COMPLIANT or NON_COMPLIANT after the association is executed on an instance.')
 , ROW ('bW7HH0l7J9', 'en', 'Kinesis Shards per Region', 'Checks for usage that is more than 80% of the Kinesis Shards per Region Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('gW7HH0l7J9', 'en', 'CloudFormation Stacks', 'Checks for usage that is more than 80% of the CloudFormation Stacks Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('aW7HH0l7J9', 'en', 'Auto Scaling Launch Configurations', 'Checks for usage that is more than 80% of the Auto Scaling Launch Configurations Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('fW7HH0l7J9', 'en', 'Auto Scaling Groups', 'Checks for usage that is more than 80% of the Auto Scaling Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('jL7PP0l7J9', 'en', 'VPC', 'Checks for usage that is more than 80% of the VPC Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('kM7QQ0l7J9', 'en', 'VPC Internet Gateways', 'Checks for usage that is more than 80% of the VPC Internet Gateways Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('lN7RR0l7J9', 'en', 'EC2-VPC Elastic IP Address', 'Checks for usage that is more than 80% of the EC2-VPC Elastic IP Address Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G279', 'en', 'Amazon EC2 Auto Scaling group should cover multiple Availability Zones', 'Checks if an Auto Scaling group spans multiple Availability Zones. The check fails if an Auto Scaling group does not span multiple availability zones.')
+, ROW ('Hs4Ma3G158', 'en', 'SSM documents should not be public', 'Checks if AWS Systems Manager documents that the account owns are public. This check fails if SSM documents that have "Self" as the owner are public.')
+, ROW ('Cm24dfsM12', 'en', 'Amazon Comprehend Underutilized Endpoints', 'Checks the throughput configuration of your endpoints. This check alerts you when endpoints are not actively used for real-time inference requests. An endpoint that isnâ€™t used for more than 15 consecutive days is considered underutilized. All endpoints accrue charges based on both the throughput set and the length of time that the endpoint is active.<br/><h4 class=headerBodyStyle>Note:</h4> This check is automatically refreshed once a day.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: The endpoint is active, but hasnâ€™t been used for real-time inference requests in the past 15 days.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>If the endpoint hasnâ€™t been used in the past 15 days, we recommend that you define a scaling policy for the resource by using <a href="https://docs.aws.amazon.com/comprehend/latest/dg/comprehend-autoscaling.html" target="blank">Application Autoscaling.</a><br/>If the endpoint has a scaling policy defined and hasnâ€™t been used in the past 30 days, consider deleting the endpoint and using asynchronous inference. For more information, see <a href="https://docs.aws.amazon.com/comprehend/latest/dg/manage-endpoints-delete.html" target="blank">Deleting an endpoint with Amazon Comprehend</a>.')
+, ROW ('Hs4Ma3G159', 'en', 'Elastic File System should be configured to encrypt file data at-rest using AWS KMS', 'Checks if Amazon Elastic File System (Amazon EFS) is configured to encrypt the file data using AWS Key Management Service (AWS KMS). The check will fail if the encrypted key is set to false on DescribeFileSystems or if the KmsKeyId key on DescribeFileSystems does not match the KmsKeyId parameter.')
 , ROW ('nO7SS0l7J9', 'en', 'IAM Instance Profiles', 'Checks for usage that is more than 80% of the IAM Instance Profiles Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('oQ7TT0l7J9', 'en', 'IAM Roles', 'Checks for usage that is more than 80% of the IAM Roles Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('pR7UU0l7J9', 'en', 'IAM Policies', 'Checks for usage that is more than 80% of the IAM Policies Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('qS7VV0l7J9', 'en', 'IAM Users', 'Checks for usage that is more than 80% of the IAM Users Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('rT7WW0l7J9', 'en', 'IAM Server Certificates', 'Checks for usage that is more than 80% of the IAM Server Certificates Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('sU7XX0l7J9', 'en', 'IAM Group', 'Checks for usage that is more than 80% of the IAM Group Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('iK7OO0l7J9', 'en', 'ELB Classic Load Balancers', 'Checks for usage that is more than 80% of the ELB Classic Load Balancers. Application Load Balancers and Network Load Balancers have a separate limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.<br/>')
-, ROW ('7fuccf1Mx7', 'en', 'RDS Cluster Roles', 'Checks for usage that is more than 80% of the RDS Cluster Roles Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('jtlIMO3qZM', 'en', 'RDS Cluster Parameter Groups', 'Checks for usage that is more than 80% of the RDS Cluster Parameter Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('dx3xfcdfMr', 'en', 'Route 53 Hosted Zones', 'Checks for usage that is more than 80% of the Route 53 Hosted Zones Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('PPkZrjsH2q', 'en', 'Amazon EBS Provisioned IOPS (SSD) Volume Attachment Configuration', 'Checks for Provisioned IOPS (SSD) volumes that are attached to an Amazon EBS-optimizable Amazon Elastic Compute Cloud (Amazon EC2) instance that is not EBS-optimized. Provisioned IOPS (SSD) volumes in the Amazon Elastic Block Store (Amazon EBS) are designed to deliver the expected performance only when they are attached to an EBS-optimized instance.')
+, ROW ('Hs4Ma3G250', 'en', 'ECS clusters should use Container Insights', 'Checks if ECS clusters use Container Insights. This check fails if Container Insights are not set up for a cluster.')
+, ROW ('Hs4Ma3G251', 'en', 'EFS access points should enforce a root directory', 'Checks if Amazon Elastic File System (Amazon EFS) access points are configured to enforce a root directory. This check fails if the value of Path is set to / (default root directory of the file system).')
+, ROW ('Hs4Ma3G130', 'en', 'Lambda functions should use supported runtimes', 'Checks that the lambda function settings for runtimes, match the expected values set for the supported runtimes for each language. The supported runtimes this check assesses for are: nodejs14.x, nodejs12.x, python3.8, python3.7, python3.6, java11, java8, go1.x, dotnetcore2.1, dotnetcore3.1, ruby2.7.')
+, ROW ('Hs4Ma3G252', 'en', 'EFS access points should enforce a user identity', 'Checks if Amazon Elastic File System (Amazon EFS) access points are configured to enforce a user identity. This check fails if â€˜PosixUserâ€™ is not defined under â€˜configurationâ€™ or if parameters are provided and there is no match in the corresponding parameter.')
+, ROW ('Hs4Ma3G131', 'en', 'Lambda function policies should prohibit public access', 'Checks if the AWS Lambda function policy attached to the Lambda resource prohibits public access. If the Lambda function policy allows public access, the check fails.')
+, ROW ('Hs4Ma3G253', 'en', 'EKS clusters should run on a supported Kubernetes version', 'Checks if an EKS cluster is running on a supported Kubernetes version. The check fails if the EKS cluster is running on an unsupported version.')
+, ROW ('Hs4Ma3G132', 'en', 'Database Migration Service replication instances should not be public', 'Checks if AWS Database Migration Service replication instances are public by examining the PubliclyAccessible field value.')
+, ROW ('lN7RR0l7J9', 'en', 'EC2-VPC Elastic IP Address', 'Checks for usage that is more than 80% of the EC2-VPC Elastic IP Address Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Z4AUBRNSmz', 'en', 'Unassociated Elastic IP Addresses', 'Checks for Elastic IP addresses (EIPs) that are not associated with a running Amazon Elastic Compute Cloud (Amazon EC2) instance. EIPs are static IP addresses designed for dynamic cloud computing. Unlike traditional static IP addresses, EIPs can mask the failure of an instance or Availability Zone by remapping a public IP address to another instance in your account. A nominal charge is imposed for an EIP that is not associated with a running instance.')
+, ROW ('dBkuNCvqn5', 'en', 'RDS Max Auths per Security Group', 'Checks for usage that is more than 80% of the RDS Max Auths per Security Group Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('H7IgTzjTYb', 'en', 'Amazon EBS Snapshots', 'Checks the age of the snapshots for your Amazon Elastic Block Store (Amazon EBS) volumes (available or in-use). Even though Amazon EBS volumes are replicated, failures can occur. Snapshots are persisted to Amazon Simple Storage Service (Amazon S3) for durable storage and point-in-time recovery.')
+, ROW ('Hs4Ma3G243', 'en', 'Auto Scaling group launch configurations should configure EC2 instances to require Instance Metadata Service Version 2 (IMDSv2)', 'Checks if only IMDSv2 is enabled. This check fails if the metadata version is not included in the launch configuration or if both IMDSv1 and IMDSv2 are enabled.')
+, ROW ('Hs4Ma3G122', 'en', 'VPC flow logging should be enabled in all VPCs', 'Checks if Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPCs. The traffic type is set to Reject.')
+, ROW ('7ujm6yhn5t', 'en', 'Amazon OpenSearch Service Reserved Instance Optimization', 'Checks your usage of Amazon OpenSearch Service (successor to Amazon Elasticsearch Service) and provides recommendations on purchase of Reserved Instances to help reduce costs incurred from using Amazon OpenSearch Service On-Demand. AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of Reserved Instance to purchase to maximize your savings. This check covers recommendations based on partial upfront payment option with 1-year or 3-year commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.')
+, ROW ('Hs4Ma3G244', 'en', 'Auto Scaling group launch configuration should not have a metadata response hop limit greater than 1', 'Checks the number of network hops that the metadata token can travel. This check fails if the metadata response hop limit is greater than 1.')
+, ROW ('Hs4Ma3G123', 'en', 'EC2 instances should not have a public IPv4 address', 'Checks if EC2 instances have a public IP address. The check fails if the publicIp field is present in the EC2 instance configuration item. This check applies to IPv4 addresses only.')
 , ROW ('gjqMBn6pjz', 'en', 'RDS Clusters', 'Checks for usage that is more than 80% of the RDS Clusters Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('UUDvOa5r34', 'en', 'RDS Reserved Instances', 'Checks for usage that is more than 80% of the RDS Reserved Instances Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('jEhCtdJKOY', 'en', 'RDS Subnets per Subnet Group', 'Checks for usage that is more than 80% of the RDS Subnets per Subnet Group Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('dYWBaXaaMM', 'en', 'RDS Subnet Groups', 'Checks for usage that is more than 80% of the RDS Subnet Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G245', 'en', 'CloudFormation stacks should be integrated with Simple Notification Service (SNS)', 'Checks if your CloudFormation stacks are sending event notifications to SNS topic. This check fails if CloudFormation stacks are not sending event notifications to an SNS topic.')
+, ROW ('Hs4Ma3G124', 'en', 'EC2 instances should use Instance Metadata Service Version 2 (IMDSv2)', 'Checks if your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is configured with Instance Metadata Service Version 2 (IMDSv2). The check passes if HttpTokens is set to required for IMDSv2. The check fails if HttpTokens is set to optional.')
+, ROW ('Hs4Ma3G246', 'en', 'CloudFront distributions should not use deprecated SSL protocols between edge locations and custom origins', 'Checks if CloudFront distributions are using deprecated SSL protocols for HTTPS communication between CloudFront edge locations and your custom origins. This check fails for a CloudFront distribution if it has a CustomOriginConfig where â€˜OriginSslProtocolsâ€™ includes â€˜SSLv3â€™.')
+, ROW ('Hs4Ma3G125', 'en', 'API Gateway should be associated with a WAF Web ACL', 'Checks to see if an API Gateway stage is using an AWS WAF Web ACL. This check fails if an AWS WAF Web ACL is not attached to a REST API Gateway stage.')
+, ROW ('Qch7DwouX1', 'en', 'Low Utilization Amazon EC2 Instances', 'Checks the Amazon Elastic Compute Cloud (Amazon EC2) instances that were running at any time during the last 14 days and alerts you if the daily CPU utilization was 10% or less and network I/O was 5 MB or less on 4 or more days. Running instances generate hourly usage charges. Although some scenarios can result in low utilization by design, you can often lower your costs by managing the number and size of your instances.')
+, ROW ('Hs4Ma3G247', 'en', 'EC2 Transit Gateways should not automatically accept VPC attachment requests', 'Checks if EC2 Transit Gateways are automatically accepting shared VPC attachments requests. This check will fail for a Transit Gateway that automatically accept shared VPC attachment requests.')
+, ROW ('Hs4Ma3G126', 'en', 'DynamoDB Accelerator (DAX) clusters should be encrypted at rest', 'Checks if a DAX cluster is encrypted at rest.')
+, ROW ('Hs4Ma3G248', 'en', 'EC2 paravirtual instance types should not be used', 'Checks if the virtualization type of an EC2 instance is paravirtual. The check fails for an EC2 instance if â€˜virtualizationTypeâ€™ is set to â€˜paravirtualâ€™.')
+, ROW ('Hs4Ma3G127', 'en', 'API Gateway REST and WebSocket API execution logging should be enabled', 'Checks if all stages of Amazon API Gateway REST and WebSocket APIs have logging enabled. The check fails if logging is not enabled for all methods of a stage or if loggingLevel is neither ERROR nor INFO.')
+, ROW ('Hs4Ma3G249', 'en', 'ECS Fargate services should run on the latest Fargate platform version', 'Checks if ECS Fargate services is running the latest Fargate platform version. This check fails if the platform version is not latest.')
+, ROW ('Hs4Ma3G128', 'en', 'API Gateway REST API stages should be configured to use SSL certificates for backend authentication', 'Checks if Amazon API Gateway REST API stages have SSL certificates configured that backend systems can use to authenticate that incoming requests are from the API Gateway.')
+, ROW ('Hs4Ma3G129', 'en', 'API Gateway REST API stages should have AWS X-Ray tracing enabled', 'Checks if AWS X-Ray active tracing is enabled for your Amazon API Gateway REST API stages.')
+, ROW ('G31sQ1E9U', 'en', 'Underutilized Amazon Redshift Clusters', 'Checks your Amazon Redshift configuration for clusters that appear to be underutilized. If an Amazon Redshift cluster has not had a connection for a prolonged period of time or is using a low amount of CPU, you can use lower-cost options such as downsizing the cluster or shutting down the cluster and taking a final snapshot. Final snapshots are retained even after you delete your cluster.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: A running cluster has not had a connection in the last 7 days.<br/>Yellow: A running cluster had less than 5% cluster-wide average CPU utilization for 99% of the last 7 days.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider shutting down the cluster and taking a final snapshot, or downsizing the cluster. See <a href="https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#rs-mgmt-shutdown-delete-cluster" target="_blank">Shutting Down and Deleting Clusters</a> and <a href="https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-clusters.html#cluster-resize-intro" target="_blank">Resizing a Cluster</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/Welcome.html" target="_blank">Amazon CloudWatch Developer Guide</a>')
+, ROW ('h3L1otH3re', 'en', 'Amazon ElastiCache Reserved Node Optimization', 'Checks your usage of ElastiCache and provides recommendations on purchase of Reserved Nodes to help reduce costs incurred from using ElastiCache On-Demand. AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of Reserved Node to purchase to maximize your savings. This check covers recommendations based on partial upfront payment option with 1-year or 3-year commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.')
+, ROW ('Hs4Ma3G260', 'en', 'OpenSearch domains should have fine-grained access control enabled', 'Checks if Amazon OpenSearch domains have fine-grained access check enabled. This check fails if the fine-grained access check is not enabled.')
+, ROW ('Hs4Ma3G261', 'en', 'Redshift clusters should not use the default database name', 'Checks if a Redshift cluster has changed the database name from its default value. This check will fail if the database name for a Redshift cluster is set to â€œdevâ€')
+, ROW ('Hs4Ma3G140', 'en', 'IAM root user access key should not exist', 'Checks if the root user access key is available.')
+, ROW ('Hs4Ma3G262', 'en', 'S3 buckets should have lifecycle policies configured', 'Checks if a lifecycle policy is configured for an S3 bucket. This check fails if the lifecycle policy is not configured for an S3 bucket.')
+, ROW ('Hs4Ma3G141', 'en', 'MFA should be enabled for all IAM users that have a console password', 'Checks if AWS Multi-Factor Authentication (MFA) is enabled for all AWS Identity and Access Management (IAM) users that use a console password.')
+, ROW ('Hs4Ma3G263', 'en', 'Logging of delivery status should be enabled for notification messages sent to a topic', 'Checks if logging is enabled for the delivery status of notification messages sent to a topic for the endpoints. This check fails if the delivery status notification for messages is not enabled.')
+, ROW ('Hs4Ma3G142', 'en', 'Hardware MFA should be enabled for the root user', 'Checks if your AWS account is enabled to use hardware multi-factor authentication (MFA) device to sign in with root credentials.')
+, ROW ('Hs4Ma3G264', 'en', 'A WAF Regional rule should have at least one condition', 'Checks if a WAF Regional rule has at least one condition. The check fails if no conditions are present within a rule.')
+, ROW ('Hs4Ma3G143', 'en', 'Password policies for IAM users should have strong configurations', 'Checks if the account password policy for IAM users uses the following recommended configurations: RequireUppercaseCharacters: true, RequireLowercaseCharacters: true, RequireSymbols: true, RequireNumbers: true, MinimumPasswordLength: 8.')
+, ROW ('N430c450f2', 'en', 'CloudFront SSL Certificate on the Origin Server', 'Checks your origin server for SSL certificates that are expired, about to expire, missing, or that use outdated encryption. If a certificate is expired, CloudFront responds to requests for your content with HTTP status code 502, Bad Gateway. Certificates that were encrypted by using the SHA-1 hashing algorithm are being deprecated by web browsers such as Chrome and Firefox. Depending on the number of SSL certificates that you have associated with your CloudFront distributions, this check might add a few cents per month to your bill with your web hosting provider, for example, AWS if youre using EC2 or ELB as the origin for your CloudFront distribution. This check does not validate your origin certificate chain or certificate authorities; you can check these in your CloudFront configuration. ')
 , ROW ('3Njm0DJQO9', 'en', 'RDS Option Groups', 'Checks for usage that is more than 80% of the RDS Option Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('keAhfbH5yb', 'en', 'RDS Event Subscriptions', 'Checks for usage that is more than 80% of the RDS Event Subscriptions Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('dV84wpqRUs', 'en', 'RDS DB Manual Snapshots', 'Checks for usage that is more than 80% of the RDS DB Manual Snapshots Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('P1jhKWEmLa', 'en', 'RDS Total Storage Quota', 'Checks for usage that is more than 80% of the RDS Total Storage Quota Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('jEECYg2YVU', 'en', 'RDS DB Parameter Groups', 'Checks for usage that is more than 80% of the RDS DB Parameter Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('pYW8UkYz2w', 'en', 'RDS Read Replicas per Master', 'Checks for usage that is more than 80% of the RDS Read Replicas per Master Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('gfZAn3W7wl', 'en', 'RDS DB Security Groups', 'Checks for usage that is more than 80% of the RDS DB Security Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('XG0aXHpIEt', 'en', 'RDS DB Instances', 'Checks for usage that is more than 80% of the RDS DB Instances Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('dBkuNCvqn5', 'en', 'RDS Max Auths per Security Group', 'Checks for usage that is more than 80% of the RDS Max Auths per Security Group Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('wH7DD0l3J9', 'en', 'EBS Throughput Optimized HDD (st1) Volume Storage', 'Checks for usage that is more than 80% of the EBS Throughput Optimized HDD (st1) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('gH5CC0e3J9', 'en', 'EBS Cold HDD (sc1) Volume Storage', 'Checks for usage that is more than 80% of the EBS Cold HDD (sc1) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('6gtQddfEw6', 'en', 'DynamoDB Read Capacity', 'Checks for usage that is more than 80% of the DynamoDB Provisioned Throughput Limit for Reads per Account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('c5ftjdfkMr', 'en', 'DynamoDB Write Capacity', 'Checks for usage that is more than 80% of the DynamoDB Provisioned Throughput Limit for Writes per Account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('ru4xfcdfMr', 'en', 'Route 53 Max Health Checks', 'Checks for usage that is more than 80% of the Route 53 Health Checks Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('dx3xfcdfMr', 'en', 'Route 53 Hosted Zones', 'Checks for usage that is more than 80% of the Route 53 Hosted Zones Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('tV7YY0l7J9', 'en', 'EBS Provisioned IOPS (SSD) Volume Aggregate IOPS', 'Checks for usage that is more than 80% of the EBS Provisioned IOPS (SSD) Volume Aggregate IOPS Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('vZ2c2W1srf', 'en', 'Savings Plan', 'Checks your usage of EC2, Fargate, and Lambda over the last 30 days and provides Savings Plan purchase recommendations, which allows you to commit to a consistent usage amount measured in $/hour for a one or three year term in exchange for discounted rates. These are sourced from AWS Cost Explorer which can be used to get more detailed recommendation information, or to purchase a savings plan. These recommendations should be considered an alternative to your RI recommendations and choosing to act fully on both sets of recommendations would likely lead to over commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account. <br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: Optimizing the purchase of Savings Plans can help reduce costs.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>See the <a href="https://console.aws.amazon.com/billing/home?/costexplorer#/costexplorer/" target="_blank">Cost Explorer</a> page for more detailed and customized recommendations and to purchase Savings Plans. <br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/>Savings Plan <a href="https://docs.aws.amazon.com/savingsplans/latest/userguide/what-is-savings-plans.html" target="_blank">User Guide</a><br/>Savings Plan <a href="https://aws.amazon.com/savingsplans/faq/" target="_blank">FAQ</a>')
+, ROW ('Hs4Ma3G254', 'en', 'Application Load Balancer should be configured with defensive or strictest desync mitigation mode', 'Checks if the Application Load Balancer is configured with defensive or strictest de-sync mitigation mode. This check fails if the Application Load Balancer is not configured with defensive or strictest desync mitigation mode.')
+, ROW ('Hs4Ma3G133', 'en', 'IAM customer managed policies should not allow decryption actions on all KMS keys', 'Checks if the default version of IAM customer managed policies allow principals to use the AWS Key Management Service (KMS) decryption actions on all resources. This check fails if kms:Decrypt or kms:ReEncryptFrom actions are allowed on all KMS keys. The check evaluates both attached and unattached customer managed policies. It does not check inline policies or AWS managed policies.')
 , ROW ('ty3xfcdfMr', 'en', 'Route 53 Reusable Delegation Sets', 'Checks for usage that is more than 80% of the Route 53 Reusable Delegation Sets Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('dx3xfbjfMr', 'en', 'Route 53 Traffic Policies', 'Checks for usage that is more than 80% of the Route 53 Traffic Policies Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('dx8afcdfMr', 'en', 'Route 53 Traffic Policy Instances', 'Checks for usage that is more than 80% of the Route 53 Traffic Policy Instances Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('cX3c2R1chu', 'en', 'Amazon EC2 Reserved Instances Optimization', 'A significant part of using AWS involves balancing your Reserved Instance (RI) usage and your On-Demand instance usage. We provide recommendations on which RIs will help reduce costs incurred from using On-Demand instances.<br/>AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days, and then categorizing the usage into eligible categories for reservations. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of RI to purchase to maximize your savings. This check covers recommendations based on Standard Reserved Instances with partial upfront payment option. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.<br/><br/><b>Alert Criteria</b><br/>Yellow: Optimizing the use of partial upfront RIs can help reduce costs.<br/><br/><b>Recommended Action</b><br/>See the <a href="https://aws.amazon.com/aws-cost-management/aws-cost-explorer/" target="_blank">Cost Explorer</a> page for more detailed and customized recommendations. Additionally, refer to the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html#ri-market-buying-guide" target="_blank">buying guide</a> to understand how to purchase RIs and the options available.<br/><br/><b>Additional Resources</b><br/>Information on RIs and how they can save you money can be found <a href="https://aws.amazon.com/ec2/pricing/reserved-instances/" target="_blank">here</a>.<br/>For more information on this recommendation, see <a href="https://aws.amazon.com/premiumsupport/technology/trusted-advisor/faqs/#Reserved_Instance_Optimization_Check_Questions" target="_blank">Reserved Instance Optimization Check Questions</a> in the Trusted Advisor FAQs.')
-, ROW ('EM8b3yLRTr', 'en', 'ELB Application Load Balancers', 'Checks for usage that is more than 80% of the ELB Application Load Balancers Limit. Classic Load Balancers and Network Load Balancers have separate limits. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.<br/>')
-, ROW ('8wIqYSt25K', 'en', 'ELB Network Load Balancers', 'Checks for usage that is more than 80% of the ELB Network Load Balancers Limit. Classic Load Balancers and Application Load Balancers have separate limits. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.<br/>')
-, ROW ('vZ2c2W1srf', 'en', 'Savings Plan', 'Checks your usage of EC2, Fargate, and Lambda over the last 30 days and provides Savings Plan purchase recommendations, which allows you to commit to a consistent usage amount measured in $/hour for a one or three year term in exchange for discounted rates. These are sourced from AWS Cost Explorer which can be used to get more detailed recommendation information, or to purchase a savings plan. These recommendations should be considered an alternative to your RI recommendations and choosing to act fully on both sets of recommendations would likely lead to over commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account. <br/><br/><b>Alert Criteria</b><br/>Yellow: Optimizing the purchase of Savings Plans can help reduce costs.<br/><br/><b>Recommended Action</b><br/>See the <a href="https://console.aws.amazon.com/billing/home?/costexplorer#/costexplorer/" target="_blank">Cost Explorer</a> page for more detailed and customized recommendations and to purchase Savings Plans. <br/><br/><b>Additional Resources</b><br/>Savings Plan <a href="https://docs.aws.amazon.com/savingsplans/latest/userguide/what-is-savings-plans.html" target="_blank">User Guide</a><br/>Savings Plan <a href="https://aws.amazon.com/savingsplans/faq/" target="_blank">FAQ</a>')
-, ROW ('h3L1otH3re', 'en', 'Amazon ElastiCache Reserved Node Optimization', 'Checks your usage of ElastiCache and provides recommendations on purchase of Reserved Nodes to help reduce costs incurred from using ElastiCache On-Demand. AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of Reserved Node to purchase to maximize your savings. This check covers recommendations based on partial upfront payment option with 1-year or 3-year commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.')
-, ROW ('1qw23er45t', 'en', 'Amazon Redshift Reserved Node Optimization', 'Checks your usage of Redshift and provides recommendations on purchase of Reserved Nodes to help reduce costs incurred from using Redshift On-Demand. AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of Reserved Nodes to purchase to maximize your savings. This check covers recommendations based on partial upfront payment option with 1-year or 3-year commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.<br/><br/><b>Alert Criteria</b><br/>Yellow: Optimizing the purchase of Redshift Reserved Nodes can help reduce costs.<br/><br/><b>Recommended Action</b><br/>See the <a href="https://console.aws.amazon.com/billing/home?/costexplorer#/costexplorer" target="_blank">Cost Explorer</a> page for more detailed recommendations, customization options (e.g. look-back period, payment option, etc.) and to purchase Redshift Reserved Nodes.<br/><br/><b>Additional Resources</b><br/>Information on Redshift Reserved Nodes and how they can save you money can be found <a href="http://docs.aws.amazon.com/redshift/latest/mgmt/purchase-reserved-node-instance.html" target="_blank">here</a>.')
-, ROW ('1qazXsw23e', 'en', 'Amazon Relational Database Service (RDS) Reserved Instance Optimization', 'Checks your usage of RDS and provides recommendations on purchase of Reserved Instances to help reduce costs incurred from using RDS On-Demand. AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of Reserved Instance to purchase to maximize your savings. This check covers recommendations based on partial upfront payment option with 1-year or 3-year commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.<br/><br/><b>Alert Criteria</b><br/>Yellow: Optimizing the purchase of RDS Reserved Instances can help reduce costs.<br/><br/><b>Recommended Action</b><br/>See the <a href="http://console.aws.amazon.com/billing/home?/costexplorer#/costexplorer" target="_blank">Cost Explorer</a> page for more detailed recommendations, customization options (e.g. look-back period, payment option, etc.) and to purchase RDS Reserved Instances.<br/><br/><b>Additional Resources</b><br/>Information on RDS Reserved Instances and how they can save you money can be found <a href="http://aws.amazon.com/rds/reserved-instances/" target="_blank">here</a>.')
-, ROW ('7ujm6yhn5t', 'en', 'Amazon OpenSearch Service Reserved Instance Optimization', 'Checks your usage of Amazon OpenSearch Service (successor to Amazon Elasticsearch Service) and provides recommendations on purchase of Reserved Instances to help reduce costs incurred from using Amazon OpenSearch Service On-Demand. AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of Reserved Instance to purchase to maximize your savings. This check covers recommendations based on partial upfront payment option with 1-year or 3-year commitment. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.')
-, ROW ('L4dfs2Q4C5', 'en', 'AWS Lambda Functions Using Deprecated Runtimes', 'Checks for Lambda functions that are configured to use a runtime that is approaching deprecation or is deprecated. Deprecated runtimes are not eligible for security updates or technical support.<br/><b>Notes:</b>')
-, ROW ('L4dfs2Q3C3', 'en', 'AWS Lambda Functions with Excessive Timeouts', 'Checks for Lambda functions with high timeout rates that may result in high cost. Lambda charges based on execution time for your function and number of requests for your function. Function timeouts result in function errors that may cause retries that incur additional request and execution time charges.<br/><b>Note:</b> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><b>Alert Criteria</b><br/>Yellow: Functions where > 10% of invocations end in an error due to a timeout on any given day within the last 7 days.<br/><br/><b>Recommended Action</b><br/>Inspect function logging and X-ray traces to determine the contributor to the high function duration. Implement logging in your code at relevant parts, such as before or after API calls or database connections. By default, AWS SDK clients timeouts may be longer than the configured function duration. Adjust API and SDK connection clients to retry or fail within the function timeout. If the expected duration is longer than the configured timeout, you can increase the timeout setting for the function. For more information, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-monitoring.html" target="blank">Monitoring and troubleshooting Lambda applications</a>.<br/><br/><b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-monitoring.html" target="blank">Monitoring and troubleshooting Lambda applications</a><br/><a href="https://aws.amazon.com/premiumsupport/knowledge-center/lambda-function-retry-timeout-sdk/" target="blank">Lambda Function Retry Timeout SDK</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/services-xray.html" target="blank">Using AWS Lambda with AWS X-Ray</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs.html" target="blank">Accessing Amazon CloudWatch logs for AWS Lambda</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/samples-errorprocessor.html" target="blank">Error Processor Sample Application for AWS Lambda</a><br/>')
-, ROW ('L4dfs2Q3C2', 'en', 'AWS Lambda Functions with High Error Rates', 'Checks for Lambda functions with high error rates that may result in high cost. Lambda charges based on the number of requests and aggregate execution time for your function. Function errors may cause retries that incur additional charges.<br/><b>Note:</b> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><b>Alert Criteria</b><br/>Yellow: Functions where > 10% of invocations end in error on any given day within the last 7 days.<br/><br/><b>Recommended Action</b><br/>Consider the following guidelines to reduce errors. Function errors include errors returned by the functions code and errors returned by the functions runtime. To help you troubleshoot Lambda errors, Lambda integrates with services like Amazon CloudWatch and AWS X-Ray. You can use a combination of logs, metrics, alarms, and X-ray tracing to quickly detect and identify issues in your function code, API, or other resources that support your application. For more information, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-monitoring.html" target="blank">Monitoring and troubleshooting Lambda applications</a>. For more information on handling errors with specific runtimes, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html" target="blank">Error handling and automatic retries in AWS Lambda</a>. For additional troubleshooting, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-troubleshooting.html" target="blank">Troubleshooting issues in Lambda</a>.You can also choose from an ecosystem of monitoring and observability tools provided by AWS Lambda partners. For additional information about Partners, see <a href="https://aws.amazon.com/lambda/partners/?partner-solutions-cards.sort-by=item.additionalFields.partnerNameLower&partner-solutions-cards.sort-order=asc" target="blank">AWS Lambda Partners</a>.<br/><br/><b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/invocation-retries.html" target="blank">Error Handling and Automatic  Retries in AWS Lambda</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-monitoring.html" target="blank">Monitoring and Troubleshooting Lambda applications</a><br/><a href="https://aws.amazon.com/premiumsupport/knowledge-center/lambda-function-retry-timeout-sdk/" target="blank">Lambda Function Retry Timeout SDK</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-troubleshooting.html" target="blank">Troubleshooting  issues in Lambda</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html#API_Invoke_Errors" target="blank">API Invoke Errors</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/samples-errorprocessor.html" target="blank">Error Processor Sample Application for AWS Lambda</a><br/>')
-, ROW ('L4dfs2Q4C6', 'en', 'AWS Lambda VPC-enabled Functions without Multi-AZ Redundancy', 'Checks for VPC-enabled Lambda functions that are vulnerable to service interruption in a single availability zone. It is recommended for VPC-enabled functions to be connected to multiple availability zones for high availability.<br/><b>Note:</b> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><b>Alert Criteria</b><br/>Yellow: A VPC-enabled Lambda function connected to subnets in a single Availability Zone.<br/><br/><b>Recommended Action</b><br/>When configuring functions for access to your VPC, choose subnets in multiple Availability Zones to ensure high availability.<br/><br/><b>Additional Resources</b><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html" target="blank">Configuring a Lambda function to access resources in a VPC</a><br/><a href="https://docs.aws.amazon.com/lambda/latest/dg/security-resilience.html" target="blank">Resilience in AWS Lambda</a><br/>')
-, ROW ('dH7RR0l6J3', 'en', 'EBS General Purpose SSD (gp3) Volume Storage', 'Checks for usage that is more than 80% of the EBS General Purpose SSD (gp3) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('gI7MM0l7J2', 'en', 'EBS Provisioned IOPS SSD (io2) Volume Storage', 'Checks for usage that is more than 80% of the EBS Provisioned IOPS SSD (io2) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
-, ROW ('Cm24dfsM12', 'en', 'Amazon Comprehend Underutilized Endpoints', 'Checks the throughput configuration of your endpoints. This check alerts you when endpoints are not actively used for real-time inference requests. An endpoint that isnâ€™t used for more than 15 consecutive days is considered underutilized. All endpoints accrue charges based on both the throughput set and the length of time that the endpoint is active.<br/><b>Note:</b> This check is automatically refreshed once a day.<br/><br/><b>Alert Criteria</b><br/>Yellow: The endpoint is active, but hasnâ€™t been used for real-time inference requests in the past 15 days.<br/><br/><b>Recommended Action</b><br/>If the endpoint hasnâ€™t been used in the past 15 days, we recommend that you define a scaling policy for the resource by using <a href="https://docs.aws.amazon.com/comprehend/latest/dg/comprehend-autoscaling.html" target="blank">Application Autoscaling.</a><br/>If the endpoint has a scaling policy defined and hasnâ€™t been used in the past 30 days, consider deleting the endpoint and using asynchronous inference. For more information, see <a href="https://docs.aws.amazon.com/comprehend/latest/dg/manage-endpoints-delete.html" target="blank">Deleting an endpoint with Amazon Comprehend</a>.')
-, ROW ('Cm24dfsM13', 'en', 'Amazon Comprehend Endpoint Access Risk', 'Checks the AWS Key Management Service (AWS KMS) key permissions for an endpoint where the underlying model was encrypted by using customer managed keys. If the customer managed key is disabled or the key policy was changed to alter the allowed permissions for Amazon Comprehend, the endpoint availability might be affected.<br/><b>Note:</b> This check is automatically refreshed multiple times a day. It might take a few hours for the latest results to appear.<br/><br/><b>Alert Criteria</b><br/>Red: The customer managed key is disabled or the key policy was changed to alter the allowed permissions for Amazon Comprehend access.<br/><br/><b>Recommended Action</b><br/>If the customer managed key was disabled, we recommend that you enable it. For more information, see <a href="https://docs.aws.amazon.com/kms/latest/developerguide/enabling-keys.html" target="blank">Enabling keys</a>. If the key policy was altered and you want to keep using the endpoint, we recommend that you update the KMS key policy. For more information, see <a href="https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying.html" target="blank">Changing a key policy</a>.')
-, ROW ('Wxdfp4B1L1', 'en', 'AWS Well-Architected high risk issues for cost optimization', 'Checks for high risk issues (HRIs) for your workloads in the cost optimization pillar. This check is based on your AWS-Well Architected reviews. Your check results depend on whether you completed the workload evaluation with AWS Well-Architected.<br/><br/><b>Alert Criteria</b><br/>Red: At least one active high risk issue was identified in the cost optimization pillar for AWS Well-Architected.')
-, ROW ('Wxdfp4B1L2', 'en', 'AWS Well-Architected high risk issues for performance efficiency', 'Checks for high risk issues (HRIs) for your workloads in the performance pillar. This check is based on your AWS-Well Architected reviews. Your check results depend on whether you completed the workload evaluation with AWS Well-Architected.<br/><br/><b>Alert Criteria</b><br/>Red: At least one active high risk issue was identified in the performance pillar for AWS Well-Architected.')
-, ROW ('Wxdfp4B1L3', 'en', 'AWS Well-Architected high risk issues for security', 'Checks for high risk issues (HRIs) for your workloads in the security pillar. This check is based on your AWS-Well Architected reviews. Your check results depend on whether you completed the workload evaluation with AWS Well-Architected.<br/><br/><b>Alert Criteria</b><br/>Red: At least one active high risk issue was identified in the security pillar for AWS Well-Architected.')
-, ROW ('Wxdfp4B1L4', 'en', 'AWS Well-Architected high risk issues for reliability', 'Checks for high risk issues (HRIs) for your workloads in the Reliability pillar. This check is based on your AWS-Well Architected reviews. Your check results depend on whether you completed the workload evaluation with AWS Well-Architected.<br/><br/><b>Alert Criteria</b><br/>Red: At least one active high risk issue was identified in the reliability pillar for AWS Well-Architected.')
-, ROW ('Qsdfp3A4L1', 'en', 'Amazon EC2 instances over-provisioned for Microsoft SQL Server', 'Checks your Amazon Elastic Compute Cloud (Amazon EC2) instances that are running SQL Server in the past 24 hours. An SQL Server database has a compute capacity limit for each instance. An instance with SQL Server Standard edition can use up to 48 vCPUs. An instance with SQL Server Web can use up to 32 vCPUs. This check alerts you if an instance exceeds this vCPU limit.If your instance is over-provisioned, you pay full price without realizing an improvement in performance. You can manage the number and size of your instances to help lower costs. Estimated monthly savings are calculated by using the same instance family with the maximum number of vCPUs that an SQL Server instance can use and the On-Demand pricing. Actual savings will vary if youâ€™re using Reserved Instances (RI) or if the instance isnâ€™t running for a full day.<br/><br/><b>Alert Criteria</b><br/>Red: An instance with SQL Server Standard edition has more than 48 vCPUs.<br/>Red: An instance with SQL Server Web edition has more than 32 vCPUs.<br/><br/><b>Recommended Action</b><br/>For SQL Server Standard edition, consider changing to an instance in the same instance family with 48 vCPUs. For SQL Server Web edition, consider changing to an instance in the same instance family with 32 vCPUs. If it is memory intensive, consider changing to memory optimized R5 instances. For more information, see <a href="https://d1.awsstatic.com/whitepapers/best-practices-for-deploying-microsoft-sql-server-on-aws.pdf?did=wp_card&trk=wp_card" target="blank">Best Practices for Deploying Microsoft SQL Server on Amazon EC2.</a><br/><br/><b>Additional Resources</b><br/><a href="https://aws.amazon.com/sql/" target="blank">Microsoft SQL Server on AWS</a><br/>You can use <a href="https://aws.amazon.com/launchwizard/" target="blank">Launch Wizard</a> to simplify your SQL Server deployment on EC2.<br/>')
-, ROW ('Qsdfp3A4L2', 'en', 'Amazon EC2 instances consolidation for Microsoft SQL Server', 'Checks your Amazon Elastic Compute Cloud (Amazon EC2) instances that are running SQL Server in the past 24 hours. This check alerts you if your instance has less than the minimum number of SQL Server licenses. From the Microsoft SQL Server Licensing Guide, you are paying 4 vCPU licenses even if an instance has only 1 or 2 vCPUs. You can consolidate smaller SQL Server instances to help lower costs.<br/><br/><b>Alert Criteria</b><br/>Yellow: An instance with SQL Server has less than 4 vCPUs.<br/><br/><b>Recommended Action</b><br/>Consider consolidating smaller SQL Server workloads into instances with at least 4 vCPUs.<br/><br/><b>Additional Resources</b><br/><a href="https://aws.amazon.com/sql/" target="blank">Microsoft SQL Server on AWS</a><br/><a href="https://aws.amazon.com/windows/resources/licensing/" target="blank">Microsoft Licensing on AWS</a><br/><a href="https://www.microsoft.com/en-us/sql-server/sql-server-2019-pricing" target="blank">Microsoft SQL Server Licensing Guide</a><br/>')
-, ROW ('Qsdfp3A4L3', 'en', 'Amazon EC2 instances with Microsoft SQL Server end of support', 'Checks the SQL Server versions for Amazon Elastic Compute Cloud (Amazon EC2) instances running in the past 24 hours. This check alerts you if the versions are near or have reached the end of support. Each SQL Server version offers 10 years of support, including 5 years of mainstream support and 5 years of extended support. After the end of support, the SQL Server version wonâ€™t receive regular security updates. Running applications with unsupported SQL Server versions can bring security or compliance risks.<br/><br/><b>Alert Criteria</b><br/>Red: An EC2 instance has an SQL Server version that reached the end of support.<br/>Yellow: An EC2 instance has an SQL Server version that will reach the end of support in 12 months.<br/><br/><b>Recommended Action</b><br/>To modernize your SQL Server workloads, consider refactoring to AWS Cloud native databases like Amazon Aurora. For more information, see <a href="https://aws.amazon.com/windows/modernization/" target="blank">Modernize Windows Workloads with AWS</a>.<br/>To move to a fully managed database, consider replatforming to Amazon Relational Database Service (Amazon RDS). For more information, see <a href="https://aws.amazon.com/rds/sqlserver/" target="blank">RDS for SQL Server</a>.<br/>To upgrade your SQL Server on EC2, consider using the automation runbook to simplify your upgrade. For more information, see the <a href="https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awsec2-CloneInstanceAndUpgradeSQLServer.html" target="blank">AWS Systems Manager documentation</a>.<br/>If you canâ€™t upgrade your SQL Server on EC2, consider the End-of-Support Migration Program (EMP) for Windows Server. For more information, see the <a href="https://aws.amazon.com/emp-windows-server/" target="blank">EMP Website</a><br/><br/><b>Additional Resources</b><br/><a href="https://aws.amazon.com/sql/sql2008-eos/" target="blank">Get ready for SQL Server end of support with AWS</a><br/><a href="https://aws.amazon.com/sql/" target="blank">Microsoft SQL Server on AWS</a><br/>')
+, ROW ('Hs4Ma3G255', 'en', 'Classic Load Balancer should be configured with defensive or strictest desync mitigation mode', 'Checks if the Classic Load Balancer is configured defensive or strictest desync mitigation mode. This check will fail if the Application Load Balancer is not configured with defensive strictest mitigation Desync mitigation mode.')
+, ROW ('Hs4Ma3G134', 'en', 'IAM principals should not have IAM inline policies that allow decryption actions on all KMS keys', 'Checks if the inline policies embedded in your IAM principals (Role/User/Group) allow the AWS Key Management Service (KMS) decryption actions on all KMS keys. This check fails if kms:Decrypt or kms:ReEncryptFrom actions are allowed on all KMS keys in an inline policy.')
+, ROW ('Hs4Ma3G256', 'en', 'Kinesis streams should be encrypted at rest', 'Checks if Kinesis streams are encrypted at rest with server-side encryption. This check fails if a Kinesis stream is not encrypted at rest with server-side encryption.')
+, ROW ('Hs4Ma3G135', 'en', 'AWS KMS keys should not be deleted unintentionally', 'Checks whether AWS Key Management Service (KMS) keys are scheduled for deletion. The check fails if a KMS key is scheduled for deletion.')
+, ROW ('gfZAn3W7wl', 'en', 'RDS DB Security Groups', 'Checks for usage that is more than 80% of the RDS DB Security Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G257', 'en', 'Network Firewall policies should have at least one rule group associated', 'Checks if a Network Firewall policy has any stateful or stateless rule groups associated. This check fails if stateless or stateful rule groups are not assigned.')
+, ROW ('Hs4Ma3G136', 'en', 'Amazon SQS queues should be encrypted at rest', 'Checks if Amazon SQS queues are encrypted at rest.')
+, ROW ('Hs4Ma3G258', 'en', 'The default stateless action for Network Firewall policies should be drop or forward for full packets', 'Checks if the default stateless action for full packets for a Network Firewall policy is drop or forward. The check passes if Drop or Forward is selected, and fails if Pass is selected.')
+, ROW ('Hs4Ma3G137', 'en', 'IAM policies should not allow full "*" administrative privileges', 'Checks if the default version of AWS Identity and Access Management (IAM) policies (also known as customer managed policies) do not have administrator access with a statement that has "Effect": "Allow" with "Action": "*" over "Resource": "*". It only assesses for the Customer Managed Policies that you created, but not inline and AWS Managed Policies.')
+, ROW ('Hs4Ma3G259', 'en', 'The default stateless action for Network Firewall policies should be drop or forward for fragmented packets', 'Checks if a Network Firewall policy has drop or forward as the default stateless action for fragmented packets. The check passes if Drop or Forward is selected, and fails if Pass is selected.')
+, ROW ('Hs4Ma3G138', 'en', 'IAM users should not have IAM policies attached', 'Checks that none of your IAM users have policies attached. Instead, IAM users must inherit permissions from IAM groups or roles.')
+, ROW ('7qGXsKIUw', 'en', 'ELB Connection Draining', 'Checks for load balancers that do not have connection draining enabled. When connection draining is not enabled and you remove (deregister) an Amazon EC2 instance from a load balancer, the load balancer stops routing traffic to that instance and closes the connection. When connection draining is enabled, the load balancer stops sending new requests to the deregistered instance but keeps the connection open to serve active requests.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/> Yellow: Connection draining is not enabled for a load balancer.<br/><br/> <h4 class=headerBodyStyle>Recommended Action</h4><br/>Enable connection draining for the load balancer. For more information, see <a target="_blank" href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html#conn-drain">Connection Draining</a> and <a target="_blank" href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/config-conn-drain.html">Enable or Disable Connection Draining for Your Load Balancer</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html">Elastic Load Balancing Concepts</a>')
+, ROW ('Hs4Ma3G139', 'en', 'IAM users access keys should be rotated every 90 days or less', 'Checks if the active access keys are rotated within 90 days.')
+, ROW ('Hs4Ma3G230', 'en', 'S3 bucket server access logging should be enabled', 'Checks if an Amazon S3 Bucket has server access logging enabled to a chosen target bucket.')
+, ROW ('Hs4Ma3G231', 'en', 'Stateless network firewall rule group should not be empty', 'Checks if a Stateless Network Firewall Rule Group contains rules. The rule will fail if there are no rules in a Stateless Network Firewall Rule Group.')
+, ROW ('Hs4Ma3G110', 'en', 'CloudTrail should have encryption at-rest enabled', 'Checks whether AWS CloudTrail is configured to use the server-side encryption (SSE) AWS Key Management Service (AWS KMS) key encryption. The check will pass if the KmsKeyId is defined.')
+, ROW ('UUDvOa5r34', 'en', 'RDS Reserved Instances', 'Checks for usage that is more than 80% of the RDS Reserved Instances Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Qsdfp3A4L1', 'en', 'Amazon EC2 instances over-provisioned for Microsoft SQL Server', 'Checks your Amazon Elastic Compute Cloud (Amazon EC2) instances that are running SQL Server in the past 24 hours. An SQL Server database has a compute capacity limit for each instance. An instance with SQL Server Standard edition can use up to 48 vCPUs. An instance with SQL Server Web can use up to 32 vCPUs. This check alerts you if an instance exceeds this vCPU limit.If your instance is over-provisioned, you pay full price without realizing an improvement in performance. You can manage the number and size of your instances to help lower costs. Estimated monthly savings are calculated by using the same instance family with the maximum number of vCPUs that an SQL Server instance can use and the On-Demand pricing. Actual savings will vary if youâ€™re using Reserved Instances (RI) or if the instance isnâ€™t running for a full day.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: An instance with SQL Server Standard edition has more than 48 vCPUs.<br/>Red: An instance with SQL Server Web edition has more than 32 vCPUs.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>For SQL Server Standard edition, consider changing to an instance in the same instance family with 48 vCPUs. For SQL Server Web edition, consider changing to an instance in the same instance family with 32 vCPUs. If it is memory intensive, consider changing to memory optimized R5 instances. For more information, see <a href="https://d1.awsstatic.com/whitepapers/best-practices-for-deploying-microsoft-sql-server-on-aws.pdf?did=wp_card&trk=wp_card" target="blank">Best Practices for Deploying Microsoft SQL Server on Amazon EC2.</a><br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://aws.amazon.com/sql/" target="blank">Microsoft SQL Server on AWS</a><br/>You can use <a href="https://aws.amazon.com/launchwizard/" target="blank">Launch Wizard</a> to simplify your SQL Server deployment on EC2.<br/>')
+, ROW ('oQ7TT0l7J9', 'en', 'IAM Roles', 'Checks for usage that is more than 80% of the IAM Roles Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G229', 'en', 'CloudFront distributions should encrypt traffic to custom origins', 'Checks if CloudFront distributions are encrypting traffic to custom origins. This check fails for a CloudFront distribution whose origin protocol policy allows http-only or if it is match-viewer and the viewer protocol policy is allow-all. ')
+, ROW ('Hs4Ma3G108', 'en', 'CloudTrail trails should be integrated with Amazon CloudWatch Logs', 'Checks if AWS CloudTrail trails are configured to send logs to Amazon CloudWatch Logs.')
+, ROW ('Hs4Ma3G109', 'en', 'CloudTrail log file validation should be enabled', 'Checks if CloudTrail log file validation is enabled.')
+, ROW ('jL7PP0l7J9', 'en', 'VPC', 'Checks for usage that is more than 80% of the VPC Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G221', 'en', 'OpenSearch domains should have audit logging enabled', 'Checks if Amazon OpenSearch Service domains have audit logging enabled.')
 , ROW ('Hs4Ma3G100', 'en', 'Amazon SageMaker notebook instances should not have direct internet access', 'Checks if direct internet access is disabled for an Amazon SageMaker notebook instance by examining the DirectInternetAccess field is disabled for an Amazon SageMaker notebook instance.')
+, ROW ('Hs4Ma3G222', 'en', 'OpenSearch domain error logging to CloudWatch Logs should be enabled', 'Checks if Amazon OpenSearch domains are configured to send error logs to CloudWatch Logs. This check fails if error logging to CloudWatch is not enabled for a domain.')
 , ROW ('Hs4Ma3G101', 'en', 'Amazon Elastic MapReduce cluster master nodes should not have public IP addresses', 'Checks if master nodes on EMR clusters have public IP addresses.')
+, ROW ('Hs4Ma3G223', 'en', 'OpenSearch domains should encrypt data sent between nodes', 'Checks if Amazon OpenSearch domains have node-to-node encryption enabled. This check fails if node-to-node encryption is disabled on the domain.')
 , ROW ('Hs4Ma3G102', 'en', 'Connections to Amazon Redshift clusters should be encrypted in transit', 'Checks if connections to Amazon Redshift clusters are required to use encryption in transit. The check fails if the Amazon Redshift cluster parameter require_SSL is not set to 1.')
+, ROW ('cX3c2R1chu', 'en', 'Amazon EC2 Reserved Instances Optimization', 'A significant part of using AWS involves balancing your Reserved Instance (RI) usage and your On-Demand instance usage. We provide recommendations on which RIs will help reduce costs incurred from using On-Demand instances.<br/>AWS generates these recommendations by analyzing your On-Demand usage for the past 30 days, and then categorizing the usage into eligible categories for reservations. We then simulate every combination of reservations in the generated category of usage in order to identify the best number of each type of RI to purchase to maximize your savings. This check covers recommendations based on Standard Reserved Instances with partial upfront payment option. This check is not available to accounts linked in Consolidated Billing. Recommendations are only available for the Paying Account.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: Optimizing the use of partial upfront RIs can help reduce costs.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>See the <a href="https://aws.amazon.com/aws-cost-management/aws-cost-explorer/" target="_blank">Cost Explorer</a> page for more detailed and customized recommendations. Additionally, refer to the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-market-general.html#ri-market-buying-guide" target="_blank">buying guide</a> to understand how to purchase RIs and the options available.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/>Information on RIs and how they can save you money can be found <a href="https://aws.amazon.com/ec2/pricing/reserved-instances/" target="_blank">here</a>.<br/>For more information on this recommendation, see <a href="https://aws.amazon.com/premiumsupport/technology/trusted-advisor/faqs/#Reserved_Instance_Optimization_Check_Questions" target="_blank">Reserved Instance Optimization Check Questions</a> in the Trusted Advisor FAQs.')
+, ROW ('Hs4Ma3G224', 'en', 'OpenSearch domains should be in a VPC', 'Checks Amazon OpenSearch Service domains are in an Amazon Virtual Private Cloud (VPC).')
 , ROW ('Hs4Ma3G103', 'en', 'Amazon Redshift clusters should prohibit public access', 'Checks if Amazon Redshift clusters are publicly accessible. It evaluates the publiclyAccessible field in the cluster configuration item.')
+, ROW ('Hs4Ma3G225', 'en', 'OpenSearch domains should have encryption at rest enabled', 'Checks if Amazon OpenSearch domains have encryption-at-rest configuration enabled. The check fails if encryption at rest is not enabled.')
 , ROW ('Hs4Ma3G104', 'en', 'Redshift clusters should use enhanced VPC routing', 'Checks if a Redshift cluster has EnhancedVpcRouting enabled.')
+, ROW ('Hs4Ma3G226', 'en', 'Amazon EC2 instances launched using Auto Scaling group launch configurations should not have Public IP addresses', 'Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled using launch configurations.')
 , ROW ('Hs4Ma3G105', 'en', 'Amazon Redshift should have automatic upgrades to major versions enabled', 'Checks if an Amazon Redshift cluster is configured with automatic upgrades to major versions.')
+, ROW ('Hs4Ma3G227', 'en', 'CloudFront distributions should use custom SSL/TLS certificates', 'Checks if CloudFront distributions are using the default SSL/TLS certificate CloudFront provides instead of a custom one. This check fails for a CloudFront distribution if it uses the default SSL/TLS certificate.')
 , ROW ('Hs4Ma3G106', 'en', 'Amazon Redshift clusters should have audit logging enabled', 'Checks if an Amazon Redshift cluster has audit logging enabled.')
+, ROW ('Hs4Ma3G228', 'en', 'CloudFront distributions should use SNI to serve HTTPS requests', 'Checks if Amazon CloudFront distributions are using a custom SSL/TLS certificate and are configured to use SNI to serve HTTPS requests as opposed to dedicated IP address.')
 , ROW ('Hs4Ma3G107', 'en', 'CloudFront distributions should require encryption in transit', 'Checks if an Amazon CloudFront distribution requires viewers to use HTTPS directly, or if it uses redirection. The check fails if ViewerProtocolPolicy is set to allow-all for defaultCacheBehavior or for cacheBehaviors.')
-, ROW ('Hs4Ma3G108', 'en', 'CloudTrail trails should be integrated with Amazon CloudWatch Logs', 'Checks if AWS CloudTrail trails are configured to send logs to Amazon CloudWatch Logs.')
-, ROW ('Hs4Ma3G109', 'en', 'CloudTrail log file validation should be enabled', 'Checks if CloudTrail log file validation is enabled.')
-, ROW ('Hs4Ma3G110', 'en', 'CloudTrail should have encryption at-rest enabled', 'Checks whether AWS CloudTrail is configured to use the server-side encryption (SSE) AWS Key Management Service (AWS KMS) key encryption. The check will pass if the KmsKeyId is defined.')
+, ROW ('S45wrEXrLz', 'en', 'VPN Tunnel Redundancy', 'Checks the number of tunnels that are active for each of your VPNs. A VPN should have two tunnels configured at all times to provide redundancy in case of outage or planned maintenance of the devices at the AWS endpoint. For some hardware, only one tunnel is active at a time (see the <a href="http://docs.aws.amazon.com/AmazonVPC/latest/NetworkAdminGuide/Welcome.html" target="_blank">Amazon Virtual Private Cloud Network Administrator Guide</a>). If a VPN has no active tunnels, charges for the VPN might still apply.')
+, ROW ('Hs4Ma3G241', 'en', 'Secrets should not be passed as container environment variable', 'Checks if the container environment variables includes the following keys - AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY,  or ECS_ENGINE_AUTH_DATA.')
+, ROW ('Hs4Ma3G120', 'en', 'Stopped EC2 instances should be removed after a specified time period', 'Checks if any EC2 instances have been stopped for more than the allowed number of days. An EC2 instance fails this check if it is stopped for longer than the maximum allowed time period, which by default is 30 days.')
+, ROW ('Hs4Ma3G242', 'en', 'Amazon ECR private repositories should have image scanning enabled', 'Checks if a private ECR repository has image scanning enabled. This check fails if a private ECR repository has image scanning disabled. Amazon ECR image scanning helps in identifying software vulnerabilities in your container images. Amazon ECR uses the Common Vulnerabilities and Exposures (CVEs) database from the open-source Clair project and provides a list of scan findings. Enabling image scanning on ECR repositories adds a layer of verification for the integrity and safety of the images being stored.')
+, ROW ('Hs4Ma3G121', 'en', 'EBS default encryption should be enabled', 'Checks if Amazon Elastic Block Store (EBS) encryption is enabled by default. The check fails if EBS default encryption is not enabled.')
+, ROW ('Hs4Ma3G119', 'en', 'EBS volumes should be attached to EC2 instances', 'Checks if EBS volumes are attached to EC2 instances.')
+, ROW ('4g3Nt5M1Th', 'en', 'AWS Direct Connect Virtual Interface Redundancy', 'Checks for virtual private gateways with Direct Connect virtual interfaces (VIFs) that are not configured on at least two Direct Connect connections. Connectivity to your virtual private gateway should have multiple virtual interfaces configured across multiple Direct Connect connections and locations to provide redundancy in case a device or location is unavailable. <br/><h4 class=headerBodyStyle>Note:</h4> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow:  A virtual private gateway has less than two virtual interfaces, or the interfaces are not configured to multiple Direct Connect connections. <br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Configure at least two virtual interfaces that are configured to two Direct Connect connections to protect against device or location unavailability. See <a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getstarted.html#createvirtualinterface">Create a Virtual Interface.</a><br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Getting Started with AWS Direct Connect</a><br/><a target="_blank" href="https://aws.amazon.com/directconnect/faqs/">AWS Direct Connect FAQs</a> <br/><a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html">Working With AWS Direct Connect Virtual Interfaces</a>')
+, ROW ('Hs4Ma3G232', 'en', 'RDS Database Clusters should use a custom administrator username', 'Checks if an RDS database cluster has changed the admin username from its default value. This rule will fail if the admin username is set to the default value.')
 , ROW ('Hs4Ma3G111', 'en', 'CloudTrail should be enabled and configured with at least one multi-region trail', 'Checks that there is at least one multi-region AWS CloudTrail trail.')
+, ROW ('Hs4Ma3G233', 'en', 'RDS database instances should use a custom administrator username', 'Checks if an Amazon Relational Database Service (Amazon RDS) database instance has changed the admin username from its default value. This rule will only run on RDS database instances. The rule will fail if the admin username is set to the default value.')
 , ROW ('Hs4Ma3G112', 'en', 'Secrets Manager secrets should be rotated within a specified number of days', 'Checks if your secrets have rotated at least once within 90 days.')
+, ROW ('Hs4Ma3G234', 'en', 'AWS CodeBuild S3 Logs should be encrypted', 'Checks if a AWS CodeBuild project configured with Amazon S3 Logs has encryption enabled for its logs.')
 , ROW ('Hs4Ma3G113', 'en', 'Secrets Manager secrets configured with automatic rotation should rotate successfully', 'Checks if an AWS Secrets Manager secret rotated successfully based on the rotation schedule. The check fails if RotationOccurringAsScheduled is false. The check does not evaluate secrets that do not have rotation configured.')
+, ROW ('Hs4Ma3G235', 'en', 'Amazon ECR private repositories should have tag immutability enabled', 'Checks if a private ECR repository has tag immutability enabled. This check fails if a private ECR repository has tag immutability disabled.')
 , ROW ('Hs4Ma3G114', 'en', 'Remove unused Secrets Manager secrets', 'Checks if your secrets have been accessed within a specified number of days. The default value is 90 days. Secrets that have not been accessed even once within the number days you define, fail this check.')
+, ROW ('Hs4Ma3G236', 'en', 'Amazon ECS Task Definitions should not share the hosts process namespace', 'Checks if Amazon ECS Task Definitions are configured to share a hosts process namespace with its containers.')
 , ROW ('Hs4Ma3G115', 'en', 'Secrets Manager secrets should have automatic rotation enabled', 'Checks if a secret stored in AWS Secrets Manager is configured to rotate automatically.')
+, ROW ('jEECYg2YVU', 'en', 'RDS DB Parameter Groups', 'Checks for usage that is more than 80% of the RDS DB Parameter Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Hs4Ma3G237', 'en', 'Amazon ECS Containers should run as non-privileged', 'Checks if the Privileged parameter in the container definition of Amazon ECS Task Definitions is set to true.')
 , ROW ('Hs4Ma3G116', 'en', 'EBS snapshots should not be public, determined by the ability to be restorable by anyone', 'Checks if Amazon Elastic Block Store snapshots are not publicly restorable.')
+, ROW ('Hs4Ma3G238', 'en', 'Amazon ECS Containers should only have read-only access to its root filesystems', 'Checks if ECS Containers are limited to read-only access to its mounted root filesystems.')
 , ROW ('Hs4Ma3G117', 'en', 'Attached EBS volumes should be encrypted at-rest', 'Checks if the EBS volumes that are in an attached state are encrypted.')
+, ROW ('dYWBaXaaMM', 'en', 'RDS Subnet Groups', 'Checks for usage that is more than 80% of the RDS Subnet Groups Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
 , ROW ('Hs4Ma3G118', 'en', 'The VPC default security group should not allow inbound and outbound traffic', 'Checks that the default security group of a VPC does not allow inbound or outbound traffic.')
-, ROW ('Hs4Ma3G119', 'en', 'EBS volumes should be attached to EC2 instances', 'Checks if EBS volumes are attached to EC2 instances.')
-, ROW ('Hs4Ma3G120', 'en', 'Stopped EC2 instances should be removed after a specified time period', 'Checks if any EC2 instances have been stopped for more than the allowed number of days. An EC2 instance fails this check if it is stopped for longer than the maximum allowed time period, which by default is 30 days.')
-, ROW ('Hs4Ma3G121', 'en', 'EBS default encryption should be enabled', 'Checks if Amazon Elastic Block Store (EBS) encryption is enabled by default. The check fails if EBS default encryption is not enabled.')
-, ROW ('Hs4Ma3G122', 'en', 'VPC flow logging should be enabled in all VPCs', 'Checks if Amazon Virtual Private Cloud flow logs are found and enabled for Amazon VPCs. The traffic type is set to Reject.')
-, ROW ('Hs4Ma3G123', 'en', 'EC2 instances should not have a public IPv4 address', 'Checks if EC2 instances have a public IP address. The check fails if the publicIp field is present in the EC2 instance configuration item. This check applies to IPv4 addresses only.')
-, ROW ('Hs4Ma3G124', 'en', 'EC2 instances should use Instance Metadata Service Version 2 (IMDSv2)', 'Checks if your Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is configured with Instance Metadata Service Version 2 (IMDSv2). The check passes if HttpTokens is set to required for IMDSv2. The check fails if HttpTokens is set to optional.')
-, ROW ('Hs4Ma3G125', 'en', 'API Gateway should be associated with a WAF Web ACL', 'Checks to see if an API Gateway stage is using an AWS WAF Web ACL. This check fails if an AWS WAF Web ACL is not attached to a REST API Gateway stage.')
-, ROW ('Hs4Ma3G126', 'en', 'DynamoDB Accelerator (DAX) clusters should be encrypted at rest', 'Checks if a DAX cluster is encrypted at rest.')
-, ROW ('Hs4Ma3G127', 'en', 'API Gateway REST and WebSocket API execution logging should be enabled', 'Checks if all stages of Amazon API Gateway REST and WebSocket APIs have logging enabled. The check fails if logging is not enabled for all methods of a stage or if loggingLevel is neither ERROR nor INFO.')
-, ROW ('Hs4Ma3G128', 'en', 'API Gateway REST API stages should be configured to use SSL certificates for backend authentication', 'Checks if Amazon API Gateway REST API stages have SSL certificates configured that backend systems can use to authenticate that incoming requests are from the API Gateway.')
-, ROW ('Hs4Ma3G129', 'en', 'API Gateway REST API stages should have AWS X-Ray tracing enabled', 'Checks if AWS X-Ray active tracing is enabled for your Amazon API Gateway REST API stages.')
-, ROW ('Hs4Ma3G130', 'en', 'Lambda functions should use supported runtimes', 'Checks that the lambda function settings for runtimes, match the expected values set for the supported runtimes for each language. The supported runtimes this check assesses for are: nodejs14.x, nodejs12.x, python3.8, python3.7, python3.6, java11, java8, go1.x, dotnetcore2.1, dotnetcore3.1, ruby2.7.')
-, ROW ('Hs4Ma3G131', 'en', 'Lambda function policies should prohibit public access', 'Checks if the AWS Lambda function policy attached to the Lambda resource prohibits public access. If the Lambda function policy allows public access, the check fails.')
-, ROW ('Hs4Ma3G132', 'en', 'Database Migration Service replication instances should not be public', 'Checks if AWS Database Migration Service replication instances are public by examining the PubliclyAccessible field value.')
-, ROW ('Hs4Ma3G133', 'en', 'IAM customer managed policies should not allow decryption actions on all KMS keys', 'Checks if the default version of IAM customer managed policies allow principals to use the AWS Key Management Service (KMS) decryption actions on all resources. This check fails if kms:Decrypt or kms:ReEncryptFrom actions are allowed on all KMS keys. The check evaluates both attached and unattached customer managed policies. It does not check inline policies or AWS managed policies.')
-, ROW ('Hs4Ma3G134', 'en', 'IAM principals should not have IAM inline policies that allow decryption actions on all KMS keys', 'Checks if the inline policies embedded in your IAM principals (Role/User/Group) allow the AWS Key Management Service (KMS) decryption actions on all KMS keys. This check fails if kms:Decrypt or kms:ReEncryptFrom actions are allowed on all KMS keys in an inline policy.')
-, ROW ('Hs4Ma3G135', 'en', 'AWS KMS keys should not be deleted unintentionally', 'Checks whether AWS Key Management Service (KMS) keys are scheduled for deletion. The check fails if a KMS key is scheduled for deletion.')
-, ROW ('Hs4Ma3G136', 'en', 'Amazon SQS queues should be encrypted at rest', 'Checks if Amazon SQS queues are encrypted at rest.')
-, ROW ('Hs4Ma3G137', 'en', 'IAM policies should not allow full "*" administrative privileges', 'Checks if the default version of AWS Identity and Access Management (IAM) policies (also known as customer managed policies) do not have administrator access with a statement that has "Effect": "Allow" with "Action": "*" over "Resource": "*". It only assesses for the Customer Managed Policies that you created, but not inline and AWS Managed Policies.')
-, ROW ('Hs4Ma3G138', 'en', 'IAM users should not have IAM policies attached', 'Checks that none of your IAM users have policies attached. Instead, IAM users must inherit permissions from IAM groups or roles.')
-, ROW ('Hs4Ma3G139', 'en', 'IAM users access keys should be rotated every 90 days or less', 'Checks if the active access keys are rotated within 90 days.')
-, ROW ('Hs4Ma3G140', 'en', 'IAM root user access key should not exist', 'Checks if the root user access key is available.')
-, ROW ('Hs4Ma3G141', 'en', 'MFA should be enabled for all IAM users that have a console password', 'Checks if AWS Multi-Factor Authentication (MFA) is enabled for all AWS Identity and Access Management (IAM) users that use a console password.')
-, ROW ('Hs4Ma3G142', 'en', 'Hardware MFA should be enabled for the root user', 'Checks if your AWS account is enabled to use hardware multi-factor authentication (MFA) device to sign in with root credentials.')
-, ROW ('Hs4Ma3G143', 'en', 'Password policies for IAM users should have strong configurations', 'Checks if the account password policy for IAM users uses the following recommended configurations: RequireUppercaseCharacters: true, RequireLowercaseCharacters: true, RequireSymbols: true, RequireNumbers: true, MinimumPasswordLength: 8.')
-, ROW ('Hs4Ma3G144', 'en', 'Unused IAM user credentials should be removed', 'Checks if your IAM users have passwords or active access keys that were not used within the previous 90 days.')
-, ROW ('Hs4Ma3G145', 'en', 'Amazon ECS task definitions should have secure networking modes and user definitions.', 'Checks if an Amazon ECS Task Definition with host networking mode has "privileged" or "user" container definitions. The check fails with host network mode and container definitions are privileged=false or empty and user=root or empty.')
-, ROW ('Hs4Ma3G146', 'en', 'ECS services should not have public IP addresses assigned to them automatically', 'Checks if ECS services are configured to automatically assign public IP addresses. This check fails if AssignPublicIP is ENABLED.')
-, ROW ('Hs4Ma3G147', 'en', 'Amazon Elasticsearch Service domains should be in a VPC', 'Checks whether Amazon Elasticsearch Service domains are in a VPC. It does not evaluate the VPC subnet routing configuration to determine public reachability. This check also does not check whether the Amazon OpenSearch Service resource-based policy permits public access by other accounts or external entities. You should ensure that Amazon Elasticsearch Service domains are not attached to public subnets. See Resource-based policies (https://docs.aws.amazon.com/opensearch-service/latest/developerguide/ac.html#ac-types-resource) in the Amazon OpenSearch Service (successor to Amazon Elasticsearch Service) Developer Guide. You should also ensure that your VPC is configured according to the recommended best practices. See Security best practices for your VPC (https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html) in the Amazon VPC User Guide.')
-, ROW ('Hs4Ma3G148', 'en', 'Elastic Beanstalk environments should have enhanced health reporting enabled', 'Checks if enhanced health reporting is enabled for your AWS Elastic Beanstalk environments.')
-, ROW ('Hs4Ma3G149', 'en', 'Elastic Beanstalk managed platform updates should be enabled', 'Checks if managed platform updates are enabled for the AWS Elastic Beanstalk environment.')
-, ROW ('Hs4Ma3G150', 'en', 'Elasticsearch domains should encrypt data sent between nodes', 'Checks if Elasticsearch domains have node-to-node encryption enabled.')
-, ROW ('Hs4Ma3G151', 'en', 'An RDS event notifications subscription should be configured for critical database parameter group events', 'Checks if an Amazon RDS Event subscription for RDS parameter groups is configured to notify on event category of "configuration change".')
-, ROW ('Hs4Ma3G152', 'en', 'An RDS event notifications subscription should be configured for critical database instance events', 'Checks if an Amazon RDS Event subscription for RDS instances is configured to notify on event categories of both "maintenance", "configuration change", and "failure".')
-, ROW ('Hs4Ma3G153', 'en', 'RDS instances should not use a database engine default port', 'Checks if RDS instances use the default port of that database engine.')
-, ROW ('Hs4Ma3G154', 'en', 'An RDS event notifications subscription should be configured for critical database security group events', 'Checks if an Amazon RDS Event subscription for RDS security groups is configured to notify on event categories of both "configuration change" and "failure".')
-, ROW ('Hs4Ma3G155', 'en', 'EC2 instances should be managed by AWS Systems Manager', 'Checks if the Amazon EC2 instances in your account are managed by AWS Systems Manager.')
-, ROW ('Hs4Ma3G156', 'en', 'EC2 instances managed by Systems Manager should have a patch compliance status of COMPLIANT after a patch installation', 'Checks if the compliance status of the Amazon EC2 Systems Manager patch compliance is COMPLIANT or NON_COMPLIANT after the patch installation on the instance. It only assesses instances that are managed by AWS Systems Manager Patch Manager.')
-, ROW ('Hs4Ma3G157', 'en', 'EC2 instances managed by Systems Manager should have an association compliance status of COMPLIANT', 'Checks if the status of the AWS Systems Manager association compliance is COMPLIANT or NON_COMPLIANT after the association is executed on an instance.')
-, ROW ('Hs4Ma3G158', 'en', 'SSM documents should not be public', 'Checks if AWS Systems Manager documents that the account owns are public. This check fails if SSM documents that have "Self" as the owner are public.')
-, ROW ('Hs4Ma3G159', 'en', 'Elastic File System should be configured to encrypt file data at-rest using AWS KMS', 'Checks if Amazon Elastic File System (Amazon EFS) is configured to encrypt the file data using AWS Key Management Service (AWS KMS). The check will fail if the encrypted key is set to false on DescribeFileSystems or if the KmsKeyId key on DescribeFileSystems does not match the KmsKeyId parameter.')
-, ROW ('Hs4Ma3G160', 'en', 'IAM authentication should be configured for RDS instances', 'Checks if an RDS DB instance has IAM database authentication enabled.')
-, ROW ('Hs4Ma3G161', 'en', 'IAM authentication should be configured for RDS clusters', 'Checks if an RDS DB cluster has IAM database authentication enabled.')
-, ROW ('Hs4Ma3G162', 'en', 'RDS automatic minor version upgrades should be enabled', 'Checks if automatic minor version upgrades are enabled for the Amazon RDS database instance.')
-, ROW ('Hs4Ma3G163', 'en', 'RDS DB clusters should be configured to copy tags to snapshots', 'Checks if RDS DB clusters are configured to copy all tags to snapshots when the snapshots are created.')
-, ROW ('Hs4Ma3G164', 'en', 'RDS DB instances should be configured to copy tags to snapshots', 'Checks if RDS DB instances are configured to copy all tags to snapshots when the snapshots are created.')
-, ROW ('Hs4Ma3G165', 'en', 'RDS instances should be deployed in a VPC', 'Checks if an RDS instance is deployed in a VPC (EC2-VPC).')
-, ROW ('Hs4Ma3G166', 'en', 'An RDS event notifications subscription should be configured for critical cluster events', 'Checks if an Amazon RDS Event subscription for RDS clusters is configured to notify on event categories of both "maintenance" and "failure".')
-, ROW ('Hs4Ma3G167', 'en', 'S3 buckets should have server-side encryption enabled', 'Checks that your Amazon S3 bucket either has Amazon S3 default encryption enabled or that the S3 bucket policy explicitly denies put-object requests without server side encryption.')
-, ROW ('Hs4Ma3G168', 'en', 'S3 buckets should require requests to use Secure Socket Layer', 'Checks if S3 buckets have policies that require requests to use Secure Socket Layer (SSL).')
-, ROW ('Hs4Ma3G169', 'en', 'S3 permissions granted to other AWS accounts in bucket policies should be restricted', 'Checks if the S3 bucket policy allows sensitive bucket-level or object-level actions from a principal in another AWS account. The check fails if any of the following actions are allowed in the S3 bucket policy for a principal in another AWS account: s3:DeleteBucketPolicy, s3:PutBucketAcl, s3:PutBucketPolicy, s3:PutObjectAcl, and s3:PutEncryptionConfiguration.')
-, ROW ('Hs4Ma3G170', 'en', 'S3 Block Public Access setting should be enabled', 'Checks if the following public access block settings are configured from account level: ignorePublicAcls: True, blockPublicPolicy: True, blockPublicAcls: True, restrictPublicBuckets: True.')
-, ROW ('Hs4Ma3G171', 'en', 'S3 buckets should prohibit public read access', 'Checks if your S3 buckets allow public read access by evaluating the Block Public Access settings, the bucket policy, and the bucket access check list (ACL).')
-, ROW ('Hs4Ma3G172', 'en', 'S3 buckets should prohibit public write access', 'Checks if your S3 buckets allow public write access by evaluating the Block Public Access settings, the bucket policy, and the bucket access check list (ACL).')
-, ROW ('Hs4Ma3G173', 'en', 'S3 Block Public Access setting should be enabled at the bucket-level', 'Checks if Amazon S3 buckets have bucket level public access blocks applied. This check fails if any of the bucket level settings are set to "false" public: ignorePublicAcls, blockPublicPolicy, blockPublicAcls, restrictPublicBuckets.')
-, ROW ('Hs4Ma3G174', 'en', 'CodeBuild GitHub or Bitbucket source repository URLs should use OAuth', 'Checks if the GitHub or Bitbucket source repository URL contains either personal access tokens or user name and password.')
-, ROW ('Hs4Ma3G175', 'en', 'CodeBuild project environment variables should not contain clear text credentials', 'Checks if the project contains environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.')
-, ROW ('Hs4Ma3G176', 'en', 'ACM certificates should be renewed after a specified time period', 'Checks if ACM Certificates in your account are marked for expiration within a specified time period. Certificates provided by ACM are automatically renewed. ACM does not automatically renew certificates that you import.')
-, ROW ('Hs4Ma3G177', 'en', 'Auto scaling groups associated with a load balancer should use load balancer health checks', 'Checks if your Auto Scaling groups that are associated with a load balancer are using Elastic Load Balancing health checks.')
-, ROW ('Hs4Ma3G178', 'en', 'Security groups should only allow unrestricted incoming traffic for authorized ports', 'Checks if the security groups allow unrestricted incoming traffic. The check fails if ports allow unrestricted traffic on ports other than 80 and 443, which are default values for parameter authorizedTcpPorts.')
-, ROW ('Hs4Ma3G179', 'en', 'SNS topics should be encrypted at-rest using AWS KMS', 'Checks if an Amazon SNS topic is encrypted at rest using AWS KMS.')
-, ROW ('Hs4Ma3G180', 'en', 'Amazon Elasticsearch Service domain error logging to CloudWatch Logs should be enabled', 'Checks whether Amazon Elasticsearch Service domains are configured to send error logs to CloudWatch Logs.')
-, ROW ('Hs4Ma3G181', 'en', 'Classic Load Balancers with SSL/HTTPS listeners should use a certificate provided by AWS Certificate Manager', 'Checks if a Classic Load Balancer uses HTTPS/SSL certificates provided by AWS Certificate Manager. The check fails if a Classic Load Balancer that is configured with an HTTPS/SSL listener does not use a certificate provided by AWS Certificate Manager.')
-, ROW ('Hs4Ma3G182', 'en', 'Classic Load Balancer listeners should be configured with HTTPS or TLS termination', 'Checks if your Classic Load Balancer listeners are configured with HTTPS or TLS protocol for front-end (client to load balancer) connections. The check is applicable if a Classic Load Balancer has listeners. If your Classic Load Balancer does not have a listener configured, then the check does not report any findings.')
-, ROW ('Hs4Ma3G183', 'en', 'Application load balancer should be configured to drop http headers', 'This check evaluates AWS Application Load Balancers (ALB) to ensure they are configured to drop http headers. By default, ALBs are not configured to drop invalid http header values. This check evaluates all ALBs fails if the attribute value of routing.http.drop_invalid_header_fields.enabled is set to false.')
-, ROW ('Hs4Ma3G184', 'en', 'Application and Classic Load Balancers logging should be enabled', 'Checks if the Application Load Balancer and the Classic Load Balancer have logging enabled. The check fails if the access_logs.s3.enabled is false.')
-, ROW ('Hs4Ma3G185', 'en', 'IAM customer managed policies that you create should not allow wildcard actions for services', 'Checks if the IAM identity-based custom policies have Allow statements that grant permissions for all actions on a service. The check fails if any policy statement includes "Effect": "Allow" with "Action": "Service:".')
-, ROW ('Hs4Ma3G186', 'en', 'AWS WAF Classic Global Web ACL logging should be enabled', 'Checks if logging is enabled for a WAF global Web ACL. This check fails if logging is not enabled for the Web ACL.')
-, ROW ('Hs4Ma3G187', 'en', 'Connections to Amazon Elasticsearch Service domains should be encrypted using TLS 1.2', 'Checks whether connections to Amazon Elasticsearch Service domains are required to use TLS 1.2.  The check fails if the Amazon Elasticsearch Service domain TLSSecurityPolicy is not Policy-Min-TLS-1-2-2019-07.')
-, ROW ('Hs4Ma3G188', 'en', 'GuardDuty should be enabled', 'Checks if Amazon GuardDuty is enabled in your AWS account and region.')
-, ROW ('Hs4Ma3G189', 'en', 'Enhanced monitoring should be configured for RDS DB instances', 'Checks if enhanced monitoring is enabled for your RDS DB instances.')
-, ROW ('Hs4Ma3G190', 'en', 'RDS clusters should have deletion protection enabled', 'Checks if RDS clusters have deletion protection enabled.')
-, ROW ('Hs4Ma3G191', 'en', 'RDS cluster snapshots and database snapshots should be encrypted at rest', 'Checks if Amazon RDS cluster snapshots and database snapshots are encrypted.')
-, ROW ('Hs4Ma3G192', 'en', 'RDS DB Instances should prohibit public access, determined by the PubliclyAccessible configuration', 'Checks if RDS instances are publicly accessible by evaluating the publiclyAccessible field in the instance configuration item.')
-, ROW ('Hs4Ma3G193', 'en', 'RDS DB instances should have encryption at-rest enabled', 'Checks if storage encryption is enabled for your RDS DB instances.')
-, ROW ('Hs4Ma3G194', 'en', 'RDS snapshot should be private', 'Checks if Amazon Relational Database Service (Amazon RDS) snapshots are public.')
-, ROW ('Hs4Ma3G195', 'en', 'CloudFront distributions should have origin access identity enabled', 'Checks if an Amazon CloudFront distribution with an Amazon S3 origin type has Origin Access Identity (OAI) configured. The check fails if the CloudFront distribution that is backed by Amazon S3 does not have OAI configured.')
-, ROW ('Hs4Ma3G196', 'en', 'AWS Config should be enabled', 'Checks if the Config service is enabled in the account for the local region and is recording all resources.')
-, ROW ('Hs4Ma3G197', 'en', 'Amazon Elasticsearch Service domains should have encryption at-rest enabled', 'Checks whether Amazon Elasticsearch Service domains have encryption at rest configuration enabled. This check fails if the EncryptionAtRestOptions field is not enabled.')
-, ROW ('Hs4Ma3G198', 'en', 'RDS DB instances should have deletion protection enabled', 'Checks if RDS DB instances have deletion protection enabled.')
-, ROW ('Hs4Ma3G199', 'en', 'Database logging should be enabled', 'Checks if the following Amazon RDS logs are enabled and sent to CloudWatch Logs: Oracle: (Alert, Audit, Trace, Listener), PostgreSQL: (Postgresql, Upgrade), MySQL: (Audit, Error, General, SlowQuery), MariaDB: (Audit, Error, General, SlowQuery), SQL Server: (Error, Agent), Aurora: (Audit, Error, General, SlowQuery), Aurora-MySQL: (Audit, Error, General, SlowQuery), Aurora-PostgreSQL: (Postgresql).')
+, ROW ('MDBdfsQ401', 'en', 'Amazon MemoryDB Multi-AZ clusters', 'Checks for MemoryDB clusters that deploy in a single Availability Zone (AZ). This check alerts you if Multi-AZ is inactive in a cluster.<br/><br/>Deployments in multiple AZs enhance MemoryDB cluster availability by asynchronously replicating to read-only replicas in a different AZ. When planned cluster maintenance occurs, or a primary node is unavailable, MemoryDB automatically promotes a replica to primary. This failover allows cluster write operations to resume, and doesnt require an administrator to intervene.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Green: Multi-AZ is active in the cluster.')
+, ROW ('0Xc6LMYG8P', 'en', 'EC2 On-Demand Instances', 'Checks for usage that is more than 80% of the EC2 On-Demand Instances Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('Bh2xRR2FGH', 'en', 'Amazon EC2 to EBS Throughput Optimization', 'Checks for Amazon EBS volumes whose performance might be affected by the maximum throughput capability of the Amazon EC2 instance they are attached to. To optimize performance, you should ensure that the maximum throughput of an EC2 instance is greater than the aggregate maximum throughput of the attached EBS volumes. This check computes the total EBS volume throughput for each five-minute period in the preceding day (UTC) for each EBS-optimized instance and alerts you if usage in more than half of those periods was greater than 95% of the maximum throughput of the EC2 instance.<br/><br/> <h4 class=headerBodyStyle>Alert Criteria</h4><br/> Yellow: In the preceding day (UTC), the aggregate throughput (megabytes/sec) of the EBS volumes attached to the EC2 instance exceeded 95% of the published throughput between the instance and the EBS volumes more than 50% of time.<br/><br/> <h4 class=headerBodyStyle>Recommended Action</h4><br/> Compare the maximum throughput of your EBS volumes (see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html" target="_blank">Amazon EBS Volume Types</a>) with the maximum throughput of the EC2 instance they are attached to (see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html#ebs-optimization-support" target="_blank">Instance Types That Support EBS Optimization</a>). Consider attaching your volumes to an instance that supports higher throughput to EBS for optimal performance.<br/><br/> <h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html" target="_blank">Amazon EBS Volume Types</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html" target="_blank">Amazon EBS-Optimized Instances</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html" target="_blank">Monitoring the Status of Your Volumes</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-attaching-volume.html" target="_blank">Attaching an Amazon EBS Volume to an Instance</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-detaching-volume.html" target="_blank">Detaching an Amazon EBS Volume from an Instance</a><br/> <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-deleting-volume.html" target="_blank">Deleting an Amazon EBS Volume</a> ')
+, ROW ('ECHdfsQ402', 'en', 'Amazon ElastiCache Multi-AZ clusters', 'Checks for ElastiCache clusters that deploy in a single Availability Zone (AZ). This check alerts you if Multi-AZ is inactive in a cluster.<br/><br/>Deployments in multiple AZs enhance ElastiCache cluster availability by asynchronously replicating to read-only replicas in a different AZ. When planned cluster maintenance occurs, or a primary node is unavailable, ElastiCache automatically promotes a replica to primary. This failover allows cluster write operations to resume, and doesnt require an administrator to intervene.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Green: Multi-AZ is active in the cluster.')
+, ROW ('Hs4Ma3G207', 'en', 'EC2 subnets should not automatically assign public IP addresses', 'Checks if the assignment of public IPs in Amazon Virtual Private Cloud (VPC) subnets have the MapPublicIpOnLaunch set to FALSE. The check will pass if the flag is set to FALSE.')
+, ROW ('Hs4Ma3G208', 'en', 'EC2 instances should not use multiple ENIs', 'Checks to see if Amazon EC2 instance uses multiple ENI/EFA. This check will pass if single network adapters is used.')
+, ROW ('Hs4Ma3G209', 'en', 'Unused Network Access Control Lists should be removed', 'Checks to see if there are any NACLs (Network Access Control List) that are unused. The check will check the item configuration of the resource AWS::EC2::NetworkAcl and determine the relationships of the NACL.')
+, ROW ('iH7PP0l7J9', 'en', 'EC2 Reserved Instance Leases', 'Checks for usage that is more than 80% of the EC2 Reserved Instance Leases Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
 , ROW ('Hs4Ma3G200', 'en', 'CloudFront distributions should have a default root object configured', 'Checks if an Amazon CloudFront distribution is configured to return a specific object that is the default root object. The check fails if the CloudFront distribution does not have a default root object configured.')
 , ROW ('Hs4Ma3G201', 'en', 'CloudFront distributions should have WAF enabled', 'Checks to see if Amazon CloudFront distributions are associated with either WAF or WAFv2 web ACLs. The check fails if a CloudFront distribution is not associated with a web ACL.')
 , ROW ('Hs4Ma3G202', 'en', 'API Gateway REST API cache data should be encrypted at rest', 'Checks if all methods in Amazon API Gateway REST API stages that have cache enabled are encrypted. The check fails if any method in API Gateway REST API stage is configured to cache and the cache is not encrypted.')
 , ROW ('Hs4Ma3G203', 'en', 'Amazon Elasticsearch Service domains should have audit logging enabled', 'This check checks whether Amazon Elasticsearch Service domains have audit logging enabled. This check fails if an Amazon Elasticsearch Service domain does not have audit logging enabled.')
 , ROW ('Hs4Ma3G204', 'en', 'Security groups should not allow unrestricted access to ports with high risk', 'Checks if unrestricted incoming traffic for the security groups is accessible to the specified ports [3389, 20, 23, 110, 143, 3306, 8080, 1433, 9200, 9300, 25, 445, 135, 21, 1434, 4333, 5432, 5500, 5601, 22 ] that have the highest risk. This check passes when none of the rules in a security group allow ingress traffic from 0.0.0.0/0 for the listed ports.')
 , ROW ('Hs4Ma3G205', 'en', 'Classic Load Balancers with HTTPS/SSL listeners should use a predefined security policy that has strong configuration', 'Checks if your Classic Load Balancer SSL listeners use the predefined policy ELBSecurityPolicy-TLS-1-2-2017-01. The check fails if the Classic Load Balancer SSL listeners do not use the predefined policy ELBSecurityPolicy-TLS-1-2-2017-01.')
+, ROW ('51fC20e7I2', 'en', 'Amazon Route 53 Latency Resource Record Sets', 'Checks for Amazon Route 53 latency record sets that are configured inefficiently. To allow Amazon Route 53 to route queries to the region with the lowest network latency, you should create latency resource record sets for a particular domain name (such as example.com) in different regions. If you create only one latency resource record set for a domain name, all queries are routed to one region, and you pay extra for latency-based routing without getting the benefits. Hosted zones created by AWS services wonâ€™t appear in your check results.')
 , ROW ('Hs4Ma3G206', 'en', 'Amazon EC2 should be configured to use VPC endpoints that are created for the Amazon EC2 service', 'Checks if a service endpoint for Amazon EC2 is created for each VPC. The check fails if a VPC does not have a VPC endpoint created for the Amazon EC2 service.')
-, ROW ('Hs4Ma3G207', 'en', 'EC2 subnets should not automatically assign public IP addresses', 'Checks if the assignment of public IPs in Amazon Virtual Private Cloud (VPC) subnets have the MapPublicIpOnLaunch set to FALSE. The check will pass if the flag is set to FALSE.')
-, ROW ('Hs4Ma3G208', 'en', 'EC2 instances should not use multiple ENIs', 'Checks to see if Amazon EC2 instance uses multiple ENI/EFA. This check will pass if single network adapters is used.')
-, ROW ('Hs4Ma3G209', 'en', 'Unused Network Access Control Lists should be removed', 'Checks to see if there are any NACLs (Network Access Control List) that are unused. The check will check the item configuration of the resource AWS::EC2::NetworkAcl and determine the relationships of the NACL.')
+, ROW ('hJ7NN0l7J9', 'en', 'SES Daily Sending Quota', 'Checks for usage that is more than 80% of the SES Daily Sending Quota Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('dH7RR0l6J3', 'en', 'EBS General Purpose SSD (gp3) Volume Storage', 'Checks for usage that is more than 80% of the EBS General Purpose SSD (gp3) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('dH7RR0l6J9', 'en', 'EBS General Purpose SSD (gp2) Volume Storage', 'Checks for usage that is more than 80% of the EBS General Purpose SSD (gp2) Volume Storage Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('zXCkfM1nI3', 'en', 'IAM Use', 'This check is intended to discourage the use of root access by checking for existence of at least one IAM user. You may ignore the alert if you are following the best practice of centralizing identities and configuring users in an <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers.html" target="_blank">external identity provider</a> or <a href="https://aws.amazon.com/single-sign-on/" target="_blank">AWS Single Sign-On</a>. ')
+, ROW ('8M012Ph3U5', 'en', 'AWS Direct Connect Location Redundancy', 'Checks for regions with one or more AWS Direct Connect connections and only one AWS Direct Connect location. Connectivity to your AWS resources should have Direct Connect connections configured to different Direct Connect locations to provide redundancy in case a location is unavailable.<br/><h4 class=headerBodyStyle>Note:</h4> Results for this check are automatically refreshed several times daily, and refresh requests are not allowed. It might take a few hours for changes to appear.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow:  The Direct Connect connections in the region are not configured to different locations.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Configure a Direct Connect connection that uses a different Direct Connect location to protect against location unavailability. For more information, see <a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Getting Started with AWS Direct Connect</a>.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a target="_blank" href="https://docs.aws.amazon.com/directconnect/latest/UserGuide/getting_started.html">Getting Started with AWS Direct Connect</a><br/><a target="_blank" href="https://aws.amazon.com/directconnect/faqs/">AWS Direct Connect FAQs</a>')
+, ROW ('Hs4Ma3G220', 'en', 'Connections to OpenSearch domains should be encrypted using TLS 1.2', 'Checks if connections to OpenSearch domains are required to use TLS 1.2. The check fails if the OpenSearch domain TLSSecurityPolicy is not Policy-Min-TLS-1-2-2019-07.')
+, ROW ('Hs4Ma3G218', 'en', 'CodeBuild project environments should not have privileged mode enabled', 'Checks if an AWS CodeBuild project environment has privileged mode enabled.')
+, ROW ('Yw2K9puPzl', 'en', 'IAM Password Policy', 'Checks the password policy for your account and warns when a password policy is not enabled, or if password content requirements have not been enabled. Password content requirements increase the overall security of your AWS environment by enforcing the creation of strong user passwords. When you create or change a password policy, the change is enforced immediately for new users but does not require existing users to change their passwords. ')
+, ROW ('Hs4Ma3G219', 'en', 'Amazon Redshift clusters should not use the default Admin username', 'Checks if a Redshift cluster has changed the Admin username from its default value. This check will fail if the admin username for a Redshift cluster is set to awsuser.')
+, ROW ('dx8afcdfMr', 'en', 'Route 53 Traffic Policy Instances', 'Checks for usage that is more than 80% of the Route 53 Traffic Policy Instances Limit per account. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
+, ROW ('c9D319e7sG', 'en', 'Amazon Route 53 MX Resource Record Sets and Sender Policy Framework', 'For each MX resource record set, checks that the TXT or SPF resource record set contains a valid SPF record. The record must start with "v=spf1". The SPF record specifies the servers that are authorized to send email for your domain, which helps detect and stop email address spoofing to reduce spam. Route 53 recommends that you use a TXT record instead of an SPF record. Trusted Advisor reports this check as green as long as each MX resource record set has at least one SPF or TXT record.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: An MX resource record set doesnâ€™t have a TXT or SPF resource record that contains a valid SPF value.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>For each MX resource record set, create a TXT resource record set that contains a valid SPF value. For more information, see <a href="http://www.open-spf.org/SPF_Record_Syntax" target="_blank">Sender Policy Framework: SPF Record Syntax</a> and <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/RRSchanges_console.html" target="_blank">Creating Resource Record Sets By Using the Amazon Route 53 Console</a>.<br/><br/><h4 class=headerBodyStyle>Additional Information</h4><br/><a href="http://en.wikipedia.org/wiki/Sender_Policy_Framework" target="_blank">Sender Policy Framework</a> (Wikipedia)<br/><a href="http://en.wikipedia.org/wiki/MX_record" target="_blank">MX record</a> (Wikipedia)')
+, ROW ('Qsdfp3A4L4', 'en', 'Amazon EC2 instances with Microsoft Windows Server end of support', 'This check alerts you if the versions are near or have reached the end of support. Each Windows Server version offers 10 years of support, including 5 years of mainstream support and 5 years of extended support.  After the end of support, the Windows Server version wonâ€™t receive regular security updates. Running applications with unsupported Windows Server versions can bring security or compliance risks.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: An EC2 instance has a Windows Server version that has reached end of support (Windows Server 2003, 2008, and 2008R2)<br/>Yellow: An EC2 instance has a Windows Server version that will reach end of support in less than 18 months (Windows Server 2012 & 2012 R2)<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider the following guidelines for end of support Windows Server EC2 instances:</br><br/>To modernize your Windows Server workloads, consider the various pathways available on the <a href="https://aws.amazon.com/windows/modernization/" target="blank">Modernize Windows Workloads with AWS</a> website.</br><br/>To upgrade your Windows Server workloads onto modern versions of Windows Server, consider using an automation runbook to simplify your upgrade. For more information, see the <a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/os-inplaceupgrade.html" target="blank">AWS Systems Manager documentation</a>.</br><br/>If you canâ€™t upgrade your Windows Server workloads due to application incompatibilities, consider the End-of-Support Migration Program (EMP) for Windows Server. For more information on the program and tooling, see the <a href="https://aws.amazon.com/emp-windows-server/" target="blank">EMP website</a>. You can also purchase Extended Security Updates (ESU) from Microsoft for a maximum of 3 years after a productâ€™s end of support date. <a href="https://aws.amazon.com/windows/faq/#eos-microsoft-products" target="blank">Learn more</a>.</br>')
+, ROW ('Qsdfp3A4L3', 'en', 'Amazon EC2 instances with Microsoft SQL Server end of support', 'Checks the SQL Server versions for Amazon Elastic Compute Cloud (Amazon EC2) instances running in the past 24 hours. This check alerts you if the versions are near or have reached the end of support. Each SQL Server version offers 10 years of support, including 5 years of mainstream support and 5 years of extended support. After the end of support, the SQL Server version wonâ€™t receive regular security updates. Running applications with unsupported SQL Server versions can bring security or compliance risks.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Red: An EC2 instance has an SQL Server version that reached the end of support.<br/>Yellow: An EC2 instance has an SQL Server version that will reach the end of support in 12 months.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>To modernize your SQL Server workloads, consider refactoring to AWS Cloud native databases like Amazon Aurora. For more information, see <a href="https://aws.amazon.com/windows/modernization/" target="blank">Modernize Windows Workloads with AWS</a>.<br/>To move to a fully managed database, consider replatforming to Amazon Relational Database Service (Amazon RDS). For more information, see <a href="https://aws.amazon.com/rds/sqlserver/" target="blank">RDS for SQL Server</a>.<br/>To upgrade your SQL Server on EC2, consider using the automation runbook to simplify your upgrade. For more information, see the <a href="https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awsec2-CloneInstanceAndUpgradeSQLServer.html" target="blank">AWS Systems Manager documentation</a>.<br/>If you canâ€™t upgrade your SQL Server on EC2, consider the End-of-Support Migration Program (EMP) for Windows Server. For more information, see the <a href="https://aws.amazon.com/emp-windows-server/" target="blank">EMP Website</a><br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://aws.amazon.com/sql/sql2008-eos/" target="blank">Get ready for SQL Server end of support with AWS</a><br/><a href="https://aws.amazon.com/sql/" target="blank">Microsoft SQL Server on AWS</a><br/>')
+, ROW ('Qsdfp3A4L2', 'en', 'Amazon EC2 instances consolidation for Microsoft SQL Server', 'Checks your Amazon Elastic Compute Cloud (Amazon EC2) instances that are running SQL Server in the past 24 hours. This check alerts you if your instance has less than the minimum number of SQL Server licenses. From the Microsoft SQL Server Licensing Guide, you are paying 4 vCPU licenses even if an instance has only 1 or 2 vCPUs. You can consolidate smaller SQL Server instances to help lower costs.<br/><br/><h4 class=headerBodyStyle>Alert Criteria</h4><br/>Yellow: An instance with SQL Server has less than 4 vCPUs.<br/><br/><h4 class=headerBodyStyle>Recommended Action</h4><br/>Consider consolidating smaller SQL Server workloads into instances with at least 4 vCPUs.<br/><br/><h4 class=headerBodyStyle>Additional Resources</h4><br/><a href="https://aws.amazon.com/sql/" target="blank">Microsoft SQL Server on AWS</a><br/><a href="https://aws.amazon.com/windows/resources/licensing/" target="blank">Microsoft Licensing on AWS</a><br/><a href="https://www.microsoft.com/en-us/sql-server/sql-server-2019-pricing" target="blank">Microsoft SQL Server Licensing Guide</a><br/>')
 , ROW ('Hs4Ma3G210', 'en', 'CloudFront distributions should have logging enabled', 'Checks to see if server access logging is enabled on Amazon CloudFront Distributions. The check will fail if access logging is not enabled for the distribution.')
-, ROW ('COr6dfpM03', 'en', 'Amazon EBS over-provisioned volumes', 'Checks the Amazon Elastic Block Storage (Amazon EBS) volumes that were running at any time during the lookback period. This check alerts you if any EBS volumes were over-provisioned for your workloads. When you have over-provisioned volumes, youâ€™re paying for unused resources. Although some scenarios can result in low optimization by design, you can often lower your costs by changing the configuration of your EBS volumes. Estimated monthly savings are calculated by using the current usage rate for EBS volumes. Actual savings will vary if the volume isnâ€™t present for a full month.<br/><br/><b>Source</b><br/>AWS Compute Optimizer<br/><br/><b>Alert Criteria</b><br/>Yellow: An EBS Volume that was over-provisioned during the lookback period. To determine if a volume is over-provisioned, we consider all default CloudWatch metrics (including IOPS and throughput). The algorithm used to identify over-provisioned EBS volumes follows AWS best practices. The algorithm is updated when a new pattern has been identified.<br/><br/><b>Recommended Action</b><br/>Consider downsizing volumes that have low utilization.<br/><br/><b>Additional Resources</b><br/>For more information about this recommendation, see the <a href="https://docs.aws.amazon.com/console/awssupport/trusted-advisor/compute-optimizer" target="blank">Trusted Advisor documentation.</a>.')
-, ROW ('COr6dfpM04', 'en', 'Amazon EBS under-provisioned volumes', 'Checks the Amazon Elastic Block Storage (Amazon EBS) volumes that were running at any time during the lookback period. This check alerts you if any EBS volumes were under-provisioned for your workloads. Consistent high utilization can indicate optimized, steady performance, but can also indicate that an application does not have enough resources.<br/><br/><b>Source</b><br/>AWS Compute Optimizer<br/><br/><b>Alert Criteria</b><br/>Yellow: An EBS Volume that was under-provisioned during the lookback period. To determine if a volume is under-provisioned, we consider all default CloudWatch metrics (including IOPS and throughput). The algorithm used to identify under-provisioned EBS volumes follows AWS best practices. The algorithm is updated when a new pattern has been identified.<br/><br/><b>Recommended Action</b><br/>Consider upsizing volumes that have high utilization.<br/><br/><b>Additional Resources</b><br/>For more information about this recommendation, see the <a href="https://docs.aws.amazon.com/console/awssupport/trusted-advisor/compute-optimizer" target="blank">Trusted Advisor documentation</a>.')
-, ROW ('COr6dfpM05', 'en', 'AWS Lambda over-provisioned functions for memory size', 'Checks the AWS Lambda functions that were invoked at least once during the lookback period. This check alerts you if any of your Lambda functions were over-provisioned for memory size. When you have Lambda functions that are over-provisioned for memory sizes, youâ€™re paying for unused resources. Although some scenarios can result in low utilization by design, you can often lower your costs by changing the memory configuration of your Lambda functions. Estimated monthly savings are calculated by using the current usage rate for Lambda functions.<br/><br/><b>Source</b><br/>AWS Compute Optimizer<br/><br/><b>Alert Criteria</b><br/>Yellow: A Lambda function that was over-provisioned for memory size during the lookback period. To determine if a Lambda function is over-provisioned, we consider all default CloudWatch metrics for that function. The algorithm used to identify over-provisioned Lambda functions for memory size follows AWS best practices. The algorithm is updated when a new pattern has been identified.<br/><br/><b>Recommended Action</b><br/>Consider reducing the memory size of your Lambda functions.<br/><br/><b>Additional Resources</b><br/>For more information about this recommendation, see the <a href="https://docs.aws.amazon.com/console/awssupport/trusted-advisor/compute-optimizer" target="blank">Trusted Advisor documentation page</a>.')
-, ROW ('COr6dfpM06', 'en', 'AWS Lambda under-provisioned functions for memory size', 'Checks the AWS Lambda functions that were invoked at least once during the lookback period. This check alerts you if any of your Lambda functions were under-provisioned for memory size. When you have Lambda functions that are under-provisioned for memory size, these functions take longer time to complete.<br/><br/><b>Source</b><br/>AWS Compute Optimizer<br/><br/><b>Alert Criteria</b><br/>Yellow: A Lambda function that was under-provisioned for memory size during the lookback period. To determine if a Lambda function is under-provisioned, we consider all default CloudWatch metrics for that function. The algorithm used to identify under-provisioned Lambda functions for memory size follows AWS best practices. The algorithm is updated when a new pattern has been identified.<br/><br/><b>Recommended Action</b><br/>Consider increasing the memory size of your Lambda functions.<br/><br/><b>Additional Resources</b><br/>For more information about this recommendation, see the <a href="https://docs.aws.amazon.com/console/awssupport/trusted-advisor/compute-optimizer" target="blank">Trusted Advisor documentation</a>.')
 , ROW ('Hs4Ma3G211', 'en', 'S3 buckets with versioning enabled should have lifecycle policies configured', 'Checks if Amazon Simple Storage Service (Amazon S3) version enabled buckets have lifecycle policy configured. This rule fails if Amazon S3 lifecycle policy is not enabled.')
 , ROW ('Hs4Ma3G212', 'en', 'S3 buckets should have event notifications enabled', 'Checks if S3 Event Notifications are enabled on an S3 bucket. This check fails if S3 Event Notifications are not enabled on a bucket.')
 , ROW ('Hs4Ma3G213', 'en', 'S3 access control lists (ACLs) should not be used to manage user access to buckets', 'Checks if S3 buckets allow user permissions via access check lists (ACLs). This check fails if ACLs are configured for user access on S3 Bucket.')
 , ROW ('Hs4Ma3G214', 'en', 'Network ACLs should not allow ingress from 0.0.0.0/0 to port 22 or port 3389', 'Checks if a network access check list (NACL) allows unrestricted access to the default ports for SSH/RDP ingress traffic. The rule fails if a NACL inbound entry allows a source CIDR block of 0.0.0.0/0 or ::/0 for ports 22 or 3389')
 , ROW ('Hs4Ma3G215', 'en', 'Unused EC2 security groups should be removed', 'Checks that security groups are attached to Amazon EC2 instances or to an elastic network interface. The check will fail the security group is not associated with an Amazon EC2 instance or an elastic network interface.')
 , ROW ('Hs4Ma3G216', 'en', 'ECR repositories should have at least one lifecycle policy configured', 'Checks if an ECR repository has at least one lifecycle policy configured. This check fails if an ECR repository does not have any lifecycle policies configured.')
+, ROW ('qS7VV0l7J9', 'en', 'IAM Users', 'Checks for usage that is more than 80% of the IAM Users Limit. Values are based on a snapshot, so your current usage might differ. Limit and usage data can take up to 24 hours to reflect any changes. In cases where limits have been recently increased, you may temporarily see utilization that exceeds the limit.')
 , ROW ('Hs4Ma3G217', 'en', 'CodeBuild project environments should have a logging configuration', 'Checks if a CodeBuild project environment has at least one log option enabled.')
-, ROW ('Hs4Ma3G218', 'en', 'CodeBuild project environments should not have privileged mode enabled', 'Checks if an AWS CodeBuild project environment has privileged mode enabled.')
-, ROW ('Hs4Ma3G219', 'en', 'Amazon Redshift clusters should not use the default Admin username', 'Checks if a Redshift cluster has changed the Admin username from its default value. This check will fail if the admin username for a Redshift cluster is set to awsuser.')
-, ROW ('Hs4Ma3G220', 'en', 'Connections to OpenSearch domains should be encrypted using TLS 1.2', 'Checks if connections to OpenSearch domains are required to use TLS 1.2. The check fails if the OpenSearch domain TLSSecurityPolicy is not Policy-Min-TLS-1-2-2019-07.')
-, ROW ('Hs4Ma3G221', 'en', 'OpenSearch domains should have audit logging enabled', 'Checks if Amazon OpenSearch Service domains have audit logging enabled.')
-, ROW ('Hs4Ma3G222', 'en', 'OpenSearch domain error logging to CloudWatch Logs should be enabled', 'Checks if Amazon OpenSearch domains are configured to send error logs to CloudWatch Logs. This check fails if error logging to CloudWatch is not enabled for a domain.')
-, ROW ('Hs4Ma3G223', 'en', 'OpenSearch domains should encrypt data sent between nodes', 'Checks if Amazon OpenSearch domains have node-to-node encryption enabled. This check fails if node-to-node encryption is disabled on the domain.')
-, ROW ('Hs4Ma3G224', 'en', 'OpenSearch domains should be in a VPC', 'Checks Amazon OpenSearch Service domains are in an Amazon Virtual Private Cloud (VPC).')
-, ROW ('Hs4Ma3G225', 'en', 'OpenSearch domains should have encryption at rest enabled', 'Checks if Amazon OpenSearch domains have encryption-at-rest configuration enabled. The check fails if encryption at rest is not enabled.')
-, ROW ('Hs4Ma3G226', 'en', 'Amazon EC2 instances launched using Auto Scaling group launch configurations should not have Public IP addresses', 'Checks if Amazon EC2 Auto Scaling groups have public IP addresses enabled using launch configurations.')
-, ROW ('Hs4Ma3G227', 'en', 'CloudFront distributions should use custom SSL/TLS certificates', 'Checks if CloudFront distributions are using the default SSL/TLS certificate CloudFront provides instead of a custom one. This check fails for a CloudFront distribution if it uses the default SSL/TLS certificate.')
-, ROW ('Hs4Ma3G228', 'en', 'CloudFront distributions should use SNI to serve HTTPS requests', 'Checks if Amazon CloudFront distributions are using a custom SSL/TLS certificate and are configured to use SNI to serve HTTPS requests as opposed to dedicated IP address.')
-, ROW ('Hs4Ma3G229', 'en', 'CloudFront distributions should encrypt traffic to custom origins', 'Checks if CloudFront distributions are encrypting traffic to custom origins. This check fails for a CloudFront distribution whose origin protocol policy allows http-only or if it is match-viewer and the viewer protocol policy is allow-all. ')
-, ROW ('Hs4Ma3G230', 'en', 'S3 bucket server access logging should be enabled', 'Checks if an Amazon S3 Bucket has server access logging enabled to a chosen target bucket.')
-, ROW ('Hs4Ma3G231', 'en', 'Stateless network firewall rule group should not be empty', 'Checks if a Stateless Network Firewall Rule Group contains rules. The rule will fail if there are no rules in a Stateless Network Firewall Rule Group.')
-, ROW ('Hs4Ma3G232', 'en', 'RDS Database Clusters should use a custom administrator username', 'Checks if an RDS database cluster has changed the admin username from its default value. This rule will fail if the admin username is set to the default value.')
-, ROW ('Hs4Ma3G233', 'en', 'RDS database instances should use a custom administrator username', 'Checks if an Amazon Relational Database Service (Amazon RDS) database instance has changed the admin username from its default value. This rule will only run on RDS database instances. The rule will fail if the admin username is set to the default value.')
 )  ignored_tabe_name (check_id, language, name, description)
```

#### html2text {}

```diff
@@ -1,639 +1,440 @@
 CREATE OR REPLACE VIEW "ta_descriptions" AS SELECT * FROM ( VALUES ROW
-('Qch7DwouX1', 'en', 'Low Utilization Amazon EC2 Instances', 'Checks the Amazon
-Elastic Compute Cloud (Amazon EC2) instances that were running at any time
-during the last 14 days and alerts you if the daily CPU utilization was 10% or
-less and network I/O was 5 MB or less on 4 or more days. Running instances
-generate hourly usage charges. Although some scenarios can result in low
-utilization by design, you can often lower your costs by managing the number
-and size of your instances.') , ROW ('hjLMh88uM8', 'en', 'Idle Load Balancers',
-'Checks your Elastic Load Balancing configuration for load balancers that are
-not actively used. Any load balancer that is configured accrues charges. If a
-load balancer has no associated back-end instances or if network traffic is
-severely limited, the load balancer is not being used effectively.') , ROW
-('DAvU99Dc4C', 'en', 'Underutilized Amazon EBS Volumes', 'Checks Amazon Elastic
-Block Store (Amazon EBS) volume configurations and warns when volumes appear to
-be underused. Charges begin when a volume is created. If a volume remains
-unattached or has very low write activity (excluding boot volumes) for a period
-of time, the volume is probably not being used.') , ROW ('Z4AUBRNSmz', 'en',
-'Unassociated Elastic IP Addresses', 'Checks for Elastic IP addresses (EIPs)
-that are not associated with a running Amazon Elastic Compute Cloud (Amazon
-EC2) instance. EIPs are static IP addresses designed for dynamic cloud
-computing. Unlike traditional static IP addresses, EIPs can mask the failure of
-an instance or Availability Zone by remapping a public IP address to another
-instance in your account. A nominal charge is imposed for an EIP that is not
-associated with a running instance.') , ROW ('HCP4007jGY', 'en', 'Security
-Groups - Specific Ports Unrestricted', 'Checks security groups for rules that
-allow unrestricted access (0.0.0.0/0) to specific ports. Unrestricted access
-increases opportunities for malicious activity (hacking, denial-of-service
-attacks, loss of data). The ports with highest risk are flagged red, and those
-with less risk are flagged yellow. Ports flagged green are typically used by
-applications that require unrestricted access, such as HTTP and SMTP.') , ROW
-('1iG5NDGVre', 'en', 'Security Groups - Unrestricted Access', 'Checks security
-groups for rules that allow unrestricted access to a resource. Unrestricted
-access increases opportunities for malicious activity (hacking, denial-of-
-service attacks, loss of data).') , ROW ('zXCkfM1nI3', 'en', 'IAM Use', 'This
-check is intended to discourage the use of root access by checking for
-existence of at least one IAM user. You may ignore the alert if you are
-following the best practice of centralizing identities and configuring users in
-an _e_x_t_e_r_n_a_l_ _i_d_e_n_t_i_t_y_ _p_r_o_v_i_d_e_r or _A_W_S_ _S_i_n_g_l_e_ _S_i_g_n_-_O_n. ') , ROW ('Pfx0RwqBli',
-'en', 'Amazon S3 Bucket Permissions', 'Checks buckets in Amazon Simple Storage
-Service (Amazon S3) that have open access permissions or allow access to any
-authenticated AWS user. Bucket permissions that grant List access can result in
-higher than expected charges if objects in the bucket are listed by unintended
-users at a high frequency. Bucket permissions that grant Upload/Delete access
-create potential security vulnerabilities by allowing users that to add,
-modify, or remove items in a bucket.') , ROW ('7DAFEmoDos', 'en', 'MFA on Root
-Account', 'Checks the root account and warns if multi-factor authentication
-(MFA) is not enabled. For increased security, we recommend that you protect
-your account by using MFA, which requires a user to enter a unique
-authentication code from their MFA hardware or virtual device when interacting
-with the AWS console and associated websites.') , ROW ('Yw2K9puPzl', 'en', 'IAM
-Password Policy', 'Checks the password policy for your account and warns when a
-password policy is not enabled, or if password content requirements have not
-been enabled. Password content requirements increase the overall security of
-your AWS environment by enforcing the creation of strong user passwords. When
-you create or change a password policy, the change is enforced immediately for
-new users but does not require existing users to change their passwords. ') ,
-ROW ('nNauJisYIT', 'en', 'Amazon RDS Security Group Access Risk', 'Checks
-security group configurations for Amazon Relational Database Service (Amazon
-RDS) and warns when a security group rule might grant overly permissive access
-to your database. Recommended configuration for any security group rule is to
-allow access from specific Amazon Elastic Compute Cloud (Amazon EC2) security
-groups or from a specific IP address. Data for Amazon Relational Database
-Service (Amazon RDS) instances created in the Asia Pacific (Seoul) region (sa-
-east-1) is not available. We are working to fix this issue as soon as
-possible.') , ROW ('H7IgTzjTYb', 'en', 'Amazon EBS Snapshots', 'Checks the age
-of the snapshots for your Amazon Elastic Block Store (Amazon EBS) volumes
-(available or in-use). Even though Amazon EBS volumes are replicated, failures
-can occur. Snapshots are persisted to Amazon Simple Storage Service (Amazon S3)
-for durable storage and point-in-time recovery.') , ROW ('wuy7G1zxql', 'en',
-'Amazon EC2 Availability Zone Balance', 'Checks the distribution of Amazon
-Elastic Compute Cloud (Amazon EC2) instances across Availability Zones in a
-region. Availability Zones are distinct locations that are designed to be
-insulated from failures in other Availability Zones and to provide inexpensive,
-low-latency network connectivity to other Availability Zones in the same
-region. By launching instances in multiple Availability Zones in the same
-region, you can help protect your applications from a single point of
-failure.') , ROW ('iqdCTZKCUp', 'en', 'Load Balancer Optimization', 'Checks
-your load balancer configuration. To help increase the level of fault tolerance
-in Amazon Elastic Compute Cloud (EC2) when using Elastic Load Balancing, we
-recommend running an equal number of instances across multiple Availability
-Zones in a region. A load balancer that is configured accrues charges, so this
-is a cost-optimization check as well.
+('rSs93HQwa1', 'en', 'Amazon RDS Public Snapshots', 'Checks the permission
+settings for your Amazon Relational Database Service (Amazon RDS) DB snapshots
+and alerts you if any snapshots are marked as public. When you make a snapshot
+public, you give all AWS accounts and users access to all the data on the
+snapshot. If you want to share a snapshot with particular users or accounts,
+mark the snapshot as private, and then specify the user or accounts you want to
+share the snapshot data with.
+****** NNoottee ******
+: Results for this check are automatically refreshed several times daily, and
+refresh requests are not allowed. It might take a few hours for changes to
+appear.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: A load balancer is enabled for a single Availability Zone.
-Yellow: A load balancer is enabled for an Availability Zone that has no active
-instances.
-Yellow: The Amazon EC2 instances that are registered with a load balancer are
-unevenly distributed across Availability Zones. (The difference between the
-highest and lowest instance counts in utilized Availability Zones is more than
-1, and the difference is more than 20% of the highest count.)
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Ensure that your load balancer points to active and healthy instances in at
-least two Availability Zones. For more information, see _A_d_d_ _A_v_a_i_l_a_b_i_l_i_t_y_ _Z_o_n_e.
-If your load balancer is configured for an Availability Zone with no healthy
-instances, or if there is an imbalance of instances across the Availability
-Zones, determine if all the Availability Zones are necessary. Omit any
-unnecessary Availability Zones and ensure there is a balanced distribution of
-instances across the remaining Availability Zones. For more information, see
-_R_e_m_o_v_e_ _A_v_a_i_l_a_b_i_l_i_t_y_ _Z_o_n_e.
+Red: The RDS snapshot is marked as public.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_A_v_a_i_l_a_b_i_l_i_t_y_ _Z_o_n_e_s_ _a_n_d_ _R_e_g_i_o_n_s
-_M_a_n_a_g_i_n_g_ _L_o_a_d_ _B_a_l_a_n_c_e_r_s
-_B_e_s_t_ _P_r_a_c_t_i_c_e_s_ _i_n_ _E_v_a_l_u_a_t_i_n_g_ _E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g') , ROW ('S45wrEXrLz',
-'en', 'VPN Tunnel Redundancy', 'Checks the number of tunnels that are active
-for each of your VPNs. A VPN should have two tunnels configured at all times to
-provide redundancy in case of outage or planned maintenance of the devices at
-the AWS endpoint. For some hardware, only one tunnel is active at a time (see
-the _A_m_a_z_o_n_ _V_i_r_t_u_a_l_ _P_r_i_v_a_t_e_ _C_l_o_u_d_ _N_e_t_w_o_r_k_ _A_d_m_i_n_i_s_t_r_a_t_o_r_ _G_u_i_d_e). If a VPN has no
-active tunnels, charges for the VPN might still apply.') , ROW ('ZRxQlPsb6c',
-'en', 'High Utilization Amazon EC2 Instances', 'Checks the Amazon Elastic
-Compute Cloud (Amazon EC2) instances that were running at any time during the
-last 14 days and alerts you if the daily CPU utilization was more than 90% on 4
-or more days. Consistent high utilization can indicate optimized, steady
-performance, but it can also indicate that an application does not have enough
-resources. To get daily CPU utilization data, download the report for this
-check.') , ROW ('8CNsSllI5v', 'en', 'Auto Scaling Group Resources', 'Checks the
-availability of resources associated with launch configurations and your Auto
-Scaling groups. Auto Scaling groups that point to unavailable resources cannot
-launch new Amazon Elastic Compute Cloud (Amazon EC2) instances. When properly
-configured, Auto Scaling causes the number of Amazon EC2 instances to increase
-seamlessly during demand spikes and decrease automatically during demand lulls.
-Auto Scaling groups and launch configurations that point to unavailable
-resources do not operate as intended.') , ROW ('opQPADkZvH', 'en', 'Amazon RDS
-Backups', 'Checks for automated backups of Amazon RDS DB instances. By default,
-backups are enabled with a retention period of 1 day. Backups reduce the risk
-of unexpected data loss and allow for point-in-time recovery.') , ROW
-('f2iK5R6Dep', 'en', 'Amazon RDS Multi-AZ', 'Checks for DB instances that are
-deployed in a single Availability Zone. Multi-AZ deployments enhance database
-availability by synchronously replicating to a standby instance in a different
-Availability Zone. During planned database maintenance or the failure of a DB
-instance or Availability Zone, Amazon RDS automatically fails over to the
-standby so that database operations can resume quickly without administrative
-intervention. Because Multi-AZ deployments for the SQL Server engine use a
-different mechanism for synchronization, this check does not examine SQL Server
-instances.') , ROW ('CLOG40CDO8', 'en', 'Auto Scaling Group Health Check',
-'Examines the health check configuration for Auto Scaling groups. If Elastic
-Load Balancing is being used for an Auto Scaling group, the recommended
-configuration is to enable an Elastic Load Balancing health check. If an
-Elastic Load Balancing health check is not used, Auto Scaling can only act upon
-the health of the Amazon Elastic Compute Cloud (Amazon EC2) instance and not on
-the application that is running on the instance.') , ROW ('BueAdJ7NrP', 'en',
-'Amazon S3 Bucket Logging', 'Checks the logging configuration of Amazon Simple
-Storage Service (Amazon S3) buckets. When server access logging is enabled,
-detailed access logs are delivered hourly to a bucket that you choose. An
-access log record contains details about each request, such as the request
-type, the resources specified in the request, and the time and date the request
-was processed. By default, bucket logging is not enabled; you should enable
-logging if you want to perform security audits or learn more about users and
-usage patterns.') , ROW ('PPkZrjsH2q', 'en', 'Amazon EBS Provisioned IOPS (SSD)
-Volume Attachment Configuration', 'Checks for Provisioned IOPS (SSD) volumes
-that are attached to an Amazon EBS-optimizable Amazon Elastic Compute Cloud
-(Amazon EC2) instance that is not EBS-optimized. Provisioned IOPS (SSD) volumes
-in the Amazon Elastic Block Store (Amazon EBS) are designed to deliver the
-expected performance only when they are attached to an EBS-optimized
-instance.') , ROW ('tfg86AVHAZ', 'en', 'Large Number of Rules in an EC2
-Security Group', 'Checks each Amazon Elastic Compute Cloud (EC2) security group
-for an excessive number of rules. If a security group has a large number of
-rules, performance can be degraded.') , ROW ('j3DFqYTe29', 'en', 'Large Number
-of EC2 Security Group Rules Applied to an Instance', 'Checks for Amazon Elastic
-Compute Cloud (EC2) instances that have a large number of security group rules.
-Performance can be degraded if an instance has a large number of rules.') , ROW
-('Ti39halfu8', 'en', 'Amazon RDS Idle DB Instances', 'Checks the configuration
-of your Amazon Relational Database Service (Amazon RDS) for any DB instances
-that appear to be idle. If a DB instance has not had a connection for a
-prolonged period of time, you can delete the instance to reduce costs. If
-persistent storage is needed for data on the instance, you can use lower-cost
-options such as taking and retaining a DB snapshot. Manually created DB
-snapshots are retained until you delete them.') , ROW ('B913Ef6fb4', 'en',
-'Amazon Route 53 Alias Resource Record Sets', 'Checks for resource record sets
-that can be changed to alias resource record sets to improve performance and
-save money. An alias resource record set routes DNS queries to an AWS resource
-(for example, an Elastic Load Balancing load balancer or an Amazon S3 bucket)
-or to another Route 53 resource record set. When you use alias resource record
-sets, Route 53 routes your DNS queries to AWS resources free of charge. Hosted
-zones created by AWS services wonÃ¢Â€Â™t appear in your check results.') , ROW
-('cF171Db240', 'en', 'Amazon Route 53 Name Server Delegations', 'Checks for
-Amazon Route 53 hosted zones for which your domain registrar or DNS is not
-using the correct Route 53 name servers. When you create a hosted zone, Route
-53 assigns a delegation set of four name servers. The names of these servers
-are ns-###.awsdns-##.com, .net, .org, and .co.uk, where ### and ## typically
-represent different numbers. Before Route 53 can route DNS queries for your
-domain, you must update your registrars name server configuration to remove the
-name servers that the registrar assigned and add all four name servers in the
-Route 53 delegation set. For maximum availability, you must add all four Route
-53 name servers. Hosted zones created by AWS services wonÃ¢Â€Â™t appear in your
-check results.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: A hosted zone for which the registrar for your domain does not use all
-four of the Route 53 name servers in the delegation set.
+Unless you are certain you want to share all the data in the snapshot with all
+AWS accounts and users, modify the permissions: mark the snapshot as private,
+and then specify the accounts that you want to give permissions to. For more
+information, see _S_h_a_r_i_n_g_ _a_ _D_B_ _S_n_a_p_s_h_o_t_ _o_r_ _D_B_ _C_l_u_s_t_e_r_ _S_n_a_p_s_h_o_t. Note: For
+temporary technical reasons, items in this check cannot be excluded from view
+in the Trusted Advisor console.To modify permissions for your snapshots
+directly, you can use a runbook in the AWS Systems Manager console. For more
+information, see _A_W_S_S_u_p_p_o_r_t_-_M_o_d_i_f_y_R_D_S_S_n_a_p_s_h_o_t_P_e_r_m_i_s_s_i_o_n.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Add or update name server records with your registrar or with the current DNS
-service for your domain to include all four of the name servers in your Route
-53 delegation set. To find these values, see _G_e_t_t_i_n_g_ _t_h_e_ _N_a_m_e_ _S_e_r_v_e_r_s_ _f_o_r_ _a
-_H_o_s_t_e_d_ _Z_o_n_e. For information about adding or updating name server records, see
-_C_r_e_a_t_i_n_g_ _a_n_d_ _M_i_g_r_a_t_i_n_g_ _D_o_m_a_i_n_s_ _a_n_d_ _S_u_b_d_o_m_a_i_n_s_ _t_o_ _A_m_a_z_o_n_ _R_o_u_t_e_Â _5_3.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_W_o_r_k_i_n_g_ _w_i_t_h_ _H_o_s_t_e_d_ _Z_o_n_e_s
-') , ROW ('C056F80cR3', 'en', 'Amazon Route 53 High TTL Resource Record Sets',
-'Checks for resource record sets that can benefit from having a lower time-to-
-live (TTL) value. TTL is the number of seconds that a resource record set is
-cached by DNS resolvers. When you specify a long TTL, DNS resolvers take longer
-to request updated DNS records, which can cause unnecessary delay in rerouting
-traffic (for example, when DNS Failover detects and responds to a failure of
-one of your endpoints). Hosted zones created by AWS services wonÃ¢Â€Â™t appear in
-your check results.') , ROW ('k3J2hns32g', 'en', 'Overutilized Amazon EBS
-Magnetic Volumes', 'Checks for Amazon Elastic Block Store (EBS) Magnetic
-volumes that are potentially overutilized and might benefit from a more
-efficient configuration. A Magnetic volume is designed for applications with
-moderate or bursty I/O requirements, and the IOPS rate is not guaranteed. It
-delivers approximately 100 IOPS on average, with a best-effort ability to burst
-to hundreds of IOPS. For consistently higher IOPS, you can use a Provisioned
-IOPS (SSD) volume. For bursty IOPS, you can use a General Purpose (SSD) volume.
-For more information, see _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e_ _T_y_p_e_s.') , ROW ('796d6f3D83', 'en',
-'CloudFront Content Delivery Optimization', 'Checks for cases where data
-transfer from Amazon Simple Storage Service (Amazon S3) buckets could be
-accelerated by using Amazon CloudFront, the AWS global content delivery
-service. When you configure CloudFront to deliver your content, requests for
-your content are automatically routed to the nearest edge location where
-content is cached, so it can be delivered to your users with the best possible
-performance. A high ratio of data transferred out to the data stored in the
-bucket indicates that you could benefit from using Amazon CloudFront to deliver
-the data. ') , ROW ('51fC20e7I2', 'en', 'Amazon Route 53 Latency Resource
-Record Sets', 'Checks for Amazon Route 53 latency record sets that are
-configured inefficiently. To allow Amazon Route 53 to route queries to the
-region with the lowest network latency, you should create latency resource
-record sets for a particular domain name (such as example.com) in different
-regions. If you create only one latency resource record set for a domain name,
-all queries are routed to one region, and you pay extra for latency-based
-routing without getting the benefits. Hosted zones created by AWS services
-wonÃ¢Â€Â™t appear in your check results.') , ROW ('c9D319e7sG', 'en', 'Amazon
-Route 53 MX Resource Record Sets and Sender Policy Framework', 'For each MX
-resource record set, checks that the TXT or SPF resource record set contains a
-valid SPF record. The record must start with "v=spf1". The SPF record specifies
-the servers that are authorized to send email for your domain, which helps
-detect and stop email address spoofing to reduce spam. Route 53 recommends that
-you use a TXT record instead of an SPF record. Trusted Advisor reports this
-check as green as long as each MX resource record set has at least one SPF or
-TXT record.
+_B_a_c_k_i_n_g_ _U_p_ _a_n_d_ _R_e_s_t_o_r_i_n_g_ _A_m_a_z_o_n_ _R_D_S_ _D_B_ _I_n_s_t_a_n_c_e_s') , ROW ('xSqX82fQu', 'en',
+'ELB Security Groups', 'Checks for load balancers configured with a missing
+security group or a security group that allows access to ports that are not
+configured for the load balancer. If a security group associated with a load
+balancer is deleted, the load balancer does not work as expected. If a security
+group allows access to ports that are not configured for the load balancer, the
+risk of loss of data or malicious attacks increases.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: An MX resource record set doesnÃ¢Â€Â™t have a TXT or SPF resource record
-that contains a valid SPF value.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-For each MX resource record set, create a TXT resource record set that contains
-a valid SPF value. For more information, see _S_e_n_d_e_r_ _P_o_l_i_c_y_ _F_r_a_m_e_w_o_r_k_:_ _S_P_F
-_R_e_c_o_r_d_ _S_y_n_t_a_x and _C_r_e_a_t_i_n_g_ _R_e_s_o_u_r_c_e_ _R_e_c_o_r_d_ _S_e_t_s_ _B_y_ _U_s_i_n_g_ _t_h_e_ _A_m_a_z_o_n_ _R_o_u_t_e_ _5_3
-_C_o_n_s_o_l_e.
+Yellow: The inbound rules of an Amazon VPC security group associated with a
+load balancer allow access to ports that are not defined in the load balancers
+listener configuration.
+Red: A security group associated with a load balancer does not exist.
 
-AAddddiittiioonnaall IInnffoorrmmaattiioonn
-_S_e_n_d_e_r_ _P_o_l_i_c_y_ _F_r_a_m_e_w_o_r_k (Wikipedia)
-_M_X_ _r_e_c_o_r_d (Wikipedia)') , ROW ('b73EEdD790', 'en', 'Amazon Route 53 Failover
-Resource Record Sets', 'Checks for Amazon Route 53 failover resource record
-sets that are misconfigured. When Amazon Route 53 health checks determine that
-the primary resource is unhealthy, Amazon Route 53 responds to queries with a
-secondary, backup resource record set. You must create correctly configured
-primary and secondary resource record sets for failover to work. Hosted zones
-created by AWS services wonÃ¢Â€Â™t appear in your check results.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Configure the security group rules to restrict access to only those ports and
+protocols that are defined in the load balancer listener configuration, plus
+the ICMP protocol to support Path MTU Discovery. See _L_i_s_t_e_n_e_r_s_ _f_o_r_ _Y_o_u_r_ _C_l_a_s_s_i_c
+_L_o_a_d_ _B_a_l_a_n_c_e_r and _S_e_c_u_r_i_t_y_ _G_r_o_u_p_s_ _f_o_r_ _L_o_a_d_ _B_a_l_a_n_c_e_r_s_ _i_n_ _a_ _V_P_C.
+If a security group is missing, apply a new security group to the load
+balancer. Create security group rules that restrict access to only those ports
+and protocols that are defined in the load balancer listener configuration. See
+_S_e_c_u_r_i_t_y_ _G_r_o_u_p_s_ _f_o_r_ _L_o_a_d_ _B_a_l_a_n_c_e_r_s_ _i_n_ _a_ _V_P_C.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g_ _U_s_e_r_ _G_u_i_d_e
+_C_o_n_f_i_g_u_r_e_ _Y_o_u_r_ _C_l_a_s_s_i_c_ _L_o_a_d_ _B_a_l_a_n_c_e_r') , ROW ('aW7HH0l7J9', 'en', 'Auto Scaling
+Launch Configurations', 'Checks for usage that is more than 80% of the Auto
+Scaling Launch Configurations Limit. Values are based on a snapshot, so your
+current usage might differ. Limit and usage data can take up to 24 hours to
+reflect any changes. In cases where limits have been recently increased, you
+may temporarily see utilization that exceeds the limit.') , ROW ('dx3xfbjfMr',
+'en', 'Route 53 Traffic Policies', 'Checks for usage that is more than 80% of
+the Route 53 Traffic Policies Limit per account. Values are based on a
+snapshot, so your current usage might differ. Limit and usage data can take up
+to 24 hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('gH5CC0e3J9', 'en', 'EBS Cold HDD (sc1) Volume Storage', 'Checks for usage
+that is more than 80% of the EBS Cold HDD (sc1) Volume Storage Limit. Values
+are based on a snapshot, so your current usage might differ. Limit and usage
+data can take up to 24 hours to reflect any changes. In cases where limits have
+been recently increased, you may temporarily see utilization that exceeds the
+limit.') , ROW ('b73EEdD790', 'en', 'Amazon Route 53 Failover Resource Record
+Sets', 'Checks for Amazon Route 53 failover resource record sets that are
+misconfigured. When Amazon Route 53 health checks determine that the primary
+resource is unhealthy, Amazon Route 53 responds to queries with a secondary,
+backup resource record set. You must create correctly configured primary and
+secondary resource record sets for failover to work. Hosted zones created by
+AWS services wonÃ¢Â€Â™t appear in your check results.
+
+****** AAlleerrtt CCrriitteerriiaa ******
 
-AAlleerrtt CCrriitteerriiaa
 Yellow: A primary failover resource record set does not have a corresponding
 secondary resource record set.
 Yellow: A secondary failover resource record set does not have a corresponding
 primary resource record set.
 Yellow: Primary and secondary resource record sets that have the same name are
 associated with the same health check.
 
-RReeccoommmmeennddeedd AAccttiioonn
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
 If a failover resource set is missing, create the corresponding resource record
 set; see _C_r_e_a_t_i_n_g_ _F_a_i_l_o_v_e_r_ _R_e_s_o_u_r_c_e_ _R_e_c_o_r_d_ _S_e_t_s.
 If your resource record sets are associated with the same health check, create
 separate health checks for each one; see _C_r_e_a_t_i_n_g_,_ _U_p_d_a_t_i_n_g_,_ _a_n_d_ _D_e_l_e_t_i_n_g
 _H_e_a_l_t_h_ _C_h_e_c_k_s.
 
-AAddddiittiioonnaall IInnffoorrmmaattiioonn
-_A_m_a_z_o_n_ _R_o_u_t_e_ _5_3_ _H_e_a_l_t_h_ _C_h_e_c_k_s_ _a_n_d_ _D_N_S_ _F_a_i_l_o_v_e_r') , ROW ('Cb877eB72b', 'en',
-'Amazon Route 53 Deleted Health Checks', 'Checks for resource record sets that
-are associated with health checks that have been deleted. Amazon Route 53 does
-not prevent you from deleting a health check that is associated with one or
-more resource record sets. If you delete a health check without updating the
-associated resource record sets, the routing of DNS queries for your DNS
-failover configuration will not work as intended. Hosted zones created by AWS
-services wonÃ¢Â€Â™t appear in your check results.
-
-AAlleerrtt CCrriitteerriiaa
-Yellow: A resource record set is associated with a health check that has been
-deleted.
-
-RReeccoommmmeennddeedd AAccttiioonn
-Create a new health check and associate it with the resource record set; see
-_C_r_e_a_t_i_n_g_,_ _U_p_d_a_t_i_n_g_,_ _a_n_d_ _D_e_l_e_t_i_n_g_ _H_e_a_l_t_h_ _C_h_e_c_k_s and _A_d_d_i_n_g_ _H_e_a_l_t_h_ _C_h_e_c_k_s_ _t_o
-_R_e_s_o_u_r_c_e_ _R_e_c_o_r_d_ _S_e_t_s.
-
-AAddddiittiioonnaall IInnffoorrmmaattiioonn
-_A_m_a_z_o_n_ _R_o_u_t_e_ _5_3_ _H_e_a_l_t_h_ _C_h_e_c_k_s_ _a_n_d_ _D_N_S_ _F_a_i_l_o_v_e_r
-_H_o_w_ _H_e_a_l_t_h_ _C_h_e_c_k_s_ _W_o_r_k_ _i_n_ _S_i_m_p_l_e_ _A_m_a_z_o_n_ _R_o_u_t_e_ _5_3_ _C_o_n_f_i_g_u_r_a_t_i_o_n_s') , ROW
-('vjafUGJ9H0', 'en', 'AWS CloudTrail Logging', 'Checks for your use of AWS
-CloudTrail. CloudTrail provides increased visibility into activity in your AWS
-account by recording information about AWS API calls made on the account. You
-can use these logs to determine, for example, what actions a particular user
-has taken during a specified time period or which users have taken actions on a
-particular resource during a specified time period. Because CloudTrail delivers
-log files to an Amazon Simple Storage Service (Amazon S3) bucket, CloudTrail
-must have write permissions for the bucket. If a trail applies to all regions
-(the default when creating a new trail), the trail appears multiple times in
-the Trusted Advisor report.') , ROW ('a2sEc6ILx', 'en', 'ELB Listener
-Security', 'Checks for load balancers with listeners that do not use
-recommended security configurations for encrypted communication. AWS recommends
-using a secure protocol (HTTPS or SSL), up-to-date security policies, and
-ciphers and protocols that are secure.
-When you use a secure protocol for a front-end connection (client to load
-balancer), the requests are encrypted between your clients and the load
-balancer, which is more secure.
-Elastic Load Balancing provides predefined security policies with ciphers and
-protocols that adhere to AWS security best practices. New versions of
-predefined policies are released as new configurations become available.
-
-AAlleerrtt CCrriitteerriiaa
-Yellow: A load balancer has no listener that uses a secure protocol (HTTPS or
-SSL).
-Yellow: A load balancer listener uses an outdated predefined SSL security
-policy.
-Yellow: A load balancer listener uses a cipher or protocol that is not
-recommended.
-Red: A load balancer listener uses an insecure cipher or protocol.
-
-RReeccoommmmeennddeedd AAccttiioonn
-    * If the traffic to your load balancer must be secure, use either the HTTPS
-      or the SSL protocol for the front-end connection.
-    * Upgrade your load balancer to the latest version of the predefined SSL
-      security policy.
-    * Use only the recommended ciphers and protocols.
-For more information, see _L_i_s_t_e_n_e_r_ _C_o_n_f_i_g_u_r_a_t_i_o_n_s_ _f_o_r_ _E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g.
-
-AAddddiittiioonnaall RReessoouurrcceess
-_L_i_s_t_e_n_e_r_ _C_o_n_f_i_g_u_r_a_t_i_o_n_s_ _Q_u_i_c_k_ _R_e_f_e_r_e_n_c_e
-_U_p_d_a_t_e_ _S_S_L_ _N_e_g_o_t_i_a_t_i_o_n_ _C_o_n_f_i_g_u_r_a_t_i_o_n_ _o_f_ _Y_o_u_r_ _L_o_a_d_ _B_a_l_a_n_c_e_r
-_S_S_L_ _N_e_g_o_t_i_a_t_i_o_n_ _C_o_n_f_i_g_u_r_a_t_i_o_n_s_ _f_o_r_ _E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g
-_S_S_L_ _S_e_c_u_r_i_t_y_ _P_o_l_i_c_y_ _T_a_b_l_e
-') , ROW ('xSqX82fQu', 'en', 'ELB Security Groups', 'Checks for load balancers
-configured with a missing security group or a security group that allows access
-to ports that are not configured for the load balancer. If a security group
-associated with a load balancer is deleted, the load balancer does not work as
-expected. If a security group allows access to ports that are not configured
-for the load balancer, the risk of loss of data or malicious attacks increases.
+****** AAddddiittiioonnaall IInnffoorrmmaattiioonn ******
 
+_A_m_a_z_o_n_ _R_o_u_t_e_ _5_3_ _H_e_a_l_t_h_ _C_h_e_c_k_s_ _a_n_d_ _D_N_S_ _F_a_i_l_o_v_e_r') , ROW ('N425c450f2', 'en',
+'CloudFront Custom SSL Certificates in the IAM Certificate Store', 'Checks the
+SSL certificates for CloudFront alternate domain names in the IAM certificate
+store and alerts you if the certificate is expired, will soon expire, uses
+outdated encryption, or is not configured correctly for the distribution. When
+a custom certificate for an alternate domain name expires, browsers that
+display your CloudFront content might show a warning message about the security
+of your website. Certificates that are encrypted by using the SHA-1 hashing
+algorithm are being deprecated by web browsers such as Chrome and Firefox. If a
+certificate doesnt contain any domain names that match either Origin Domain
+Name or the domain name in the Host header of viewer requests, CloudFront
+returns an HTTP status code 502 (bad gateway) to the user. For more
+information, see _U_s_i_n_g_ _A_l_t_e_r_n_a_t_e_ _D_o_m_a_i_n_ _N_a_m_e_s_ _a_n_d_ _H_T_T_P_S.') , ROW ('L4dfs2Q4C5',
+'en', 'AWS Lambda Functions Using Deprecated Runtimes', 'Checks for Lambda
+functions that are configured to use a runtime that is approaching deprecation
+or is deprecated. Deprecated runtimes are not eligible for security updates or
+technical support.
+****** NNootteess:: ******
+') , ROW ('L4dfs2Q4C6', 'en', 'AWS Lambda VPC-enabled Functions without Multi-
+AZ Redundancy', 'Checks for VPC-enabled Lambda functions that are vulnerable to
+service interruption in a single availability zone. It is recommended for VPC-
+enabled functions to be connected to multiple availability zones for high
+availability.
+****** NNoottee:: ******
+Results for this check are automatically refreshed several times daily, and
+refresh requests are not allowed. It might take a few hours for changes to
+appear.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: The inbound rules of an Amazon VPC security group associated with a
-load balancer allow access to ports that are not defined in the load balancers
-listener configuration.
-Red: A security group associated with a load balancer does not exist.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Configure the security group rules to restrict access to only those ports and
-protocols that are defined in the load balancer listener configuration, plus
-the ICMP protocol to support Path MTU Discovery. See _L_i_s_t_e_n_e_r_s_ _f_o_r_ _Y_o_u_r_ _C_l_a_s_s_i_c
-_L_o_a_d_ _B_a_l_a_n_c_e_r and _S_e_c_u_r_i_t_y_ _G_r_o_u_p_s_ _f_o_r_ _L_o_a_d_ _B_a_l_a_n_c_e_r_s_ _i_n_ _a_ _V_P_C.
-If a security group is missing, apply a new security group to the load
-balancer. Create security group rules that restrict access to only those ports
-and protocols that are defined in the load balancer listener configuration. See
-_S_e_c_u_r_i_t_y_ _G_r_o_u_p_s_ _f_o_r_ _L_o_a_d_ _B_a_l_a_n_c_e_r_s_ _i_n_ _a_ _V_P_C.
+Yellow: A VPC-enabled Lambda function connected to subnets in a single
+Availability Zone.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g_ _U_s_e_r_ _G_u_i_d_e
-_C_o_n_f_i_g_u_r_e_ _Y_o_u_r_ _C_l_a_s_s_i_c_ _L_o_a_d_ _B_a_l_a_n_c_e_r') , ROW ('xdeXZKIUy', 'en', 'ELB Cross-
-Zone Load Balancing', 'With Cross-zone load balancing turned off, there is a
-risk of service unavailability due to uneven distribution of traffic or backend
-overloading. This problem can occur when clients incorrectly cache DNS
-information, or when there are an unequal number of instances in each
-Availability Zone (for example, if you have taken down some instances for
-maintenance).
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: Cross-zone load balancing is not enabled for a load balancer.
+When configuring functions for access to your VPC, choose subnets in multiple
+Availability Zones to ensure high availability.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Confirm that the Amazon EC2 instances registered with the load balancer are
-launched in multiple Availability Zones, and then enable cross-zone load
-balancing for the load balancer. For more information, see _A_v_a_i_l_a_b_i_l_i_t_y_ _Z_o_n_e_s
-_a_n_d_ _R_e_g_i_o_n_s and _E_n_a_b_l_e_ _o_r_ _D_i_s_a_b_l_e_ _C_r_o_s_s_-_Z_o_n_e_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g_ _f_o_r_ _Y_o_u_r_ _L_o_a_d
-_B_a_l_a_n_c_e_r.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_R_e_q_u_e_s_t_ _R_o_u_t_i_n_g
-_E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g_ _C_o_n_c_e_p_t_s') , ROW ('7qGXsKIUw', 'en', 'ELB Connection
-Draining', 'Checks for load balancers that do not have connection draining
-enabled. When connection draining is not enabled and you remove (deregister) an
-Amazon EC2 instance from a load balancer, the load balancer stops routing
-traffic to that instance and closes the connection. When connection draining is
-enabled, the load balancer stops sending new requests to the deregistered
-instance but keeps the connection open to serve active requests.
+_C_o_n_f_i_g_u_r_i_n_g_ _a_ _L_a_m_b_d_a_ _f_u_n_c_t_i_o_n_ _t_o_ _a_c_c_e_s_s_ _r_e_s_o_u_r_c_e_s_ _i_n_ _a_ _V_P_C
+_R_e_s_i_l_i_e_n_c_e_ _i_n_ _A_W_S_ _L_a_m_b_d_a
+') , ROW ('cF171Db240', 'en', 'Amazon Route 53 Name Server Delegations',
+'Checks for Amazon Route 53 hosted zones for which your domain registrar or DNS
+is not using the correct Route 53 name servers. When you create a hosted zone,
+Route 53 assigns a delegation set of four name servers. The names of these
+servers are ns-###.awsdns-##.com, .net, .org, and .co.uk, where ### and ##
+typically represent different numbers. Before Route 53 can route DNS queries
+for your domain, you must update your registrars name server configuration to
+remove the name servers that the registrar assigned and add all four name
+servers in the Route 53 delegation set. For maximum availability, you must add
+all four Route 53 name servers. Hosted zones created by AWS services wonÃ¢Â€Â™t
+appear in your check results.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: Connection draining is not enabled for a load balancer.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Enable connection draining for the load balancer. For more information, see
-_C_o_n_n_e_c_t_i_o_n_ _D_r_a_i_n_i_n_g and _E_n_a_b_l_e_ _o_r_ _D_i_s_a_b_l_e_ _C_o_n_n_e_c_t_i_o_n_ _D_r_a_i_n_i_n_g_ _f_o_r_ _Y_o_u_r_ _L_o_a_d
-_B_a_l_a_n_c_e_r.
+Yellow: A hosted zone for which the registrar for your domain does not use all
+four of the Route 53 name servers in the delegation set.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g_ _C_o_n_c_e_p_t_s') , ROW ('N415c450f2', 'en', 'CloudFront Header
-Forwarding and Cache Hit Ratio', 'Checks the HTTP request headers that
-CloudFront currently receives from the client and forwards to your origin
-server. Some headers, such as Date or User-Agent, significantly reduce the
-cache hit ratio (the proportion of requests that are served from a CloudFront
-edge cache). This increases the load on your origin and reduces performance
-because CloudFront must forward more requests to your origin.') , ROW
-('N425c450f2', 'en', 'CloudFront Custom SSL Certificates in the IAM Certificate
-Store', 'Checks the SSL certificates for CloudFront alternate domain names in
-the IAM certificate store and alerts you if the certificate is expired, will
-soon expire, uses outdated encryption, or is not configured correctly for the
-distribution. When a custom certificate for an alternate domain name expires,
-browsers that display your CloudFront content might show a warning message
-about the security of your website. Certificates that are encrypted by using
-the SHA-1 hashing algorithm are being deprecated by web browsers such as Chrome
-and Firefox. If a certificate doesnt contain any domain names that match either
-Origin Domain Name or the domain name in the Host header of viewer requests,
-CloudFront returns an HTTP status code 502 (bad gateway) to the user. For more
-information, see _U_s_i_n_g_ _A_l_t_e_r_n_a_t_e_ _D_o_m_a_i_n_ _N_a_m_e_s_ _a_n_d_ _H_T_T_P_S.') , ROW ('N430c450f2',
-'en', 'CloudFront SSL Certificate on the Origin Server', 'Checks your origin
-server for SSL certificates that are expired, about to expire, missing, or that
-use outdated encryption. If a certificate is expired, CloudFront responds to
-requests for your content with HTTP status code 502, Bad Gateway. Certificates
-that were encrypted by using the SHA-1 hashing algorithm are being deprecated
-by web browsers such as Chrome and Firefox. Depending on the number of SSL
-certificates that you have associated with your CloudFront distributions, this
-check might add a few cents per month to your bill with your web hosting
-provider, for example, AWS if youre using EC2 or ELB as the origin for your
-CloudFront distribution. This check does not validate your origin certificate
-chain or certificate authorities; you can check these in your CloudFront
-configuration. ') , ROW ('Bh2xRR2FGH', 'en', 'Amazon EC2 to EBS Throughput
-Optimization', 'Checks for Amazon EBS volumes whose performance might be
-affected by the maximum throughput capability of the Amazon EC2 instance they
-are attached to. To optimize performance, you should ensure that the maximum
-throughput of an EC2 instance is greater than the aggregate maximum throughput
-of the attached EBS volumes. This check computes the total EBS volume
-throughput for each five-minute period in the preceding day (UTC) for each EBS-
-optimized instance and alerts you if usage in more than half of those periods
-was greater than 95% of the maximum throughput of the EC2 instance.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: In the preceding day (UTC), the aggregate throughput (megabytes/sec) of
-the EBS volumes attached to the EC2 instance exceeded 95% of the published
-throughput between the instance and the EBS volumes more than 50% of time.
+Add or update name server records with your registrar or with the current DNS
+service for your domain to include all four of the name servers in your Route
+53 delegation set. To find these values, see _G_e_t_t_i_n_g_ _t_h_e_ _N_a_m_e_ _S_e_r_v_e_r_s_ _f_o_r_ _a
+_H_o_s_t_e_d_ _Z_o_n_e. For information about adding or updating name server records, see
+_C_r_e_a_t_i_n_g_ _a_n_d_ _M_i_g_r_a_t_i_n_g_ _D_o_m_a_i_n_s_ _a_n_d_ _S_u_b_d_o_m_a_i_n_s_ _t_o_ _A_m_a_z_o_n_ _R_o_u_t_e_Â _5_3.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Compare the maximum throughput of your EBS volumes (see _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e
-_T_y_p_e_s) with the maximum throughput of the EC2 instance they are attached to
-(see _I_n_s_t_a_n_c_e_ _T_y_p_e_s_ _T_h_a_t_ _S_u_p_p_o_r_t_ _E_B_S_ _O_p_t_i_m_i_z_a_t_i_o_n). Consider attaching your
-volumes to an instance that supports higher throughput to EBS for optimal
-performance.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e_ _T_y_p_e_s
-_A_m_a_z_o_n_ _E_B_S_-_O_p_t_i_m_i_z_e_d_ _I_n_s_t_a_n_c_e_s
-_M_o_n_i_t_o_r_i_n_g_ _t_h_e_ _S_t_a_t_u_s_ _o_f_ _Y_o_u_r_ _V_o_l_u_m_e_s
-_A_t_t_a_c_h_i_n_g_ _a_n_ _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e_ _t_o_ _a_n_ _I_n_s_t_a_n_c_e
-_D_e_t_a_c_h_i_n_g_ _a_n_ _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e_ _f_r_o_m_ _a_n_ _I_n_s_t_a_n_c_e
-_D_e_l_e_t_i_n_g_ _a_n_ _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e ') , ROW ('N420c450f2', 'en', 'CloudFront
-Alternate Domain Names', 'Checks Amazon CloudFront distributions for alternate
-domain names (CNAMES) that have incorrectly configured DNS settings. If a
-CloudFront distribution includes alternate domain names, the DNS configuration
-for the domains must route DNS queries to that distribution.
+_W_o_r_k_i_n_g_ _w_i_t_h_ _H_o_s_t_e_d_ _Z_o_n_e_s
+') , ROW ('cG7HH0l7J9', 'en', 'EBS Magnetic (standard) Volume Storage', 'Checks
+for usage that is more than 80% of the EBS Magnetic (standard) Volume Storage
+Limit. Values are based on a snapshot, so your current usage might differ.
+Limit and usage data can take up to 24 hours to reflect any changes. In cases
+where limits have been recently increased, you may temporarily see utilization
+that exceeds the limit.') , ROW ('sU7XX0l7J9', 'en', 'IAM Group', 'Checks for
+usage that is more than 80% of the IAM Group Limit. Values are based on a
+snapshot, so your current usage might differ. Limit and usage data can take up
+to 24 hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('N420c450f2', 'en', 'CloudFront Alternate Domain Names', 'Checks Amazon
+CloudFront distributions for alternate domain names (CNAMES) that have
+incorrectly configured DNS settings. If a CloudFront distribution includes
+alternate domain names, the DNS configuration for the domains must route DNS
+queries to that distribution.
 
 Note: This check assumes Amazon Route 53 DNS and Amazon CloudFront distribution
 are configured in the same AWS account. As such the Alert list may include
 resources otherwise working as expected due to DNS setting outsides of this AWS
 account.
 
-AAlleerrtt CCrriitteerriiaa
+****** AAlleerrtt CCrriitteerriiaa ******
+
 Yellow: A CloudFront distribution includes alternate domain names, but the DNS
 configuration is not correctly set up with a CNAME record or an Amazon Route 53
 alias resource record.
 Yellow: A CloudFront distribution includes alternate domain names, but Trusted
 Advisor could not evaluate the DNS configuration because there were too many
 redirects.
 Yellow: A CloudFront distribution includes alternate domain names, but Trusted
 Advisor could not evaluate the DNS configuration for some other reason, most
 likely because of a timeout.
 
-RReeccoommmmeennddeedd AAccttiioonn
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
 Update the DNS configuration to route DNS queries to the CloudFront
 distribution; see _U_s_i_n_g_ _A_l_t_e_r_n_a_t_e_ _D_o_m_a_i_n_ _N_a_m_e_s_ _(_C_N_A_M_E_s_). If youre using Amazon
 Route 53 as your DNS service, see _R_o_u_t_i_n_g_ _T_r_a_f_f_i_c_ _t_o_ _a_n_ _A_m_a_z_o_n_ _C_l_o_u_d_F_r_o_n_t_ _W_e_b
 _D_i_s_t_r_i_b_u_t_i_o_n_ _b_y_ _U_s_i_n_g_ _Y_o_u_r_ _D_o_m_a_i_n_ _N_a_m_e. If the check timed out, try refreshing
 the check.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_A_m_a_z_o_n_ _C_l_o_u_d_F_r_o_n_t_ _D_e_v_e_l_o_p_e_r_ _G_u_i_d_e') , ROW ('DqdJqYeRm5', 'en', 'IAM Access Key
-Rotation', 'Checks for active IAM access keys that have not been rotated in the
-last 90 days. When you rotate your access keys regularly, you reduce the chance
-that a compromised key could be used without your knowledge to access
-resources. For the purposes of this check, the last rotation date and time is
-when the access key was created or most recently activated. The access key
-number and date come from the aacccceessss__kkeeyy__11__llaasstt__rroottaatteedd and
-aacccceessss__kkeeyy__22__llaasstt__rroottaatteedd information in the most recent IAM credential report.
-Because the regeneration frequency of a credential report is restricted,
-refreshing this check might not reflect recent changes (for details, see
-_G_e_t_t_i_n_g_ _C_r_e_d_e_n_t_i_a_l_ _R_e_p_o_r_t_s_ _f_o_r_ _Y_o_u_r_ _A_W_S_ _A_c_c_o_u_n_t).
-In order to create and rotate access keys, a user must have the appropriate
-permissions. For more information, see _A_l_l_o_w_ _U_s_e_r_s_ _t_o_ _M_a_n_a_g_e_ _T_h_e_i_r_ _O_w_n
-_P_a_s_s_w_o_r_d_s_,_ _A_c_c_e_s_s_ _K_e_y_s_,_ _a_n_d_ _S_S_H_ _K_e_y_s.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAlleerrtt CCrriitteerriiaa
-Green: The access key is active and has been rotated in the last 90 days.
-Yellow: The access key is active and has been rotated in the last 2 years, but
-more than 90 days ago.
-Red: The access key is active and has not been rotated in the last 2 years.
+_A_m_a_z_o_n_ _C_l_o_u_d_F_r_o_n_t_ _D_e_v_e_l_o_p_e_r_ _G_u_i_d_e') , ROW ('COr6dfpM04', 'en', 'Amazon EBS
+under-provisioned volumes', 'Checks the Amazon Elastic Block Storage (Amazon
+EBS) volumes that were running at any time during the lookback period. This
+check alerts you if any EBS volumes were under-provisioned for your workloads.
+Consistent high utilization can indicate optimized, steady performance, but can
+also indicate that an application does not have enough resources.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Rotate access keys on a regular basis. See _R_o_t_a_t_i_n_g_ _A_c_c_e_s_s_ _K_e_y_s and _M_a_n_a_g_i_n_g
-_A_c_c_e_s_s_ _K_e_y_s_ _f_o_r_ _I_A_M_ _U_s_e_r_s.
+****** SSoouurrccee ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_I_A_M_ _B_e_s_t_ _P_r_a_c_t_i_c_e_s
-_H_o_w_ _t_o_ _r_o_t_a_t_e_ _a_c_c_e_s_s_ _k_e_y_s_ _f_o_r_ _I_A_M_ _u_s_e_r_s (AWS blog)') , ROW ('12Fnkpl8Y5', 'en',
-'Exposed Access Keys', 'Checks popular code repositories for access keys that
-have been exposed to the public and for irregular Amazon Elastic Compute Cloud
-(Amazon EC2) usage that could be the result of a compromised access key. An
-access key consists of an access key ID and the corresponding secret access
-key. Exposed access keys pose a security risk to your account and other users,
-could lead to excessive charges from unauthorized activity or abuse, and
-violate the _A_W_S_ _C_u_s_t_o_m_e_r_ _A_g_r_e_e_m_e_n_t. If your access key is exposed, take
-immediate action to secure your account. To protect your account from excessive
-charges, AWS temporarily limits your ability to create certain AWS resources
-when exposed access keys are identified. This does not make your account
-secure; it only partially limits the unauthorized usage for which you could be
-charged. Note: This check does not guarantee the identification of exposed
-access keys or compromised EC2 instances. You are ultimately responsible for
-the safety and security of your access keys and AWS resources.
+AWS Compute Optimizer
 
-If a deadline is shown for an access key, AWS may suspend your AWS account if
-the unauthorized usage is not stopped by that date. If you believe an alert is
-in error, _c_o_n_t_a_c_t_ _A_W_S_ _S_u_p_p_o_r_t.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-The information displayed in Trusted Advisor may not reflect the most recent
-state of your account. No exposed access keys are marked as resolved until all
-exposed access keys on the account have been resolved. This data
-synchronization can take up to one week.
+Yellow: An EBS Volume that was under-provisioned during the lookback period. To
+determine if a volume is under-provisioned, we consider all default CloudWatch
+metrics (including IOPS and throughput). The algorithm used to identify under-
+provisioned EBS volumes follows AWS best practices. The algorithm is updated
+when a new pattern has been identified.
 
-AAlleerrtt CCrriitteerriiaa
-Red: Potentially compromised - AWS has identified an access key ID and
-corresponding secret access key that have been exposed on the Internet and may
-have been compromised (used).
-Red: Exposed - AWS has identified an access key ID and corresponding secret
-access key that have been exposed on the Internet.
-Red: Suspected - Irregular Amazon EC2 usage indicates that an access key may
-have been compromised, but it has not been identified as exposed on the
-Internet.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Delete the affected access key as soon as possible. If the key is associated
-with an IAM user, see _M_a_n_a_g_i_n_g_ _A_c_c_e_s_s_ _K_e_y_s_ _f_o_r_ _I_A_M_ _U_s_e_r_s.
+Consider upsizing volumes that have high utilization.
 
-Check your account for unauthorized usage. Log in to the _A_W_S_ _M_a_n_a_g_e_m_e_n_t_ _C_o_n_s_o_l_e
-and check each service console for suspicious resources. Pay special attention
-to running Amazon EC2 instances, Spot Instance requests, access keys, and IAM
-users. You can also check overall usage on the _B_i_l_l_i_n_g_ _&_ _C_o_s_t_ _M_a_n_a_g_e_m_e_n_t
-_D_a_s_h_b_o_a_r_d.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_B_e_s_t_ _P_r_a_c_t_i_c_e_s_ _f_o_r_ _M_a_n_a_g_i_n_g_ _A_W_S_ _A_c_c_e_s_s_ _K_e_y_s
-_A_W_S_ _S_e_c_u_r_i_t_y_ _A_u_d_i_t_ _G_u_i_d_e_l_i_n_e_s') , ROW ('G31sQ1E9U', 'en', 'Underutilized Amazon
-Redshift Clusters', 'Checks your Amazon Redshift configuration for clusters
-that appear to be underutilized. If an Amazon Redshift cluster has not had a
-connection for a prolonged period of time or is using a low amount of CPU, you
-can use lower-cost options such as downsizing the cluster or shutting down the
-cluster and taking a final snapshot. Final snapshots are retained even after
-you delete your cluster.
+For more information about this recommendation, see the _T_r_u_s_t_e_d_ _A_d_v_i_s_o_r
+_d_o_c_u_m_e_n_t_a_t_i_o_n.') , ROW ('COr6dfpM03', 'en', 'Amazon EBS over-provisioned
+volumes', 'Checks the Amazon Elastic Block Storage (Amazon EBS) volumes that
+were running at any time during the lookback period. This check alerts you if
+any EBS volumes were over-provisioned for your workloads. When you have over-
+provisioned volumes, youÃ¢Â€Â™re paying for unused resources. Although some
+scenarios can result in low optimization by design, you can often lower your
+costs by changing the configuration of your EBS volumes. Estimated monthly
+savings are calculated by using the current usage rate for EBS volumes. Actual
+savings will vary if the volume isnÃ¢Â€Â™t present for a full month.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: A running cluster has not had a connection in the last 7 days.
-Yellow: A running cluster had less than 5% cluster-wide average CPU utilization
-for 99% of the last 7 days.
+****** SSoouurrccee ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Consider shutting down the cluster and taking a final snapshot, or downsizing
-the cluster. See _S_h_u_t_t_i_n_g_ _D_o_w_n_ _a_n_d_ _D_e_l_e_t_i_n_g_ _C_l_u_s_t_e_r_s and _R_e_s_i_z_i_n_g_ _a_ _C_l_u_s_t_e_r.
+AWS Compute Optimizer
 
-AAddddiittiioonnaall RReessoouurrcceess
-_A_m_a_z_o_n_ _C_l_o_u_d_W_a_t_c_h_ _D_e_v_e_l_o_p_e_r_ _G_u_i_d_e') , ROW ('1e93e4c0b5', 'en', 'Amazon EC2
-Reserved Instance Lease Expiration', 'Checks for Amazon EC2 Reserved Instances
-that are scheduled to expire within the next 30 days or have expired in the
-preceding 30 days. Reserved Instances do not renew automatically; you can
-continue using an EC2 instance covered by the reservation without interruption,
-but you will be charged On-Demand rates. New Reserved Instances can have the
-same parameters as the expired ones, or you can purchase Reserved Instances
-with different parameters.
-The estimated monthly savings we show is the difference between the On-Demand
-and Reserved Instance rates for the same instance type.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: The Reserved Instance lease expires in less than 30 days.
-Yellow: The Reserved Instance lease expired in the preceding 30 days.
+Yellow: An EBS Volume that was over-provisioned during the lookback period. To
+determine if a volume is over-provisioned, we consider all default CloudWatch
+metrics (including IOPS and throughput). The algorithm used to identify over-
+provisioned EBS volumes follows AWS best practices. The algorithm is updated
+when a new pattern has been identified.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Consider purchasing a new Reserved Instance to replace the one that is nearing
-the end of its term. For more information, see _H_o_w_ _t_o_ _P_u_r_c_h_a_s_e_ _R_e_s_e_r_v_e_d
-_I_n_s_t_a_n_c_e_s and _B_u_y_i_n_g_ _R_e_s_e_r_v_e_d_ _I_n_s_t_a_n_c_e_s.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_R_e_s_e_r_v_e_d_ _I_n_s_t_a_n_c_e_s
-_I_n_s_t_a_n_c_e_ _T_y_p_e_s') , ROW ('R365s2Qddf', 'en', 'Amazon S3 Bucket Versioning',
-'Checks for Amazon Simple Storage Service buckets that do not have versioning
-enabled, or have versioning suspended. When versioning is enabled, you can
-easily recover from both unintended user actions and application failures.
-Versioning allows you to preserve, retrieve, and restore any version of any
-object stored in a bucket. You can use lifecycle rules to manage all versions
-of your objects as well as their associated costs by automatically archiving
-objects to the Glacier storage class or removing them after a specified time
-period. You can also choose to require multi-factor authentication (MFA) for
-any object deletions or configuration changes to your buckets.
+Consider downsizing volumes that have low utilization.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+For more information about this recommendation, see the _T_r_u_s_t_e_d_ _A_d_v_i_s_o_r
+_d_o_c_u_m_e_n_t_a_t_i_o_n_..') , ROW ('jtlIMO3qZM', 'en', 'RDS Cluster Parameter Groups',
+'Checks for usage that is more than 80% of the RDS Cluster Parameter Groups
+Limit. Values are based on a snapshot, so your current usage might differ.
+Limit and usage data can take up to 24 hours to reflect any changes. In cases
+where limits have been recently increased, you may temporarily see utilization
+that exceeds the limit.') , ROW ('COr6dfpM06', 'en', 'AWS Lambda under-
+provisioned functions for memory size', 'Checks the AWS Lambda functions that
+were invoked at least once during the lookback period. This check alerts you if
+any of your Lambda functions were under-provisioned for memory size. When you
+have Lambda functions that are under-provisioned for memory size, these
+functions take longer time to complete.
+
+****** SSoouurrccee ******
+
+AWS Compute Optimizer
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: A Lambda function that was under-provisioned for memory size during the
+lookback period. To determine if a Lambda function is under-provisioned, we
+consider all default CloudWatch metrics for that function. The algorithm used
+to identify under-provisioned Lambda functions for memory size follows AWS best
+practices. The algorithm is updated when a new pattern has been identified.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Consider increasing the memory size of your Lambda functions.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+For more information about this recommendation, see the _T_r_u_s_t_e_d_ _A_d_v_i_s_o_r
+_d_o_c_u_m_e_n_t_a_t_i_o_n.') , ROW ('COr6dfpM05', 'en', 'AWS Lambda over-provisioned
+functions for memory size', 'Checks the AWS Lambda functions that were invoked
+at least once during the lookback period. This check alerts you if any of your
+Lambda functions were over-provisioned for memory size. When you have Lambda
+functions that are over-provisioned for memory sizes, youÃ¢Â€Â™re paying for
+unused resources. Although some scenarios can result in low utilization by
+design, you can often lower your costs by changing the memory configuration of
+your Lambda functions. Estimated monthly savings are calculated by using the
+current usage rate for Lambda functions.
+
+****** SSoouurrccee ******
+
+AWS Compute Optimizer
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: A Lambda function that was over-provisioned for memory size during the
+lookback period. To determine if a Lambda function is over-provisioned, we
+consider all default CloudWatch metrics for that function. The algorithm used
+to identify over-provisioned Lambda functions for memory size follows AWS best
+practices. The algorithm is updated when a new pattern has been identified.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Consider reducing the memory size of your Lambda functions.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+For more information about this recommendation, see the _T_r_u_s_t_e_d_ _A_d_v_i_s_o_r
+_d_o_c_u_m_e_n_t_a_t_i_o_n_ _p_a_g_e.') , ROW ('f2iK5R6Dep', 'en', 'Amazon RDS Multi-AZ', 'Checks
+for DB instances that are deployed in a single Availability Zone. Multi-AZ
+deployments enhance database availability by synchronously replicating to a
+standby instance in a different Availability Zone. During planned database
+maintenance or the failure of a DB instance or Availability Zone, Amazon RDS
+automatically fails over to the standby so that database operations can resume
+quickly without administrative intervention. Because Multi-AZ deployments for
+the SQL Server engine use a different mechanism for synchronization, this check
+does not examine SQL Server instances.') , ROW ('jEhCtdJKOY', 'en', 'RDS
+Subnets per Subnet Group', 'Checks for usage that is more than 80% of the RDS
+Subnets per Subnet Group Limit. Values are based on a snapshot, so your current
+usage might differ. Limit and usage data can take up to 24 hours to reflect any
+changes. In cases where limits have been recently increased, you may
+temporarily see utilization that exceeds the limit.') , ROW ('a2sEc6ILx', 'en',
+'ELB Listener Security', 'Checks for load balancers with listeners that do not
+use recommended security configurations for encrypted communication. AWS
+recommends using a secure protocol (HTTPS or SSL), up-to-date security
+policies, and ciphers and protocols that are secure.
+When you use a secure protocol for a front-end connection (client to load
+balancer), the requests are encrypted between your clients and the load
+balancer, which is more secure.
+Elastic Load Balancing provides predefined security policies with ciphers and
+protocols that adhere to AWS security best practices. New versions of
+predefined policies are released as new configurations become available.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: A load balancer has no listener that uses a secure protocol (HTTPS or
+SSL).
+Yellow: A load balancer listener uses an outdated predefined SSL security
+policy.
+Yellow: A load balancer listener uses a cipher or protocol that is not
+recommended.
+Red: A load balancer listener uses an insecure cipher or protocol.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+    * If the traffic to your load balancer must be secure, use either the HTTPS
+      or the SSL protocol for the front-end connection.
+    * Upgrade your load balancer to the latest version of the predefined SSL
+      security policy.
+    * Use only the recommended ciphers and protocols.
+For more information, see _L_i_s_t_e_n_e_r_ _C_o_n_f_i_g_u_r_a_t_i_o_n_s_ _f_o_r_ _E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_L_i_s_t_e_n_e_r_ _C_o_n_f_i_g_u_r_a_t_i_o_n_s_ _Q_u_i_c_k_ _R_e_f_e_r_e_n_c_e
+_U_p_d_a_t_e_ _S_S_L_ _N_e_g_o_t_i_a_t_i_o_n_ _C_o_n_f_i_g_u_r_a_t_i_o_n_ _o_f_ _Y_o_u_r_ _L_o_a_d_ _B_a_l_a_n_c_e_r
+_S_S_L_ _N_e_g_o_t_i_a_t_i_o_n_ _C_o_n_f_i_g_u_r_a_t_i_o_n_s_ _f_o_r_ _E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g
+_S_S_L_ _S_e_c_u_r_i_t_y_ _P_o_l_i_c_y_ _T_a_b_l_e
+') , ROW ('ePs02jT06w', 'en', 'Amazon EBS Public Snapshots', 'Checks the
+permission settings for your Amazon Elastic Block Store (Amazon EBS) volume
+snapshots and alerts you if any snapshots are marked as public. When you make a
+snapshot public, you give all AWS accounts and users access to all the data on
+the snapshot. If you want to share a snapshot with particular users or
+accounts, mark the snapshot as private, and then specify the user or accounts
+you want to share the snapshot data with.
+****** NNoottee ******
+: Results for this check are automatically refreshed several times daily, and
+refresh requests are not allowed. It might take a few hours for changes to
+appear.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Red: The EBS volume snapshot is marked as public.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Unless you are certain you want to share all the data in the snapshot with all
+AWS accounts and users, modify the permissions: mark the snapshot as private,
+and then specify the accounts that you want to give permissions to. For more
+information, see _S_h_a_r_i_n_g_ _a_n_ _A_m_a_z_o_n_ _E_B_S_ _S_n_a_p_s_h_o_t. Note: For temporary technical
+reasons, items in this check cannot be excluded from view in the Trusted
+Advisor console.To modify permissions for your snapshots directly, you can use
+a runbook in the AWS Systems Manager console. For more information, see
+_A_W_S_S_u_p_p_o_r_t_-_M_o_d_i_f_y_E_B_S_S_n_a_p_s_h_o_t_P_e_r_m_i_s_s_i_o_n.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_A_m_a_z_o_n_ _E_B_S_ _S_n_a_p_s_h_o_t_s') , ROW ('R365s2Qddf', 'en', 'Amazon S3 Bucket
+Versioning', 'Checks for Amazon Simple Storage Service buckets that do not have
+versioning enabled, or have versioning suspended. When versioning is enabled,
+you can easily recover from both unintended user actions and application
+failures. Versioning allows you to preserve, retrieve, and restore any version
+of any object stored in a bucket. You can use lifecycle rules to manage all
+versions of your objects as well as their associated costs by automatically
+archiving objects to the Glacier storage class or removing them after a
+specified time period. You can also choose to require multi-factor
+authentication (MFA) for any object deletions or configuration changes to your
+buckets.
 
 Versioning cannot be disabled after it has been enabled, but it can be
 suspended, which prevents new versions of objects from being created. Using
 versioning can increase your costs for Amazon S3, because you pay for storage
 of multiple versions of an object.
 
-AAlleerrtt CCrriitteerriiaa
+****** AAlleerrtt CCrriitteerriiaa ******
+
 Green: Versioning is enabled for the bucket.
 Yellow: Versioning is not enabled for the bucket.
 Yellow: Versioning is suspended for the bucket.
 
-RReeccoommmmeennddeedd AAccttiioonn
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
 Enable bucket versioning on most buckets to prevent accidental deletion or
 overwriting. See _U_s_i_n_g_ _V_e_r_s_i_o_n_i_n_g and _E_n_a_b_l_i_n_g_ _V_e_r_s_i_o_n_i_n_g_ _P_r_o_g_r_a_m_m_a_t_i_c_a_l_l_y.
 
 If bucket versioning is suspended, consider reenabling versioning. For
 information on working with objects in a versioning-suspended bucket, see
 _M_a_n_a_g_i_n_g_ _O_b_j_e_c_t_s_ _i_n_ _a_ _V_e_r_s_i_o_n_i_n_g_-_S_u_s_p_e_n_d_e_d_ _B_u_c_k_e_t.
 
@@ -643,1231 +444,1863 @@
 _M_a_n_a_g_e_m_e_n_t.
 
 MFA Delete requires additional authentication when the versioning status of the
 bucket is changed or when versions of an object are deleted. It requires the
 user to enter credentials and a code from an approved authentication device.
 For more information, see _M_F_A_ _D_e_l_e_t_e.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_W_o_r_k_i_n_g_ _w_i_t_h_ _B_u_c_k_e_t_s') , ROW ('0t121N1Ty3', 'en', 'AWS Direct Connect
-Connection Redundancy', 'Checks for regions that have only one AWS Direct
-Connect connection. Connectivity to your AWS resources should have two Direct
-Connect connections configured at all times to provide redundancy in case a
-device is unavailable.
-NNoottee:: Results for this check are automatically refreshed several times daily,
-and refresh requests are not allowed. It might take a few hours for changes to
-appear.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: The region has only one Direct Connect connection.
+_W_o_r_k_i_n_g_ _w_i_t_h_ _B_u_c_k_e_t_s') , ROW ('Wxdfp4B1L2', 'en', 'AWS Well-Architected high
+risk issues for performance efficiency', 'Checks for high risk issues (HRIs)
+for your workloads in the performance pillar. This check is based on your AWS-
+Well Architected reviews. Your check results depend on whether you completed
+the workload evaluation with AWS Well-Architected.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Configure an additional Direct Connect connection in this region to protect
-against device unavailability. For more information, see _C_o_n_f_i_g_u_r_e_ _R_e_d_u_n_d_a_n_t
-_C_o_n_n_e_c_t_i_o_n_s_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t. To protect against site unavailability and
-add location redundancy, configure the additional Direct Connect connection to
-a different Direct Connect location.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_G_e_t_t_i_n_g_ _S_t_a_r_t_e_d_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t
-_A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t_ _F_A_Q_s ') , ROW ('8M012Ph3U5', 'en', 'AWS Direct Connect
-Location Redundancy', 'Checks for regions with one or more AWS Direct Connect
-connections and only one AWS Direct Connect location. Connectivity to your AWS
-resources should have Direct Connect connections configured to different Direct
-Connect locations to provide redundancy in case a location is unavailable.
-NNoottee:: Results for this check are automatically refreshed several times daily,
-and refresh requests are not allowed. It might take a few hours for changes to
+Red: At least one active high risk issue was identified in the performance
+pillar for AWS Well-Architected.') , ROW ('Wxdfp4B1L3', 'en', 'AWS Well-
+Architected high risk issues for security', 'Checks for high risk issues (HRIs)
+for your workloads in the security pillar. This check is based on your AWS-Well
+Architected reviews. Your check results depend on whether you completed the
+workload evaluation with AWS Well-Architected.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Red: At least one active high risk issue was identified in the security pillar
+for AWS Well-Architected.') , ROW ('8wIqYSt25K', 'en', 'ELB Network Load
+Balancers', 'Checks for usage that is more than 80% of the ELB Network Load
+Balancers Limit. Classic Load Balancers and Application Load Balancers have
+separate limits. Values are based on a snapshot, so your current usage might
+differ. Limit and usage data can take up to 24 hours to reflect any changes. In
+cases where limits have been recently increased, you may temporarily see
+utilization that exceeds the limit.
+') , ROW ('Wxdfp4B1L4', 'en', 'AWS Well-Architected high risk issues for
+reliability', 'Checks for high risk issues (HRIs) for your workloads in the
+Reliability pillar. This check is based on your AWS-Well Architected reviews.
+Your check results depend on whether you completed the workload evaluation with
+AWS Well-Architected.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Red: At least one active high risk issue was identified in the reliability
+pillar for AWS Well-Architected.') , ROW ('Wxdfp4B1L1', 'en', 'AWS Well-
+Architected high risk issues for cost optimization', 'Checks for high risk
+issues (HRIs) for your workloads in the cost optimization pillar. This check is
+based on your AWS-Well Architected reviews. Your check results depend on
+whether you completed the workload evaluation with AWS Well-Architected.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Red: At least one active high risk issue was identified in the cost
+optimization pillar for AWS Well-Architected.') , ROW ('opQPADkZvH', 'en',
+'Amazon RDS Backups', 'Checks for automated backups of Amazon RDS DB instances.
+By default, backups are enabled with a retention period of 1 day. Backups
+reduce the risk of unexpected data loss and allow for point-in-time recovery.')
+, ROW ('L4dfs2Q3C2', 'en', 'AWS Lambda Functions with High Error Rates',
+'Checks for Lambda functions with high error rates that may result in high
+cost. Lambda charges based on the number of requests and aggregate execution
+time for your function. Function errors may cause retries that incur additional
+charges.
+****** NNoottee:: ******
+Results for this check are automatically refreshed several times daily, and
+refresh requests are not allowed. It might take a few hours for changes to
 appear.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: The Direct Connect connections in the region are not configured to
-different locations.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Configure a Direct Connect connection that uses a different Direct Connect
-location to protect against location unavailability. For more information, see
-_G_e_t_t_i_n_g_ _S_t_a_r_t_e_d_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t.
+Yellow: Functions where > 10% of invocations end in error on any given day
+within the last 7 days.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_G_e_t_t_i_n_g_ _S_t_a_r_t_e_d_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t
-_A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t_ _F_A_Q_s') , ROW ('4g3Nt5M1Th', 'en', 'AWS Direct Connect
-Virtual Interface Redundancy', 'Checks for virtual private gateways with Direct
-Connect virtual interfaces (VIFs) that are not configured on at least two
-Direct Connect connections. Connectivity to your virtual private gateway should
-have multiple virtual interfaces configured across multiple Direct Connect
-connections and locations to provide redundancy in case a device or location is
-unavailable.
-NNoottee:: Results for this check are automatically refreshed several times daily,
-and refresh requests are not allowed. It might take a few hours for changes to
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Consider the following guidelines to reduce errors. Function errors include
+errors returned by the functions code and errors returned by the functions
+runtime. To help you troubleshoot Lambda errors, Lambda integrates with
+services like Amazon CloudWatch and AWS X-Ray. You can use a combination of
+logs, metrics, alarms, and X-ray tracing to quickly detect and identify issues
+in your function code, API, or other resources that support your application.
+For more information, see _M_o_n_i_t_o_r_i_n_g_ _a_n_d_ _t_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _L_a_m_b_d_a_ _a_p_p_l_i_c_a_t_i_o_n_s.
+For more information on handling errors with specific runtimes, see _E_r_r_o_r
+_h_a_n_d_l_i_n_g_ _a_n_d_ _a_u_t_o_m_a_t_i_c_ _r_e_t_r_i_e_s_ _i_n_ _A_W_S_ _L_a_m_b_d_a. For additional troubleshooting,
+see _T_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _i_s_s_u_e_s_ _i_n_ _L_a_m_b_d_a.You can also choose from an ecosystem of
+monitoring and observability tools provided by AWS Lambda partners. For
+additional information about Partners, see _A_W_S_ _L_a_m_b_d_a_ _P_a_r_t_n_e_r_s.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_E_r_r_o_r_ _H_a_n_d_l_i_n_g_ _a_n_d_ _A_u_t_o_m_a_t_i_c_ _R_e_t_r_i_e_s_ _i_n_ _A_W_S_ _L_a_m_b_d_a
+_M_o_n_i_t_o_r_i_n_g_ _a_n_d_ _T_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _L_a_m_b_d_a_ _a_p_p_l_i_c_a_t_i_o_n_s
+_L_a_m_b_d_a_ _F_u_n_c_t_i_o_n_ _R_e_t_r_y_ _T_i_m_e_o_u_t_ _S_D_K
+_T_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _i_s_s_u_e_s_ _i_n_ _L_a_m_b_d_a
+_A_P_I_ _I_n_v_o_k_e_ _E_r_r_o_r_s
+_E_r_r_o_r_ _P_r_o_c_e_s_s_o_r_ _S_a_m_p_l_e_ _A_p_p_l_i_c_a_t_i_o_n_ _f_o_r_ _A_W_S_ _L_a_m_b_d_a
+') , ROW ('L4dfs2Q3C3', 'en', 'AWS Lambda Functions with Excessive Timeouts',
+'Checks for Lambda functions with high timeout rates that may result in high
+cost. Lambda charges based on execution time for your function and number of
+requests for your function. Function timeouts result in function errors that
+may cause retries that incur additional request and execution time charges.
+****** NNoottee:: ******
+Results for this check are automatically refreshed several times daily, and
+refresh requests are not allowed. It might take a few hours for changes to
 appear.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: A virtual private gateway has less than two virtual interfaces, or the
-interfaces are not configured to multiple Direct Connect connections.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Configure at least two virtual interfaces that are configured to two Direct
-Connect connections to protect against device or location unavailability. See
-_C_r_e_a_t_e_ _a_ _V_i_r_t_u_a_l_ _I_n_t_e_r_f_a_c_e_.
+Yellow: Functions where > 10% of invocations end in an error due to a timeout
+on any given day within the last 7 days.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_G_e_t_t_i_n_g_ _S_t_a_r_t_e_d_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t
-_A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t_ _F_A_Q_s
-_W_o_r_k_i_n_g_ _W_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t_ _V_i_r_t_u_a_l_ _I_n_t_e_r_f_a_c_e_s') , ROW ('xuy7H1avtl', 'en',
-'Amazon Aurora DB Instance Accessibility', 'Checks for cases where an Amazon
-Aurora DB cluster has both private and public instances. When your primary
-instance fails, a replica can be promoted to a primary instance. If that
-replica is private, users who have only public access would no longer be able
-to connect to the database after failover. Its best practice for all the DB
-instances in a cluster to have the same accessibility.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Inspect function logging and X-ray traces to determine the contributor to the
+high function duration. Implement logging in your code at relevant parts, such
+as before or after API calls or database connections. By default, AWS SDK
+clients timeouts may be longer than the configured function duration. Adjust
+API and SDK connection clients to retry or fail within the function timeout. If
+the expected duration is longer than the configured timeout, you can increase
+the timeout setting for the function. For more information, see _M_o_n_i_t_o_r_i_n_g_ _a_n_d
+_t_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _L_a_m_b_d_a_ _a_p_p_l_i_c_a_t_i_o_n_s.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_M_o_n_i_t_o_r_i_n_g_ _a_n_d_ _t_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _L_a_m_b_d_a_ _a_p_p_l_i_c_a_t_i_o_n_s
+_L_a_m_b_d_a_ _F_u_n_c_t_i_o_n_ _R_e_t_r_y_ _T_i_m_e_o_u_t_ _S_D_K
+_U_s_i_n_g_ _A_W_S_ _L_a_m_b_d_a_ _w_i_t_h_ _A_W_S_ _X_-_R_a_y
+_A_c_c_e_s_s_i_n_g_ _A_m_a_z_o_n_ _C_l_o_u_d_W_a_t_c_h_ _l_o_g_s_ _f_o_r_ _A_W_S_ _L_a_m_b_d_a
+_E_r_r_o_r_ _P_r_o_c_e_s_s_o_r_ _S_a_m_p_l_e_ _A_p_p_l_i_c_a_t_i_o_n_ _f_o_r_ _A_W_S_ _L_a_m_b_d_a
+') , ROW ('vjafUGJ9H0', 'en', 'AWS CloudTrail Logging', 'Checks for your use of
+AWS CloudTrail. CloudTrail provides increased visibility into activity in your
+AWS account by recording information about AWS API calls made on the account.
+You can use these logs to determine, for example, what actions a particular
+user has taken during a specified time period or which users have taken actions
+on a particular resource during a specified time period. Because CloudTrail
+delivers log files to an Amazon Simple Storage Service (Amazon S3) bucket,
+CloudTrail must have write permissions for the bucket. If a trail applies to
+all regions (the default when creating a new trail), the trail appears multiple
+times in the Trusted Advisor report.') , ROW ('7fuccf1Mx7', 'en', 'RDS Cluster
+Roles', 'Checks for usage that is more than 80% of the RDS Cluster Roles Limit.
+Values are based on a snapshot, so your current usage might differ. Limit and
+usage data can take up to 24 hours to reflect any changes. In cases where
+limits have been recently increased, you may temporarily see utilization that
+exceeds the limit.') , ROW ('ru4xfcdfMr', 'en', 'Route 53 Max Health Checks',
+'Checks for usage that is more than 80% of the Route 53 Health Checks Limit per
+account. Values are based on a snapshot, so your current usage might differ.
+Limit and usage data can take up to 24 hours to reflect any changes. In cases
+where limits have been recently increased, you may temporarily see utilization
+that exceeds the limit.') , ROW ('dV84wpqRUs', 'en', 'RDS DB Manual Snapshots',
+'Checks for usage that is more than 80% of the RDS DB Manual Snapshots Limit.
+Values are based on a snapshot, so your current usage might differ. Limit and
+usage data can take up to 24 hours to reflect any changes. In cases where
+limits have been recently increased, you may temporarily see utilization that
+exceeds the limit.') , ROW ('xuy7H1avtl', 'en', 'Amazon Aurora DB Instance
+Accessibility', 'Checks for cases where an Amazon Aurora DB cluster has both
+private and public instances. When your primary instance fails, a replica can
+be promoted to a primary instance. If that replica is private, users who have
+only public access would no longer be able to connect to the database after
+failover. Its best practice for all the DB instances in a cluster to have the
+same accessibility.
+
+****** AAlleerrtt CCrriitteerriiaa ******
 
-AAlleerrtt CCrriitteerriiaa
 Yellow: The instances in an Aurora DB cluster have different accessibility (a
 mix of public and private).
 
-RReeccoommmmeennddeedd AAccttiioonn
-Modify the PPuubblliiccllyy AAcccceessssiibbllee setting of the instances in the DB cluster so
-that they are all either public or private. For details, see the instructions
-for MySQL instances at _M_o_d_i_f_y_i_n_g_ _a_ _D_B_ _I_n_s_t_a_n_c_e_ _R_u_n_n_i_n_g_ _t_h_e_ _M_y_S_Q_L_ _D_a_t_a_b_a_s_e
-_E_n_g_i_n_e.
-
-AAddddiittiioonnaall RReessoouurrcceess
-_F_a_u_l_t_ _T_o_l_e_r_a_n_c_e_ _f_o_r_ _a_n_ _A_u_r_o_r_a_ _D_B_ _C_l_u_s_t_e_r') , ROW ('ePs02jT06w', 'en', 'Amazon
-EBS Public Snapshots', 'Checks the permission settings for your Amazon Elastic
-Block Store (Amazon EBS) volume snapshots and alerts you if any snapshots are
-marked as public. When you make a snapshot public, you give all AWS accounts
-and users access to all the data on the snapshot. If you want to share a
-snapshot with particular users or accounts, mark the snapshot as private, and
-then specify the user or accounts you want to share the snapshot data with.
-NNoottee: Results for this check are automatically refreshed several times daily,
-and refresh requests are not allowed. It might take a few hours for changes to
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Modify the
+****** PPuubblliiccllyy AAcccceessssiibbllee ******
+setting of the instances in the DB cluster so that they are all either public
+or private. For details, see the instructions for MySQL instances at _M_o_d_i_f_y_i_n_g
+_a_ _D_B_ _I_n_s_t_a_n_c_e_ _R_u_n_n_i_n_g_ _t_h_e_ _M_y_S_Q_L_ _D_a_t_a_b_a_s_e_ _E_n_g_i_n_e.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_F_a_u_l_t_ _T_o_l_e_r_a_n_c_e_ _f_o_r_ _a_n_ _A_u_r_o_r_a_ _D_B_ _C_l_u_s_t_e_r') , ROW ('0t121N1Ty3', 'en', 'AWS
+Direct Connect Connection Redundancy', 'Checks for regions that have only one
+AWS Direct Connect connection. Connectivity to your AWS resources should have
+two Direct Connect connections configured at all times to provide redundancy in
+case a device is unavailable.
+****** NNoottee:: ******
+Results for this check are automatically refreshed several times daily, and
+refresh requests are not allowed. It might take a few hours for changes to
 appear.
 
-AAlleerrtt CCrriitteerriiaa
-Red: The EBS volume snapshot is marked as public.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Unless you are certain you want to share all the data in the snapshot with all
-AWS accounts and users, modify the permissions: mark the snapshot as private,
-and then specify the accounts that you want to give permissions to. For more
-information, see _S_h_a_r_i_n_g_ _a_n_ _A_m_a_z_o_n_ _E_B_S_ _S_n_a_p_s_h_o_t. Note: For temporary technical
-reasons, items in this check cannot be excluded from view in the Trusted
-Advisor console.To modify permissions for your snapshots directly, you can use
-a runbook in the AWS Systems Manager console. For more information, see
-_A_W_S_S_u_p_p_o_r_t_-_M_o_d_i_f_y_E_B_S_S_n_a_p_s_h_o_t_P_e_r_m_i_s_s_i_o_n.
+Yellow: The region has only one Direct Connect connection.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_A_m_a_z_o_n_ _E_B_S_ _S_n_a_p_s_h_o_t_s') , ROW ('rSs93HQwa1', 'en', 'Amazon RDS Public
-Snapshots', 'Checks the permission settings for your Amazon Relational Database
-Service (Amazon RDS) DB snapshots and alerts you if any snapshots are marked as
-public. When you make a snapshot public, you give all AWS accounts and users
-access to all the data on the snapshot. If you want to share a snapshot with
-particular users or accounts, mark the snapshot as private, and then specify
-the user or accounts you want to share the snapshot data with. NNoottee: Results
-for this check are automatically refreshed several times daily, and refresh
-requests are not allowed. It might take a few hours for changes to appear.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Red: The RDS snapshot is marked as public.
+Configure an additional Direct Connect connection in this region to protect
+against device unavailability. For more information, see _C_o_n_f_i_g_u_r_e_ _R_e_d_u_n_d_a_n_t
+_C_o_n_n_e_c_t_i_o_n_s_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t. To protect against site unavailability and
+add location redundancy, configure the additional Direct Connect connection to
+a different Direct Connect location.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Unless you are certain you want to share all the data in the snapshot with all
-AWS accounts and users, modify the permissions: mark the snapshot as private,
-and then specify the accounts that you want to give permissions to. For more
-information, see _S_h_a_r_i_n_g_ _a_ _D_B_ _S_n_a_p_s_h_o_t_ _o_r_ _D_B_ _C_l_u_s_t_e_r_ _S_n_a_p_s_h_o_t. Note: For
-temporary technical reasons, items in this check cannot be excluded from view
-in the Trusted Advisor console.To modify permissions for your snapshots
-directly, you can use a runbook in the AWS Systems Manager console. For more
-information, see _A_W_S_S_u_p_p_o_r_t_-_M_o_d_i_f_y_R_D_S_S_n_a_p_s_h_o_t_P_e_r_m_i_s_s_i_o_n.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_B_a_c_k_i_n_g_ _U_p_ _a_n_d_ _R_e_s_t_o_r_i_n_g_ _A_m_a_z_o_n_ _R_D_S_ _D_B_ _I_n_s_t_a_n_c_e_s') , ROW ('0Xc6LMYG8P', 'en',
-'EC2 On-Demand Instances', 'Checks for usage that is more than 80% of the EC2
-On-Demand Instances Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('hJ7NN0l7J9',
-'en', 'SES Daily Sending Quota', 'Checks for usage that is more than 80% of the
-SES Daily Sending Quota Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('tV7YY0l7J9',
-'en', 'EBS Provisioned IOPS (SSD) Volume Aggregate IOPS', 'Checks for usage
-that is more than 80% of the EBS Provisioned IOPS (SSD) Volume Aggregate IOPS
-Limit. Values are based on a snapshot, so your current usage might differ.
-Limit and usage data can take up to 24 hours to reflect any changes. In cases
-where limits have been recently increased, you may temporarily see utilization
-that exceeds the limit.') , ROW ('gI7MM0l7J9', 'en', 'EBS Provisioned IOPS SSD
-(io1) Volume Storage', 'Checks for usage that is more than 80% of the EBS
-Provisioned IOPS SSD (io1) Volume Storage Limit. Values are based on a
-snapshot, so your current usage might differ. Limit and usage data can take up
-to 24 hours to reflect any changes. In cases where limits have been recently
-increased, you may temporarily see utilization that exceeds the limit.') , ROW
-('eI7KK0l7J9', 'en', 'EBS Active Snapshots', 'Checks for usage that is more
-than 80% of the EBS Active Snapshots Limit. Values are based on a snapshot, so
-your current usage might differ. Limit and usage data can take up to 24 hours
-to reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('dH7RR0l6J9',
-'en', 'EBS General Purpose SSD (gp2) Volume Storage', 'Checks for usage that is
-more than 80% of the EBS General Purpose SSD (gp2) Volume Storage Limit. Values
-are based on a snapshot, so your current usage might differ. Limit and usage
-data can take up to 24 hours to reflect any changes. In cases where limits have
-been recently increased, you may temporarily see utilization that exceeds the
-limit.') , ROW ('cG7HH0l7J9', 'en', 'EBS Magnetic (standard) Volume Storage',
-'Checks for usage that is more than 80% of the EBS Magnetic (standard) Volume
-Storage Limit. Values are based on a snapshot, so your current usage might
-differ. Limit and usage data can take up to 24 hours to reflect any changes. In
-cases where limits have been recently increased, you may temporarily see
-utilization that exceeds the limit.') , ROW ('aW9HH0l8J6', 'en', 'EC2-Classic
-Elastic IP Addresses', 'Checks for usage that is more than 80% of the EC2-
-Classic Elastic IP Addresses Limit. Values are based on a snapshot, so your
-current usage might differ. Limit and usage data can take up to 24 hours to
-reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('iH7PP0l7J9',
-'en', 'EC2 Reserved Instance Leases', 'Checks for usage that is more than 80%
-of the EC2 Reserved Instance Leases Limit. Values are based on a snapshot, so
-your current usage might differ. Limit and usage data can take up to 24 hours
-to reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('bW7HH0l7J9',
-'en', 'Kinesis Shards per Region', 'Checks for usage that is more than 80% of
-the Kinesis Shards per Region Limit. Values are based on a snapshot, so your
-current usage might differ. Limit and usage data can take up to 24 hours to
-reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('gW7HH0l7J9',
-'en', 'CloudFormation Stacks', 'Checks for usage that is more than 80% of the
-CloudFormation Stacks Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('aW7HH0l7J9',
-'en', 'Auto Scaling Launch Configurations', 'Checks for usage that is more than
-80% of the Auto Scaling Launch Configurations Limit. Values are based on a
+_G_e_t_t_i_n_g_ _S_t_a_r_t_e_d_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t
+_A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t_ _F_A_Q_s ') , ROW ('RH23stmM01', 'en', 'AWS Resilience Hub
+resilience scores', 'Checks if you have run an assessment for your applications
+in Resilience Hub. This check alerts you if your resilience scores are below a
+specific value. Results for this check are automatically refreshed once every
+day.
+
+AAlleerrtt CCrriitteerriiaa
+Green: Your application has a resilience score of 70 or greater.') , ROW
+('RH23stmM02', 'en', 'AWS Resilience Hub policy breached', 'Checks Resilience
+Hub for applications that dont meet the recovery time objective (RTO) and
+recovery point objective (RPO) that the policy defines. The check alerts you if
+your application doesnt meet the RTO and RPO objectives youve set for an
+application in Resilience Hub.
+
+AAlleerrtt CCrriitteerriiaa
+Green: The application has a policy and meets the RTO and RPO objectives.') ,
+ROW ('hc0dfs7601', 'en', 'AWS CloudHSM clusters running HSM instances in a
+single AZ', 'Checks your clusters that run HSM instances in a single
+Availability Zone (AZ). This check alerts you if your clusters are at risk of
+not having the most recent backup.
+
+AAlleerrtt CCrriitteerriiaa
+Yellow: A CloudHSM cluster is running all HSM instances in a single
+Availability Zone for more than 1 hour.') , ROW ('DqdJqYeRm5', 'en', 'IAM
+Access Key Rotation', 'Checks for active IAM access keys that have not been
+rotated in the last 90 days. When you rotate your access keys regularly, you
+reduce the chance that a compromised key could be used without your knowledge
+to access resources. For the purposes of this check, the last rotation date and
+time is when the access key was created or most recently activated. The access
+key number and date come from the
+****** aacccceessss__kkeeyy__11__llaasstt__rroottaatteedd ******
+and
+****** aacccceessss__kkeeyy__22__llaasstt__rroottaatteedd ******
+information in the most recent IAM credential report. Because the regeneration
+frequency of a credential report is restricted, refreshing this check might not
+reflect recent changes (for details, see _G_e_t_t_i_n_g_ _C_r_e_d_e_n_t_i_a_l_ _R_e_p_o_r_t_s_ _f_o_r_ _Y_o_u_r
+_A_W_S_ _A_c_c_o_u_n_t).
+In order to create and rotate access keys, a user must have the appropriate
+permissions. For more information, see _A_l_l_o_w_ _U_s_e_r_s_ _t_o_ _M_a_n_a_g_e_ _T_h_e_i_r_ _O_w_n
+_P_a_s_s_w_o_r_d_s_,_ _A_c_c_e_s_s_ _K_e_y_s_,_ _a_n_d_ _S_S_H_ _K_e_y_s.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Green: The access key is active and has been rotated in the last 90 days.
+Yellow: The access key is active and has been rotated in the last 2 years, but
+more than 90 days ago.
+Red: The access key is active and has not been rotated in the last 2 years.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Rotate access keys on a regular basis. See _R_o_t_a_t_i_n_g_ _A_c_c_e_s_s_ _K_e_y_s and _M_a_n_a_g_i_n_g
+_A_c_c_e_s_s_ _K_e_y_s_ _f_o_r_ _I_A_M_ _U_s_e_r_s.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_I_A_M_ _B_e_s_t_ _P_r_a_c_t_i_c_e_s
+_H_o_w_ _t_o_ _r_o_t_a_t_e_ _a_c_c_e_s_s_ _k_e_y_s_ _f_o_r_ _I_A_M_ _u_s_e_r_s (AWS blog)') , ROW ('7DAFEmoDos', 'en',
+'MFA on Root Account', 'Checks the root account and warns if multi-factor
+authentication (MFA) is not enabled. For increased security, we recommend that
+you protect your account by using MFA, which requires a user to enter a unique
+authentication code from their MFA hardware or virtual device when interacting
+with the AWS console and associated websites.') , ROW ('tfg86AVHAZ', 'en',
+'Large Number of Rules in an EC2 Security Group', 'Checks each Amazon Elastic
+Compute Cloud (EC2) security group for an excessive number of rules. If a
+security group has a large number of rules, performance can be degraded.') ,
+ROW ('kM7QQ0l7J9', 'en', 'VPC Internet Gateways', 'Checks for usage that is
+more than 80% of the VPC Internet Gateways Limit. Values are based on a
 snapshot, so your current usage might differ. Limit and usage data can take up
 to 24 hours to reflect any changes. In cases where limits have been recently
 increased, you may temporarily see utilization that exceeds the limit.') , ROW
-('fW7HH0l7J9', 'en', 'Auto Scaling Groups', 'Checks for usage that is more than
-80% of the Auto Scaling Groups Limit. Values are based on a snapshot, so your
-current usage might differ. Limit and usage data can take up to 24 hours to
-reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('jL7PP0l7J9',
-'en', 'VPC', 'Checks for usage that is more than 80% of the VPC Limit. Values
+('HCP4007jGY', 'en', 'Security Groups - Specific Ports Unrestricted', 'Checks
+security groups for rules that allow unrestricted access (0.0.0.0/0) to
+specific ports. Unrestricted access increases opportunities for malicious
+activity (hacking, denial-of-service attacks, loss of data). The ports with
+highest risk are flagged red, and those with less risk are flagged yellow.
+Ports flagged green are typically used by applications that require
+unrestricted access, such as HTTP and SMTP.') , ROW ('Pfx0RwqBli', 'en',
+'Amazon S3 Bucket Permissions', 'Checks buckets in Amazon Simple Storage
+Service (Amazon S3) that have open access permissions or allow access to any
+authenticated AWS user. Bucket permissions that grant List access can result in
+higher than expected charges if objects in the bucket are listed by unintended
+users at a high frequency. Bucket permissions that grant Upload/Delete access
+create potential security vulnerabilities by allowing users that to add,
+modify, or remove items in a bucket.') , ROW ('Hs4Ma3G191', 'en', 'RDS cluster
+snapshots and database snapshots should be encrypted at rest', 'Checks if
+Amazon RDS cluster snapshots and database snapshots are encrypted.') , ROW
+('Hs4Ma3G192', 'en', 'RDS DB Instances should prohibit public access,
+determined by the PubliclyAccessible configuration', 'Checks if RDS instances
+are publicly accessible by evaluating the publiclyAccessible field in the
+instance configuration item.') , ROW ('Hs4Ma3G193', 'en', 'RDS DB instances
+should have encryption at-rest enabled', 'Checks if storage encryption is
+enabled for your RDS DB instances.') , ROW ('Hs4Ma3G194', 'en', 'RDS snapshot
+should be private', 'Checks if Amazon Relational Database Service (Amazon RDS)
+snapshots are public.') , ROW ('Hs4Ma3G195', 'en', 'CloudFront distributions
+should have origin access identity enabled', 'Checks if an Amazon CloudFront
+distribution with an Amazon S3 origin type has Origin Access Identity (OAI)
+configured. The check fails if the CloudFront distribution that is backed by
+Amazon S3 does not have OAI configured.') , ROW ('Hs4Ma3G196', 'en', 'AWS
+Config should be enabled', 'Checks if the Config service is enabled in the
+account for the local region and is recording all resources.') , ROW
+('B913Ef6fb4', 'en', 'Amazon Route 53 Alias Resource Record Sets', 'Checks for
+resource record sets that can be changed to alias resource record sets to
+improve performance and save money. An alias resource record set routes DNS
+queries to an AWS resource (for example, an Elastic Load Balancing load
+balancer or an Amazon S3 bucket) or to another Route 53 resource record set.
+When you use alias resource record sets, Route 53 routes your DNS queries to
+AWS resources free of charge. Hosted zones created by AWS services wonÃ¢Â€Â™t
+appear in your check results.') , ROW ('Hs4Ma3G197', 'en', 'Amazon
+Elasticsearch Service domains should have encryption at-rest enabled', 'Checks
+whether Amazon Elasticsearch Service domains have encryption at rest
+configuration enabled. This check fails if the EncryptionAtRestOptions field is
+not enabled.') , ROW ('Hs4Ma3G198', 'en', 'RDS DB instances should have
+deletion protection enabled', 'Checks if RDS DB instances have deletion
+protection enabled.') , ROW ('1iG5NDGVre', 'en', 'Security Groups -
+Unrestricted Access', 'Checks security groups for rules that allow unrestricted
+access to a resource. Unrestricted access increases opportunities for malicious
+activity (hacking, denial-of-service attacks, loss of data).') , ROW
+('Hs4Ma3G190', 'en', 'RDS clusters should have deletion protection enabled',
+'Checks if RDS clusters have deletion protection enabled.') , ROW
+('nNauJisYIT', 'en', 'Amazon RDS Security Group Access Risk', 'Checks security
+group configurations for Amazon Relational Database Service (Amazon RDS) and
+warns when a security group rule might grant overly permissive access to your
+database. Recommended configuration for any security group rule is to allow
+access from specific Amazon Elastic Compute Cloud (Amazon EC2) security groups
+or from a specific IP address. Data for Amazon Relational Database Service
+(Amazon RDS) instances created in the Asia Pacific (Seoul) region (sa-east-1)
+is not available. We are working to fix this issue as soon as possible.') , ROW
+('Hs4Ma3G188', 'en', 'GuardDuty should be enabled', 'Checks if Amazon GuardDuty
+is enabled in your AWS account and region.') , ROW ('Hs4Ma3G189', 'en',
+'Enhanced monitoring should be configured for RDS DB instances', 'Checks if
+enhanced monitoring is enabled for your RDS DB instances.') , ROW
+('1e93e4c0b5', 'en', 'Amazon EC2 Reserved Instance Lease Expiration', 'Checks
+for Amazon EC2 Reserved Instances that are scheduled to expire within the next
+30 days or have expired in the preceding 30 days. Reserved Instances do not
+renew automatically; you can continue using an EC2 instance covered by the
+reservation without interruption, but you will be charged On-Demand rates. New
+Reserved Instances can have the same parameters as the expired ones, or you can
+purchase Reserved Instances with different parameters.
+The estimated monthly savings we show is the difference between the On-Demand
+and Reserved Instance rates for the same instance type.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: The Reserved Instance lease expires in less than 30 days.
+Yellow: The Reserved Instance lease expired in the preceding 30 days.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Consider purchasing a new Reserved Instance to replace the one that is nearing
+the end of its term. For more information, see _H_o_w_ _t_o_ _P_u_r_c_h_a_s_e_ _R_e_s_e_r_v_e_d
+_I_n_s_t_a_n_c_e_s and _B_u_y_i_n_g_ _R_e_s_e_r_v_e_d_ _I_n_s_t_a_n_c_e_s.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_R_e_s_e_r_v_e_d_ _I_n_s_t_a_n_c_e_s
+_I_n_s_t_a_n_c_e_ _T_y_p_e_s') , ROW ('C056F80cR3', 'en', 'Amazon Route 53 High TTL Resource
+Record Sets', 'Checks for resource record sets that can benefit from having a
+lower time-to-live (TTL) value. TTL is the number of seconds that a resource
+record set is cached by DNS resolvers. When you specify a long TTL, DNS
+resolvers take longer to request updated DNS records, which can cause
+unnecessary delay in rerouting traffic (for example, when DNS Failover detects
+and responds to a failure of one of your endpoints). Hosted zones created by
+AWS services wonÃ¢Â€Â™t appear in your check results.') , ROW ('6gtQddfEw6', 'en',
+'DynamoDB Read Capacity', 'Checks for usage that is more than 80% of the
+DynamoDB Provisioned Throughput Limit for Reads per Account. Values are based
+on a snapshot, so your current usage might differ. Limit and usage data can
+take up to 24 hours to reflect any changes. In cases where limits have been
+recently increased, you may temporarily see utilization that exceeds the
+limit.') , ROW ('Hs4Ma3G199', 'en', 'Database logging should be enabled',
+'Checks if the following Amazon RDS logs are enabled and sent to CloudWatch
+Logs: Oracle: (Alert, Audit, Trace, Listener), PostgreSQL: (Postgresql,
+Upgrade), MySQL: (Audit, Error, General, SlowQuery), MariaDB: (Audit, Error,
+General, SlowQuery), SQL Server: (Error, Agent), Aurora: (Audit, Error,
+General, SlowQuery), Aurora-MySQL: (Audit, Error, General, SlowQuery), Aurora-
+PostgreSQL: (Postgresql).') , ROW ('XG0aXHpIEt', 'en', 'RDS DB Instances',
+'Checks for usage that is more than 80% of the RDS DB Instances Limit. Values
 are based on a snapshot, so your current usage might differ. Limit and usage
 data can take up to 24 hours to reflect any changes. In cases where limits have
 been recently increased, you may temporarily see utilization that exceeds the
-limit.') , ROW ('kM7QQ0l7J9', 'en', 'VPC Internet Gateways', 'Checks for usage
-that is more than 80% of the VPC Internet Gateways Limit. Values are based on a
-snapshot, so your current usage might differ. Limit and usage data can take up
-to 24 hours to reflect any changes. In cases where limits have been recently
-increased, you may temporarily see utilization that exceeds the limit.') , ROW
-('lN7RR0l7J9', 'en', 'EC2-VPC Elastic IP Address', 'Checks for usage that is
-more than 80% of the EC2-VPC Elastic IP Address Limit. Values are based on a
-snapshot, so your current usage might differ. Limit and usage data can take up
-to 24 hours to reflect any changes. In cases where limits have been recently
-increased, you may temporarily see utilization that exceeds the limit.') , ROW
-('nO7SS0l7J9', 'en', 'IAM Instance Profiles', 'Checks for usage that is more
-than 80% of the IAM Instance Profiles Limit. Values are based on a snapshot, so
+limit.') , ROW ('wuy7G1zxql', 'en', 'Amazon EC2 Availability Zone Balance',
+'Checks the distribution of Amazon Elastic Compute Cloud (Amazon EC2) instances
+across Availability Zones in a region. Availability Zones are distinct
+locations that are designed to be insulated from failures in other Availability
+Zones and to provide inexpensive, low-latency network connectivity to other
+Availability Zones in the same region. By launching instances in multiple
+Availability Zones in the same region, you can help protect your applications
+from a single point of failure.') , ROW ('Hs4Ma3G170', 'en', 'S3 Block Public
+Access setting should be enabled', 'Checks if the following public access block
+settings are configured from account level: ignorePublicAcls: True,
+blockPublicPolicy: True, blockPublicAcls: True, restrictPublicBuckets: True.')
+, ROW ('Hs4Ma3G171', 'en', 'S3 buckets should prohibit public read access',
+'Checks if your S3 buckets allow public read access by evaluating the Block
+Public Access settings, the bucket policy, and the bucket access check list
+(ACL).') , ROW ('Hs4Ma3G172', 'en', 'S3 buckets should prohibit public write
+access', 'Checks if your S3 buckets allow public write access by evaluating the
+Block Public Access settings, the bucket policy, and the bucket access check
+list (ACL).') , ROW ('c1z7dfpz01', 'en', 'Amazon ECS service using a single
+AZ', 'Checks that your service configuration uses a single Availability Zone
+(AZ).') , ROW ('Hs4Ma3G173', 'en', 'S3 Block Public Access setting should be
+enabled at the bucket-level', 'Checks if Amazon S3 buckets have bucket level
+public access blocks applied. This check fails if any of the bucket level
+settings are set to "false" public: ignorePublicAcls, blockPublicPolicy,
+blockPublicAcls, restrictPublicBuckets.') , ROW ('c1z7dfpz02', 'en', 'Amazon
+ECS Multi-AZ placement strategy', 'Checks that your Amazon ECS service uses the
+spread placement strategy. This strategy distributes tasks across Availability
+Zones (AZs) in the same AWS Region and can help protect your applications from
+a single point of failure.') , ROW ('Hs4Ma3G174', 'en', 'CodeBuild GitHub or
+Bitbucket source repository URLs should use OAuth', 'Checks if the GitHub or
+Bitbucket source repository URL contains either personal access tokens or user
+name and password.') , ROW ('Hs4Ma3G175', 'en', 'CodeBuild project environment
+variables should not contain clear text credentials', 'Checks if the project
+contains environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.') ,
+ROW ('Hs4Ma3G176', 'en', 'ACM certificates should be renewed after a specified
+time period', 'Checks if ACM Certificates in your account are marked for
+expiration within a specified time period. Certificates provided by ACM are
+automatically renewed. ACM does not automatically renew certificates that you
+import.') , ROW ('CLOG40CDO8', 'en', 'Auto Scaling Group Health Check',
+'Examines the health check configuration for Auto Scaling groups. If Elastic
+Load Balancing is being used for an Auto Scaling group, the recommended
+configuration is to enable an Elastic Load Balancing health check. If an
+Elastic Load Balancing health check is not used, Auto Scaling can only act upon
+the health of the Amazon Elastic Compute Cloud (Amazon EC2) instance and not on
+the application that is running on the instance.') , ROW ('aW9HH0l8J6', 'en',
+'EC2-Classic Elastic IP Addresses', 'Checks for usage that is more than 80% of
+the EC2-Classic Elastic IP Addresses Limit. Values are based on a snapshot, so
 your current usage might differ. Limit and usage data can take up to 24 hours
 to reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('oQ7TT0l7J9',
-'en', 'IAM Roles', 'Checks for usage that is more than 80% of the IAM Roles
-Limit. Values are based on a snapshot, so your current usage might differ.
-Limit and usage data can take up to 24 hours to reflect any changes. In cases
-where limits have been recently increased, you may temporarily see utilization
-that exceeds the limit.') , ROW ('pR7UU0l7J9', 'en', 'IAM Policies', 'Checks
-for usage that is more than 80% of the IAM Policies Limit. Values are based on
-a snapshot, so your current usage might differ. Limit and usage data can take
-up to 24 hours to reflect any changes. In cases where limits have been recently
-increased, you may temporarily see utilization that exceeds the limit.') , ROW
-('qS7VV0l7J9', 'en', 'IAM Users', 'Checks for usage that is more than 80% of
-the IAM Users Limit. Values are based on a snapshot, so your current usage
-might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('rT7WW0l7J9',
-'en', 'IAM Server Certificates', 'Checks for usage that is more than 80% of the
-IAM Server Certificates Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('sU7XX0l7J9',
-'en', 'IAM Group', 'Checks for usage that is more than 80% of the IAM Group
+may temporarily see utilization that exceeds the limit.') , ROW ('wH7DD0l3J9',
+'en', 'EBS Throughput Optimized HDD (st1) Volume Storage', 'Checks for usage
+that is more than 80% of the EBS Throughput Optimized HDD (st1) Volume Storage
 Limit. Values are based on a snapshot, so your current usage might differ.
 Limit and usage data can take up to 24 hours to reflect any changes. In cases
 where limits have been recently increased, you may temporarily see utilization
 that exceeds the limit.') , ROW ('iK7OO0l7J9', 'en', 'ELB Classic Load
 Balancers', 'Checks for usage that is more than 80% of the ELB Classic Load
 Balancers. Application Load Balancers and Network Load Balancers have a
 separate limit. Values are based on a snapshot, so your current usage might
 differ. Limit and usage data can take up to 24 hours to reflect any changes. In
 cases where limits have been recently increased, you may temporarily see
 utilization that exceeds the limit.
-') , ROW ('7fuccf1Mx7', 'en', 'RDS Cluster Roles', 'Checks for usage that is
-more than 80% of the RDS Cluster Roles Limit. Values are based on a snapshot,
-so your current usage might differ. Limit and usage data can take up to 24
-hours to reflect any changes. In cases where limits have been recently
-increased, you may temporarily see utilization that exceeds the limit.') , ROW
-('jtlIMO3qZM', 'en', 'RDS Cluster Parameter Groups', 'Checks for usage that is
-more than 80% of the RDS Cluster Parameter Groups Limit. Values are based on a
+') , ROW ('DAvU99Dc4C', 'en', 'Underutilized Amazon EBS Volumes', 'Checks
+Amazon Elastic Block Store (Amazon EBS) volume configurations and warns when
+volumes appear to be underused. Charges begin when a volume is created. If a
+volume remains unattached or has very low write activity (excluding boot
+volumes) for a period of time, the volume is probably not being used.') , ROW
+('pYW8UkYz2w', 'en', 'RDS Read Replicas per Master', 'Checks for usage that is
+more than 80% of the RDS Read Replicas per Master Limit. Values are based on a
 snapshot, so your current usage might differ. Limit and usage data can take up
 to 24 hours to reflect any changes. In cases where limits have been recently
 increased, you may temporarily see utilization that exceeds the limit.') , ROW
-('gjqMBn6pjz', 'en', 'RDS Clusters', 'Checks for usage that is more than 80% of
-the RDS Clusters Limit. Values are based on a snapshot, so your current usage
-might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('UUDvOa5r34',
-'en', 'RDS Reserved Instances', 'Checks for usage that is more than 80% of the
-RDS Reserved Instances Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('jEhCtdJKOY',
-'en', 'RDS Subnets per Subnet Group', 'Checks for usage that is more than 80%
-of the RDS Subnets per Subnet Group Limit. Values are based on a snapshot, so
-your current usage might differ. Limit and usage data can take up to 24 hours
-to reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('dYWBaXaaMM',
-'en', 'RDS Subnet Groups', 'Checks for usage that is more than 80% of the RDS
-Subnet Groups Limit. Values are based on a snapshot, so your current usage
-might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('3Njm0DJQO9',
-'en', 'RDS Option Groups', 'Checks for usage that is more than 80% of the RDS
-Option Groups Limit. Values are based on a snapshot, so your current usage
+('pR7UU0l7J9', 'en', 'IAM Policies', 'Checks for usage that is more than 80% of
+the IAM Policies Limit. Values are based on a snapshot, so your current usage
 might differ. Limit and usage data can take up to 24 hours to reflect any
 changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('keAhfbH5yb',
-'en', 'RDS Event Subscriptions', 'Checks for usage that is more than 80% of the
-RDS Event Subscriptions Limit. Values are based on a snapshot, so your current
+temporarily see utilization that exceeds the limit.') , ROW ('eI7KK0l7J9',
+'en', 'EBS Active Snapshots', 'Checks for usage that is more than 80% of the
+EBS Active Snapshots Limit. Values are based on a snapshot, so your current
 usage might differ. Limit and usage data can take up to 24 hours to reflect any
 changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('dV84wpqRUs',
-'en', 'RDS DB Manual Snapshots', 'Checks for usage that is more than 80% of the
-RDS DB Manual Snapshots Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('P1jhKWEmLa',
-'en', 'RDS Total Storage Quota', 'Checks for usage that is more than 80% of the
-RDS Total Storage Quota Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('jEECYg2YVU',
-'en', 'RDS DB Parameter Groups', 'Checks for usage that is more than 80% of the
-RDS DB Parameter Groups Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('pYW8UkYz2w',
-'en', 'RDS Read Replicas per Master', 'Checks for usage that is more than 80%
-of the RDS Read Replicas per Master Limit. Values are based on a snapshot, so
-your current usage might differ. Limit and usage data can take up to 24 hours
-to reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('gfZAn3W7wl',
-'en', 'RDS DB Security Groups', 'Checks for usage that is more than 80% of the
-RDS DB Security Groups Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('XG0aXHpIEt',
-'en', 'RDS DB Instances', 'Checks for usage that is more than 80% of the RDS DB
-Instances Limit. Values are based on a snapshot, so your current usage might
-differ. Limit and usage data can take up to 24 hours to reflect any changes. In
-cases where limits have been recently increased, you may temporarily see
-utilization that exceeds the limit.') , ROW ('dBkuNCvqn5', 'en', 'RDS Max Auths
-per Security Group', 'Checks for usage that is more than 80% of the RDS Max
-Auths per Security Group Limit. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('wH7DD0l3J9',
-'en', 'EBS Throughput Optimized HDD (st1) Volume Storage', 'Checks for usage
-that is more than 80% of the EBS Throughput Optimized HDD (st1) Volume Storage
-Limit. Values are based on a snapshot, so your current usage might differ.
-Limit and usage data can take up to 24 hours to reflect any changes. In cases
-where limits have been recently increased, you may temporarily see utilization
-that exceeds the limit.') , ROW ('gH5CC0e3J9', 'en', 'EBS Cold HDD (sc1) Volume
-Storage', 'Checks for usage that is more than 80% of the EBS Cold HDD (sc1)
-Volume Storage Limit. Values are based on a snapshot, so your current usage
-might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('6gtQddfEw6',
-'en', 'DynamoDB Read Capacity', 'Checks for usage that is more than 80% of the
-DynamoDB Provisioned Throughput Limit for Reads per Account. Values are based
-on a snapshot, so your current usage might differ. Limit and usage data can
-take up to 24 hours to reflect any changes. In cases where limits have been
-recently increased, you may temporarily see utilization that exceeds the
-limit.') , ROW ('c5ftjdfkMr', 'en', 'DynamoDB Write Capacity', 'Checks for
-usage that is more than 80% of the DynamoDB Provisioned Throughput Limit for
-Writes per Account. Values are based on a snapshot, so your current usage might
-differ. Limit and usage data can take up to 24 hours to reflect any changes. In
-cases where limits have been recently increased, you may temporarily see
-utilization that exceeds the limit.') , ROW ('ru4xfcdfMr', 'en', 'Route 53 Max
-Health Checks', 'Checks for usage that is more than 80% of the Route 53 Health
-Checks Limit per account. Values are based on a snapshot, so your current usage
-might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('dx3xfcdfMr',
-'en', 'Route 53 Hosted Zones', 'Checks for usage that is more than 80% of the
-Route 53 Hosted Zones Limit per account. Values are based on a snapshot, so
-your current usage might differ. Limit and usage data can take up to 24 hours
-to reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('ty3xfcdfMr',
-'en', 'Route 53 Reusable Delegation Sets', 'Checks for usage that is more than
-80% of the Route 53 Reusable Delegation Sets Limit per account. Values are
-based on a snapshot, so your current usage might differ. Limit and usage data
-can take up to 24 hours to reflect any changes. In cases where limits have been
-recently increased, you may temporarily see utilization that exceeds the
-limit.') , ROW ('dx3xfbjfMr', 'en', 'Route 53 Traffic Policies', 'Checks for
-usage that is more than 80% of the Route 53 Traffic Policies Limit per account.
+temporarily see utilization that exceeds the limit.') , ROW ('Hs4Ma3G166',
+'en', 'An RDS event notifications subscription should be configured for
+critical cluster events', 'Checks if an Amazon RDS Event subscription for RDS
+clusters is configured to notify on event categories of both "maintenance" and
+"failure".') , ROW ('Hs4Ma3G167', 'en', 'S3 buckets should have server-side
+encryption enabled', 'Checks that your Amazon S3 bucket either has Amazon S3
+default encryption enabled or that the S3 bucket policy explicitly denies put-
+object requests without server side encryption.') , ROW ('Hs4Ma3G168', 'en',
+'S3 buckets should require requests to use Secure Socket Layer', 'Checks if S3
+buckets have policies that require requests to use Secure Socket Layer (SSL).')
+, ROW ('Hs4Ma3G169', 'en', 'S3 permissions granted to other AWS accounts in
+bucket policies should be restricted', 'Checks if the S3 bucket policy allows
+sensitive bucket-level or object-level actions from a principal in another AWS
+account. The check fails if any of the following actions are allowed in the S3
+bucket policy for a principal in another AWS account: s3:DeleteBucketPolicy,
+s3:PutBucketAcl, s3:PutBucketPolicy, s3:PutObjectAcl, and s3:
+PutEncryptionConfiguration.') , ROW ('fW7HH0l7J9', 'en', 'Auto Scaling Groups',
+'Checks for usage that is more than 80% of the Auto Scaling Groups Limit.
 Values are based on a snapshot, so your current usage might differ. Limit and
 usage data can take up to 24 hours to reflect any changes. In cases where
 limits have been recently increased, you may temporarily see utilization that
-exceeds the limit.') , ROW ('dx8afcdfMr', 'en', 'Route 53 Traffic Policy
-Instances', 'Checks for usage that is more than 80% of the Route 53 Traffic
-Policy Instances Limit per account. Values are based on a snapshot, so your
-current usage might differ. Limit and usage data can take up to 24 hours to
-reflect any changes. In cases where limits have been recently increased, you
-may temporarily see utilization that exceeds the limit.') , ROW ('cX3c2R1chu',
-'en', 'Amazon EC2 Reserved Instances Optimization', 'A significant part of
-using AWS involves balancing your Reserved Instance (RI) usage and your On-
-Demand instance usage. We provide recommendations on which RIs will help reduce
-costs incurred from using On-Demand instances.
-AWS generates these recommendations by analyzing your On-Demand usage for the
-past 30 days, and then categorizing the usage into eligible categories for
-reservations. We then simulate every combination of reservations in the
-generated category of usage in order to identify the best number of each type
-of RI to purchase to maximize your savings. This check covers recommendations
-based on Standard Reserved Instances with partial upfront payment option. This
-check is not available to accounts linked in Consolidated Billing.
-Recommendations are only available for the Paying Account.
+exceeds the limit.') , ROW ('P1jhKWEmLa', 'en', 'RDS Total Storage Quota',
+'Checks for usage that is more than 80% of the RDS Total Storage Quota Limit.
+Values are based on a snapshot, so your current usage might differ. Limit and
+usage data can take up to 24 hours to reflect any changes. In cases where
+limits have been recently increased, you may temporarily see utilization that
+exceeds the limit.') , ROW ('Hs4Ma3G180', 'en', 'Amazon Elasticsearch Service
+domain error logging to CloudWatch Logs should be enabled', 'Checks whether
+Amazon Elasticsearch Service domains are configured to send error logs to
+CloudWatch Logs.') , ROW ('Hs4Ma3G181', 'en', 'Classic Load Balancers with SSL/
+HTTPS listeners should use a certificate provided by AWS Certificate Manager',
+'Checks if a Classic Load Balancer uses HTTPS/SSL certificates provided by AWS
+Certificate Manager. The check fails if a Classic Load Balancer that is
+configured with an HTTPS/SSL listener does not use a certificate provided by
+AWS Certificate Manager.') , ROW ('Hs4Ma3G182', 'en', 'Classic Load Balancer
+listeners should be configured with HTTPS or TLS termination', 'Checks if your
+Classic Load Balancer listeners are configured with HTTPS or TLS protocol for
+front-end (client to load balancer) connections. The check is applicable if a
+Classic Load Balancer has listeners. If your Classic Load Balancer does not
+have a listener configured, then the check does not report any findings.') ,
+ROW ('1qazXsw23e', 'en', 'Amazon Relational Database Service (RDS) Reserved
+Instance Optimization', 'Checks your usage of RDS and provides recommendations
+on purchase of Reserved Instances to help reduce costs incurred from using RDS
+On-Demand. AWS generates these recommendations by analyzing your On-Demand
+usage for the past 30 days. We then simulate every combination of reservations
+in the generated category of usage in order to identify the best number of each
+type of Reserved Instance to purchase to maximize your savings. This check
+covers recommendations based on partial upfront payment option with 1-year or
+3-year commitment. This check is not available to accounts linked in
+Consolidated Billing. Recommendations are only available for the Paying
+Account.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: Optimizing the use of partial upfront RIs can help reduce costs.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-See the _C_o_s_t_ _E_x_p_l_o_r_e_r page for more detailed and customized recommendations.
-Additionally, refer to the _b_u_y_i_n_g_ _g_u_i_d_e to understand how to purchase RIs and
-the options available.
+Yellow: Optimizing the purchase of RDS Reserved Instances can help reduce
+costs.
 
-AAddddiittiioonnaall RReessoouurrcceess
-Information on RIs and how they can save you money can be found _h_e_r_e.
-For more information on this recommendation, see _R_e_s_e_r_v_e_d_ _I_n_s_t_a_n_c_e_ _O_p_t_i_m_i_z_a_t_i_o_n
-_C_h_e_c_k_ _Q_u_e_s_t_i_o_n_s in the Trusted Advisor FAQs.') , ROW ('EM8b3yLRTr', 'en', 'ELB
-Application Load Balancers', 'Checks for usage that is more than 80% of the ELB
-Application Load Balancers Limit. Classic Load Balancers and Network Load
-Balancers have separate limits. Values are based on a snapshot, so your current
-usage might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.
-') , ROW ('8wIqYSt25K', 'en', 'ELB Network Load Balancers', 'Checks for usage
-that is more than 80% of the ELB Network Load Balancers Limit. Classic Load
-Balancers and Application Load Balancers have separate limits. Values are based
-on a snapshot, so your current usage might differ. Limit and usage data can
-take up to 24 hours to reflect any changes. In cases where limits have been
-recently increased, you may temporarily see utilization that exceeds the limit.
-') , ROW ('vZ2c2W1srf', 'en', 'Savings Plan', 'Checks your usage of EC2,
-Fargate, and Lambda over the last 30 days and provides Savings Plan purchase
-recommendations, which allows you to commit to a consistent usage amount
-measured in $/hour for a one or three year term in exchange for discounted
-rates. These are sourced from AWS Cost Explorer which can be used to get more
-detailed recommendation information, or to purchase a savings plan. These
-recommendations should be considered an alternative to your RI recommendations
-and choosing to act fully on both sets of recommendations would likely lead to
-over commitment. This check is not available to accounts linked in Consolidated
-Billing. Recommendations are only available for the Paying Account.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: Optimizing the purchase of Savings Plans can help reduce costs.
+See the _C_o_s_t_ _E_x_p_l_o_r_e_r page for more detailed recommendations, customization
+options (e.g. look-back period, payment option, etc.) and to purchase RDS
+Reserved Instances.
 
-RReeccoommmmeennddeedd AAccttiioonn
-See the _C_o_s_t_ _E_x_p_l_o_r_e_r page for more detailed and customized recommendations and
-to purchase Savings Plans.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-Savings Plan _U_s_e_r_ _G_u_i_d_e
-Savings Plan _F_A_Q') , ROW ('h3L1otH3re', 'en', 'Amazon ElastiCache Reserved Node
-Optimization', 'Checks your usage of ElastiCache and provides recommendations
-on purchase of Reserved Nodes to help reduce costs incurred from using
-ElastiCache On-Demand. AWS generates these recommendations by analyzing your
-On-Demand usage for the past 30 days. We then simulate every combination of
-reservations in the generated category of usage in order to identify the best
-number of each type of Reserved Node to purchase to maximize your savings. This
-check covers recommendations based on partial upfront payment option with 1-
-year or 3-year commitment. This check is not available to accounts linked in
-Consolidated Billing. Recommendations are only available for the Paying
-Account.') , ROW ('1qw23er45t', 'en', 'Amazon Redshift Reserved Node
-Optimization', 'Checks your usage of Redshift and provides recommendations on
-purchase of Reserved Nodes to help reduce costs incurred from using Redshift
-On-Demand. AWS generates these recommendations by analyzing your On-Demand
-usage for the past 30 days. We then simulate every combination of reservations
-in the generated category of usage in order to identify the best number of each
-type of Reserved Nodes to purchase to maximize your savings. This check covers
-recommendations based on partial upfront payment option with 1-year or 3-year
-commitment. This check is not available to accounts linked in Consolidated
-Billing. Recommendations are only available for the Paying Account.
+Information on RDS Reserved Instances and how they can save you money can be
+found _h_e_r_e.') , ROW ('Hs4Ma3G183', 'en', 'Application load balancer should be
+configured to drop http headers', 'This check evaluates AWS Application Load
+Balancers (ALB) to ensure they are configured to drop http headers. By default,
+ALBs are not configured to drop invalid http header values. This check
+evaluates all ALBs fails if the attribute value of
+routing.http.drop_invalid_header_fields.enabled is set to false.') , ROW
+('Hs4Ma3G184', 'en', 'Application and Classic Load Balancers logging should be
+enabled', 'Checks if the Application Load Balancer and the Classic Load
+Balancer have logging enabled. The check fails if the access_logs.s3.enabled is
+false.') , ROW ('Hs4Ma3G185', 'en', 'IAM customer managed policies that you
+create should not allow wildcard actions for services', 'Checks if the IAM
+identity-based custom policies have Allow statements that grant permissions for
+all actions on a service. The check fails if any policy statement includes
+"Effect": "Allow" with "Action": "Service:".') , ROW ('Hs4Ma3G186', 'en', 'AWS
+WAF Classic Global Web ACL logging should be enabled', 'Checks if logging is
+enabled for a WAF global Web ACL. This check fails if logging is not enabled
+for the Web ACL.') , ROW ('Hs4Ma3G187', 'en', 'Connections to Amazon
+Elasticsearch Service domains should be encrypted using TLS 1.2', 'Checks
+whether connections to Amazon Elasticsearch Service domains are required to use
+TLS 1.2. The check fails if the Amazon Elasticsearch Service domain
+TLSSecurityPolicy is not Policy-Min-TLS-1-2-2019-07.') , ROW ('12Fnkpl8Y5',
+'en', 'Exposed Access Keys', 'Checks popular code repositories for access keys
+that have been exposed to the public and for irregular Amazon Elastic Compute
+Cloud (Amazon EC2) usage that could be the result of a compromised access key.
+An access key consists of an access key ID and the corresponding secret access
+key. Exposed access keys pose a security risk to your account and other users,
+could lead to excessive charges from unauthorized activity or abuse, and
+violate the _A_W_S_ _C_u_s_t_o_m_e_r_ _A_g_r_e_e_m_e_n_t. If your access key is exposed, take
+immediate action to secure your account. To protect your account from excessive
+charges, AWS temporarily limits your ability to create certain AWS resources
+when exposed access keys are identified. This does not make your account
+secure; it only partially limits the unauthorized usage for which you could be
+charged. Note: This check does not guarantee the identification of exposed
+access keys or compromised EC2 instances. You are ultimately responsible for
+the safety and security of your access keys and AWS resources.
+
+If a deadline is shown for an access key, AWS may suspend your AWS account if
+the unauthorized usage is not stopped by that date. If you believe an alert is
+in error, _c_o_n_t_a_c_t_ _A_W_S_ _S_u_p_p_o_r_t.
+
+The information displayed in Trusted Advisor may not reflect the most recent
+state of your account. No exposed access keys are marked as resolved until all
+exposed access keys on the account have been resolved. This data
+synchronization can take up to one week.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Red: Potentially compromised - AWS has identified an access key ID and
+corresponding secret access key that have been exposed on the Internet and may
+have been compromised (used).
+Red: Exposed - AWS has identified an access key ID and corresponding secret
+access key that have been exposed on the Internet.
+Red: Suspected - Irregular Amazon EC2 usage indicates that an access key may
+have been compromised, but it has not been identified as exposed on the
+Internet.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Delete the affected access key as soon as possible. If the key is associated
+with an IAM user, see _M_a_n_a_g_i_n_g_ _A_c_c_e_s_s_ _K_e_y_s_ _f_o_r_ _I_A_M_ _U_s_e_r_s.
+
+Check your account for unauthorized usage. Log in to the _A_W_S_ _M_a_n_a_g_e_m_e_n_t_ _C_o_n_s_o_l_e
+and check each service console for suspicious resources. Pay special attention
+to running Amazon EC2 instances, Spot Instance requests, access keys, and IAM
+users. You can also check overall usage on the _B_i_l_l_i_n_g_ _&_ _C_o_s_t_ _M_a_n_a_g_e_m_e_n_t
+_D_a_s_h_b_o_a_r_d.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_B_e_s_t_ _P_r_a_c_t_i_c_e_s_ _f_o_r_ _M_a_n_a_g_i_n_g_ _A_W_S_ _A_c_c_e_s_s_ _K_e_y_s
+_A_W_S_ _S_e_c_u_r_i_t_y_ _A_u_d_i_t_ _G_u_i_d_e_l_i_n_e_s') , ROW ('8CNsSllI5v', 'en', 'Auto Scaling Group
+Resources', 'Checks the availability of resources associated with launch
+configurations and your Auto Scaling groups. Auto Scaling groups that point to
+unavailable resources cannot launch new Amazon Elastic Compute Cloud (Amazon
+EC2) instances. When properly configured, Auto Scaling causes the number of
+Amazon EC2 instances to increase seamlessly during demand spikes and decrease
+automatically during demand lulls. Auto Scaling groups and launch
+configurations that point to unavailable resources do not operate as
+intended.') , ROW ('k3J2hns32g', 'en', 'Overutilized Amazon EBS Magnetic
+Volumes', 'Checks for Amazon Elastic Block Store (EBS) Magnetic volumes that
+are potentially overutilized and might benefit from a more efficient
+configuration. A Magnetic volume is designed for applications with moderate or
+bursty I/O requirements, and the IOPS rate is not guaranteed. It delivers
+approximately 100 IOPS on average, with a best-effort ability to burst to
+hundreds of IOPS. For consistently higher IOPS, you can use a Provisioned IOPS
+(SSD) volume. For bursty IOPS, you can use a General Purpose (SSD) volume. For
+more information, see _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e_ _T_y_p_e_s.') , ROW ('hjLMh88uM8', 'en',
+'Idle Load Balancers', 'Checks your Elastic Load Balancing configuration for
+load balancers that are not actively used. Any load balancer that is configured
+accrues charges. If a load balancer has no associated back-end instances or if
+network traffic is severely limited, the load balancer is not being used
+effectively.') , ROW ('Hs4Ma3G177', 'en', 'Auto scaling groups associated with
+a load balancer should use load balancer health checks', 'Checks if your Auto
+Scaling groups that are associated with a load balancer are using Elastic Load
+Balancing health checks.') , ROW ('Hs4Ma3G178', 'en', 'Security groups should
+only allow unrestricted incoming traffic for authorized ports', 'Checks if the
+security groups allow unrestricted incoming traffic. The check fails if ports
+allow unrestricted traffic on ports other than 80 and 443, which are default
+values for parameter authorizedTcpPorts.') , ROW ('BueAdJ7NrP', 'en', 'Amazon
+S3 Bucket Logging', 'Checks the logging configuration of Amazon Simple Storage
+Service (Amazon S3) buckets. When server access logging is enabled, detailed
+access logs are delivered hourly to a bucket that you choose. An access log
+record contains details about each request, such as the request type, the
+resources specified in the request, and the time and date the request was
+processed. By default, bucket logging is not enabled; you should enable logging
+if you want to perform security audits or learn more about users and usage
+patterns.') , ROW ('Hs4Ma3G179', 'en', 'SNS topics should be encrypted at-rest
+using AWS KMS', 'Checks if an Amazon SNS topic is encrypted at rest using AWS
+KMS.') , ROW ('xdeXZKIUy', 'en', 'ELB Cross-Zone Load Balancing', 'With Cross-
+zone load balancing turned off, there is a risk of service unavailability due
+to uneven distribution of traffic or backend overloading. This problem can
+occur when clients incorrectly cache DNS information, or when there are an
+unequal number of instances in each Availability Zone (for example, if you have
+taken down some instances for maintenance).
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: Cross-zone load balancing is not enabled for a load balancer.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Confirm that the Amazon EC2 instances registered with the load balancer are
+launched in multiple Availability Zones, and then enable cross-zone load
+balancing for the load balancer. For more information, see _A_v_a_i_l_a_b_i_l_i_t_y_ _Z_o_n_e_s
+_a_n_d_ _R_e_g_i_o_n_s and _E_n_a_b_l_e_ _o_r_ _D_i_s_a_b_l_e_ _C_r_o_s_s_-_Z_o_n_e_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g_ _f_o_r_ _Y_o_u_r_ _L_o_a_d
+_B_a_l_a_n_c_e_r.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_R_e_q_u_e_s_t_ _R_o_u_t_i_n_g
+_E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g_ _C_o_n_c_e_p_t_s') , ROW ('gW7HH0l7J9', 'en', 'CloudFormation
+Stacks', 'Checks for usage that is more than 80% of the CloudFormation Stacks
+Limit. Values are based on a snapshot, so your current usage might differ.
+Limit and usage data can take up to 24 hours to reflect any changes. In cases
+where limits have been recently increased, you may temporarily see utilization
+that exceeds the limit.') , ROW ('gI7MM0l7J2', 'en', 'EBS Provisioned IOPS SSD
+(io2) Volume Storage', 'Checks for usage that is more than 80% of the EBS
+Provisioned IOPS SSD (io2) Volume Storage Limit. Values are based on a
+snapshot, so your current usage might differ. Limit and usage data can take up
+to 24 hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('Hs4Ma3G270', 'en', 'EC2 Auto Scaling groups should use EC2 launch templates',
+'Checks if an Amazon EC2 Auto Scaling group is created from an EC2 launch
+template. This check fails if an Amazon EC2 Auto Scaling group is not created
+with a launch template or if a launch template is not specified in a mixed
+instances policy.') , ROW ('Hs4Ma3G271', 'en', 'API Gateway routes should
+specify an authorization type', 'Checks if Amazon API Gateway routes have an
+authorization type. The check fails if the API Gateway route does not specify
+an authorization type') , ROW ('Hs4Ma3G150', 'en', 'Elasticsearch domains
+should encrypt data sent between nodes', 'Checks if Elasticsearch domains have
+node-to-node encryption enabled.') , ROW ('Hs4Ma3G272', 'en', 'Users should not
+have root access to SageMaker notebook instances', 'Checks if root access is
+turned off for Amazon SageMaker notebook instances. The check fails if root
+access is turned on for a SageMaker notebook instance.') , ROW ('Hs4Ma3G151',
+'en', 'An RDS event notifications subscription should be configured for
+critical database parameter group events', 'Checks if an Amazon RDS Event
+subscription for RDS parameter groups is configured to notify on event category
+of "configuration change".') , ROW ('Hs4Ma3G273', 'en', 'Security contact
+information should be provided for an AWS account.', 'Checks if an Amazon Web
+Services (AWS) account has security contact information. The check fails if
+security contact information is not provided for the account.') , ROW
+('Hs4Ma3G152', 'en', 'An RDS event notifications subscription should be
+configured for critical database instance events', 'Checks if an Amazon RDS
+Event subscription for RDS instances is configured to notify on event
+categories of both "maintenance", "configuration change", and "failure".') ,
+ROW ('EM8b3yLRTr', 'en', 'ELB Application Load Balancers', 'Checks for usage
+that is more than 80% of the ELB Application Load Balancers Limit. Classic Load
+Balancers and Network Load Balancers have separate limits. Values are based on
+a snapshot, so your current usage might differ. Limit and usage data can take
+up to 24 hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.
+') , ROW ('rT7WW0l7J9', 'en', 'IAM Server Certificates', 'Checks for usage that
+is more than 80% of the IAM Server Certificates Limit. Values are based on a
+snapshot, so your current usage might differ. Limit and usage data can take up
+to 24 hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('Hs4Ma3G274', 'en', 'SageMaker notebook instances should be launched in a
+custom VPC', 'Checks if an Amazon SageMaker notebook instance is launched
+within a custom VPC. The check fails if a SageMaker notebook instance is not
+launched within a custom VPC.') , ROW ('Hs4Ma3G153', 'en', 'RDS instances
+should not use a database engine default port', 'Checks if RDS instances use
+the default port of that database engine.') , ROW ('Hs4Ma3G275', 'en',
+'CloudFront distributions should not point to non-existent S3 origins', 'Checks
+if Amazon CloudFront distributions are pointing to non-existent S3 origins. The
+check fails for a CloudFront distribution if the origin is configured to point
+to a non-existent bucket. This check only applies to CloudFront distributions
+where an S3 bucket without static website hosting is the S3 origin.') , ROW
+('Hs4Ma3G154', 'en', 'An RDS event notifications subscription should be
+configured for critical database security group events', 'Checks if an Amazon
+RDS Event subscription for RDS security groups is configured to notify on event
+categories of both "configuration change" and "failure".') , ROW ('N415c450f2',
+'en', 'CloudFront Header Forwarding and Cache Hit Ratio', 'Checks the HTTP
+request headers that CloudFront currently receives from the client and forwards
+to your origin server. Some headers, such as Date or User-Agent, significantly
+reduce the cache hit ratio (the proportion of requests that are served from a
+CloudFront edge cache). This increases the load on your origin and reduces
+performance because CloudFront must forward more requests to your origin.') ,
+ROW ('Hs4Ma3G265', 'en', 'A WAF Regional rule group should have at least one
+rule', 'Checks if a WAF Regional rule group has at least one rule. The check
+fails if no rules are present within a rule group.') , ROW ('Hs4Ma3G144', 'en',
+'Unused IAM user credentials should be removed', 'Checks if your IAM users have
+passwords or active access keys that were not used within the previous 90
+days.') , ROW ('iqdCTZKCUp', 'en', 'Load Balancer Optimization', 'Checks your
+load balancer configuration. To help increase the level of fault tolerance in
+Amazon Elastic Compute Cloud (EC2) when using Elastic Load Balancing, we
+recommend running an equal number of instances across multiple Availability
+Zones in a region. A load balancer that is configured accrues charges, so this
+is a cost-optimization check as well.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: A load balancer is enabled for a single Availability Zone.
+Yellow: A load balancer is enabled for an Availability Zone that has no active
+instances.
+Yellow: The Amazon EC2 instances that are registered with a load balancer are
+unevenly distributed across Availability Zones. (The difference between the
+highest and lowest instance counts in utilized Availability Zones is more than
+1, and the difference is more than 20% of the highest count.)
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Ensure that your load balancer points to active and healthy instances in at
+least two Availability Zones. For more information, see _A_d_d_ _A_v_a_i_l_a_b_i_l_i_t_y_ _Z_o_n_e.
+If your load balancer is configured for an Availability Zone with no healthy
+instances, or if there is an imbalance of instances across the Availability
+Zones, determine if all the Availability Zones are necessary. Omit any
+unnecessary Availability Zones and ensure there is a balanced distribution of
+instances across the remaining Availability Zones. For more information, see
+_R_e_m_o_v_e_ _A_v_a_i_l_a_b_i_l_i_t_y_ _Z_o_n_e.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_A_v_a_i_l_a_b_i_l_i_t_y_ _Z_o_n_e_s_ _a_n_d_ _R_e_g_i_o_n_s
+_M_a_n_a_g_i_n_g_ _L_o_a_d_ _B_a_l_a_n_c_e_r_s
+_B_e_s_t_ _P_r_a_c_t_i_c_e_s_ _i_n_ _E_v_a_l_u_a_t_i_n_g_ _E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g') , ROW ('gI7MM0l7J9',
+'en', 'EBS Provisioned IOPS SSD (io1) Volume Storage', 'Checks for usage that
+is more than 80% of the EBS Provisioned IOPS SSD (io1) Volume Storage Limit.
+Values are based on a snapshot, so your current usage might differ. Limit and
+usage data can take up to 24 hours to reflect any changes. In cases where
+limits have been recently increased, you may temporarily see utilization that
+exceeds the limit.') , ROW ('Hs4Ma3G266', 'en', 'A WAF Regional web ACL should
+have at least one rule or rule group', 'Checks if a WAF Regional web ACL
+contains any WAF rules or WAF rule groups. This check fails if a web ACL does
+not contain any WAF rules or rule groups.') , ROW ('Hs4Ma3G145', 'en', 'Amazon
+ECS task definitions should have secure networking modes and user
+definitions.', 'Checks if an Amazon ECS Task Definition with host networking
+mode has "privileged" or "user" container definitions. The check fails with
+host network mode and container definitions are privileged=false or empty and
+user=root or empty.') , ROW ('Ti39halfu8', 'en', 'Amazon RDS Idle DB
+Instances', 'Checks the configuration of your Amazon Relational Database
+Service (Amazon RDS) for any DB instances that appear to be idle. If a DB
+instance has not had a connection for a prolonged period of time, you can
+delete the instance to reduce costs. If persistent storage is needed for data
+on the instance, you can use lower-cost options such as taking and retaining a
+DB snapshot. Manually created DB snapshots are retained until you delete
+them.') , ROW ('Hs4Ma3G267', 'en', 'A WAF global rule should have at least one
+condition', 'Checks if a WAF global rule has at least one condition. This check
+fails if no conditions are present within a rule.') , ROW ('Hs4Ma3G146', 'en',
+'ECS services should not have public IP addresses assigned to them
+automatically', 'Checks if ECS services are configured to automatically assign
+public IP addresses. This check fails if AssignPublicIP is ENABLED.') , ROW
+('j3DFqYTe29', 'en', 'Large Number of EC2 Security Group Rules Applied to an
+Instance', 'Checks for Amazon Elastic Compute Cloud (EC2) instances that have a
+large number of security group rules. Performance can be degraded if an
+instance has a large number of rules.') , ROW ('Hs4Ma3G268', 'en', 'A WAF
+global rule group should have at least one rule', 'Checks if a WAF global rule
+group has at least one rule. The check fails if no rules are present within a
+rule group.') , ROW ('Hs4Ma3G147', 'en', 'Amazon Elasticsearch Service domains
+should be in a VPC', 'Checks whether Amazon Elasticsearch Service domains are
+in a VPC. It does not evaluate the VPC subnet routing configuration to
+determine public reachability. This check also does not check whether the
+Amazon OpenSearch Service resource-based policy permits public access by other
+accounts or external entities. You should ensure that Amazon Elasticsearch
+Service domains are not attached to public subnets. See Resource-based policies
+(https://docs.aws.amazon.com/opensearch-service/latest/developerguide/
+ac.html#ac-types-resource) in the Amazon OpenSearch Service (successor to
+Amazon Elasticsearch Service) Developer Guide. You should also ensure that your
+VPC is configured according to the recommended best practices. See Security
+best practices for your VPC (https://docs.aws.amazon.com/vpc/latest/userguide/
+vpc-security-best-practices.html) in the Amazon VPC User Guide.') , ROW
+('Hs4Ma3G269', 'en', 'A WAF global web ACL should have at least one rule or
+rule group', 'Checks if a WAF global web ACL contains any WAF rules or WAF rule
+groups. This check fails if a web ACL does not contain any WAF rules or WAF
+rule groups.') , ROW ('Hs4Ma3G148', 'en', 'Elastic Beanstalk environments
+should have enhanced health reporting enabled', 'Checks if enhanced health
+reporting is enabled for your AWS Elastic Beanstalk environments.') , ROW
+('1qw23er45t', 'en', 'Amazon Redshift Reserved Node Optimization', 'Checks your
+usage of Redshift and provides recommendations on purchase of Reserved Nodes to
+help reduce costs incurred from using Redshift On-Demand. AWS generates these
+recommendations by analyzing your On-Demand usage for the past 30 days. We then
+simulate every combination of reservations in the generated category of usage
+in order to identify the best number of each type of Reserved Nodes to purchase
+to maximize your savings. This check covers recommendations based on partial
+upfront payment option with 1-year or 3-year commitment. This check is not
+available to accounts linked in Consolidated Billing. Recommendations are only
+available for the Paying Account.
+
+****** AAlleerrtt CCrriitteerriiaa ******
 
-AAlleerrtt CCrriitteerriiaa
 Yellow: Optimizing the purchase of Redshift Reserved Nodes can help reduce
 costs.
 
-RReeccoommmmeennddeedd AAccttiioonn
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
 See the _C_o_s_t_ _E_x_p_l_o_r_e_r page for more detailed recommendations, customization
 options (e.g. look-back period, payment option, etc.) and to purchase Redshift
 Reserved Nodes.
 
-AAddddiittiioonnaall RReessoouurrcceess
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
 Information on Redshift Reserved Nodes and how they can save you money can be
-found _h_e_r_e.') , ROW ('1qazXsw23e', 'en', 'Amazon Relational Database Service
-(RDS) Reserved Instance Optimization', 'Checks your usage of RDS and provides
-recommendations on purchase of Reserved Instances to help reduce costs incurred
-from using RDS On-Demand. AWS generates these recommendations by analyzing your
-On-Demand usage for the past 30 days. We then simulate every combination of
-reservations in the generated category of usage in order to identify the best
-number of each type of Reserved Instance to purchase to maximize your savings.
-This check covers recommendations based on partial upfront payment option with
-1-year or 3-year commitment. This check is not available to accounts linked in
-Consolidated Billing. Recommendations are only available for the Paying
-Account.
+found _h_e_r_e.') , ROW ('Hs4Ma3G149', 'en', 'Elastic Beanstalk managed platform
+updates should be enabled', 'Checks if managed platform updates are enabled for
+the AWS Elastic Beanstalk environment.') , ROW ('Cb877eB72b', 'en', 'Amazon
+Route 53 Deleted Health Checks', 'Checks for resource record sets that are
+associated with health checks that have been deleted. Amazon Route 53 does not
+prevent you from deleting a health check that is associated with one or more
+resource record sets. If you delete a health check without updating the
+associated resource record sets, the routing of DNS queries for your DNS
+failover configuration will not work as intended. Hosted zones created by AWS
+services wonÃ¢Â€Â™t appear in your check results.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: Optimizing the purchase of RDS Reserved Instances can help reduce
-costs.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-See the _C_o_s_t_ _E_x_p_l_o_r_e_r page for more detailed recommendations, customization
-options (e.g. look-back period, payment option, etc.) and to purchase RDS
-Reserved Instances.
+Yellow: A resource record set is associated with a health check that has been
+deleted.
 
-AAddddiittiioonnaall RReessoouurrcceess
-Information on RDS Reserved Instances and how they can save you money can be
-found _h_e_r_e.') , ROW ('7ujm6yhn5t', 'en', 'Amazon OpenSearch Service Reserved
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Create a new health check and associate it with the resource record set; see
+_C_r_e_a_t_i_n_g_,_ _U_p_d_a_t_i_n_g_,_ _a_n_d_ _D_e_l_e_t_i_n_g_ _H_e_a_l_t_h_ _C_h_e_c_k_s and _A_d_d_i_n_g_ _H_e_a_l_t_h_ _C_h_e_c_k_s_ _t_o
+_R_e_s_o_u_r_c_e_ _R_e_c_o_r_d_ _S_e_t_s.
+
+****** AAddddiittiioonnaall IInnffoorrmmaattiioonn ******
+
+_A_m_a_z_o_n_ _R_o_u_t_e_ _5_3_ _H_e_a_l_t_h_ _C_h_e_c_k_s_ _a_n_d_ _D_N_S_ _F_a_i_l_o_v_e_r
+_H_o_w_ _H_e_a_l_t_h_ _C_h_e_c_k_s_ _W_o_r_k_ _i_n_ _S_i_m_p_l_e_ _A_m_a_z_o_n_ _R_o_u_t_e_ _5_3_ _C_o_n_f_i_g_u_r_a_t_i_o_n_s') , ROW
+('Hs4Ma3G280', 'en', 'Application, Network and Gateway Load Balancers should
+span multiple Availability Zones', 'Checks if an Elastic Load Balancer V2
+(Application, Network, or Gateway Load Balancer) has registered instances from
+multiple Availability Zones. The check fails if an Elastic Load Balancer V2 has
+instances registered in less than 2 Availability Zones.') , ROW ('796d6f3D83',
+'en', 'CloudFront Content Delivery Optimization', 'Checks for cases where data
+transfer from Amazon Simple Storage Service (Amazon S3) buckets could be
+accelerated by using Amazon CloudFront, the AWS global content delivery
+service. When you configure CloudFront to deliver your content, requests for
+your content are automatically routed to the nearest edge location where
+content is cached, so it can be delivered to your users with the best possible
+performance. A high ratio of data transferred out to the data stored in the
+bucket indicates that you could benefit from using Amazon CloudFront to deliver
+the data. ') , ROW ('Hs4Ma3G160', 'en', 'IAM authentication should be
+configured for RDS instances', 'Checks if an RDS DB instance has IAM database
+authentication enabled.') , ROW ('Hs4Ma3G161', 'en', 'IAM authentication should
+be configured for RDS clusters', 'Checks if an RDS DB cluster has IAM database
+authentication enabled.') , ROW ('Hs4Ma3G162', 'en', 'RDS automatic minor
+version upgrades should be enabled', 'Checks if automatic minor version
+upgrades are enabled for the Amazon RDS database instance.') , ROW
+('Hs4Ma3G163', 'en', 'RDS DB clusters should be configured to copy tags to
+snapshots', 'Checks if RDS DB clusters are configured to copy all tags to
+snapshots when the snapshots are created.') , ROW ('Hs4Ma3G164', 'en', 'RDS DB
+instances should be configured to copy tags to snapshots', 'Checks if RDS DB
+instances are configured to copy all tags to snapshots when the snapshots are
+created.') , ROW ('Hs4Ma3G165', 'en', 'RDS instances should be deployed in a
+VPC', 'Checks if an RDS instance is deployed in a VPC (EC2-VPC).') , ROW
+('keAhfbH5yb', 'en', 'RDS Event Subscriptions', 'Checks for usage that is more
+than 80% of the RDS Event Subscriptions Limit. Values are based on a snapshot,
+so your current usage might differ. Limit and usage data can take up to 24
+hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('c5ftjdfkMr', 'en', 'DynamoDB Write Capacity', 'Checks for usage that is more
+than 80% of the DynamoDB Provisioned Throughput Limit for Writes per Account.
+Values are based on a snapshot, so your current usage might differ. Limit and
+usage data can take up to 24 hours to reflect any changes. In cases where
+limits have been recently increased, you may temporarily see utilization that
+exceeds the limit.') , ROW ('Hs4Ma3G276', 'en', 'A WAFV2 web ACL should have at
+least one rule or rule group', 'Checks if a WAFV2 web ACL contains at least one
+WAF rule or WAF rule group. The check fails if a web ACL does not contain any
+WAF rule or rule group.') , ROW ('Hs4Ma3G155', 'en', 'EC2 instances should be
+managed by AWS Systems Manager', 'Checks if the Amazon EC2 instances in your
+account are managed by AWS Systems Manager.') , ROW ('Cm24dfsM13', 'en',
+'Amazon Comprehend Endpoint Access Risk', 'Checks the AWS Key Management
+Service (AWS KMS) key permissions for an endpoint where the underlying model
+was encrypted by using customer managed keys. If the customer managed key is
+disabled or the key policy was changed to alter the allowed permissions for
+Amazon Comprehend, the endpoint availability might be affected.
+****** NNoottee:: ******
+This check is automatically refreshed multiple times a day. It might take a few
+hours for the latest results to appear.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Red: The customer managed key is disabled or the key policy was changed to
+alter the allowed permissions for Amazon Comprehend access.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+If the customer managed key was disabled, we recommend that you enable it. For
+more information, see _E_n_a_b_l_i_n_g_ _k_e_y_s. If the key policy was altered and you want
+to keep using the endpoint, we recommend that you update the KMS key policy.
+For more information, see _C_h_a_n_g_i_n_g_ _a_ _k_e_y_ _p_o_l_i_c_y.') , ROW ('Hs4Ma3G277', 'en',
+'EC2 launch templates should not assign public IPs to network interfaces',
+'Checks if Amazon EC2 launch templates are configured to assign public IP
+addresses to network interfaces upon launch. The check fails if an EC2 launch
+template is configured to assign a public IP address to network interfaces or
+if there is at least one network interface that has a public IP address.') ,
+ROW ('Hs4Ma3G156', 'en', 'EC2 instances managed by Systems Manager should have
+a patch compliance status of COMPLIANT after a patch installation', 'Checks if
+the compliance status of the Amazon EC2 Systems Manager patch compliance is
+COMPLIANT or NON_COMPLIANT after the patch installation on the instance. It
+only assesses instances that are managed by AWS Systems Manager Patch
+Manager.') , ROW ('ZRxQlPsb6c', 'en', 'High Utilization Amazon EC2 Instances',
+'Checks the Amazon Elastic Compute Cloud (Amazon EC2) instances that were
+running at any time during the last 14 days and alerts you if the daily CPU
+utilization was more than 90% on 4 or more days. Consistent high utilization
+can indicate optimized, steady performance, but it can also indicate that an
+application does not have enough resources. To get daily CPU utilization data,
+download the report for this check.') , ROW ('Hs4Ma3G278', 'en', 'Access
+logging should be configured for API Gateway V2 Stages', 'Checks if Amazon API
+Gateway V2 stages have access logging configured. This check fails if access
+log settings arenÃ¢Â€Â™t defined.') , ROW ('Hs4Ma3G157', 'en', 'EC2 instances
+managed by Systems Manager should have an association compliance status of
+COMPLIANT', 'Checks if the status of the AWS Systems Manager association
+compliance is COMPLIANT or NON_COMPLIANT after the association is executed on
+an instance.') , ROW ('bW7HH0l7J9', 'en', 'Kinesis Shards per Region', 'Checks
+for usage that is more than 80% of the Kinesis Shards per Region Limit. Values
+are based on a snapshot, so your current usage might differ. Limit and usage
+data can take up to 24 hours to reflect any changes. In cases where limits have
+been recently increased, you may temporarily see utilization that exceeds the
+limit.') , ROW ('Hs4Ma3G279', 'en', 'Amazon EC2 Auto Scaling group should cover
+multiple Availability Zones', 'Checks if an Auto Scaling group spans multiple
+Availability Zones. The check fails if an Auto Scaling group does not span
+multiple availability zones.') , ROW ('Hs4Ma3G158', 'en', 'SSM documents should
+not be public', 'Checks if AWS Systems Manager documents that the account owns
+are public. This check fails if SSM documents that have "Self" as the owner are
+public.') , ROW ('Cm24dfsM12', 'en', 'Amazon Comprehend Underutilized
+Endpoints', 'Checks the throughput configuration of your endpoints. This check
+alerts you when endpoints are not actively used for real-time inference
+requests. An endpoint that isnÃ¢Â€Â™t used for more than 15 consecutive days is
+considered underutilized. All endpoints accrue charges based on both the
+throughput set and the length of time that the endpoint is active.
+****** NNoottee:: ******
+This check is automatically refreshed once a day.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: The endpoint is active, but hasnÃ¢Â€Â™t been used for real-time inference
+requests in the past 15 days.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+If the endpoint hasnÃ¢Â€Â™t been used in the past 15 days, we recommend that you
+define a scaling policy for the resource by using _A_p_p_l_i_c_a_t_i_o_n_ _A_u_t_o_s_c_a_l_i_n_g_.
+If the endpoint has a scaling policy defined and hasnÃ¢Â€Â™t been used in the past
+30 days, consider deleting the endpoint and using asynchronous inference. For
+more information, see _D_e_l_e_t_i_n_g_ _a_n_ _e_n_d_p_o_i_n_t_ _w_i_t_h_ _A_m_a_z_o_n_ _C_o_m_p_r_e_h_e_n_d.') , ROW
+('Hs4Ma3G159', 'en', 'Elastic File System should be configured to encrypt file
+data at-rest using AWS KMS', 'Checks if Amazon Elastic File System (Amazon EFS)
+is configured to encrypt the file data using AWS Key Management Service (AWS
+KMS). The check will fail if the encrypted key is set to false on
+DescribeFileSystems or if the KmsKeyId key on DescribeFileSystems does not
+match the KmsKeyId parameter.') , ROW ('nO7SS0l7J9', 'en', 'IAM Instance
+Profiles', 'Checks for usage that is more than 80% of the IAM Instance Profiles
+Limit. Values are based on a snapshot, so your current usage might differ.
+Limit and usage data can take up to 24 hours to reflect any changes. In cases
+where limits have been recently increased, you may temporarily see utilization
+that exceeds the limit.') , ROW ('dx3xfcdfMr', 'en', 'Route 53 Hosted Zones',
+'Checks for usage that is more than 80% of the Route 53 Hosted Zones Limit per
+account. Values are based on a snapshot, so your current usage might differ.
+Limit and usage data can take up to 24 hours to reflect any changes. In cases
+where limits have been recently increased, you may temporarily see utilization
+that exceeds the limit.') , ROW ('PPkZrjsH2q', 'en', 'Amazon EBS Provisioned
+IOPS (SSD) Volume Attachment Configuration', 'Checks for Provisioned IOPS (SSD)
+volumes that are attached to an Amazon EBS-optimizable Amazon Elastic Compute
+Cloud (Amazon EC2) instance that is not EBS-optimized. Provisioned IOPS (SSD)
+volumes in the Amazon Elastic Block Store (Amazon EBS) are designed to deliver
+the expected performance only when they are attached to an EBS-optimized
+instance.') , ROW ('Hs4Ma3G250', 'en', 'ECS clusters should use Container
+Insights', 'Checks if ECS clusters use Container Insights. This check fails if
+Container Insights are not set up for a cluster.') , ROW ('Hs4Ma3G251', 'en',
+'EFS access points should enforce a root directory', 'Checks if Amazon Elastic
+File System (Amazon EFS) access points are configured to enforce a root
+directory. This check fails if the value of Path is set to / (default root
+directory of the file system).') , ROW ('Hs4Ma3G130', 'en', 'Lambda functions
+should use supported runtimes', 'Checks that the lambda function settings for
+runtimes, match the expected values set for the supported runtimes for each
+language. The supported runtimes this check assesses for are: nodejs14.x,
+nodejs12.x, python3.8, python3.7, python3.6, java11, java8, go1.x,
+dotnetcore2.1, dotnetcore3.1, ruby2.7.') , ROW ('Hs4Ma3G252', 'en', 'EFS access
+points should enforce a user identity', 'Checks if Amazon Elastic File System
+(Amazon EFS) access points are configured to enforce a user identity. This
+check fails if Ã¢Â€Â˜PosixUserÃ¢Â€Â™ is not defined under Ã¢Â€Â˜configurationÃ¢Â€Â™ or if
+parameters are provided and there is no match in the corresponding parameter.')
+, ROW ('Hs4Ma3G131', 'en', 'Lambda function policies should prohibit public
+access', 'Checks if the AWS Lambda function policy attached to the Lambda
+resource prohibits public access. If the Lambda function policy allows public
+access, the check fails.') , ROW ('Hs4Ma3G253', 'en', 'EKS clusters should run
+on a supported Kubernetes version', 'Checks if an EKS cluster is running on a
+supported Kubernetes version. The check fails if the EKS cluster is running on
+an unsupported version.') , ROW ('Hs4Ma3G132', 'en', 'Database Migration
+Service replication instances should not be public', 'Checks if AWS Database
+Migration Service replication instances are public by examining the
+PubliclyAccessible field value.') , ROW ('lN7RR0l7J9', 'en', 'EC2-VPC Elastic
+IP Address', 'Checks for usage that is more than 80% of the EC2-VPC Elastic IP
+Address Limit. Values are based on a snapshot, so your current usage might
+differ. Limit and usage data can take up to 24 hours to reflect any changes. In
+cases where limits have been recently increased, you may temporarily see
+utilization that exceeds the limit.') , ROW ('Z4AUBRNSmz', 'en', 'Unassociated
+Elastic IP Addresses', 'Checks for Elastic IP addresses (EIPs) that are not
+associated with a running Amazon Elastic Compute Cloud (Amazon EC2) instance.
+EIPs are static IP addresses designed for dynamic cloud computing. Unlike
+traditional static IP addresses, EIPs can mask the failure of an instance or
+Availability Zone by remapping a public IP address to another instance in your
+account. A nominal charge is imposed for an EIP that is not associated with a
+running instance.') , ROW ('dBkuNCvqn5', 'en', 'RDS Max Auths per Security
+Group', 'Checks for usage that is more than 80% of the RDS Max Auths per
+Security Group Limit. Values are based on a snapshot, so your current usage
+might differ. Limit and usage data can take up to 24 hours to reflect any
+changes. In cases where limits have been recently increased, you may
+temporarily see utilization that exceeds the limit.') , ROW ('H7IgTzjTYb',
+'en', 'Amazon EBS Snapshots', 'Checks the age of the snapshots for your Amazon
+Elastic Block Store (Amazon EBS) volumes (available or in-use). Even though
+Amazon EBS volumes are replicated, failures can occur. Snapshots are persisted
+to Amazon Simple Storage Service (Amazon S3) for durable storage and point-in-
+time recovery.') , ROW ('Hs4Ma3G243', 'en', 'Auto Scaling group launch
+configurations should configure EC2 instances to require Instance Metadata
+Service Version 2 (IMDSv2)', 'Checks if only IMDSv2 is enabled. This check
+fails if the metadata version is not included in the launch configuration or if
+both IMDSv1 and IMDSv2 are enabled.') , ROW ('Hs4Ma3G122', 'en', 'VPC flow
+logging should be enabled in all VPCs', 'Checks if Amazon Virtual Private Cloud
+flow logs are found and enabled for Amazon VPCs. The traffic type is set to
+Reject.') , ROW ('7ujm6yhn5t', 'en', 'Amazon OpenSearch Service Reserved
 Instance Optimization', 'Checks your usage of Amazon OpenSearch Service
 (successor to Amazon Elasticsearch Service) and provides recommendations on
 purchase of Reserved Instances to help reduce costs incurred from using Amazon
 OpenSearch Service On-Demand. AWS generates these recommendations by analyzing
 your On-Demand usage for the past 30 days. We then simulate every combination
 of reservations in the generated category of usage in order to identify the
 best number of each type of Reserved Instance to purchase to maximize your
 savings. This check covers recommendations based on partial upfront payment
 option with 1-year or 3-year commitment. This check is not available to
 accounts linked in Consolidated Billing. Recommendations are only available for
-the Paying Account.') , ROW ('L4dfs2Q4C5', 'en', 'AWS Lambda Functions Using
-Deprecated Runtimes', 'Checks for Lambda functions that are configured to use a
-runtime that is approaching deprecation or is deprecated. Deprecated runtimes
-are not eligible for security updates or technical support.
-NNootteess::') , ROW ('L4dfs2Q3C3', 'en', 'AWS Lambda Functions with Excessive
-Timeouts', 'Checks for Lambda functions with high timeout rates that may result
-in high cost. Lambda charges based on execution time for your function and
-number of requests for your function. Function timeouts result in function
-errors that may cause retries that incur additional request and execution time
-charges.
-NNoottee:: Results for this check are automatically refreshed several times daily,
-and refresh requests are not allowed. It might take a few hours for changes to
-appear.
+the Paying Account.') , ROW ('Hs4Ma3G244', 'en', 'Auto Scaling group launch
+configuration should not have a metadata response hop limit greater than 1',
+'Checks the number of network hops that the metadata token can travel. This
+check fails if the metadata response hop limit is greater than 1.') , ROW
+('Hs4Ma3G123', 'en', 'EC2 instances should not have a public IPv4 address',
+'Checks if EC2 instances have a public IP address. The check fails if the
+publicIp field is present in the EC2 instance configuration item. This check
+applies to IPv4 addresses only.') , ROW ('gjqMBn6pjz', 'en', 'RDS Clusters',
+'Checks for usage that is more than 80% of the RDS Clusters Limit. Values are
+based on a snapshot, so your current usage might differ. Limit and usage data
+can take up to 24 hours to reflect any changes. In cases where limits have been
+recently increased, you may temporarily see utilization that exceeds the
+limit.') , ROW ('Hs4Ma3G245', 'en', 'CloudFormation stacks should be integrated
+with Simple Notification Service (SNS)', 'Checks if your CloudFormation stacks
+are sending event notifications to SNS topic. This check fails if
+CloudFormation stacks are not sending event notifications to an SNS topic.') ,
+ROW ('Hs4Ma3G124', 'en', 'EC2 instances should use Instance Metadata Service
+Version 2 (IMDSv2)', 'Checks if your Amazon Elastic Compute Cloud (Amazon EC2)
+instance metadata version is configured with Instance Metadata Service Version
+2 (IMDSv2). The check passes if HttpTokens is set to required for IMDSv2. The
+check fails if HttpTokens is set to optional.') , ROW ('Hs4Ma3G246', 'en',
+'CloudFront distributions should not use deprecated SSL protocols between edge
+locations and custom origins', 'Checks if CloudFront distributions are using
+deprecated SSL protocols for HTTPS communication between CloudFront edge
+locations and your custom origins. This check fails for a CloudFront
+distribution if it has a CustomOriginConfig where Ã¢Â€Â˜OriginSslProtocolsÃ¢Â€Â™
+includes Ã¢Â€Â˜SSLv3Ã¢Â€Â™.') , ROW ('Hs4Ma3G125', 'en', 'API Gateway should be
+associated with a WAF Web ACL', 'Checks to see if an API Gateway stage is using
+an AWS WAF Web ACL. This check fails if an AWS WAF Web ACL is not attached to a
+REST API Gateway stage.') , ROW ('Qch7DwouX1', 'en', 'Low Utilization Amazon
+EC2 Instances', 'Checks the Amazon Elastic Compute Cloud (Amazon EC2) instances
+that were running at any time during the last 14 days and alerts you if the
+daily CPU utilization was 10% or less and network I/O was 5 MB or less on 4 or
+more days. Running instances generate hourly usage charges. Although some
+scenarios can result in low utilization by design, you can often lower your
+costs by managing the number and size of your instances.') , ROW ('Hs4Ma3G247',
+'en', 'EC2 Transit Gateways should not automatically accept VPC attachment
+requests', 'Checks if EC2 Transit Gateways are automatically accepting shared
+VPC attachments requests. This check will fail for a Transit Gateway that
+automatically accept shared VPC attachment requests.') , ROW ('Hs4Ma3G126',
+'en', 'DynamoDB Accelerator (DAX) clusters should be encrypted at rest',
+'Checks if a DAX cluster is encrypted at rest.') , ROW ('Hs4Ma3G248', 'en',
+'EC2 paravirtual instance types should not be used', 'Checks if the
+virtualization type of an EC2 instance is paravirtual. The check fails for an
+EC2 instance if Ã¢Â€Â˜virtualizationTypeÃ¢Â€Â™ is set to Ã¢Â€Â˜paravirtualÃ¢Â€Â™.') , ROW
+('Hs4Ma3G127', 'en', 'API Gateway REST and WebSocket API execution logging
+should be enabled', 'Checks if all stages of Amazon API Gateway REST and
+WebSocket APIs have logging enabled. The check fails if logging is not enabled
+for all methods of a stage or if loggingLevel is neither ERROR nor INFO.') ,
+ROW ('Hs4Ma3G249', 'en', 'ECS Fargate services should run on the latest Fargate
+platform version', 'Checks if ECS Fargate services is running the latest
+Fargate platform version. This check fails if the platform version is not
+latest.') , ROW ('Hs4Ma3G128', 'en', 'API Gateway REST API stages should be
+configured to use SSL certificates for backend authentication', 'Checks if
+Amazon API Gateway REST API stages have SSL certificates configured that
+backend systems can use to authenticate that incoming requests are from the API
+Gateway.') , ROW ('Hs4Ma3G129', 'en', 'API Gateway REST API stages should have
+AWS X-Ray tracing enabled', 'Checks if AWS X-Ray active tracing is enabled for
+your Amazon API Gateway REST API stages.') , ROW ('G31sQ1E9U', 'en',
+'Underutilized Amazon Redshift Clusters', 'Checks your Amazon Redshift
+configuration for clusters that appear to be underutilized. If an Amazon
+Redshift cluster has not had a connection for a prolonged period of time or is
+using a low amount of CPU, you can use lower-cost options such as downsizing
+the cluster or shutting down the cluster and taking a final snapshot. Final
+snapshots are retained even after you delete your cluster.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: Functions where > 10% of invocations end in an error due to a timeout
-on any given day within the last 7 days.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Inspect function logging and X-ray traces to determine the contributor to the
-high function duration. Implement logging in your code at relevant parts, such
-as before or after API calls or database connections. By default, AWS SDK
-clients timeouts may be longer than the configured function duration. Adjust
-API and SDK connection clients to retry or fail within the function timeout. If
-the expected duration is longer than the configured timeout, you can increase
-the timeout setting for the function. For more information, see _M_o_n_i_t_o_r_i_n_g_ _a_n_d
-_t_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _L_a_m_b_d_a_ _a_p_p_l_i_c_a_t_i_o_n_s.
+Yellow: A running cluster has not had a connection in the last 7 days.
+Yellow: A running cluster had less than 5% cluster-wide average CPU utilization
+for 99% of the last 7 days.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_M_o_n_i_t_o_r_i_n_g_ _a_n_d_ _t_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _L_a_m_b_d_a_ _a_p_p_l_i_c_a_t_i_o_n_s
-_L_a_m_b_d_a_ _F_u_n_c_t_i_o_n_ _R_e_t_r_y_ _T_i_m_e_o_u_t_ _S_D_K
-_U_s_i_n_g_ _A_W_S_ _L_a_m_b_d_a_ _w_i_t_h_ _A_W_S_ _X_-_R_a_y
-_A_c_c_e_s_s_i_n_g_ _A_m_a_z_o_n_ _C_l_o_u_d_W_a_t_c_h_ _l_o_g_s_ _f_o_r_ _A_W_S_ _L_a_m_b_d_a
-_E_r_r_o_r_ _P_r_o_c_e_s_s_o_r_ _S_a_m_p_l_e_ _A_p_p_l_i_c_a_t_i_o_n_ _f_o_r_ _A_W_S_ _L_a_m_b_d_a
-') , ROW ('L4dfs2Q3C2', 'en', 'AWS Lambda Functions with High Error Rates',
-'Checks for Lambda functions with high error rates that may result in high
-cost. Lambda charges based on the number of requests and aggregate execution
-time for your function. Function errors may cause retries that incur additional
-charges.
-NNoottee:: Results for this check are automatically refreshed several times daily,
-and refresh requests are not allowed. It might take a few hours for changes to
-appear.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: Functions where > 10% of invocations end in error on any given day
-within the last 7 days.
+Consider shutting down the cluster and taking a final snapshot, or downsizing
+the cluster. See _S_h_u_t_t_i_n_g_ _D_o_w_n_ _a_n_d_ _D_e_l_e_t_i_n_g_ _C_l_u_s_t_e_r_s and _R_e_s_i_z_i_n_g_ _a_ _C_l_u_s_t_e_r.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Consider the following guidelines to reduce errors. Function errors include
-errors returned by the functions code and errors returned by the functions
-runtime. To help you troubleshoot Lambda errors, Lambda integrates with
-services like Amazon CloudWatch and AWS X-Ray. You can use a combination of
-logs, metrics, alarms, and X-ray tracing to quickly detect and identify issues
-in your function code, API, or other resources that support your application.
-For more information, see _M_o_n_i_t_o_r_i_n_g_ _a_n_d_ _t_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _L_a_m_b_d_a_ _a_p_p_l_i_c_a_t_i_o_n_s.
-For more information on handling errors with specific runtimes, see _E_r_r_o_r
-_h_a_n_d_l_i_n_g_ _a_n_d_ _a_u_t_o_m_a_t_i_c_ _r_e_t_r_i_e_s_ _i_n_ _A_W_S_ _L_a_m_b_d_a. For additional troubleshooting,
-see _T_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _i_s_s_u_e_s_ _i_n_ _L_a_m_b_d_a.You can also choose from an ecosystem of
-monitoring and observability tools provided by AWS Lambda partners. For
-additional information about Partners, see _A_W_S_ _L_a_m_b_d_a_ _P_a_r_t_n_e_r_s.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-_E_r_r_o_r_ _H_a_n_d_l_i_n_g_ _a_n_d_ _A_u_t_o_m_a_t_i_c_ _R_e_t_r_i_e_s_ _i_n_ _A_W_S_ _L_a_m_b_d_a
-_M_o_n_i_t_o_r_i_n_g_ _a_n_d_ _T_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _L_a_m_b_d_a_ _a_p_p_l_i_c_a_t_i_o_n_s
-_L_a_m_b_d_a_ _F_u_n_c_t_i_o_n_ _R_e_t_r_y_ _T_i_m_e_o_u_t_ _S_D_K
-_T_r_o_u_b_l_e_s_h_o_o_t_i_n_g_ _i_s_s_u_e_s_ _i_n_ _L_a_m_b_d_a
-_A_P_I_ _I_n_v_o_k_e_ _E_r_r_o_r_s
-_E_r_r_o_r_ _P_r_o_c_e_s_s_o_r_ _S_a_m_p_l_e_ _A_p_p_l_i_c_a_t_i_o_n_ _f_o_r_ _A_W_S_ _L_a_m_b_d_a
-') , ROW ('L4dfs2Q4C6', 'en', 'AWS Lambda VPC-enabled Functions without Multi-
-AZ Redundancy', 'Checks for VPC-enabled Lambda functions that are vulnerable to
-service interruption in a single availability zone. It is recommended for VPC-
-enabled functions to be connected to multiple availability zones for high
-availability.
-NNoottee:: Results for this check are automatically refreshed several times daily,
-and refresh requests are not allowed. It might take a few hours for changes to
-appear.
+_A_m_a_z_o_n_ _C_l_o_u_d_W_a_t_c_h_ _D_e_v_e_l_o_p_e_r_ _G_u_i_d_e') , ROW ('h3L1otH3re', 'en', 'Amazon
+ElastiCache Reserved Node Optimization', 'Checks your usage of ElastiCache and
+provides recommendations on purchase of Reserved Nodes to help reduce costs
+incurred from using ElastiCache On-Demand. AWS generates these recommendations
+by analyzing your On-Demand usage for the past 30 days. We then simulate every
+combination of reservations in the generated category of usage in order to
+identify the best number of each type of Reserved Node to purchase to maximize
+your savings. This check covers recommendations based on partial upfront
+payment option with 1-year or 3-year commitment. This check is not available to
+accounts linked in Consolidated Billing. Recommendations are only available for
+the Paying Account.') , ROW ('Hs4Ma3G260', 'en', 'OpenSearch domains should
+have fine-grained access control enabled', 'Checks if Amazon OpenSearch domains
+have fine-grained access check enabled. This check fails if the fine-grained
+access check is not enabled.') , ROW ('Hs4Ma3G261', 'en', 'Redshift clusters
+should not use the default database name', 'Checks if a Redshift cluster has
+changed the database name from its default value. This check will fail if the
+database name for a Redshift cluster is set to Ã¢Â€ÂœdevÃ¢Â€Â') , ROW ('Hs4Ma3G140',
+'en', 'IAM root user access key should not exist', 'Checks if the root user
+access key is available.') , ROW ('Hs4Ma3G262', 'en', 'S3 buckets should have
+lifecycle policies configured', 'Checks if a lifecycle policy is configured for
+an S3 bucket. This check fails if the lifecycle policy is not configured for an
+S3 bucket.') , ROW ('Hs4Ma3G141', 'en', 'MFA should be enabled for all IAM
+users that have a console password', 'Checks if AWS Multi-Factor Authentication
+(MFA) is enabled for all AWS Identity and Access Management (IAM) users that
+use a console password.') , ROW ('Hs4Ma3G263', 'en', 'Logging of delivery
+status should be enabled for notification messages sent to a topic', 'Checks if
+logging is enabled for the delivery status of notification messages sent to a
+topic for the endpoints. This check fails if the delivery status notification
+for messages is not enabled.') , ROW ('Hs4Ma3G142', 'en', 'Hardware MFA should
+be enabled for the root user', 'Checks if your AWS account is enabled to use
+hardware multi-factor authentication (MFA) device to sign in with root
+credentials.') , ROW ('Hs4Ma3G264', 'en', 'A WAF Regional rule should have at
+least one condition', 'Checks if a WAF Regional rule has at least one
+condition. The check fails if no conditions are present within a rule.') , ROW
+('Hs4Ma3G143', 'en', 'Password policies for IAM users should have strong
+configurations', 'Checks if the account password policy for IAM users uses the
+following recommended configurations: RequireUppercaseCharacters: true,
+RequireLowercaseCharacters: true, RequireSymbols: true, RequireNumbers: true,
+MinimumPasswordLength: 8.') , ROW ('N430c450f2', 'en', 'CloudFront SSL
+Certificate on the Origin Server', 'Checks your origin server for SSL
+certificates that are expired, about to expire, missing, or that use outdated
+encryption. If a certificate is expired, CloudFront responds to requests for
+your content with HTTP status code 502, Bad Gateway. Certificates that were
+encrypted by using the SHA-1 hashing algorithm are being deprecated by web
+browsers such as Chrome and Firefox. Depending on the number of SSL
+certificates that you have associated with your CloudFront distributions, this
+check might add a few cents per month to your bill with your web hosting
+provider, for example, AWS if youre using EC2 or ELB as the origin for your
+CloudFront distribution. This check does not validate your origin certificate
+chain or certificate authorities; you can check these in your CloudFront
+configuration. ') , ROW ('3Njm0DJQO9', 'en', 'RDS Option Groups', 'Checks for
+usage that is more than 80% of the RDS Option Groups Limit. Values are based on
+a snapshot, so your current usage might differ. Limit and usage data can take
+up to 24 hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('tV7YY0l7J9', 'en', 'EBS Provisioned IOPS (SSD) Volume Aggregate IOPS',
+'Checks for usage that is more than 80% of the EBS Provisioned IOPS (SSD)
+Volume Aggregate IOPS Limit. Values are based on a snapshot, so your current
+usage might differ. Limit and usage data can take up to 24 hours to reflect any
+changes. In cases where limits have been recently increased, you may
+temporarily see utilization that exceeds the limit.') , ROW ('vZ2c2W1srf',
+'en', 'Savings Plan', 'Checks your usage of EC2, Fargate, and Lambda over the
+last 30 days and provides Savings Plan purchase recommendations, which allows
+you to commit to a consistent usage amount measured in $/hour for a one or
+three year term in exchange for discounted rates. These are sourced from AWS
+Cost Explorer which can be used to get more detailed recommendation
+information, or to purchase a savings plan. These recommendations should be
+considered an alternative to your RI recommendations and choosing to act fully
+on both sets of recommendations would likely lead to over commitment. This
+check is not available to accounts linked in Consolidated Billing.
+Recommendations are only available for the Paying Account.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: A VPC-enabled Lambda function connected to subnets in a single
-Availability Zone.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-When configuring functions for access to your VPC, choose subnets in multiple
-Availability Zones to ensure high availability.
+Yellow: Optimizing the purchase of Savings Plans can help reduce costs.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_C_o_n_f_i_g_u_r_i_n_g_ _a_ _L_a_m_b_d_a_ _f_u_n_c_t_i_o_n_ _t_o_ _a_c_c_e_s_s_ _r_e_s_o_u_r_c_e_s_ _i_n_ _a_ _V_P_C
-_R_e_s_i_l_i_e_n_c_e_ _i_n_ _A_W_S_ _L_a_m_b_d_a
-') , ROW ('dH7RR0l6J3', 'en', 'EBS General Purpose SSD (gp3) Volume Storage',
-'Checks for usage that is more than 80% of the EBS General Purpose SSD (gp3)
-Volume Storage Limit. Values are based on a snapshot, so your current usage
-might differ. Limit and usage data can take up to 24 hours to reflect any
-changes. In cases where limits have been recently increased, you may
-temporarily see utilization that exceeds the limit.') , ROW ('gI7MM0l7J2',
-'en', 'EBS Provisioned IOPS SSD (io2) Volume Storage', 'Checks for usage that
-is more than 80% of the EBS Provisioned IOPS SSD (io2) Volume Storage Limit.
-Values are based on a snapshot, so your current usage might differ. Limit and
-usage data can take up to 24 hours to reflect any changes. In cases where
-limits have been recently increased, you may temporarily see utilization that
-exceeds the limit.') , ROW ('Cm24dfsM12', 'en', 'Amazon Comprehend
-Underutilized Endpoints', 'Checks the throughput configuration of your
-endpoints. This check alerts you when endpoints are not actively used for real-
-time inference requests. An endpoint that isnÃ¢Â€Â™t used for more than 15
-consecutive days is considered underutilized. All endpoints accrue charges
-based on both the throughput set and the length of time that the endpoint is
-active.
-NNoottee:: This check is automatically refreshed once a day.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: The endpoint is active, but hasnÃ¢Â€Â™t been used for real-time inference
-requests in the past 15 days.
+See the _C_o_s_t_ _E_x_p_l_o_r_e_r page for more detailed and customized recommendations and
+to purchase Savings Plans.
 
-RReeccoommmmeennddeedd AAccttiioonn
-If the endpoint hasnÃ¢Â€Â™t been used in the past 15 days, we recommend that you
-define a scaling policy for the resource by using _A_p_p_l_i_c_a_t_i_o_n_ _A_u_t_o_s_c_a_l_i_n_g_.
-If the endpoint has a scaling policy defined and hasnÃ¢Â€Â™t been used in the past
-30 days, consider deleting the endpoint and using asynchronous inference. For
-more information, see _D_e_l_e_t_i_n_g_ _a_n_ _e_n_d_p_o_i_n_t_ _w_i_t_h_ _A_m_a_z_o_n_ _C_o_m_p_r_e_h_e_n_d.') , ROW
-('Cm24dfsM13', 'en', 'Amazon Comprehend Endpoint Access Risk', 'Checks the AWS
-Key Management Service (AWS KMS) key permissions for an endpoint where the
-underlying model was encrypted by using customer managed keys. If the customer
-managed key is disabled or the key policy was changed to alter the allowed
-permissions for Amazon Comprehend, the endpoint availability might be affected.
-NNoottee:: This check is automatically refreshed multiple times a day. It might take
-a few hours for the latest results to appear.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAlleerrtt CCrriitteerriiaa
-Red: The customer managed key is disabled or the key policy was changed to
-alter the allowed permissions for Amazon Comprehend access.
+Savings Plan _U_s_e_r_ _G_u_i_d_e
+Savings Plan _F_A_Q') , ROW ('Hs4Ma3G254', 'en', 'Application Load Balancer should
+be configured with defensive or strictest desync mitigation mode', 'Checks if
+the Application Load Balancer is configured with defensive or strictest de-sync
+mitigation mode. This check fails if the Application Load Balancer is not
+configured with defensive or strictest desync mitigation mode.') , ROW
+('Hs4Ma3G133', 'en', 'IAM customer managed policies should not allow decryption
+actions on all KMS keys', 'Checks if the default version of IAM customer
+managed policies allow principals to use the AWS Key Management Service (KMS)
+decryption actions on all resources. This check fails if kms:Decrypt or kms:
+ReEncryptFrom actions are allowed on all KMS keys. The check evaluates both
+attached and unattached customer managed policies. It does not check inline
+policies or AWS managed policies.') , ROW ('ty3xfcdfMr', 'en', 'Route 53
+Reusable Delegation Sets', 'Checks for usage that is more than 80% of the Route
+53 Reusable Delegation Sets Limit per account. Values are based on a snapshot,
+so your current usage might differ. Limit and usage data can take up to 24
+hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('Hs4Ma3G255', 'en', 'Classic Load Balancer should be configured with defensive
+or strictest desync mitigation mode', 'Checks if the Classic Load Balancer is
+configured defensive or strictest desync mitigation mode. This check will fail
+if the Application Load Balancer is not configured with defensive strictest
+mitigation Desync mitigation mode.') , ROW ('Hs4Ma3G134', 'en', 'IAM principals
+should not have IAM inline policies that allow decryption actions on all KMS
+keys', 'Checks if the inline policies embedded in your IAM principals (Role/
+User/Group) allow the AWS Key Management Service (KMS) decryption actions on
+all KMS keys. This check fails if kms:Decrypt or kms:ReEncryptFrom actions are
+allowed on all KMS keys in an inline policy.') , ROW ('Hs4Ma3G256', 'en',
+'Kinesis streams should be encrypted at rest', 'Checks if Kinesis streams are
+encrypted at rest with server-side encryption. This check fails if a Kinesis
+stream is not encrypted at rest with server-side encryption.') , ROW
+('Hs4Ma3G135', 'en', 'AWS KMS keys should not be deleted unintentionally',
+'Checks whether AWS Key Management Service (KMS) keys are scheduled for
+deletion. The check fails if a KMS key is scheduled for deletion.') , ROW
+('gfZAn3W7wl', 'en', 'RDS DB Security Groups', 'Checks for usage that is more
+than 80% of the RDS DB Security Groups Limit. Values are based on a snapshot,
+so your current usage might differ. Limit and usage data can take up to 24
+hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('Hs4Ma3G257', 'en', 'Network Firewall policies should have at least one rule
+group associated', 'Checks if a Network Firewall policy has any stateful or
+stateless rule groups associated. This check fails if stateless or stateful
+rule groups are not assigned.') , ROW ('Hs4Ma3G136', 'en', 'Amazon SQS queues
+should be encrypted at rest', 'Checks if Amazon SQS queues are encrypted at
+rest.') , ROW ('Hs4Ma3G258', 'en', 'The default stateless action for Network
+Firewall policies should be drop or forward for full packets', 'Checks if the
+default stateless action for full packets for a Network Firewall policy is drop
+or forward. The check passes if Drop or Forward is selected, and fails if Pass
+is selected.') , ROW ('Hs4Ma3G137', 'en', 'IAM policies should not allow full
+"*" administrative privileges', 'Checks if the default version of AWS Identity
+and Access Management (IAM) policies (also known as customer managed policies)
+do not have administrator access with a statement that has "Effect": "Allow"
+with "Action": "*" over "Resource": "*". It only assesses for the Customer
+Managed Policies that you created, but not inline and AWS Managed Policies.') ,
+ROW ('Hs4Ma3G259', 'en', 'The default stateless action for Network Firewall
+policies should be drop or forward for fragmented packets', 'Checks if a
+Network Firewall policy has drop or forward as the default stateless action for
+fragmented packets. The check passes if Drop or Forward is selected, and fails
+if Pass is selected.') , ROW ('Hs4Ma3G138', 'en', 'IAM users should not have
+IAM policies attached', 'Checks that none of your IAM users have policies
+attached. Instead, IAM users must inherit permissions from IAM groups or
+roles.') , ROW ('7qGXsKIUw', 'en', 'ELB Connection Draining', 'Checks for load
+balancers that do not have connection draining enabled. When connection
+draining is not enabled and you remove (deregister) an Amazon EC2 instance from
+a load balancer, the load balancer stops routing traffic to that instance and
+closes the connection. When connection draining is enabled, the load balancer
+stops sending new requests to the deregistered instance but keeps the
+connection open to serve active requests.
 
-RReeccoommmmeennddeedd AAccttiioonn
-If the customer managed key was disabled, we recommend that you enable it. For
-more information, see _E_n_a_b_l_i_n_g_ _k_e_y_s. If the key policy was altered and you want
-to keep using the endpoint, we recommend that you update the KMS key policy.
-For more information, see _C_h_a_n_g_i_n_g_ _a_ _k_e_y_ _p_o_l_i_c_y.') , ROW ('Wxdfp4B1L1', 'en',
-'AWS Well-Architected high risk issues for cost optimization', 'Checks for high
-risk issues (HRIs) for your workloads in the cost optimization pillar. This
-check is based on your AWS-Well Architected reviews. Your check results depend
-on whether you completed the workload evaluation with AWS Well-Architected.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-AAlleerrtt CCrriitteerriiaa
-Red: At least one active high risk issue was identified in the cost
-optimization pillar for AWS Well-Architected.') , ROW ('Wxdfp4B1L2', 'en', 'AWS
-Well-Architected high risk issues for performance efficiency', 'Checks for high
-risk issues (HRIs) for your workloads in the performance pillar. This check is
-based on your AWS-Well Architected reviews. Your check results depend on
-whether you completed the workload evaluation with AWS Well-Architected.
+Yellow: Connection draining is not enabled for a load balancer.
 
-AAlleerrtt CCrriitteerriiaa
-Red: At least one active high risk issue was identified in the performance
-pillar for AWS Well-Architected.') , ROW ('Wxdfp4B1L3', 'en', 'AWS Well-
-Architected high risk issues for security', 'Checks for high risk issues (HRIs)
-for your workloads in the security pillar. This check is based on your AWS-Well
-Architected reviews. Your check results depend on whether you completed the
-workload evaluation with AWS Well-Architected.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Red: At least one active high risk issue was identified in the security pillar
-for AWS Well-Architected.') , ROW ('Wxdfp4B1L4', 'en', 'AWS Well-Architected
-high risk issues for reliability', 'Checks for high risk issues (HRIs) for your
-workloads in the Reliability pillar. This check is based on your AWS-Well
-Architected reviews. Your check results depend on whether you completed the
-workload evaluation with AWS Well-Architected.
+Enable connection draining for the load balancer. For more information, see
+_C_o_n_n_e_c_t_i_o_n_ _D_r_a_i_n_i_n_g and _E_n_a_b_l_e_ _o_r_ _D_i_s_a_b_l_e_ _C_o_n_n_e_c_t_i_o_n_ _D_r_a_i_n_i_n_g_ _f_o_r_ _Y_o_u_r_ _L_o_a_d
+_B_a_l_a_n_c_e_r.
 
-AAlleerrtt CCrriitteerriiaa
-Red: At least one active high risk issue was identified in the reliability
-pillar for AWS Well-Architected.') , ROW ('Qsdfp3A4L1', 'en', 'Amazon EC2
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_E_l_a_s_t_i_c_ _L_o_a_d_ _B_a_l_a_n_c_i_n_g_ _C_o_n_c_e_p_t_s') , ROW ('Hs4Ma3G139', 'en', 'IAM users access
+keys should be rotated every 90 days or less', 'Checks if the active access
+keys are rotated within 90 days.') , ROW ('Hs4Ma3G230', 'en', 'S3 bucket server
+access logging should be enabled', 'Checks if an Amazon S3 Bucket has server
+access logging enabled to a chosen target bucket.') , ROW ('Hs4Ma3G231', 'en',
+'Stateless network firewall rule group should not be empty', 'Checks if a
+Stateless Network Firewall Rule Group contains rules. The rule will fail if
+there are no rules in a Stateless Network Firewall Rule Group.') , ROW
+('Hs4Ma3G110', 'en', 'CloudTrail should have encryption at-rest enabled',
+'Checks whether AWS CloudTrail is configured to use the server-side encryption
+(SSE) AWS Key Management Service (AWS KMS) key encryption. The check will pass
+if the KmsKeyId is defined.') , ROW ('UUDvOa5r34', 'en', 'RDS Reserved
+Instances', 'Checks for usage that is more than 80% of the RDS Reserved
+Instances Limit. Values are based on a snapshot, so your current usage might
+differ. Limit and usage data can take up to 24 hours to reflect any changes. In
+cases where limits have been recently increased, you may temporarily see
+utilization that exceeds the limit.') , ROW ('Qsdfp3A4L1', 'en', 'Amazon EC2
 instances over-provisioned for Microsoft SQL Server', 'Checks your Amazon
 Elastic Compute Cloud (Amazon EC2) instances that are running SQL Server in the
 past 24 hours. An SQL Server database has a compute capacity limit for each
 instance. An instance with SQL Server Standard edition can use up to 48 vCPUs.
 An instance with SQL Server Web can use up to 32 vCPUs. This check alerts you
 if an instance exceeds this vCPU limit.If your instance is over-provisioned,
 you pay full price without realizing an improvement in performance. You can
 manage the number and size of your instances to help lower costs. Estimated
 monthly savings are calculated by using the same instance family with the
 maximum number of vCPUs that an SQL Server instance can use and the On-Demand
 pricing. Actual savings will vary if youÃ¢Â€Â™re using Reserved Instances (RI) or
 if the instance isnÃ¢Â€Â™t running for a full day.
 
-AAlleerrtt CCrriitteerriiaa
+****** AAlleerrtt CCrriitteerriiaa ******
+
 Red: An instance with SQL Server Standard edition has more than 48 vCPUs.
 Red: An instance with SQL Server Web edition has more than 32 vCPUs.
 
-RReeccoommmmeennddeedd AAccttiioonn
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
 For SQL Server Standard edition, consider changing to an instance in the same
 instance family with 48 vCPUs. For SQL Server Web edition, consider changing to
 an instance in the same instance family with 32 vCPUs. If it is memory
 intensive, consider changing to memory optimized R5 instances. For more
 information, see _B_e_s_t_ _P_r_a_c_t_i_c_e_s_ _f_o_r_ _D_e_p_l_o_y_i_n_g_ _M_i_c_r_o_s_o_f_t_ _S_Q_L_ _S_e_r_v_e_r_ _o_n_ _A_m_a_z_o_n
 _E_C_2_.
 
-AAddddiittiioonnaall RReessoouurrcceess
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
 _M_i_c_r_o_s_o_f_t_ _S_Q_L_ _S_e_r_v_e_r_ _o_n_ _A_W_S
 You can use _L_a_u_n_c_h_ _W_i_z_a_r_d to simplify your SQL Server deployment on EC2.
-') , ROW ('Qsdfp3A4L2', 'en', 'Amazon EC2 instances consolidation for Microsoft
-SQL Server', 'Checks your Amazon Elastic Compute Cloud (Amazon EC2) instances
-that are running SQL Server in the past 24 hours. This check alerts you if your
-instance has less than the minimum number of SQL Server licenses. From the
-Microsoft SQL Server Licensing Guide, you are paying 4 vCPU licenses even if an
-instance has only 1 or 2 vCPUs. You can consolidate smaller SQL Server
-instances to help lower costs.
+') , ROW ('oQ7TT0l7J9', 'en', 'IAM Roles', 'Checks for usage that is more than
+80% of the IAM Roles Limit. Values are based on a snapshot, so your current
+usage might differ. Limit and usage data can take up to 24 hours to reflect any
+changes. In cases where limits have been recently increased, you may
+temporarily see utilization that exceeds the limit.') , ROW ('Hs4Ma3G229',
+'en', 'CloudFront distributions should encrypt traffic to custom origins',
+'Checks if CloudFront distributions are encrypting traffic to custom origins.
+This check fails for a CloudFront distribution whose origin protocol policy
+allows http-only or if it is match-viewer and the viewer protocol policy is
+allow-all. ') , ROW ('Hs4Ma3G108', 'en', 'CloudTrail trails should be
+integrated with Amazon CloudWatch Logs', 'Checks if AWS CloudTrail trails are
+configured to send logs to Amazon CloudWatch Logs.') , ROW ('Hs4Ma3G109', 'en',
+'CloudTrail log file validation should be enabled', 'Checks if CloudTrail log
+file validation is enabled.') , ROW ('jL7PP0l7J9', 'en', 'VPC', 'Checks for
+usage that is more than 80% of the VPC Limit. Values are based on a snapshot,
+so your current usage might differ. Limit and usage data can take up to 24
+hours to reflect any changes. In cases where limits have been recently
+increased, you may temporarily see utilization that exceeds the limit.') , ROW
+('Hs4Ma3G221', 'en', 'OpenSearch domains should have audit logging enabled',
+'Checks if Amazon OpenSearch Service domains have audit logging enabled.') ,
+ROW ('Hs4Ma3G100', 'en', 'Amazon SageMaker notebook instances should not have
+direct internet access', 'Checks if direct internet access is disabled for an
+Amazon SageMaker notebook instance by examining the DirectInternetAccess field
+is disabled for an Amazon SageMaker notebook instance.') , ROW ('Hs4Ma3G222',
+'en', 'OpenSearch domain error logging to CloudWatch Logs should be enabled',
+'Checks if Amazon OpenSearch domains are configured to send error logs to
+CloudWatch Logs. This check fails if error logging to CloudWatch is not enabled
+for a domain.') , ROW ('Hs4Ma3G101', 'en', 'Amazon Elastic MapReduce cluster
+master nodes should not have public IP addresses', 'Checks if master nodes on
+EMR clusters have public IP addresses.') , ROW ('Hs4Ma3G223', 'en', 'OpenSearch
+domains should encrypt data sent between nodes', 'Checks if Amazon OpenSearch
+domains have node-to-node encryption enabled. This check fails if node-to-node
+encryption is disabled on the domain.') , ROW ('Hs4Ma3G102', 'en', 'Connections
+to Amazon Redshift clusters should be encrypted in transit', 'Checks if
+connections to Amazon Redshift clusters are required to use encryption in
+transit. The check fails if the Amazon Redshift cluster parameter require_SSL
+is not set to 1.') , ROW ('cX3c2R1chu', 'en', 'Amazon EC2 Reserved Instances
+Optimization', 'A significant part of using AWS involves balancing your
+Reserved Instance (RI) usage and your On-Demand instance usage. We provide
+recommendations on which RIs will help reduce costs incurred from using On-
+Demand instances.
+AWS generates these recommendations by analyzing your On-Demand usage for the
+past 30 days, and then categorizing the usage into eligible categories for
+reservations. We then simulate every combination of reservations in the
+generated category of usage in order to identify the best number of each type
+of RI to purchase to maximize your savings. This check covers recommendations
+based on Standard Reserved Instances with partial upfront payment option. This
+check is not available to accounts linked in Consolidated Billing.
+Recommendations are only available for the Paying Account.
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: An instance with SQL Server has less than 4 vCPUs.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-RReeccoommmmeennddeedd AAccttiioonn
-Consider consolidating smaller SQL Server workloads into instances with at
-least 4 vCPUs.
+Yellow: Optimizing the use of partial upfront RIs can help reduce costs.
 
-AAddddiittiioonnaall RReessoouurrcceess
-_M_i_c_r_o_s_o_f_t_ _S_Q_L_ _S_e_r_v_e_r_ _o_n_ _A_W_S
-_M_i_c_r_o_s_o_f_t_ _L_i_c_e_n_s_i_n_g_ _o_n_ _A_W_S
-_M_i_c_r_o_s_o_f_t_ _S_Q_L_ _S_e_r_v_e_r_ _L_i_c_e_n_s_i_n_g_ _G_u_i_d_e
-') , ROW ('Qsdfp3A4L3', 'en', 'Amazon EC2 instances with Microsoft SQL Server
-end of support', 'Checks the SQL Server versions for Amazon Elastic Compute
-Cloud (Amazon EC2) instances running in the past 24 hours. This check alerts
-you if the versions are near or have reached the end of support. Each SQL
-Server version offers 10 years of support, including 5 years of mainstream
-support and 5 years of extended support. After the end of support, the SQL
-Server version wonÃ¢Â€Â™t receive regular security updates. Running applications
-with unsupported SQL Server versions can bring security or compliance risks.
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+See the _C_o_s_t_ _E_x_p_l_o_r_e_r page for more detailed and customized recommendations.
+Additionally, refer to the _b_u_y_i_n_g_ _g_u_i_d_e to understand how to purchase RIs and
+the options available.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+Information on RIs and how they can save you money can be found _h_e_r_e.
+For more information on this recommendation, see _R_e_s_e_r_v_e_d_ _I_n_s_t_a_n_c_e_ _O_p_t_i_m_i_z_a_t_i_o_n
+_C_h_e_c_k_ _Q_u_e_s_t_i_o_n_s in the Trusted Advisor FAQs.') , ROW ('Hs4Ma3G224', 'en',
+'OpenSearch domains should be in a VPC', 'Checks Amazon OpenSearch Service
+domains are in an Amazon Virtual Private Cloud (VPC).') , ROW ('Hs4Ma3G103',
+'en', 'Amazon Redshift clusters should prohibit public access', 'Checks if
+Amazon Redshift clusters are publicly accessible. It evaluates the
+publiclyAccessible field in the cluster configuration item.') , ROW
+('Hs4Ma3G225', 'en', 'OpenSearch domains should have encryption at rest
+enabled', 'Checks if Amazon OpenSearch domains have encryption-at-rest
+configuration enabled. The check fails if encryption at rest is not enabled.')
+, ROW ('Hs4Ma3G104', 'en', 'Redshift clusters should use enhanced VPC routing',
+'Checks if a Redshift cluster has EnhancedVpcRouting enabled.') , ROW
+('Hs4Ma3G226', 'en', 'Amazon EC2 instances launched using Auto Scaling group
+launch configurations should not have Public IP addresses', 'Checks if Amazon
+EC2 Auto Scaling groups have public IP addresses enabled using launch
+configurations.') , ROW ('Hs4Ma3G105', 'en', 'Amazon Redshift should have
+automatic upgrades to major versions enabled', 'Checks if an Amazon Redshift
+cluster is configured with automatic upgrades to major versions.') , ROW
+('Hs4Ma3G227', 'en', 'CloudFront distributions should use custom SSL/TLS
+certificates', 'Checks if CloudFront distributions are using the default SSL/
+TLS certificate CloudFront provides instead of a custom one. This check fails
+for a CloudFront distribution if it uses the default SSL/TLS certificate.') ,
+ROW ('Hs4Ma3G106', 'en', 'Amazon Redshift clusters should have audit logging
+enabled', 'Checks if an Amazon Redshift cluster has audit logging enabled.') ,
+ROW ('Hs4Ma3G228', 'en', 'CloudFront distributions should use SNI to serve
+HTTPS requests', 'Checks if Amazon CloudFront distributions are using a custom
+SSL/TLS certificate and are configured to use SNI to serve HTTPS requests as
+opposed to dedicated IP address.') , ROW ('Hs4Ma3G107', 'en', 'CloudFront
+distributions should require encryption in transit', 'Checks if an Amazon
+CloudFront distribution requires viewers to use HTTPS directly, or if it uses
+redirection. The check fails if ViewerProtocolPolicy is set to allow-all for
+defaultCacheBehavior or for cacheBehaviors.') , ROW ('S45wrEXrLz', 'en', 'VPN
+Tunnel Redundancy', 'Checks the number of tunnels that are active for each of
+your VPNs. A VPN should have two tunnels configured at all times to provide
+redundancy in case of outage or planned maintenance of the devices at the AWS
+endpoint. For some hardware, only one tunnel is active at a time (see the
+_A_m_a_z_o_n_ _V_i_r_t_u_a_l_ _P_r_i_v_a_t_e_ _C_l_o_u_d_ _N_e_t_w_o_r_k_ _A_d_m_i_n_i_s_t_r_a_t_o_r_ _G_u_i_d_e). If a VPN has no
+active tunnels, charges for the VPN might still apply.') , ROW ('Hs4Ma3G241',
+'en', 'Secrets should not be passed as container environment variable', 'Checks
+if the container environment variables includes the following keys -
+AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, or ECS_ENGINE_AUTH_DATA.') , ROW
+('Hs4Ma3G120', 'en', 'Stopped EC2 instances should be removed after a specified
+time period', 'Checks if any EC2 instances have been stopped for more than the
+allowed number of days. An EC2 instance fails this check if it is stopped for
+longer than the maximum allowed time period, which by default is 30 days.') ,
+ROW ('Hs4Ma3G242', 'en', 'Amazon ECR private repositories should have image
+scanning enabled', 'Checks if a private ECR repository has image scanning
+enabled. This check fails if a private ECR repository has image scanning
+disabled. Amazon ECR image scanning helps in identifying software
+vulnerabilities in your container images. Amazon ECR uses the Common
+Vulnerabilities and Exposures (CVEs) database from the open-source Clair
+project and provides a list of scan findings. Enabling image scanning on ECR
+repositories adds a layer of verification for the integrity and safety of the
+images being stored.') , ROW ('Hs4Ma3G121', 'en', 'EBS default encryption
+should be enabled', 'Checks if Amazon Elastic Block Store (EBS) encryption is
+enabled by default. The check fails if EBS default encryption is not enabled.')
+, ROW ('Hs4Ma3G119', 'en', 'EBS volumes should be attached to EC2 instances',
+'Checks if EBS volumes are attached to EC2 instances.') , ROW ('4g3Nt5M1Th',
+'en', 'AWS Direct Connect Virtual Interface Redundancy', 'Checks for virtual
+private gateways with Direct Connect virtual interfaces (VIFs) that are not
+configured on at least two Direct Connect connections. Connectivity to your
+virtual private gateway should have multiple virtual interfaces configured
+across multiple Direct Connect connections and locations to provide redundancy
+in case a device or location is unavailable.
+****** NNoottee:: ******
+Results for this check are automatically refreshed several times daily, and
+refresh requests are not allowed. It might take a few hours for changes to
+appear.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: A virtual private gateway has less than two virtual interfaces, or the
+interfaces are not configured to multiple Direct Connect connections.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Configure at least two virtual interfaces that are configured to two Direct
+Connect connections to protect against device or location unavailability. See
+_C_r_e_a_t_e_ _a_ _V_i_r_t_u_a_l_ _I_n_t_e_r_f_a_c_e_.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_G_e_t_t_i_n_g_ _S_t_a_r_t_e_d_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t
+_A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t_ _F_A_Q_s
+_W_o_r_k_i_n_g_ _W_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t_ _V_i_r_t_u_a_l_ _I_n_t_e_r_f_a_c_e_s') , ROW ('Hs4Ma3G232', 'en',
+'RDS Database Clusters should use a custom administrator username', 'Checks if
+an RDS database cluster has changed the admin username from its default value.
+This rule will fail if the admin username is set to the default value.') , ROW
+('Hs4Ma3G111', 'en', 'CloudTrail should be enabled and configured with at least
+one multi-region trail', 'Checks that there is at least one multi-region AWS
+CloudTrail trail.') , ROW ('Hs4Ma3G233', 'en', 'RDS database instances should
+use a custom administrator username', 'Checks if an Amazon Relational Database
+Service (Amazon RDS) database instance has changed the admin username from its
+default value. This rule will only run on RDS database instances. The rule will
+fail if the admin username is set to the default value.') , ROW ('Hs4Ma3G112',
+'en', 'Secrets Manager secrets should be rotated within a specified number of
+days', 'Checks if your secrets have rotated at least once within 90 days.') ,
+ROW ('Hs4Ma3G234', 'en', 'AWS CodeBuild S3 Logs should be encrypted', 'Checks
+if a AWS CodeBuild project configured with Amazon S3 Logs has encryption
+enabled for its logs.') , ROW ('Hs4Ma3G113', 'en', 'Secrets Manager secrets
+configured with automatic rotation should rotate successfully', 'Checks if an
+AWS Secrets Manager secret rotated successfully based on the rotation schedule.
+The check fails if RotationOccurringAsScheduled is false. The check does not
+evaluate secrets that do not have rotation configured.') , ROW ('Hs4Ma3G235',
+'en', 'Amazon ECR private repositories should have tag immutability enabled',
+'Checks if a private ECR repository has tag immutability enabled. This check
+fails if a private ECR repository has tag immutability disabled.') , ROW
+('Hs4Ma3G114', 'en', 'Remove unused Secrets Manager secrets', 'Checks if your
+secrets have been accessed within a specified number of days. The default value
+is 90 days. Secrets that have not been accessed even once within the number
+days you define, fail this check.') , ROW ('Hs4Ma3G236', 'en', 'Amazon ECS Task
+Definitions should not share the hosts process namespace', 'Checks if Amazon
+ECS Task Definitions are configured to share a hosts process namespace with its
+containers.') , ROW ('Hs4Ma3G115', 'en', 'Secrets Manager secrets should have
+automatic rotation enabled', 'Checks if a secret stored in AWS Secrets Manager
+is configured to rotate automatically.') , ROW ('jEECYg2YVU', 'en', 'RDS DB
+Parameter Groups', 'Checks for usage that is more than 80% of the RDS DB
+Parameter Groups Limit. Values are based on a snapshot, so your current usage
+might differ. Limit and usage data can take up to 24 hours to reflect any
+changes. In cases where limits have been recently increased, you may
+temporarily see utilization that exceeds the limit.') , ROW ('Hs4Ma3G237',
+'en', 'Amazon ECS Containers should run as non-privileged', 'Checks if the
+Privileged parameter in the container definition of Amazon ECS Task Definitions
+is set to true.') , ROW ('Hs4Ma3G116', 'en', 'EBS snapshots should not be
+public, determined by the ability to be restorable by anyone', 'Checks if
+Amazon Elastic Block Store snapshots are not publicly restorable.') , ROW
+('Hs4Ma3G238', 'en', 'Amazon ECS Containers should only have read-only access
+to its root filesystems', 'Checks if ECS Containers are limited to read-only
+access to its mounted root filesystems.') , ROW ('Hs4Ma3G117', 'en', 'Attached
+EBS volumes should be encrypted at-rest', 'Checks if the EBS volumes that are
+in an attached state are encrypted.') , ROW ('dYWBaXaaMM', 'en', 'RDS Subnet
+Groups', 'Checks for usage that is more than 80% of the RDS Subnet Groups
+Limit. Values are based on a snapshot, so your current usage might differ.
+Limit and usage data can take up to 24 hours to reflect any changes. In cases
+where limits have been recently increased, you may temporarily see utilization
+that exceeds the limit.') , ROW ('Hs4Ma3G118', 'en', 'The VPC default security
+group should not allow inbound and outbound traffic', 'Checks that the default
+security group of a VPC does not allow inbound or outbound traffic.') , ROW
+('MDBdfsQ401', 'en', 'Amazon MemoryDB Multi-AZ clusters', 'Checks for MemoryDB
+clusters that deploy in a single Availability Zone (AZ). This check alerts you
+if Multi-AZ is inactive in a cluster.
+
+Deployments in multiple AZs enhance MemoryDB cluster availability by
+asynchronously replicating to read-only replicas in a different AZ. When
+planned cluster maintenance occurs, or a primary node is unavailable, MemoryDB
+automatically promotes a replica to primary. This failover allows cluster write
+operations to resume, and doesnt require an administrator to intervene.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Green: Multi-AZ is active in the cluster.') , ROW ('0Xc6LMYG8P', 'en', 'EC2 On-
+Demand Instances', 'Checks for usage that is more than 80% of the EC2 On-Demand
+Instances Limit. Values are based on a snapshot, so your current usage might
+differ. Limit and usage data can take up to 24 hours to reflect any changes. In
+cases where limits have been recently increased, you may temporarily see
+utilization that exceeds the limit.') , ROW ('Bh2xRR2FGH', 'en', 'Amazon EC2 to
+EBS Throughput Optimization', 'Checks for Amazon EBS volumes whose performance
+might be affected by the maximum throughput capability of the Amazon EC2
+instance they are attached to. To optimize performance, you should ensure that
+the maximum throughput of an EC2 instance is greater than the aggregate maximum
+throughput of the attached EBS volumes. This check computes the total EBS
+volume throughput for each five-minute period in the preceding day (UTC) for
+each EBS-optimized instance and alerts you if usage in more than half of those
+periods was greater than 95% of the maximum throughput of the EC2 instance.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: In the preceding day (UTC), the aggregate throughput (megabytes/sec) of
+the EBS volumes attached to the EC2 instance exceeded 95% of the published
+throughput between the instance and the EBS volumes more than 50% of time.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Compare the maximum throughput of your EBS volumes (see _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e
+_T_y_p_e_s) with the maximum throughput of the EC2 instance they are attached to
+(see _I_n_s_t_a_n_c_e_ _T_y_p_e_s_ _T_h_a_t_ _S_u_p_p_o_r_t_ _E_B_S_ _O_p_t_i_m_i_z_a_t_i_o_n). Consider attaching your
+volumes to an instance that supports higher throughput to EBS for optimal
+performance.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e_ _T_y_p_e_s
+_A_m_a_z_o_n_ _E_B_S_-_O_p_t_i_m_i_z_e_d_ _I_n_s_t_a_n_c_e_s
+_M_o_n_i_t_o_r_i_n_g_ _t_h_e_ _S_t_a_t_u_s_ _o_f_ _Y_o_u_r_ _V_o_l_u_m_e_s
+_A_t_t_a_c_h_i_n_g_ _a_n_ _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e_ _t_o_ _a_n_ _I_n_s_t_a_n_c_e
+_D_e_t_a_c_h_i_n_g_ _a_n_ _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e_ _f_r_o_m_ _a_n_ _I_n_s_t_a_n_c_e
+_D_e_l_e_t_i_n_g_ _a_n_ _A_m_a_z_o_n_ _E_B_S_ _V_o_l_u_m_e ') , ROW ('ECHdfsQ402', 'en', 'Amazon ElastiCache
+Multi-AZ clusters', 'Checks for ElastiCache clusters that deploy in a single
+Availability Zone (AZ). This check alerts you if Multi-AZ is inactive in a
+cluster.
+
+Deployments in multiple AZs enhance ElastiCache cluster availability by
+asynchronously replicating to read-only replicas in a different AZ. When
+planned cluster maintenance occurs, or a primary node is unavailable,
+ElastiCache automatically promotes a replica to primary. This failover allows
+cluster write operations to resume, and doesnt require an administrator to
+intervene.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Green: Multi-AZ is active in the cluster.') , ROW ('Hs4Ma3G207', 'en', 'EC2
+subnets should not automatically assign public IP addresses', 'Checks if the
+assignment of public IPs in Amazon Virtual Private Cloud (VPC) subnets have the
+MapPublicIpOnLaunch set to FALSE. The check will pass if the flag is set to
+FALSE.') , ROW ('Hs4Ma3G208', 'en', 'EC2 instances should not use multiple
+ENIs', 'Checks to see if Amazon EC2 instance uses multiple ENI/EFA. This check
+will pass if single network adapters is used.') , ROW ('Hs4Ma3G209', 'en',
+'Unused Network Access Control Lists should be removed', 'Checks to see if
+there are any NACLs (Network Access Control List) that are unused. The check
+will check the item configuration of the resource AWS::EC2::NetworkAcl and
+determine the relationships of the NACL.') , ROW ('iH7PP0l7J9', 'en', 'EC2
+Reserved Instance Leases', 'Checks for usage that is more than 80% of the EC2
+Reserved Instance Leases Limit. Values are based on a snapshot, so your current
+usage might differ. Limit and usage data can take up to 24 hours to reflect any
+changes. In cases where limits have been recently increased, you may
+temporarily see utilization that exceeds the limit.') , ROW ('Hs4Ma3G200',
+'en', 'CloudFront distributions should have a default root object configured',
+'Checks if an Amazon CloudFront distribution is configured to return a specific
+object that is the default root object. The check fails if the CloudFront
+distribution does not have a default root object configured.') , ROW
+('Hs4Ma3G201', 'en', 'CloudFront distributions should have WAF enabled',
+'Checks to see if Amazon CloudFront distributions are associated with either
+WAF or WAFv2 web ACLs. The check fails if a CloudFront distribution is not
+associated with a web ACL.') , ROW ('Hs4Ma3G202', 'en', 'API Gateway REST API
+cache data should be encrypted at rest', 'Checks if all methods in Amazon API
+Gateway REST API stages that have cache enabled are encrypted. The check fails
+if any method in API Gateway REST API stage is configured to cache and the
+cache is not encrypted.') , ROW ('Hs4Ma3G203', 'en', 'Amazon Elasticsearch
+Service domains should have audit logging enabled', 'This check checks whether
+Amazon Elasticsearch Service domains have audit logging enabled. This check
+fails if an Amazon Elasticsearch Service domain does not have audit logging
+enabled.') , ROW ('Hs4Ma3G204', 'en', 'Security groups should not allow
+unrestricted access to ports with high risk', 'Checks if unrestricted incoming
+traffic for the security groups is accessible to the specified ports [3389, 20,
+23, 110, 143, 3306, 8080, 1433, 9200, 9300, 25, 445, 135, 21, 1434, 4333, 5432,
+5500, 5601, 22 ] that have the highest risk. This check passes when none of the
+rules in a security group allow ingress traffic from 0.0.0.0/0 for the listed
+ports.') , ROW ('Hs4Ma3G205', 'en', 'Classic Load Balancers with HTTPS/SSL
+listeners should use a predefined security policy that has strong
+configuration', 'Checks if your Classic Load Balancer SSL listeners use the
+predefined policy ELBSecurityPolicy-TLS-1-2-2017-01. The check fails if the
+Classic Load Balancer SSL listeners do not use the predefined policy
+ELBSecurityPolicy-TLS-1-2-2017-01.') , ROW ('51fC20e7I2', 'en', 'Amazon Route
+53 Latency Resource Record Sets', 'Checks for Amazon Route 53 latency record
+sets that are configured inefficiently. To allow Amazon Route 53 to route
+queries to the region with the lowest network latency, you should create
+latency resource record sets for a particular domain name (such as example.com)
+in different regions. If you create only one latency resource record set for a
+domain name, all queries are routed to one region, and you pay extra for
+latency-based routing without getting the benefits. Hosted zones created by AWS
+services wonÃ¢Â€Â™t appear in your check results.') , ROW ('Hs4Ma3G206', 'en',
+'Amazon EC2 should be configured to use VPC endpoints that are created for the
+Amazon EC2 service', 'Checks if a service endpoint for Amazon EC2 is created
+for each VPC. The check fails if a VPC does not have a VPC endpoint created for
+the Amazon EC2 service.') , ROW ('hJ7NN0l7J9', 'en', 'SES Daily Sending Quota',
+'Checks for usage that is more than 80% of the SES Daily Sending Quota Limit.
+Values are based on a snapshot, so your current usage might differ. Limit and
+usage data can take up to 24 hours to reflect any changes. In cases where
+limits have been recently increased, you may temporarily see utilization that
+exceeds the limit.') , ROW ('dH7RR0l6J3', 'en', 'EBS General Purpose SSD (gp3)
+Volume Storage', 'Checks for usage that is more than 80% of the EBS General
+Purpose SSD (gp3) Volume Storage Limit. Values are based on a snapshot, so your
+current usage might differ. Limit and usage data can take up to 24 hours to
+reflect any changes. In cases where limits have been recently increased, you
+may temporarily see utilization that exceeds the limit.') , ROW ('dH7RR0l6J9',
+'en', 'EBS General Purpose SSD (gp2) Volume Storage', 'Checks for usage that is
+more than 80% of the EBS General Purpose SSD (gp2) Volume Storage Limit. Values
+are based on a snapshot, so your current usage might differ. Limit and usage
+data can take up to 24 hours to reflect any changes. In cases where limits have
+been recently increased, you may temporarily see utilization that exceeds the
+limit.') , ROW ('zXCkfM1nI3', 'en', 'IAM Use', 'This check is intended to
+discourage the use of root access by checking for existence of at least one IAM
+user. You may ignore the alert if you are following the best practice of
+centralizing identities and configuring users in an _e_x_t_e_r_n_a_l_ _i_d_e_n_t_i_t_y_ _p_r_o_v_i_d_e_r
+or _A_W_S_ _S_i_n_g_l_e_ _S_i_g_n_-_O_n. ') , ROW ('8M012Ph3U5', 'en', 'AWS Direct Connect
+Location Redundancy', 'Checks for regions with one or more AWS Direct Connect
+connections and only one AWS Direct Connect location. Connectivity to your AWS
+resources should have Direct Connect connections configured to different Direct
+Connect locations to provide redundancy in case a location is unavailable.
+****** NNoottee:: ******
+Results for this check are automatically refreshed several times daily, and
+refresh requests are not allowed. It might take a few hours for changes to
+appear.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: The Direct Connect connections in the region are not configured to
+different locations.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Configure a Direct Connect connection that uses a different Direct Connect
+location to protect against location unavailability. For more information, see
+_G_e_t_t_i_n_g_ _S_t_a_r_t_e_d_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t.
+
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
+_G_e_t_t_i_n_g_ _S_t_a_r_t_e_d_ _w_i_t_h_ _A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t
+_A_W_S_ _D_i_r_e_c_t_ _C_o_n_n_e_c_t_ _F_A_Q_s') , ROW ('Hs4Ma3G220', 'en', 'Connections to OpenSearch
+domains should be encrypted using TLS 1.2', 'Checks if connections to
+OpenSearch domains are required to use TLS 1.2. The check fails if the
+OpenSearch domain TLSSecurityPolicy is not Policy-Min-TLS-1-2-2019-07.') , ROW
+('Hs4Ma3G218', 'en', 'CodeBuild project environments should not have privileged
+mode enabled', 'Checks if an AWS CodeBuild project environment has privileged
+mode enabled.') , ROW ('Yw2K9puPzl', 'en', 'IAM Password Policy', 'Checks the
+password policy for your account and warns when a password policy is not
+enabled, or if password content requirements have not been enabled. Password
+content requirements increase the overall security of your AWS environment by
+enforcing the creation of strong user passwords. When you create or change a
+password policy, the change is enforced immediately for new users but does not
+require existing users to change their passwords. ') , ROW ('Hs4Ma3G219', 'en',
+'Amazon Redshift clusters should not use the default Admin username', 'Checks
+if a Redshift cluster has changed the Admin username from its default value.
+This check will fail if the admin username for a Redshift cluster is set to
+awsuser.') , ROW ('dx8afcdfMr', 'en', 'Route 53 Traffic Policy Instances',
+'Checks for usage that is more than 80% of the Route 53 Traffic Policy
+Instances Limit per account. Values are based on a snapshot, so your current
+usage might differ. Limit and usage data can take up to 24 hours to reflect any
+changes. In cases where limits have been recently increased, you may
+temporarily see utilization that exceeds the limit.') , ROW ('c9D319e7sG',
+'en', 'Amazon Route 53 MX Resource Record Sets and Sender Policy Framework',
+'For each MX resource record set, checks that the TXT or SPF resource record
+set contains a valid SPF record. The record must start with "v=spf1". The SPF
+record specifies the servers that are authorized to send email for your domain,
+which helps detect and stop email address spoofing to reduce spam. Route 53
+recommends that you use a TXT record instead of an SPF record. Trusted Advisor
+reports this check as green as long as each MX resource record set has at least
+one SPF or TXT record.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Yellow: An MX resource record set doesnÃ¢Â€Â™t have a TXT or SPF resource record
+that contains a valid SPF value.
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+For each MX resource record set, create a TXT resource record set that contains
+a valid SPF value. For more information, see _S_e_n_d_e_r_ _P_o_l_i_c_y_ _F_r_a_m_e_w_o_r_k_:_ _S_P_F
+_R_e_c_o_r_d_ _S_y_n_t_a_x and _C_r_e_a_t_i_n_g_ _R_e_s_o_u_r_c_e_ _R_e_c_o_r_d_ _S_e_t_s_ _B_y_ _U_s_i_n_g_ _t_h_e_ _A_m_a_z_o_n_ _R_o_u_t_e_ _5_3
+_C_o_n_s_o_l_e.
+
+****** AAddddiittiioonnaall IInnffoorrmmaattiioonn ******
+
+_S_e_n_d_e_r_ _P_o_l_i_c_y_ _F_r_a_m_e_w_o_r_k (Wikipedia)
+_M_X_ _r_e_c_o_r_d (Wikipedia)') , ROW ('Qsdfp3A4L4', 'en', 'Amazon EC2 instances with
+Microsoft Windows Server end of support', 'This check alerts you if the
+versions are near or have reached the end of support. Each Windows Server
+version offers 10 years of support, including 5 years of mainstream support and
+5 years of extended support. After the end of support, the Windows Server
+version wonÃ¢Â€Â™t receive regular security updates. Running applications with
+unsupported Windows Server versions can bring security or compliance risks.
+
+****** AAlleerrtt CCrriitteerriiaa ******
+
+Red: An EC2 instance has a Windows Server version that has reached end of
+support (Windows Server 2003, 2008, and 2008R2)
+Yellow: An EC2 instance has a Windows Server version that will reach end of
+support in less than 18 months (Windows Server 2012 & 2012 R2)
+
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
+Consider the following guidelines for end of support Windows Server EC2
+instances:
+To modernize your Windows Server workloads, consider the various pathways
+available on the _M_o_d_e_r_n_i_z_e_ _W_i_n_d_o_w_s_ _W_o_r_k_l_o_a_d_s_ _w_i_t_h_ _A_W_S website.
+To upgrade your Windows Server workloads onto modern versions of Windows
+Server, consider using an automation runbook to simplify your upgrade. For more
+information, see the _A_W_S_ _S_y_s_t_e_m_s_ _M_a_n_a_g_e_r_ _d_o_c_u_m_e_n_t_a_t_i_o_n.
+If you canÃ¢Â€Â™t upgrade your Windows Server workloads due to application
+incompatibilities, consider the End-of-Support Migration Program (EMP) for
+Windows Server. For more information on the program and tooling, see the _E_M_P
+_w_e_b_s_i_t_e. You can also purchase Extended Security Updates (ESU) from Microsoft
+for a maximum of 3 years after a productÃ¢Â€Â™s end of support date. _L_e_a_r_n_ _m_o_r_e.')
+, ROW ('Qsdfp3A4L3', 'en', 'Amazon EC2 instances with Microsoft SQL Server end
+of support', 'Checks the SQL Server versions for Amazon Elastic Compute Cloud
+(Amazon EC2) instances running in the past 24 hours. This check alerts you if
+the versions are near or have reached the end of support. Each SQL Server
+version offers 10 years of support, including 5 years of mainstream support and
+5 years of extended support. After the end of support, the SQL Server version
+wonÃ¢Â€Â™t receive regular security updates. Running applications with unsupported
+SQL Server versions can bring security or compliance risks.
+
+****** AAlleerrtt CCrriitteerriiaa ******
 
-AAlleerrtt CCrriitteerriiaa
 Red: An EC2 instance has an SQL Server version that reached the end of support.
 Yellow: An EC2 instance has an SQL Server version that will reach the end of
 support in 12 months.
 
-RReeccoommmmeennddeedd AAccttiioonn
+****** RReeccoommmmeennddeedd AAccttiioonn ******
+
 To modernize your SQL Server workloads, consider refactoring to AWS Cloud
 native databases like Amazon Aurora. For more information, see _M_o_d_e_r_n_i_z_e
 _W_i_n_d_o_w_s_ _W_o_r_k_l_o_a_d_s_ _w_i_t_h_ _A_W_S.
 To move to a fully managed database, consider replatforming to Amazon
 Relational Database Service (Amazon RDS). For more information, see _R_D_S_ _f_o_r_ _S_Q_L
 _S_e_r_v_e_r.
 To upgrade your SQL Server on EC2, consider using the automation runbook to
 simplify your upgrade. For more information, see the _A_W_S_ _S_y_s_t_e_m_s_ _M_a_n_a_g_e_r
 _d_o_c_u_m_e_n_t_a_t_i_o_n.
 If you canÃ¢Â€Â™t upgrade your SQL Server on EC2, consider the End-of-Support
 Migration Program (EMP) for Windows Server. For more information, see the _E_M_P
 _W_e_b_s_i_t_e
 
-AAddddiittiioonnaall RReessoouurrcceess
+****** AAddddiittiioonnaall RReessoouurrcceess ******
+
 _G_e_t_ _r_e_a_d_y_ _f_o_r_ _S_Q_L_ _S_e_r_v_e_r_ _e_n_d_ _o_f_ _s_u_p_p_o_r_t_ _w_i_t_h_ _A_W_S
 _M_i_c_r_o_s_o_f_t_ _S_Q_L_ _S_e_r_v_e_r_ _o_n_ _A_W_S
-') , ROW ('Hs4Ma3G100', 'en', 'Amazon SageMaker notebook instances should not
-have direct internet access', 'Checks if direct internet access is disabled for
-an Amazon SageMaker notebook instance by examining the DirectInternetAccess
-field is disabled for an Amazon SageMaker notebook instance.') , ROW
-('Hs4Ma3G101', 'en', 'Amazon Elastic MapReduce cluster master nodes should not
-have public IP addresses', 'Checks if master nodes on EMR clusters have public
-IP addresses.') , ROW ('Hs4Ma3G102', 'en', 'Connections to Amazon Redshift
-clusters should be encrypted in transit', 'Checks if connections to Amazon
-Redshift clusters are required to use encryption in transit. The check fails if
-the Amazon Redshift cluster parameter require_SSL is not set to 1.') , ROW
-('Hs4Ma3G103', 'en', 'Amazon Redshift clusters should prohibit public access',
-'Checks if Amazon Redshift clusters are publicly accessible. It evaluates the
-publiclyAccessible field in the cluster configuration item.') , ROW
-('Hs4Ma3G104', 'en', 'Redshift clusters should use enhanced VPC routing',
-'Checks if a Redshift cluster has EnhancedVpcRouting enabled.') , ROW
-('Hs4Ma3G105', 'en', 'Amazon Redshift should have automatic upgrades to major
-versions enabled', 'Checks if an Amazon Redshift cluster is configured with
-automatic upgrades to major versions.') , ROW ('Hs4Ma3G106', 'en', 'Amazon
-Redshift clusters should have audit logging enabled', 'Checks if an Amazon
-Redshift cluster has audit logging enabled.') , ROW ('Hs4Ma3G107', 'en',
-'CloudFront distributions should require encryption in transit', 'Checks if an
-Amazon CloudFront distribution requires viewers to use HTTPS directly, or if it
-uses redirection. The check fails if ViewerProtocolPolicy is set to allow-all
-for defaultCacheBehavior or for cacheBehaviors.') , ROW ('Hs4Ma3G108', 'en',
-'CloudTrail trails should be integrated with Amazon CloudWatch Logs', 'Checks
-if AWS CloudTrail trails are configured to send logs to Amazon CloudWatch
-Logs.') , ROW ('Hs4Ma3G109', 'en', 'CloudTrail log file validation should be
-enabled', 'Checks if CloudTrail log file validation is enabled.') , ROW
-('Hs4Ma3G110', 'en', 'CloudTrail should have encryption at-rest enabled',
-'Checks whether AWS CloudTrail is configured to use the server-side encryption
-(SSE) AWS Key Management Service (AWS KMS) key encryption. The check will pass
-if the KmsKeyId is defined.') , ROW ('Hs4Ma3G111', 'en', 'CloudTrail should be
-enabled and configured with at least one multi-region trail', 'Checks that
-there is at least one multi-region AWS CloudTrail trail.') , ROW ('Hs4Ma3G112',
-'en', 'Secrets Manager secrets should be rotated within a specified number of
-days', 'Checks if your secrets have rotated at least once within 90 days.') ,
-ROW ('Hs4Ma3G113', 'en', 'Secrets Manager secrets configured with automatic
-rotation should rotate successfully', 'Checks if an AWS Secrets Manager secret
-rotated successfully based on the rotation schedule. The check fails if
-RotationOccurringAsScheduled is false. The check does not evaluate secrets that
-do not have rotation configured.') , ROW ('Hs4Ma3G114', 'en', 'Remove unused
-Secrets Manager secrets', 'Checks if your secrets have been accessed within a
-specified number of days. The default value is 90 days. Secrets that have not
-been accessed even once within the number days you define, fail this check.') ,
-ROW ('Hs4Ma3G115', 'en', 'Secrets Manager secrets should have automatic
-rotation enabled', 'Checks if a secret stored in AWS Secrets Manager is
-configured to rotate automatically.') , ROW ('Hs4Ma3G116', 'en', 'EBS snapshots
-should not be public, determined by the ability to be restorable by anyone',
-'Checks if Amazon Elastic Block Store snapshots are not publicly restorable.')
-, ROW ('Hs4Ma3G117', 'en', 'Attached EBS volumes should be encrypted at-rest',
-'Checks if the EBS volumes that are in an attached state are encrypted.') , ROW
-('Hs4Ma3G118', 'en', 'The VPC default security group should not allow inbound
-and outbound traffic', 'Checks that the default security group of a VPC does
-not allow inbound or outbound traffic.') , ROW ('Hs4Ma3G119', 'en', 'EBS
-volumes should be attached to EC2 instances', 'Checks if EBS volumes are
-attached to EC2 instances.') , ROW ('Hs4Ma3G120', 'en', 'Stopped EC2 instances
-should be removed after a specified time period', 'Checks if any EC2 instances
-have been stopped for more than the allowed number of days. An EC2 instance
-fails this check if it is stopped for longer than the maximum allowed time
-period, which by default is 30 days.') , ROW ('Hs4Ma3G121', 'en', 'EBS default
-encryption should be enabled', 'Checks if Amazon Elastic Block Store (EBS)
-encryption is enabled by default. The check fails if EBS default encryption is
-not enabled.') , ROW ('Hs4Ma3G122', 'en', 'VPC flow logging should be enabled
-in all VPCs', 'Checks if Amazon Virtual Private Cloud flow logs are found and
-enabled for Amazon VPCs. The traffic type is set to Reject.') , ROW
-('Hs4Ma3G123', 'en', 'EC2 instances should not have a public IPv4 address',
-'Checks if EC2 instances have a public IP address. The check fails if the
-publicIp field is present in the EC2 instance configuration item. This check
-applies to IPv4 addresses only.') , ROW ('Hs4Ma3G124', 'en', 'EC2 instances
-should use Instance Metadata Service Version 2 (IMDSv2)', 'Checks if your
-Amazon Elastic Compute Cloud (Amazon EC2) instance metadata version is
-configured with Instance Metadata Service Version 2 (IMDSv2). The check passes
-if HttpTokens is set to required for IMDSv2. The check fails if HttpTokens is
-set to optional.') , ROW ('Hs4Ma3G125', 'en', 'API Gateway should be associated
-with a WAF Web ACL', 'Checks to see if an API Gateway stage is using an AWS WAF
-Web ACL. This check fails if an AWS WAF Web ACL is not attached to a REST API
-Gateway stage.') , ROW ('Hs4Ma3G126', 'en', 'DynamoDB Accelerator (DAX)
-clusters should be encrypted at rest', 'Checks if a DAX cluster is encrypted at
-rest.') , ROW ('Hs4Ma3G127', 'en', 'API Gateway REST and WebSocket API
-execution logging should be enabled', 'Checks if all stages of Amazon API
-Gateway REST and WebSocket APIs have logging enabled. The check fails if
-logging is not enabled for all methods of a stage or if loggingLevel is neither
-ERROR nor INFO.') , ROW ('Hs4Ma3G128', 'en', 'API Gateway REST API stages
-should be configured to use SSL certificates for backend authentication',
-'Checks if Amazon API Gateway REST API stages have SSL certificates configured
-that backend systems can use to authenticate that incoming requests are from
-the API Gateway.') , ROW ('Hs4Ma3G129', 'en', 'API Gateway REST API stages
-should have AWS X-Ray tracing enabled', 'Checks if AWS X-Ray active tracing is
-enabled for your Amazon API Gateway REST API stages.') , ROW ('Hs4Ma3G130',
-'en', 'Lambda functions should use supported runtimes', 'Checks that the lambda
-function settings for runtimes, match the expected values set for the supported
-runtimes for each language. The supported runtimes this check assesses for are:
-nodejs14.x, nodejs12.x, python3.8, python3.7, python3.6, java11, java8, go1.x,
-dotnetcore2.1, dotnetcore3.1, ruby2.7.') , ROW ('Hs4Ma3G131', 'en', 'Lambda
-function policies should prohibit public access', 'Checks if the AWS Lambda
-function policy attached to the Lambda resource prohibits public access. If the
-Lambda function policy allows public access, the check fails.') , ROW
-('Hs4Ma3G132', 'en', 'Database Migration Service replication instances should
-not be public', 'Checks if AWS Database Migration Service replication instances
-are public by examining the PubliclyAccessible field value.') , ROW
-('Hs4Ma3G133', 'en', 'IAM customer managed policies should not allow decryption
-actions on all KMS keys', 'Checks if the default version of IAM customer
-managed policies allow principals to use the AWS Key Management Service (KMS)
-decryption actions on all resources. This check fails if kms:Decrypt or kms:
-ReEncryptFrom actions are allowed on all KMS keys. The check evaluates both
-attached and unattached customer managed policies. It does not check inline
-policies or AWS managed policies.') , ROW ('Hs4Ma3G134', 'en', 'IAM principals
-should not have IAM inline policies that allow decryption actions on all KMS
-keys', 'Checks if the inline policies embedded in your IAM principals (Role/
-User/Group) allow the AWS Key Management Service (KMS) decryption actions on
-all KMS keys. This check fails if kms:Decrypt or kms:ReEncryptFrom actions are
-allowed on all KMS keys in an inline policy.') , ROW ('Hs4Ma3G135', 'en', 'AWS
-KMS keys should not be deleted unintentionally', 'Checks whether AWS Key
-Management Service (KMS) keys are scheduled for deletion. The check fails if a
-KMS key is scheduled for deletion.') , ROW ('Hs4Ma3G136', 'en', 'Amazon SQS
-queues should be encrypted at rest', 'Checks if Amazon SQS queues are encrypted
-at rest.') , ROW ('Hs4Ma3G137', 'en', 'IAM policies should not allow full "*"
-administrative privileges', 'Checks if the default version of AWS Identity and
-Access Management (IAM) policies (also known as customer managed policies) do
-not have administrator access with a statement that has "Effect": "Allow" with
-"Action": "*" over "Resource": "*". It only assesses for the Customer Managed
-Policies that you created, but not inline and AWS Managed Policies.') , ROW
-('Hs4Ma3G138', 'en', 'IAM users should not have IAM policies attached', 'Checks
-that none of your IAM users have policies attached. Instead, IAM users must
-inherit permissions from IAM groups or roles.') , ROW ('Hs4Ma3G139', 'en', 'IAM
-users access keys should be rotated every 90 days or less', 'Checks if the
-active access keys are rotated within 90 days.') , ROW ('Hs4Ma3G140', 'en',
-'IAM root user access key should not exist', 'Checks if the root user access
-key is available.') , ROW ('Hs4Ma3G141', 'en', 'MFA should be enabled for all
-IAM users that have a console password', 'Checks if AWS Multi-Factor
-Authentication (MFA) is enabled for all AWS Identity and Access Management
-(IAM) users that use a console password.') , ROW ('Hs4Ma3G142', 'en', 'Hardware
-MFA should be enabled for the root user', 'Checks if your AWS account is
-enabled to use hardware multi-factor authentication (MFA) device to sign in
-with root credentials.') , ROW ('Hs4Ma3G143', 'en', 'Password policies for IAM
-users should have strong configurations', 'Checks if the account password
-policy for IAM users uses the following recommended configurations:
-RequireUppercaseCharacters: true, RequireLowercaseCharacters: true,
-RequireSymbols: true, RequireNumbers: true, MinimumPasswordLength: 8.') , ROW
-('Hs4Ma3G144', 'en', 'Unused IAM user credentials should be removed', 'Checks
-if your IAM users have passwords or active access keys that were not used
-within the previous 90 days.') , ROW ('Hs4Ma3G145', 'en', 'Amazon ECS task
-definitions should have secure networking modes and user definitions.', 'Checks
-if an Amazon ECS Task Definition with host networking mode has "privileged" or
-"user" container definitions. The check fails with host network mode and
-container definitions are privileged=false or empty and user=root or empty.') ,
-ROW ('Hs4Ma3G146', 'en', 'ECS services should not have public IP addresses
-assigned to them automatically', 'Checks if ECS services are configured to
-automatically assign public IP addresses. This check fails if AssignPublicIP is
-ENABLED.') , ROW ('Hs4Ma3G147', 'en', 'Amazon Elasticsearch Service domains
-should be in a VPC', 'Checks whether Amazon Elasticsearch Service domains are
-in a VPC. It does not evaluate the VPC subnet routing configuration to
-determine public reachability. This check also does not check whether the
-Amazon OpenSearch Service resource-based policy permits public access by other
-accounts or external entities. You should ensure that Amazon Elasticsearch
-Service domains are not attached to public subnets. See Resource-based policies
-(https://docs.aws.amazon.com/opensearch-service/latest/developerguide/
-ac.html#ac-types-resource) in the Amazon OpenSearch Service (successor to
-Amazon Elasticsearch Service) Developer Guide. You should also ensure that your
-VPC is configured according to the recommended best practices. See Security
-best practices for your VPC (https://docs.aws.amazon.com/vpc/latest/userguide/
-vpc-security-best-practices.html) in the Amazon VPC User Guide.') , ROW
-('Hs4Ma3G148', 'en', 'Elastic Beanstalk environments should have enhanced
-health reporting enabled', 'Checks if enhanced health reporting is enabled for
-your AWS Elastic Beanstalk environments.') , ROW ('Hs4Ma3G149', 'en', 'Elastic
-Beanstalk managed platform updates should be enabled', 'Checks if managed
-platform updates are enabled for the AWS Elastic Beanstalk environment.') , ROW
-('Hs4Ma3G150', 'en', 'Elasticsearch domains should encrypt data sent between
-nodes', 'Checks if Elasticsearch domains have node-to-node encryption
-enabled.') , ROW ('Hs4Ma3G151', 'en', 'An RDS event notifications subscription
-should be configured for critical database parameter group events', 'Checks if
-an Amazon RDS Event subscription for RDS parameter groups is configured to
-notify on event category of "configuration change".') , ROW ('Hs4Ma3G152',
-'en', 'An RDS event notifications subscription should be configured for
-critical database instance events', 'Checks if an Amazon RDS Event subscription
-for RDS instances is configured to notify on event categories of both
-"maintenance", "configuration change", and "failure".') , ROW ('Hs4Ma3G153',
-'en', 'RDS instances should not use a database engine default port', 'Checks if
-RDS instances use the default port of that database engine.') , ROW
-('Hs4Ma3G154', 'en', 'An RDS event notifications subscription should be
-configured for critical database security group events', 'Checks if an Amazon
-RDS Event subscription for RDS security groups is configured to notify on event
-categories of both "configuration change" and "failure".') , ROW ('Hs4Ma3G155',
-'en', 'EC2 instances should be managed by AWS Systems Manager', 'Checks if the
-Amazon EC2 instances in your account are managed by AWS Systems Manager.') ,
-ROW ('Hs4Ma3G156', 'en', 'EC2 instances managed by Systems Manager should have
-a patch compliance status of COMPLIANT after a patch installation', 'Checks if
-the compliance status of the Amazon EC2 Systems Manager patch compliance is
-COMPLIANT or NON_COMPLIANT after the patch installation on the instance. It
-only assesses instances that are managed by AWS Systems Manager Patch
-Manager.') , ROW ('Hs4Ma3G157', 'en', 'EC2 instances managed by Systems Manager
-should have an association compliance status of COMPLIANT', 'Checks if the
-status of the AWS Systems Manager association compliance is COMPLIANT or
-NON_COMPLIANT after the association is executed on an instance.') , ROW
-('Hs4Ma3G158', 'en', 'SSM documents should not be public', 'Checks if AWS
-Systems Manager documents that the account owns are public. This check fails if
-SSM documents that have "Self" as the owner are public.') , ROW ('Hs4Ma3G159',
-'en', 'Elastic File System should be configured to encrypt file data at-rest
-using AWS KMS', 'Checks if Amazon Elastic File System (Amazon EFS) is
-configured to encrypt the file data using AWS Key Management Service (AWS KMS).
-The check will fail if the encrypted key is set to false on DescribeFileSystems
-or if the KmsKeyId key on DescribeFileSystems does not match the KmsKeyId
-parameter.') , ROW ('Hs4Ma3G160', 'en', 'IAM authentication should be
-configured for RDS instances', 'Checks if an RDS DB instance has IAM database
-authentication enabled.') , ROW ('Hs4Ma3G161', 'en', 'IAM authentication should
-be configured for RDS clusters', 'Checks if an RDS DB cluster has IAM database
-authentication enabled.') , ROW ('Hs4Ma3G162', 'en', 'RDS automatic minor
-version upgrades should be enabled', 'Checks if automatic minor version
-upgrades are enabled for the Amazon RDS database instance.') , ROW
-('Hs4Ma3G163', 'en', 'RDS DB clusters should be configured to copy tags to
-snapshots', 'Checks if RDS DB clusters are configured to copy all tags to
-snapshots when the snapshots are created.') , ROW ('Hs4Ma3G164', 'en', 'RDS DB
-instances should be configured to copy tags to snapshots', 'Checks if RDS DB
-instances are configured to copy all tags to snapshots when the snapshots are
-created.') , ROW ('Hs4Ma3G165', 'en', 'RDS instances should be deployed in a
-VPC', 'Checks if an RDS instance is deployed in a VPC (EC2-VPC).') , ROW
-('Hs4Ma3G166', 'en', 'An RDS event notifications subscription should be
-configured for critical cluster events', 'Checks if an Amazon RDS Event
-subscription for RDS clusters is configured to notify on event categories of
-both "maintenance" and "failure".') , ROW ('Hs4Ma3G167', 'en', 'S3 buckets
-should have server-side encryption enabled', 'Checks that your Amazon S3 bucket
-either has Amazon S3 default encryption enabled or that the S3 bucket policy
-explicitly denies put-object requests without server side encryption.') , ROW
-('Hs4Ma3G168', 'en', 'S3 buckets should require requests to use Secure Socket
-Layer', 'Checks if S3 buckets have policies that require requests to use Secure
-Socket Layer (SSL).') , ROW ('Hs4Ma3G169', 'en', 'S3 permissions granted to
-other AWS accounts in bucket policies should be restricted', 'Checks if the S3
-bucket policy allows sensitive bucket-level or object-level actions from a
-principal in another AWS account. The check fails if any of the following
-actions are allowed in the S3 bucket policy for a principal in another AWS
-account: s3:DeleteBucketPolicy, s3:PutBucketAcl, s3:PutBucketPolicy, s3:
-PutObjectAcl, and s3:PutEncryptionConfiguration.') , ROW ('Hs4Ma3G170', 'en',
-'S3 Block Public Access setting should be enabled', 'Checks if the following
-public access block settings are configured from account level:
-ignorePublicAcls: True, blockPublicPolicy: True, blockPublicAcls: True,
-restrictPublicBuckets: True.') , ROW ('Hs4Ma3G171', 'en', 'S3 buckets should
-prohibit public read access', 'Checks if your S3 buckets allow public read
-access by evaluating the Block Public Access settings, the bucket policy, and
-the bucket access check list (ACL).') , ROW ('Hs4Ma3G172', 'en', 'S3 buckets
-should prohibit public write access', 'Checks if your S3 buckets allow public
-write access by evaluating the Block Public Access settings, the bucket policy,
-and the bucket access check list (ACL).') , ROW ('Hs4Ma3G173', 'en', 'S3 Block
-Public Access setting should be enabled at the bucket-level', 'Checks if Amazon
-S3 buckets have bucket level public access blocks applied. This check fails if
-any of the bucket level settings are set to "false" public: ignorePublicAcls,
-blockPublicPolicy, blockPublicAcls, restrictPublicBuckets.') , ROW
-('Hs4Ma3G174', 'en', 'CodeBuild GitHub or Bitbucket source repository URLs
-should use OAuth', 'Checks if the GitHub or Bitbucket source repository URL
-contains either personal access tokens or user name and password.') , ROW
-('Hs4Ma3G175', 'en', 'CodeBuild project environment variables should not
-contain clear text credentials', 'Checks if the project contains environment
-variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY.') , ROW ('Hs4Ma3G176',
-'en', 'ACM certificates should be renewed after a specified time period',
-'Checks if ACM Certificates in your account are marked for expiration within a
-specified time period. Certificates provided by ACM are automatically renewed.
-ACM does not automatically renew certificates that you import.') , ROW
-('Hs4Ma3G177', 'en', 'Auto scaling groups associated with a load balancer
-should use load balancer health checks', 'Checks if your Auto Scaling groups
-that are associated with a load balancer are using Elastic Load Balancing
-health checks.') , ROW ('Hs4Ma3G178', 'en', 'Security groups should only allow
-unrestricted incoming traffic for authorized ports', 'Checks if the security
-groups allow unrestricted incoming traffic. The check fails if ports allow
-unrestricted traffic on ports other than 80 and 443, which are default values
-for parameter authorizedTcpPorts.') , ROW ('Hs4Ma3G179', 'en', 'SNS topics
-should be encrypted at-rest using AWS KMS', 'Checks if an Amazon SNS topic is
-encrypted at rest using AWS KMS.') , ROW ('Hs4Ma3G180', 'en', 'Amazon
-Elasticsearch Service domain error logging to CloudWatch Logs should be
-enabled', 'Checks whether Amazon Elasticsearch Service domains are configured
-to send error logs to CloudWatch Logs.') , ROW ('Hs4Ma3G181', 'en', 'Classic
-Load Balancers with SSL/HTTPS listeners should use a certificate provided by
-AWS Certificate Manager', 'Checks if a Classic Load Balancer uses HTTPS/SSL
-certificates provided by AWS Certificate Manager. The check fails if a Classic
-Load Balancer that is configured with an HTTPS/SSL listener does not use a
-certificate provided by AWS Certificate Manager.') , ROW ('Hs4Ma3G182', 'en',
-'Classic Load Balancer listeners should be configured with HTTPS or TLS
-termination', 'Checks if your Classic Load Balancer listeners are configured
-with HTTPS or TLS protocol for front-end (client to load balancer) connections.
-The check is applicable if a Classic Load Balancer has listeners. If your
-Classic Load Balancer does not have a listener configured, then the check does
-not report any findings.') , ROW ('Hs4Ma3G183', 'en', 'Application load
-balancer should be configured to drop http headers', 'This check evaluates AWS
-Application Load Balancers (ALB) to ensure they are configured to drop http
-headers. By default, ALBs are not configured to drop invalid http header
-values. This check evaluates all ALBs fails if the attribute value of
-routing.http.drop_invalid_header_fields.enabled is set to false.') , ROW
-('Hs4Ma3G184', 'en', 'Application and Classic Load Balancers logging should be
-enabled', 'Checks if the Application Load Balancer and the Classic Load
-Balancer have logging enabled. The check fails if the access_logs.s3.enabled is
-false.') , ROW ('Hs4Ma3G185', 'en', 'IAM customer managed policies that you
-create should not allow wildcard actions for services', 'Checks if the IAM
-identity-based custom policies have Allow statements that grant permissions for
-all actions on a service. The check fails if any policy statement includes
-"Effect": "Allow" with "Action": "Service:".') , ROW ('Hs4Ma3G186', 'en', 'AWS
-WAF Classic Global Web ACL logging should be enabled', 'Checks if logging is
-enabled for a WAF global Web ACL. This check fails if logging is not enabled
-for the Web ACL.') , ROW ('Hs4Ma3G187', 'en', 'Connections to Amazon
-Elasticsearch Service domains should be encrypted using TLS 1.2', 'Checks
-whether connections to Amazon Elasticsearch Service domains are required to use
-TLS 1.2. The check fails if the Amazon Elasticsearch Service domain
-TLSSecurityPolicy is not Policy-Min-TLS-1-2-2019-07.') , ROW ('Hs4Ma3G188',
-'en', 'GuardDuty should be enabled', 'Checks if Amazon GuardDuty is enabled in
-your AWS account and region.') , ROW ('Hs4Ma3G189', 'en', 'Enhanced monitoring
-should be configured for RDS DB instances', 'Checks if enhanced monitoring is
-enabled for your RDS DB instances.') , ROW ('Hs4Ma3G190', 'en', 'RDS clusters
-should have deletion protection enabled', 'Checks if RDS clusters have deletion
-protection enabled.') , ROW ('Hs4Ma3G191', 'en', 'RDS cluster snapshots and
-database snapshots should be encrypted at rest', 'Checks if Amazon RDS cluster
-snapshots and database snapshots are encrypted.') , ROW ('Hs4Ma3G192', 'en',
-'RDS DB Instances should prohibit public access, determined by the
-PubliclyAccessible configuration', 'Checks if RDS instances are publicly
-accessible by evaluating the publiclyAccessible field in the instance
-configuration item.') , ROW ('Hs4Ma3G193', 'en', 'RDS DB instances should have
-encryption at-rest enabled', 'Checks if storage encryption is enabled for your
-RDS DB instances.') , ROW ('Hs4Ma3G194', 'en', 'RDS snapshot should be
-private', 'Checks if Amazon Relational Database Service (Amazon RDS) snapshots
-are public.') , ROW ('Hs4Ma3G195', 'en', 'CloudFront distributions should have
-origin access identity enabled', 'Checks if an Amazon CloudFront distribution
-with an Amazon S3 origin type has Origin Access Identity (OAI) configured. The
-check fails if the CloudFront distribution that is backed by Amazon S3 does not
-have OAI configured.') , ROW ('Hs4Ma3G196', 'en', 'AWS Config should be
-enabled', 'Checks if the Config service is enabled in the account for the local
-region and is recording all resources.') , ROW ('Hs4Ma3G197', 'en', 'Amazon
-Elasticsearch Service domains should have encryption at-rest enabled', 'Checks
-whether Amazon Elasticsearch Service domains have encryption at rest
-configuration enabled. This check fails if the EncryptionAtRestOptions field is
-not enabled.') , ROW ('Hs4Ma3G198', 'en', 'RDS DB instances should have
-deletion protection enabled', 'Checks if RDS DB instances have deletion
-protection enabled.') , ROW ('Hs4Ma3G199', 'en', 'Database logging should be
-enabled', 'Checks if the following Amazon RDS logs are enabled and sent to
-CloudWatch Logs: Oracle: (Alert, Audit, Trace, Listener), PostgreSQL:
-(Postgresql, Upgrade), MySQL: (Audit, Error, General, SlowQuery), MariaDB:
-(Audit, Error, General, SlowQuery), SQL Server: (Error, Agent), Aurora: (Audit,
-Error, General, SlowQuery), Aurora-MySQL: (Audit, Error, General, SlowQuery),
-Aurora-PostgreSQL: (Postgresql).') , ROW ('Hs4Ma3G200', 'en', 'CloudFront
-distributions should have a default root object configured', 'Checks if an
-Amazon CloudFront distribution is configured to return a specific object that
-is the default root object. The check fails if the CloudFront distribution does
-not have a default root object configured.') , ROW ('Hs4Ma3G201', 'en',
-'CloudFront distributions should have WAF enabled', 'Checks to see if Amazon
-CloudFront distributions are associated with either WAF or WAFv2 web ACLs. The
-check fails if a CloudFront distribution is not associated with a web ACL.') ,
-ROW ('Hs4Ma3G202', 'en', 'API Gateway REST API cache data should be encrypted
-at rest', 'Checks if all methods in Amazon API Gateway REST API stages that
-have cache enabled are encrypted. The check fails if any method in API Gateway
-REST API stage is configured to cache and the cache is not encrypted.') , ROW
-('Hs4Ma3G203', 'en', 'Amazon Elasticsearch Service domains should have audit
-logging enabled', 'This check checks whether Amazon Elasticsearch Service
-domains have audit logging enabled. This check fails if an Amazon Elasticsearch
-Service domain does not have audit logging enabled.') , ROW ('Hs4Ma3G204',
-'en', 'Security groups should not allow unrestricted access to ports with high
-risk', 'Checks if unrestricted incoming traffic for the security groups is
-accessible to the specified ports [3389, 20, 23, 110, 143, 3306, 8080, 1433,
-9200, 9300, 25, 445, 135, 21, 1434, 4333, 5432, 5500, 5601, 22 ] that have the
-highest risk. This check passes when none of the rules in a security group
-allow ingress traffic from 0.0.0.0/0 for the listed ports.') , ROW
-('Hs4Ma3G205', 'en', 'Classic Load Balancers with HTTPS/SSL listeners should
-use a predefined security policy that has strong configuration', 'Checks if
-your Classic Load Balancer SSL listeners use the predefined policy
-ELBSecurityPolicy-TLS-1-2-2017-01. The check fails if the Classic Load Balancer
-SSL listeners do not use the predefined policy ELBSecurityPolicy-TLS-1-2-2017-
-01.') , ROW ('Hs4Ma3G206', 'en', 'Amazon EC2 should be configured to use VPC
-endpoints that are created for the Amazon EC2 service', 'Checks if a service
-endpoint for Amazon EC2 is created for each VPC. The check fails if a VPC does
-not have a VPC endpoint created for the Amazon EC2 service.') , ROW
-('Hs4Ma3G207', 'en', 'EC2 subnets should not automatically assign public IP
-addresses', 'Checks if the assignment of public IPs in Amazon Virtual Private
-Cloud (VPC) subnets have the MapPublicIpOnLaunch set to FALSE. The check will
-pass if the flag is set to FALSE.') , ROW ('Hs4Ma3G208', 'en', 'EC2 instances
-should not use multiple ENIs', 'Checks to see if Amazon EC2 instance uses
-multiple ENI/EFA. This check will pass if single network adapters is used.') ,
-ROW ('Hs4Ma3G209', 'en', 'Unused Network Access Control Lists should be
-removed', 'Checks to see if there are any NACLs (Network Access Control List)
-that are unused. The check will check the item configuration of the resource
-AWS::EC2::NetworkAcl and determine the relationships of the NACL.') , ROW
-('Hs4Ma3G210', 'en', 'CloudFront distributions should have logging enabled',
-'Checks to see if server access logging is enabled on Amazon CloudFront
-Distributions. The check will fail if access logging is not enabled for the
-distribution.') , ROW ('COr6dfpM03', 'en', 'Amazon EBS over-provisioned
-volumes', 'Checks the Amazon Elastic Block Storage (Amazon EBS) volumes that
-were running at any time during the lookback period. This check alerts you if
-any EBS volumes were over-provisioned for your workloads. When you have over-
-provisioned volumes, youÃ¢Â€Â™re paying for unused resources. Although some
-scenarios can result in low optimization by design, you can often lower your
-costs by changing the configuration of your EBS volumes. Estimated monthly
-savings are calculated by using the current usage rate for EBS volumes. Actual
-savings will vary if the volume isnÃ¢Â€Â™t present for a full month.
-
-SSoouurrccee
-AWS Compute Optimizer
-
-AAlleerrtt CCrriitteerriiaa
-Yellow: An EBS Volume that was over-provisioned during the lookback period. To
-determine if a volume is over-provisioned, we consider all default CloudWatch
-metrics (including IOPS and throughput). The algorithm used to identify over-
-provisioned EBS volumes follows AWS best practices. The algorithm is updated
-when a new pattern has been identified.
-
-RReeccoommmmeennddeedd AAccttiioonn
-Consider downsizing volumes that have low utilization.
-
-AAddddiittiioonnaall RReessoouurrcceess
-For more information about this recommendation, see the _T_r_u_s_t_e_d_ _A_d_v_i_s_o_r
-_d_o_c_u_m_e_n_t_a_t_i_o_n_..') , ROW ('COr6dfpM04', 'en', 'Amazon EBS under-provisioned
-volumes', 'Checks the Amazon Elastic Block Storage (Amazon EBS) volumes that
-were running at any time during the lookback period. This check alerts you if
-any EBS volumes were under-provisioned for your workloads. Consistent high
-utilization can indicate optimized, steady performance, but can also indicate
-that an application does not have enough resources.
-
-SSoouurrccee
-AWS Compute Optimizer
-
-AAlleerrtt CCrriitteerriiaa
-Yellow: An EBS Volume that was under-provisioned during the lookback period. To
-determine if a volume is under-provisioned, we consider all default CloudWatch
-metrics (including IOPS and throughput). The algorithm used to identify under-
-provisioned EBS volumes follows AWS best practices. The algorithm is updated
-when a new pattern has been identified.
-
-RReeccoommmmeennddeedd AAccttiioonn
-Consider upsizing volumes that have high utilization.
-
-AAddddiittiioonnaall RReessoouurrcceess
-For more information about this recommendation, see the _T_r_u_s_t_e_d_ _A_d_v_i_s_o_r
-_d_o_c_u_m_e_n_t_a_t_i_o_n.') , ROW ('COr6dfpM05', 'en', 'AWS Lambda over-provisioned
-functions for memory size', 'Checks the AWS Lambda functions that were invoked
-at least once during the lookback period. This check alerts you if any of your
-Lambda functions were over-provisioned for memory size. When you have Lambda
-functions that are over-provisioned for memory sizes, youÃ¢Â€Â™re paying for
-unused resources. Although some scenarios can result in low utilization by
-design, you can often lower your costs by changing the memory configuration of
-your Lambda functions. Estimated monthly savings are calculated by using the
-current usage rate for Lambda functions.
-
-SSoouurrccee
-AWS Compute Optimizer
-
-AAlleerrtt CCrriitteerriiaa
-Yellow: A Lambda function that was over-provisioned for memory size during the
-lookback period. To determine if a Lambda function is over-provisioned, we
-consider all default CloudWatch metrics for that function. The algorithm used
-to identify over-provisioned Lambda functions for memory size follows AWS best
-practices. The algorithm is updated when a new pattern has been identified.
+') , ROW ('Qsdfp3A4L2', 'en', 'Amazon EC2 instances consolidation for Microsoft
+SQL Server', 'Checks your Amazon Elastic Compute Cloud (Amazon EC2) instances
+that are running SQL Server in the past 24 hours. This check alerts you if your
+instance has less than the minimum number of SQL Server licenses. From the
+Microsoft SQL Server Licensing Guide, you are paying 4 vCPU licenses even if an
+instance has only 1 or 2 vCPUs. You can consolidate smaller SQL Server
+instances to help lower costs.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Consider reducing the memory size of your Lambda functions.
+****** AAlleerrtt CCrriitteerriiaa ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-For more information about this recommendation, see the _T_r_u_s_t_e_d_ _A_d_v_i_s_o_r
-_d_o_c_u_m_e_n_t_a_t_i_o_n_ _p_a_g_e.') , ROW ('COr6dfpM06', 'en', 'AWS Lambda under-provisioned
-functions for memory size', 'Checks the AWS Lambda functions that were invoked
-at least once during the lookback period. This check alerts you if any of your
-Lambda functions were under-provisioned for memory size. When you have Lambda
-functions that are under-provisioned for memory size, these functions take
-longer time to complete.
+Yellow: An instance with SQL Server has less than 4 vCPUs.
 
-SSoouurrccee
-AWS Compute Optimizer
+****** RReeccoommmmeennddeedd AAccttiioonn ******
 
-AAlleerrtt CCrriitteerriiaa
-Yellow: A Lambda function that was under-provisioned for memory size during the
-lookback period. To determine if a Lambda function is under-provisioned, we
-consider all default CloudWatch metrics for that function. The algorithm used
-to identify under-provisioned Lambda functions for memory size follows AWS best
-practices. The algorithm is updated when a new pattern has been identified.
+Consider consolidating smaller SQL Server workloads into instances with at
+least 4 vCPUs.
 
-RReeccoommmmeennddeedd AAccttiioonn
-Consider increasing the memory size of your Lambda functions.
+****** AAddddiittiioonnaall RReessoouurrcceess ******
 
-AAddddiittiioonnaall RReessoouurrcceess
-For more information about this recommendation, see the _T_r_u_s_t_e_d_ _A_d_v_i_s_o_r
-_d_o_c_u_m_e_n_t_a_t_i_o_n.') , ROW ('Hs4Ma3G211', 'en', 'S3 buckets with versioning enabled
-should have lifecycle policies configured', 'Checks if Amazon Simple Storage
-Service (Amazon S3) version enabled buckets have lifecycle policy configured.
-This rule fails if Amazon S3 lifecycle policy is not enabled.') , ROW
-('Hs4Ma3G212', 'en', 'S3 buckets should have event notifications enabled',
+_M_i_c_r_o_s_o_f_t_ _S_Q_L_ _S_e_r_v_e_r_ _o_n_ _A_W_S
+_M_i_c_r_o_s_o_f_t_ _L_i_c_e_n_s_i_n_g_ _o_n_ _A_W_S
+_M_i_c_r_o_s_o_f_t_ _S_Q_L_ _S_e_r_v_e_r_ _L_i_c_e_n_s_i_n_g_ _G_u_i_d_e
+') , ROW ('Hs4Ma3G210', 'en', 'CloudFront distributions should have logging
+enabled', 'Checks to see if server access logging is enabled on Amazon
+CloudFront Distributions. The check will fail if access logging is not enabled
+for the distribution.') , ROW ('Hs4Ma3G211', 'en', 'S3 buckets with versioning
+enabled should have lifecycle policies configured', 'Checks if Amazon Simple
+Storage Service (Amazon S3) version enabled buckets have lifecycle policy
+configured. This rule fails if Amazon S3 lifecycle policy is not enabled.') ,
+ROW ('Hs4Ma3G212', 'en', 'S3 buckets should have event notifications enabled',
 'Checks if S3 Event Notifications are enabled on an S3 bucket. This check fails
 if S3 Event Notifications are not enabled on a bucket.') , ROW ('Hs4Ma3G213',
 'en', 'S3 access control lists (ACLs) should not be used to manage user access
 to buckets', 'Checks if S3 buckets allow user permissions via access check
 lists (ACLs). This check fails if ACLs are configured for user access on S3
 Bucket.') , ROW ('Hs4Ma3G214', 'en', 'Network ACLs should not allow ingress
 from 0.0.0.0/0 to port 22 or port 3389', 'Checks if a network access check list
@@ -1876,62 +2309,16 @@
 0.0.0.0/0 or ::/0 for ports 22 or 3389') , ROW ('Hs4Ma3G215', 'en', 'Unused EC2
 security groups should be removed', 'Checks that security groups are attached
 to Amazon EC2 instances or to an elastic network interface. The check will fail
 the security group is not associated with an Amazon EC2 instance or an elastic
 network interface.') , ROW ('Hs4Ma3G216', 'en', 'ECR repositories should have
 at least one lifecycle policy configured', 'Checks if an ECR repository has at
 least one lifecycle policy configured. This check fails if an ECR repository
-does not have any lifecycle policies configured.') , ROW ('Hs4Ma3G217', 'en',
-'CodeBuild project environments should have a logging configuration', 'Checks
-if a CodeBuild project environment has at least one log option enabled.') , ROW
-('Hs4Ma3G218', 'en', 'CodeBuild project environments should not have privileged
-mode enabled', 'Checks if an AWS CodeBuild project environment has privileged
-mode enabled.') , ROW ('Hs4Ma3G219', 'en', 'Amazon Redshift clusters should not
-use the default Admin username', 'Checks if a Redshift cluster has changed the
-Admin username from its default value. This check will fail if the admin
-username for a Redshift cluster is set to awsuser.') , ROW ('Hs4Ma3G220', 'en',
-'Connections to OpenSearch domains should be encrypted using TLS 1.2', 'Checks
-if connections to OpenSearch domains are required to use TLS 1.2. The check
-fails if the OpenSearch domain TLSSecurityPolicy is not Policy-Min-TLS-1-2-
-2019-07.') , ROW ('Hs4Ma3G221', 'en', 'OpenSearch domains should have audit
-logging enabled', 'Checks if Amazon OpenSearch Service domains have audit
-logging enabled.') , ROW ('Hs4Ma3G222', 'en', 'OpenSearch domain error logging
-to CloudWatch Logs should be enabled', 'Checks if Amazon OpenSearch domains are
-configured to send error logs to CloudWatch Logs. This check fails if error
-logging to CloudWatch is not enabled for a domain.') , ROW ('Hs4Ma3G223', 'en',
-'OpenSearch domains should encrypt data sent between nodes', 'Checks if Amazon
-OpenSearch domains have node-to-node encryption enabled. This check fails if
-node-to-node encryption is disabled on the domain.') , ROW ('Hs4Ma3G224', 'en',
-'OpenSearch domains should be in a VPC', 'Checks Amazon OpenSearch Service
-domains are in an Amazon Virtual Private Cloud (VPC).') , ROW ('Hs4Ma3G225',
-'en', 'OpenSearch domains should have encryption at rest enabled', 'Checks if
-Amazon OpenSearch domains have encryption-at-rest configuration enabled. The
-check fails if encryption at rest is not enabled.') , ROW ('Hs4Ma3G226', 'en',
-'Amazon EC2 instances launched using Auto Scaling group launch configurations
-should not have Public IP addresses', 'Checks if Amazon EC2 Auto Scaling groups
-have public IP addresses enabled using launch configurations.') , ROW
-('Hs4Ma3G227', 'en', 'CloudFront distributions should use custom SSL/TLS
-certificates', 'Checks if CloudFront distributions are using the default SSL/
-TLS certificate CloudFront provides instead of a custom one. This check fails
-for a CloudFront distribution if it uses the default SSL/TLS certificate.') ,
-ROW ('Hs4Ma3G228', 'en', 'CloudFront distributions should use SNI to serve
-HTTPS requests', 'Checks if Amazon CloudFront distributions are using a custom
-SSL/TLS certificate and are configured to use SNI to serve HTTPS requests as
-opposed to dedicated IP address.') , ROW ('Hs4Ma3G229', 'en', 'CloudFront
-distributions should encrypt traffic to custom origins', 'Checks if CloudFront
-distributions are encrypting traffic to custom origins. This check fails for a
-CloudFront distribution whose origin protocol policy allows http-only or if it
-is match-viewer and the viewer protocol policy is allow-all. ') , ROW
-('Hs4Ma3G230', 'en', 'S3 bucket server access logging should be enabled',
-'Checks if an Amazon S3 Bucket has server access logging enabled to a chosen
-target bucket.') , ROW ('Hs4Ma3G231', 'en', 'Stateless network firewall rule
-group should not be empty', 'Checks if a Stateless Network Firewall Rule Group
-contains rules. The rule will fail if there are no rules in a Stateless Network
-Firewall Rule Group.') , ROW ('Hs4Ma3G232', 'en', 'RDS Database Clusters should
-use a custom administrator username', 'Checks if an RDS database cluster has
-changed the admin username from its default value. This rule will fail if the
-admin username is set to the default value.') , ROW ('Hs4Ma3G233', 'en', 'RDS
-database instances should use a custom administrator username', 'Checks if an
-Amazon Relational Database Service (Amazon RDS) database instance has changed
-the admin username from its default value. This rule will only run on RDS
-database instances. The rule will fail if the admin username is set to the
-default value.') ) ignored_tabe_name (check_id, language, name, description)
+does not have any lifecycle policies configured.') , ROW ('qS7VV0l7J9', 'en',
+'IAM Users', 'Checks for usage that is more than 80% of the IAM Users Limit.
+Values are based on a snapshot, so your current usage might differ. Limit and
+usage data can take up to 24 hours to reflect any changes. In cases where
+limits have been recently increased, you may temporarily see utilization that
+exceeds the limit.') , ROW ('Hs4Ma3G217', 'en', 'CodeBuild project environments
+should have a logging configuration', 'Checks if a CodeBuild project
+environment has at least one log option enabled.') ) ignored_tabe_name
+(check_id, language, name, description)
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/tao/glue_table.json` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/tao/glue_table.json`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/tao/ta_org_view.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/tao/ta_org_view.sql`

 * *Files 2% similar despite different names*

```diff
@@ -239,9 +239,9 @@
 "total number of questions in cost optimization pillar",
 "number of questions answered for cost optimization",
 "number of identified hris for cost optimization",
 "cluster name"
 FROM
   "ta_organizational_view_reports"
 WHERE  
-(("from_unixtime"(CAST("timestamp" AS decimal)) > (current_date - INTERVAL  '3' MONTH)))
+ "timestamp" not like '%Z%' AND (("from_unixtime"(CAST(substr("timestamp",1,10) AS decimal)) > (current_date - INTERVAL  '3' MONTH)))
 AND (status IS NULL OR status not in ('ok', 'Green') OR checkid IN ('Wxdfp4B1L1', 'Wxdfp4B1L2', 'Wxdfp4B1L3', 'Wxdfp4B1L4'))
```

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/daily_anomaly_detection.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/daily_anomaly_detection.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_anomaly_detection.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_anomaly_detection.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_bill_by_account.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_bill_by_account.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_bill_by_account_ri.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_bill_by_account_ri.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp_ri.sql` & `cid_cmd-0.3.0/cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp_ri.sql`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/common.py` & `cid_cmd-0.3.0/cid/helpers/quicksight/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,1276 +1,1454 @@
-import os
-import sys
+import re
 import json
+import uuid
+import time
+import datetime
 import logging
-import functools
-from pathlib import Path
 from string import Template
-from typing import Dict
+from typing import Dict, List, Union
 from pkg_resources import resource_string
 
-if sys.version_info < (3, 8):
-    from importlib_metadata import entry_points
-else:
-    from importlib.metadata import entry_points
-
-import yaml
-import click
-import requests
-from deepmerge import always_merger
-from botocore.exceptions import ClientError, NoCredentialsError, CredentialRetrievalError
+from tqdm import tqdm
 
-
-from cid import utils
 from cid.base import CidBase
-from cid.plugin import Plugin
-from cid.utils import get_parameter, get_parameters, set_parameters, unset_parameter, get_yesno_parameter
-from cid.helpers.account_map import AccountMap
-from cid.helpers import Athena, CUR, Glue, QuickSight, Dashboard, Dataset, Datasource
+from cid.helpers import diff, timezone, randtime
+from cid.helpers.quicksight.dashboard import Dashboard
+from cid.helpers.quicksight.dataset import Dataset
+from cid.helpers.quicksight.datasource import Datasource
 from cid.helpers.quicksight.template import Template as CidQsTemplate
-from cid._version import __version__
-from cid.export import export_analysis
-from cid.logger import set_cid_logger
-from cid.exceptions import CidError, CidCritical
+from cid.utils import get_parameter, get_parameters, exec_env, cid_print, ago, unset_parameter
+from cid.exceptions import CidCritical, CidError
 
 logger = logging.getLogger(__name__)
 
-class Cid():
+class QuickSight(CidBase):
+    # Define defaults
+    cidAccountId = '223485597511'
+    _AthenaWorkGroup: str = None
+    _dashboards: Dict[str, Dashboard] = None
+    _datasets: Dict[str, Dataset] = None
+    _datasources: Dict[str, Datasource] = None
+    _templates: Dict[str, CidQsTemplate] = dict()
+    _identityRegion: str = None
+    _user: dict = None
+    _principal_arn: dict = None
+    _group: dict = None
+    _subscription_info: dict = None
+    client = None
+
+    def __init__(self, session, resources=None) -> None:
+        self._resources = resources
+        super().__init__(session)
+
+        # QuickSight clients
+        logger.info('Creating QuickSight client')
+        self.client = self.session.client('quicksight')
+        self.identityClient = self.session.client('quicksight', region_name=self.identityRegion)
 
-    def __init__(self, **kwargs) -> None:
-        self.base: CidBase = None
-        # Defined resources
-        self.resources = dict()
-        self.dashboards = dict()
-        self.plugins = self.__loadPlugins()
-        self._clients = dict()
-        self._visited_views = [] # Views updated in the current session
-        self.qs_url = 'https://{region}.quicksight.aws.amazon.com/sn/dashboards/{dashboard_id}'
-        self.all_yes = kwargs.get('yes')
-        self.verbose = kwargs.get('verbose')
-        set_parameters(kwargs, self.all_yes)
-        self._logger = None
 
-    def aws_login(self):
-        params = {
-            'profile_name': None,
-            'region_name': None,
-            'aws_access_key_id': None,
-            'aws_secret_access_key': None,
-            'aws_session_token': None
-        }
-        for key in params.keys():
-            value = get_parameters().get(key.replace('_', '-'))
-            if  value != None:
-                params[key] = value
-
-        print('Checking AWS environment...')
-        try:
-            self.base = CidBase(session=utils.get_boto_session(**params))
-            if self.base.session.profile_name:
-                print(f'\tprofile name: {self.base.session.profile_name}')
-                logger.info(f'AWS profile name: {self.base.session.profile_name}')
-            self.qs_url_params = {
-                'account_id': self.base.account_id,
-                'region': self.base.session.region_name
-            }
-        except (NoCredentialsError, CredentialRetrievalError):
-            raise CidCritical('Error: Not authenticated, please check AWS credentials')
-        except ClientError as e:
-            raise CidCritical(f'ClientError: {e}')
-        print(f'\taccountId: {self.base.account_id}\n\tAWS userId: {self.base.username}')
-        logger.info(f'AWS accountId: {self.base.account_id}')
-        logger.info(f'AWS userId: {self.base.username}')
-        print('\tRegion: {}'.format(self.base.session.region_name))
-        logger.info(f'AWS region: {self.base.session.region_name}')
-        print('\n')
+    @property
+    def AthenaWorkGroup(self) -> str:
+        return self._AthenaWorkGroup
+
+    @AthenaWorkGroup.setter
+    def AthenaWorkGroup(self, value):
+        self._AthenaWorkGroup = value
 
     @property
-    def qs(self) -> QuickSight:
-        if not self._clients.get('quicksight'):
-            self._clients.update({
-                'quicksight': QuickSight(self.base.session, resources=self.resources)
-            })
-        return self._clients.get('quicksight')
+    def user(self) -> dict:
+        if not self._user:
+            username = get_parameters().get('quicksight-user', self.username)
+            if username:
+                try:
+                    self._user =  self.describe_user(username)
+                except Exception as exc:
+                    logger.debug(exc, exc_info=True)
+                    logger.error(f'Failed to find your QuickSight username ({exc}). Is QuickSight activated?')
+        return self._user
 
     @property
-    def athena(self) -> Athena:
-        if not self._clients.get('athena'):
-            self._clients.update({
-                'athena': Athena(self.base.session, resources=self.resources)
-            })
-        return self._clients.get('athena')
+    def group(self) -> dict:
+        if not self._group:
+            groupname = get_parameters().get('quicksight-group', None)
+            if groupname:
+                try:
+                    self._group =  self.describe_group(groupname)
+                except Exception as exc:
+                    logger.debug(exc, stack_info=True)
+                    logger.error(f'Failed to find your QuickSight groupname ({exc}). Is QuickSight activated?')
+        return self._group
 
     @property
-    def glue(self) -> Glue:
-        if not self._clients.get('glue'):
-            self._clients.update({
-                'glue': Glue(self.base.session)
-            })
-        return self._clients.get('glue')
+    def identityRegion(self) -> str:
+        if not self._identityRegion:
+            try:
+                logger.info(f'Detecting QuickSight identity region, trying {self.region}')
+                username = get_parameters().get('quicksight-user', self.username)
+                parameters = {
+                    'AwsAccountId': self.account_id,
+                    'UserName': username,
+                    'Namespace': 'default'
+                }
+                self.client.describe_user(**parameters)
+                self._identityRegion = self.region
+            except self.client.exceptions.AccessDeniedException as exc:
+                logger.debug(exc)
+                pattern = f'Operation is being called from endpoint {self.region}, but your identity region is (.*). Please use the (.*) endpoint.'
+                match = re.search(pattern, exc.response['Error']['Message'])
+                if match:
+                    logger.info(f'Switching QuickSight identity region to {match.group(1)}')
+                    self._identityRegion = match.group(1)
+                else:
+                    raise
+            except self.client.exceptions.ResourceNotFoundException:
+                logger.info(f'QuickSight identity region detection failed, using {self.region}')
+                self._identityRegion = self.region
+            except Exception as exc:
+                logger.debug(exc, exc_info=True)
+                logger.info(f'QuickSight identity region detection failed, using {self.region}')
+                self._identityRegion = self.region
+            logger.info(f'Using QuickSight identity region: {self._identityRegion}')
+        return self._identityRegion
+
+    def edition(self, fresh: bool=False) -> str:
+        """ get QuickSight Edition
+        :fresh: set to True if you want it fresh (not cached)
+        """
+        if fresh or not hasattr(self, '_subscription_info'):
+            self._subscription_info = self.describe_account_subscription()
+        status = self._subscription_info.get('AccountSubscriptionStatus')
+        if status != 'ACCOUNT_CREATED':
+            return None
+        return self._subscription_info.get('Edition')
 
     @property
-    def cur(self) -> CUR:
-        if not self._clients.get('cur'):
-            _cur = CUR(self.base.session)
-            _cur.athena = self.athena
-            print('Checking if CUR is enabled and available...')
-
-            if not _cur.configured:
-                raise ClientError("Error: please ensure CUR is enabled, if yes allow it some time to propagate")
-
-            print(f'\tAthena table: {_cur.tableName}')
-            print(f"\tResource IDs: {'yes' if _cur.hasResourceIDs else 'no'}")
-            if not _cur.hasResourceIDs:
-                raise ClientError("Error: CUR has to be created with Resource IDs")
-            print(f"\tSavingsPlans: {'yes' if _cur.hasSavingsPlans else 'no'}")
-            print(f"\tReserved Instances: {'yes' if _cur.hasReservations else 'no'}")
-            print('\n')
-            self._clients.update({
-                'cur': _cur
-            })
-        return self._clients.get('cur')
+    def supported_dashboards(self) -> dict:
+        return self._resources.get('dashboards')
 
     @property
-    def accountMap(self) -> AccountMap:
-        if not self._clients.get('accountMap'):
-            _account_map = AccountMap(self.base.session)
-            _account_map.athena = self.athena
-            _account_map.cur = self.cur
+    def supported_datasets(self) -> dict:
+        return self._resources.get('datasets')
 
-            self._clients.update({
-                'accountMap': _account_map
-            })
-        return self._clients.get('accountMap')
+    @property
+    def supported_views(self) -> dict:
+        return self._resources.get('views')
 
-    def command(func):
-        ''' a decorator that ensure that we logged in to AWS acc, and loaded additional resource files
-        '''
-        @functools.wraps(func)
-        def wrap(self, *args, **kwargs):
-            self.all_yes = self.all_yes or kwargs.get('yes') # Flag params need special treatment
-            if kwargs.get('verbose'): # Count params need special treatment
-                self.verbose = self.verbose + kwargs.get('verbose')
-            set_parameters(kwargs, all_yes=self.all_yes)
-            logger.debug(json.dumps(get_parameters()))
-            if not self._logger:
-                self._logger = set_cid_logger(
-                    verbosity=self.verbose,
-                    log_filename=get_parameters().get('log_filename', 'cid.log')
-                )
-                logger.info(f'Initializing CID {__version__} for {func.__name__}')
-            if not self.base:
-                self.aws_login()
-            self.load_resources()
-            return func(self, *args, **kwargs)
-        return wrap
-
-    def __loadPlugins(self) -> dict:
-        try:
-            _entry_points = entry_points().get('cid.plugins')
-        except: # fallback for python version more than 3.7.x AND still less then 3.8
-            _entry_points = [ep for ep in entry_points() if ep.group == 'cid.plugins']
-
-        plugins = dict()
-        print('Loading plugins...')
-        logger.info(f'Located {len(_entry_points)} plugin(s)')
-        for ep in _entry_points:
-            if ep.value in plugins.keys():
-                logger.info(f'Plugin {ep.value} already loaded, skipping')
-                continue
-            logger.info(f'Loading plugin: {ep.name} ({ep.value})')
-            plugin = Plugin(ep.value)
-            print(f"\t{ep.name} loaded")
-            plugins.update({ep.value: plugin})
-            try:
-                self.resources = always_merger.merge(
-                    self.resources, plugin.provides())
-            except AttributeError:
-                pass
-        print('\n')
-        logger.info('Finished loading plugins')
-        return plugins
-
-    def getPlugin(self, plugin) -> dict:
-        return self.plugins.get(plugin)
-
-
-    def get_definition(self, type: str, name: str=None, id: str=None) -> dict:
-        """ return resource definition that matches parameters """
-        if type not in ['dashboard', 'dataset', 'view']:
-            print(f'Error: {type} is not a valid type')
-            raise ValueError(f'{type} is not a valid definition type')
-        if type in  ['dataset', 'view'] and name:
-            return self.resources.get(f'{type}s').get(name)
-        elif type in ['dashboard']:
-            for definition in self.resources.get(f'{type}s').values():
-                if name is not None and definition.get('name') != name:
-                    continue
-                if id is not None and definition.get('dashboardId') != id:
-                    continue
-                return definition
-        return None
+    @property
+    def dashboards(self) -> Dict[str, Dashboard]:
+        """Returns a list of deployed dashboards"""
+        if self._dashboards is None:
+            self.discover_dashboards()
+        return self._dashboards
 
+    @property
+    def datasets(self) -> Dict[str, Dataset]:
+        """Returns a list of deployed dashboards"""
+        if self._datasets is None:
+            self.discover_datasets()
+        return self._datasets or {}
+
+    @property
+    def athena_datasources(self) -> Dict[str, Datasource]:
+        """Returns a list of existing athena datasources"""
+        return {d.id: d for d in self.get_datasources(type='ATHENA')}
+
+    @property
+    def datasources(self) -> Dict[str, Datasource]:
+        """Returns a list of existing datasources"""
+        if self._datasources is None:
+            logger.info(f"Discovering datasources for account {self.account_id}")
+            self.discover_data_sources()
+
+        return self._datasources
+
+    def ensure_subscription(self) -> None:
+        """Ensure that the QuickSight subscription is active"""
+        if not self.edition(fresh=True):
+            raise CidCritical('QuickSight is not activated. Please run `cid-cmd initqs` command, or activate QuickSight Enterprise Edition from the console.')
+        if self.edition() == 'STANDARD':
+            raise CidCritical(f'QuickSight Enterprise edition is required, you have {self.edition}.')
+        logger.info(f'QuickSight subscription: {self._subscription_info}')
+
+    def describe_account_subscription(self) -> dict:
+        """Returns the account subscription details"""
+        result = {}
 
-    @command
-    def export(self, **kwargs):
-        export_analysis(self.qs)
-
-    def track(self, action, dashboard_id):
-        """ Send dashboard_id and account_id to adoption tracker """
-        method = {'created':'PUT', 'updated':'PATCH', 'deleted': 'DELETE'}.get(action, None)
-        if not method:
-            logger.debug(f"This will not fail the deployment. Logging action {action} is not supported. This issue will be ignored")
-            return
-        endpoint = 'https://okakvoavfg.execute-api.eu-west-1.amazonaws.com/'
-        payload = {
-            'dashboard_id': dashboard_id,
-            'account_id': self.base.account_id,
-            action + '_via': 'Lambda' if os.environ.get('AWS_EXECUTION_ENV', '').startswith('AWS_Lambda') else 'CID',
-        }
         try:
-            res = requests.request(
-                method=method,
-                url=endpoint,
-                data=json.dumps(payload),
-                headers={'Content-Type': 'application/json'}
-            )
-            if res.status_code != 200:
-                logger.debug(f"This will not fail the deployment. There has been an issue logging action {action}  for dashboard {dashboard_id} and account {self.base.account_id}, server did not respond with a 200 response,actual  status: {res.status_code}, response data {res.text}. This issue will be ignored")
-        except Exception as e:
-            logger.debug(f"Issue logging action {action}  for dashboard {dashboard_id} , due to a urllib3 exception {str(e)} . This issue will be ignored")
+            result = self.client.describe_account_subscription(AwsAccountId=self.account_id).get('AccountInfo')
+        except self.client.exceptions.AccessDeniedException:
+            # In case we lack privileges to DescribeAccountSubscription API
+            # we use ListDashboards API call that throws UnsupportedUserEditionException
+            # in case the account doesn't have Enterprise edition
+            logger.info('Insufficient privileges to describe account subscription, working around')
+            try:
+                self.client.list_dashboards(AwsAccountId=self.account_id)
+                result = {'Edition': 'ENTERPRISE', 'AccountSubscriptionStatus': 'ACCOUNT_CREATED'}
+            except self.client.exceptions.UnsupportedUserEditionException as exc:
+                logger.debug(f'UnsupportedUserEditionException means edition is STANDARD: {exc}')
+                result = {'Edition': 'STANDARD', 'AccountSubscriptionStatus': 'ACCOUNT_CREATED'}
+        except self.client.exceptions.ResourceNotFoundException as exc:
+            logger.debug(exc, exc_info=True)
+            logger.info('QuickSight not activated?')
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+        return result
+
+
+    def discover_dashboard(self, dashboardId: str) -> Dashboard:
+        """Discover a single dashboard: describe and pull downstream info (datasets, related templates and views) """
+
+        def _safe_int(value, default=None):
+            """Safe int from string"""
+            return int(str(value)) if str(value).isdecimal() else default
+
+        dashboard = self.describe_dashboard(DashboardId=dashboardId)
+        if not dashboard:
+            raise CidCritical(f'Dashboard {dashboardId} was not found')
+        # Look for dashboard definition by DashboardId
+        _definition = next((v for v in self.supported_dashboards.values() if v['dashboardId'] == dashboard.id), None)
+        if not _definition:
+            # Look for dashboard definition by templateId.
+            # This is for a specific use-case when a dashboard with another id points to managed template
+            source_arn = dashboard.raw.get('Version', {}).get('SourceEntityArn', '')
+            if source_arn:
+                template_id = source_arn.split('/version/')[0].split('/')[-1]
+                template_account = source_arn.split(':').pop(4)
+                logger.info(template_id)
+                _definition = next((v for v in self.supported_dashboards.values() if 'templateId' in v and v['templateId'] == template_id), None)
+        if not _definition:
+            logger.info(f'Unsupported dashboard "{dashboard.name}" ({dashboard.template_arn})')
+            return None
+
+        logger.info(f'Supported dashboard "{dashboard.name}" ({dashboard.template_arn})')
+        dashboard.definition = _definition
+        logger.info(f'Found definition for "{dashboard.name}" ({dashboard.template_arn})')
+
+        # Check for extra information from resource definition
+        version_obj = _definition.get('versions', dict())
+        min_template_version = _safe_int(version_obj.get('minTemplateVersion'))
+        default_description_version = version_obj.get('minTemplateDescription')
+
+        # Fetch template referenced as dashboard source (if any)
+        _template_arn = dashboard.version.get('SourceEntityArn')
+        if _template_arn and isinstance(_template_arn, str) \
+            and len(_template_arn.split(':')) > 5 \
+            and _template_arn.split(':')[5].startswith('template/'):
+
+            params = {
+                "template_id": _template_arn.split('/')[1],
+                "account_id": _template_arn.split(':')[4],
+                "region": _template_arn.split(':')[3]
+            }
+
+            if '/version/' in _template_arn:
+                params['version_number'] = _safe_int(_template_arn.split('/version/')[-1])
+            elif min_template_version:
+                logger.info(f"Using default version number {min_template_version} in place")
+                params['version_number'] = min_template_version
+
+            if 'version_number' in params:
+                try:
+                    _template = self.describe_template(**params)
+                    if isinstance(_template, CidQsTemplate):
+                        dashboard.deployedTemplate = _template
+                except Exception as exc:
+                    logger.debug(exc, exc_info=True)
+                    logger.info(f'Unable to describe template for {dashboardId}, {exc}')
+            else:
+                logger.info("Minimum template version could not be found for Dashboard {dashboardId}: {_template_arn}, deployed template could not be described")
 
 
-    def load_resources(self):
-        ''' load additional resources from command line parameters
-        '''
-        if get_parameters().get('resources'):
-            source = get_parameters().get('resources')
-            logging.info(f'Loading resources from {source}')
-            resources = {}
+        # Fetch datasets
+        for dataset in dashboard.version.get('DataSetArns', []):
+            dataset_id = dataset.split('/')[-1]
             try:
-                if source.startswith('https://'):
-                    resp = requests.get(source)
-                    assert resp.status_code in [200, 201], f'Error {resp.status_code} while loading url. {resp.text}'
-                    resources = yaml.safe_load(resp.text)
+                _dataset = self.describe_dataset(id=dataset_id)
+                if not isinstance(_dataset, Dataset):
+                    logger.info(f'Dataset "{dataset_id}" is missing')
                 else:
-                    with open(source, encoding='utf-8') as file_:
-                        resources = yaml.safe_load(file_)
+                    logger.info(f"Detected dataset: \"{_dataset.name}\" ({_dataset.id} in {dashboard.name})")
+                    dashboard.datasets.update({_dataset.name: _dataset.id})
+            except self.client.exceptions.AccessDeniedException:
+                logger.info(f'Access denied describing DataSetId {dataset_id} for Dashboard {dashboardId}')
+            except self.client.exceptions.InvalidParameterValueException:
+                logger.info(f'Invalid dataset {dataset_id}')
+        logger.info(f"{dashboard.name} has {len(dashboard.datasets)} datasets")
+
+        # Fetch the latest version of sourceTemplate referenced in definition
+        source_template_account_id = _definition.get('sourceAccountId')
+        template_id = _definition.get('templateId')
+        region = _definition.get('region', 'us-east-1')
+        if template_id:
+            try:
+                logger.debug(f'Loading latest source template {template_id} from source account {source_template_account_id} in {region}')
+                template = self.describe_template(template_id, account_id=source_template_account_id, region=region)
+                dashboard.sourceTemplate = template
             except Exception as exc:
-                raise CidCritical(f'Failed to load resources from {source}: {type(exc)} {exc}')
-            self.resources = always_merger.merge(self.resources, resources)
+                logger.debug(exc, exc_info=True)
+                logger.info(f'Unable to describe template {template_id} in {source_template_account_id} ({region})')
 
+        # Checking for version override in template definition
+        for dashboard_template in [dashboard.deployedTemplate, dashboard.sourceTemplate]:
+            if not isinstance(dashboard_template, CidQsTemplate)\
+                or int(dashboard_template.version) <= 0 \
+                or not version_obj:
+                continue
 
-    @command
-    def deploy(self, dashboard_id: str=None, recursive=True, update=False, **kwargs):
-        """ Deploy Dashboard Command"""
-        self._deploy(dashboard_id, recursive, update, **kwargs)
+            logger.debug("versions object found in template")
+            version_map = version_obj.get('versionMap', dict())
+            description_override = version_map.get(int(dashboard_template.version))
 
+            try:
+                if description_override:
+                    logger.info(f"Template description is overridden with: {description_override}")
+                    description_override = str(description_override)
+                    dashboard_template.raw['Version']['Description'] = description_override
+                else:
+                    if min_template_version and default_description_version:
+                        if int(dashboard_template.version) <= min_template_version:
+                            logger.info(f"The template version does not provide cid_version in description, using the default template description: {default_description_version}")
+                            dashboard_template.raw['Version']['Description'] = default_description_version
+            except ValueError as val_error:
+                logger.debug(val_error,  exc_info=True)
+                logger.info("The provided values of the versions object are not well formed, please use int for template version and str for template description")
+            except Exception as exc:
+                logger.debug(exc, exc_info=True)
+                logger.info("Unable to override template description")
 
-    def _deploy(self, dashboard_id: str=None, recursive=True, update=False, **kwargs):
-        """ Deploy Dashboard """
+        # Fetch all views recursively
+        all_views = []
+        def _recursive_add_view(view):
+            all_views.append(view)
+            for dep_view in (self.supported_views.get(view) or {}).get('dependsOn', {}).get('views', []):
+                _recursive_add_view(dep_view)
+        for dataset_name in dashboard.datasets:
+            for view in (self.supported_datasets.get(dataset_name) or {}).get('dependsOn', {}).get('views', []):
+                _recursive_add_view(view)
+        dashboard.views = all_views
+        self._dashboards = self._dashboards or {}
+        self._dashboards[dashboardId] = dashboard
+        logger.info(f'"{dashboard.name}" ({dashboardId}) discover complete')
+        return dashboard
 
-        self.qs.ensure_subscription()
+    def ensure_group_exists(self, groupname='cid-owners', description='Created by Cloud Intelligence Dashboards'):
+        try:
+            group = self.identityClient.describe_group(
+                AwsAccountId=self.account_id,
+                Namespace='default',
+                GroupName=groupname
+            ).get('Group')
+        except self.client.exceptions.ResourceNotFoundException:
+            group = self.identityClient.create_group(
+                AwsAccountId=self.account_id,
+                GroupName=groupname,
+                Namespace='default',
+                Description=description,
+            ).get('Group')
+        except self.client.exceptions.AccessDeniedException as exc:
+            raise CidCritical('Cannot access groups. (AccessDenied). Please use quicksight-user parameter '
+                'or ensure you have permissions quicksight::DescribeGroup and quicksight::CreateGroup') from exc
+        return group
+
+
+    def get_principal_arn(self):
+        if self._principal_arn:
+            return self._principal_arn
+
+        if self.group and self.user:
+            raise CidCritical('provided both quicksight-group and quicksight-user. Please keep just one.')
+        if self.group:
+            self._principal_arn = self.group.get('Arn')
+        elif self.user:
+            self._principal_arn = self.user.get('Arn')
+
+        if self._principal_arn:
+            return self._principal_arn
+
+        # No parameters provided, let's ask user. Following parameter is not supposed to be used by CLI users.
+        auth_type = self.describe_account_subscription().get('AuthenticationType')
+        if auth_type not in ["ACTIVE_DIRECTORY", 'IAM_IDENTITY_CENTER']:
+            choices = [
+                'group cid-owners (recommended)',
+                'select group',
+                f'current user {self.username}',
+                'select user',
+            ]
+        else: # cannot create groups if managed by AD or IAM IC. And cannot read users.
+            choices = [
+                'select group',
+                'select user',
+            ]
+        quicksight_owner = get_parameter('quicksight-owner-choice',
+            message='You have not provided quicksight-user or quicksight-group. Do you what your objects to be owned by a user or a group?',
+            choices=choices,
+            default=choices[0],
+        )
 
-        if dashboard_id is None:
-            dashboard_id = get_parameter(
-                param_name='dashboard-id',
-                message="Please select dashboard to install",
-                choices={
-                   f"[{dashboard.get('dashboardId')}] {dashboard.get('name')}" : dashboard.get('dashboardId')
-                   for k, dashboard in self.resources.get('dashboards').items()
-                },
-            )
-        if not dashboard_id:
-            print('No dashboard selected')
-            return
-
-        # Get selected dashboard definition
-        dashboard_definition = self.get_definition("dashboard", id=dashboard_id)
-        
-        dashboard = self.qs.dashboards.get(dashboard_id)
-        
-        if not dashboard_definition:
-            if isinstance(dashboard, Dashboard):
-                dashboard_definition = dashboard.definition
-            else:
-                raise ValueError(f'Cannot find dashboard with id={dashboard_id} in resources file.')
+        if quicksight_owner.startswith("current user"):
+            try:
+                self._user =  self.describe_user(self.username) # Only works for IAM
+            except Exception as exc:
+                logger.debug(exc, stack_info=True)
+                logger.error(f'Failed to find your QuickSight username ({exc}). Is QuickSight activated? Is there a user ({self.username})?')
+            if not self._user:
+                self._user = self.select_user() # fallback to user choice
+            if not self._user:
+                raise CidCritical('Cannot get QuickSight username. Is Enterprise subscription activated in QuickSight?')
+            logger.info(f"Using QuickSight user {self._user.get('UserName')}")
+            self._principal_arn = self._user.get('Arn')
+
+        elif quicksight_owner.startswith("select group"):
+            self._group = self.select_group()
+            if not self._group:
+                raise CidCritical('Cannot get QuickSight group.')
+            self._principal_arn = self._group.get('Arn')
+
+        elif quicksight_owner.startswith("select user"):
+            self._user = self.select_user()
+            if not self._user:
+                raise CidCritical('Cannot get QuickSight username. Is Enterprise subscription activated in QuickSight?')
+            self._principal_arn = self._user.get('Arn')
+
+        elif quicksight_owner.startswith("group cid-owners"):
+            group = self.ensure_group_exists('cid-owners')
+            self._principal_arn = group.get('Arn')
+
+        if not self._principal_arn:
+            raise CidCritical('Cannot find principal_arn. Please provide --quicksight-username or --quicksight-groupname')
+        return self._principal_arn
+
+
+    def create_data_source(self, athena_workgroup, datasource_id: str=None, role_arn: str=None) -> Datasource:
+        """Create a new data source"""
+        logger.info('Creating Athena data source')
+
+        columns_tpl = {
+            'PrincipalArn': self.get_principal_arn()
+        }
+        data_source_permissions_tpl = Template(resource_string(
+            package_or_requirement='cid.builtin.core',
+            resource_name='data/permissions/data_source_permissions.json',
+        ).decode('utf-8'))
+        data_source_permissions = json.loads(data_source_permissions_tpl.safe_substitute(columns_tpl))
+        datasource_name = datasource_id or "CID Athena"
+        datasource_id = datasource_id or str(uuid.uuid4())
+        params = {
+            "AwsAccountId": self.account_id,
+            "DataSourceId": datasource_id,
+            "Name": datasource_name,
+            "Type": "ATHENA",
+            "DataSourceParameters": {
+                "AthenaParameters": {
+                    "WorkGroup": athena_workgroup,
+                }
+            },
+            "Permissions": [
+                data_source_permissions
+            ]
+        }
+        if role_arn:
+            params['DataSourceParameters']['AthenaParameters']['RoleArn'] = role_arn
+        try:
+            logger.info(f'Creating data source {params}')
+            create_status = self.client.create_data_source(**params)
+            logger.debug(f'Data source creation result {create_status}')
+            # Wait for the datasource completion
+            for _ in tqdm(range(60), desc='DataSet Creation', leave=False):
+                time.sleep(1)
+                datasource = self.describe_data_source(datasource_id, update=True)
+                logger.debug(f'Waiting for datasource {datasource_id}. current status={datasource.status}')
+                if not datasource.status.endswith('IN_PROGRESS'):
+                    break
+            if not datasource.is_healthy:
+                logger.error(f'DataSource parameters: {json.dumps(params, indent=2)}')
+                logger.error(f'DataSource creation failed: {datasource.error_info}.')
+                if "The QuickSight service role required to access your AWS resources has not been created yet." in str(datasource.error_info):
+                    logger.error(
+                        'Please check that QuickSight has a default role that can access S3 Buckets and Athena https://quicksight.aws.amazon.com/sn/admin?#aws '
+                        'OR provide a custom datasource role as a parameter --quicksight-datasource-role-arn'
+                    )
+                if get_parameter(
+                    param_name='quicksight-delete-failed-datasource',
+                    message=f'Data source creation failed: {datasource.error_info}. Delete(recommended)?',
+                    choices=['yes', 'no'],
+                    default='yes'
+                ) == 'yes':
+                    try:
+                        self.delete_data_source(datasource.id)
+                    except self.client.exceptions.AccessDeniedException:
+                        logger.info('Access denied deleting Athena datasource')
+                return None
+            for _ in tqdm(range(5), desc='Waiting for Data Source', leave=False):
+                time.sleep(1)
+            return datasource
+        except self.client.exceptions.ResourceExistsException:
+            datasource = self.describe_data_source(datasource_id, update=True)
+            logger.error(f'Data source already exists {datasource.raw}')
+            if not datasource.is_healthy:
+                if get_parameter(
+                    param_name='quicksight-delete-failed-datasource',
+                    message=f'Data source creation failed: {datasource.error_info}. Delete?',
+                    choices=['yes', 'no'],
+                ) == 'yes':
+                    try:
+                        self.delete_data_source(datasource.id)
+                        raise CidCritical('Issue on datasource creation. Please retry.')
+                    except self.client.exceptions.AccessDeniedException:
+                        raise CidCritical('Access denied deleting datasource in QS. Please cleanup manually and retry.')
+            return datasource
+        except self.client.exceptions.AccessDeniedException as exc:
+            logger.info('Access denied creating Athena datasource')
+            logger.debug(exc, exc_info=True)
+            return None
+        return None
 
-        required_datasets = dashboard_definition.get('dependsOn', dict()).get('datasets', list())
+    def create_folder(self, folder_name: str, **create_parameters) -> dict:
+        """Create a new folder"""
+        logger.info('Creating QuickSight folder')
+        folder_id = str(uuid.uuid4())
+        create_parameters.update({
+            "AwsAccountId": self.account_id,
+            "FolderId": folder_id,
+            "Name": folder_name,
+            "FolderType": "SHARED",
+        })
+        try:
+            logger.info(f'Creating folder {create_parameters}')
+            result = self.client.create_folder(**create_parameters)
+            logger.debug(f'Folder creation result {result}')
+            if (result.get('Status') != 200):
+                logger.info(f'Folder creation failed with status {result.get("Status")}')
+                return None
+            folder = self.describe_folder(result['FolderId'])
+            return folder
+        except self.client.exceptions.ResourceExistsException:
+            logger.info('Folder already exists')
+            return self.describe_folder(folder_id)
+        except self.client.exceptions.AccessDeniedException:
+            logger.info('Access denied creating folder')
+            raise
+        return None
 
-        dashboard_datasets = dashboard.datasets if dashboard else {}
-        
-        for name, id in dashboard_datasets.items():
-            if id not in self.qs.datasets:
-                logger.info(f'Removing unknown dataset "{name}" ({id}) from dashboard {dashboard_id}')
-                del dashboard_datasets[name]
-
-        # Get QuickSight template details
-        try:
-            source_template = self.qs.describe_template(
-                template_id=dashboard_definition.get('templateId'),
-                account_id=dashboard_definition.get('sourceAccountId'),
-                region=dashboard_definition.get('region', 'us-east-1')
-            )
-        except CidError as exc:
-            raise CidCritical(exc) # Cannot proceed without a valid template
-        dashboard_definition.update({'sourceTemplate': source_template})
-        print(f'\nLatest template: {source_template.arn}/version/{source_template.version}')
-                    
-        if recursive:
-            self.create_datasets(required_datasets, dashboard_datasets, recursive=recursive, update=update)
-
-        # Prepare API parameters
-        if not dashboard_definition.get('datasets'):
-            dashboard_definition.update({'datasets': {}})
-        for dataset_name in required_datasets:
-            ds = next((v for v in self.qs.datasets.values() if v.name == dataset_name), None)
-            if isinstance(ds, Dataset):
-                dataset_fields = {col.get('Name'): col.get('Type') for col in ds.columns}
-                required_fileds = {col.get('Name'): col.get('DataType') for col in source_template.datasets.get(dataset_name)}
-                unmatched = {}
-                for k,v in required_fileds.items():
-                    if k not in dataset_fields or dataset_fields[k] != v:
-                        unmatched.update({k: {'expected': v, 'found': dataset_fields.get(k)}})
-                if unmatched:
-                    raise CidCritical(f'Dataset "{dataset_name}" ({ds.id}) is missing required fields. {(unmatched)}')
-                else:
-                    print(f'Using dataset {dataset_name}: {ds.id}')
-                    dashboard_definition.get('datasets').update({dataset_name: ds.arn})
-  
-
-        kwargs = dict()
-        local_overrides = f'work/{self.base.account_id}/{dashboard_id}.json'
-        logger.info(f'Looking for local overrides file "{local_overrides}"...')
+    def create_folder_membership(self, folder_id: str, member_id: str, member_type: str) -> bool:
+        """Create a new folder membership"""
+        logger.info(f'Creating folder membership for {member_type}: {member_id}')
+        params = {
+            "AwsAccountId": self.account_id,
+            "FolderId": folder_id,
+            "MemberId": member_id,
+            "MemberType": member_type
+        }
         try:
-            with open(local_overrides, 'r', encoding='utf-8') as r:
-                try:
-                    print('found')
-                    if click.confirm(f'Use local overrides from {local_overrides}?'):
-                        kwargs = json.load(r)
-                        print('loaded')
-                except Exception as e:
-                    # Catch exception and dump a reason
-                    click.echo('failed to load, dumping error message')
-                    print(json.dumps(e, indent=4, sort_keys=True, default=str))
-        except FileNotFoundError:
-            logger.info('local overrides file not found')
-
-        _url = self.qs_url.format(dashboard_id=dashboard_id, **self.qs_url_params)
-
-        dashboard = self.qs.dashboards.get(dashboard_id)
-        if isinstance(dashboard, Dashboard):
-            if update:
-                return self.update_dashboard(dashboard_id, recursive, required_datasets, dashboard_datasets,**kwargs)
+            logger.info(f'Creating folder membership {params}')
+            result = self.client.create_folder_membership(**params)
+            logger.debug(f'Folder membership creation result {result}')
+            logger.info(f'Folder membership creation status {result.get("Status")}')
+            if (result['Status'] != 200):
+                logger.info(f'Folder membership creation failed with code {result.get("Status")}')
+                return False
+            return True
+        except self.client.exceptions.ResourceExistsException:
+            logger.error('Folder membership already exists')
+        except self.client.exceptions.AccessDeniedException:
+            logger.info('Access denied creating folder membership')
+        return False
+
+    def discover_data_sources(self) -> None:
+        """ Discover existing datasources"""
+        if self._datasources is None:
+            self._datasources = {}
+        logger.info('Discovering existing datasources')
+        try:
+            for v in self.list_data_sources():
+                _datasource = Datasource(v)
+                logger.info(f'Found datasource "{_datasource.name}" ({_datasource.id}) status={_datasource.status}')
+                self._datasources.update({_datasource.id: _datasource})
+        except self.client.exceptions.AccessDeniedException:
+            logger.info('Access denied discovering data sources')
+            for v in self.datasets.values():
+                for d in v.datasources:
+                    self.describe_data_source(d)
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+
+    def discover_dashboards(self, refresh: bool=False) -> None:
+        """ Discover deployed dashboards """
+        if refresh or self._dashboards is None:
+            self._dashboards = {}
+        logger.info('Discovering deployed dashboards')
+        deployed_dashboards=self.list_dashboards()
+        logger.info(f'Found {len(deployed_dashboards)} deployed dashboards')
+        logger.debug(deployed_dashboards)
+        bar = tqdm(deployed_dashboards, desc='Discovering Dashboards', leave=False)
+        for dashboard in bar:
+            # Discover found dashboards
+            dashboard_name = dashboard.get('Name')
+            dashboard_id = dashboard.get('DashboardId')
+            bar.set_description(f'Discovering {dashboard_name[:10]:<10}', refresh=True)
+            logger.info(f'Discovering "{dashboard_name}"')
+            self.discover_dashboard(dashboard_id)
+
+    def list_dashboards(self) -> list:
+        parameters = {
+            'AwsAccountId': self.account_id
+        }
+        try:
+            result = self.client.list_dashboards(**parameters)
+            if result.get('Status') != 200:
+                raise CidCritical(f'list_dashboards returns: {result}')
             else:
-                print(f'Dashboard {dashboard_id} exists. See {_url}')
-                return dashboard_id
-
-        print(f'Deploying dashboard {dashboard_id}')
+                logger.debug(result)
+                return result.get('DashboardSummaryList')
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+            return []
+
+    def list_data_sources(self) -> list:
+        parameters = {
+            'AwsAccountId': self.account_id
+        }
+        data_sources = []
         try:
-            dashboard = self.qs.create_dashboard(dashboard_definition, **kwargs)
-            print(f"\n#######\n####### Congratulations!\n####### {dashboard_definition.get('name')} is available at: {_url}\n#######")
-            self.track('created', dashboard_id)
-        except self.qs.client.exceptions.ResourceExistsException:
-            print('error, already exists')
-            print(f"#######\n####### {dashboard_definition.get('name')} is available at: {_url}\n#######")
-        except Exception as e:
-            # Catch exception and dump a reason
-            logger.debug(e, exc_info=True)
-            print(f'failed with an error message: {e}')
-            self.delete(dashboard_id)
-            raise CidCritical(f'Deploy failed: {e}')
-
-        if get_yesno_parameter(
-                param_name=f'share-with-account',
-                message=f'Share this dashboard with everyone in the account?',
-                default='yes'):
-            set_parameters({'share-method': 'account'})
-            self.share(dashboard_id)
-
-        return dashboard_id
-
-
-    @command
-    def open(self, dashboard_id, **kwargs):
-        """Open QuickSight dashboard in browser"""
-
-        aws_execution_env = os.environ.get('AWS_EXECUTION_ENV', '')
-        if  aws_execution_env == 'CloudShell' or aws_execution_env.startswith('AWS_Lambda'):
-            print(f"Operation is not supported in {aws_execution_env}")
+            for page in self.client.get_paginator('list_data_sources').paginate(**parameters):
+                data_sources += page.get('DataSources',[])
+            return data_sources
+        except self.client.exceptions.AccessDeniedException:
+            logger.info('Access denied listing data sources')
+            raise
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+            return list()
+
+    def clear_dashboard_selection (self):
+        """ Clears the current dashboard selection. """
+        unset_parameter('dashboard-id')
+
+    def select_dashboard(self, force=False) -> str:
+        """ Select from a list of discovered dashboards """
+        dashboard_id = get_parameters().get('dashboard-id')
+        if dashboard_id:
             return dashboard_id
-        if not dashboard_id:
-            dashboard_id = self.qs.select_dashboard(force=True)
-            dashboard = self.qs.dashboards.get(dashboard_id)
-        else:
-            # Describe dashboard by the ID given, no discovery
-            dashboard = self.qs.describe_dashboard(DashboardId=dashboard_id)
-
-        click.echo('Getting dashboard status...', nl=False)
-        if dashboard is not None:
-            if dashboard.version.get('Status') not in ['CREATION_SUCCESSFUL']:
-                print(json.dumps(dashboard.version.get('Errors'),
-                      indent=4, sort_keys=True, default=str))
-                click.echo(
-                    f'\nDashboard is unhealthy, please check errors above.')
-            click.echo('healthy, opening...')
-            click.launch(self.qs_url.format(dashboard_id=dashboard_id, **self.qs_url_params))
-        else:
-            click.echo('not deployed.')
-        
-        return dashboard_id
-
-    @command
-    def status(self, dashboard_id, **kwargs):
-        """Check QuickSight dashboard status"""
-
-        if not dashboard_id:
-            if not self.qs.dashboards:
-                print('No deployed dashboards found')
-                return
-            dashboard_id = self.qs.select_dashboard(force=True)
-            if not dashboard_id:
-                print('No dashboard selected')
-                return
-            dashboard = self.qs.dashboards.get(dashboard_id)
-        else:
-            dashboard = self.qs.discover_dashboard(dashboardId=dashboard_id)
-
-        if dashboard is not None:
-            dashboard.display_status()
-            dashboard.display_url(self.qs_url, **self.qs_url_params)
-        else:
-            click.echo('not deployed.')
-
-    @command
-    def delete(self, dashboard_id, **kwargs):
-        """Delete QuickSight dashboard"""
-
-        if not dashboard_id:
-            if not self.qs.dashboards:
-                print('No deployed dashboards')
-                return
-            dashboard_id = self.qs.select_dashboard(force=True)
-            if not dashboard_id:
-                return
 
-        if self.qs.dashboards and dashboard_id in self.qs.dashboards:
-            datasets = self.qs.dashboards.get(dashboard_id).datasets # save for later
-        else:
-            dashboard_definition = self.get_definition("dashboard", id=dashboard_id)
-            datasets = {d: None for d in (dashboard_definition or {}).get('dependsOn', {}).get('datasets', [])}
+        if not self.dashboards:
+            return None
+        choices = {}
+        for dashboard in self.dashboards.values():
+            health = '' if dashboard.health else ' UNHEALTHY'
+            status = '' if dashboard.status == 'up to date' else ' ' + dashboard.status.upper()
+            key = f'{dashboard.name} ({dashboard.arn.split("/")[-1]}){health}{status}'
+            notice = dashboard.definition.get('deprecationNotice', '')
+            if notice:
+                key = f'{key} {notice}'
+            if ((dashboard.latest or not dashboard.health or notice) and not force):
+                choices[key] = None
+            else:
+                choices[key] = dashboard.id
 
         try:
-            # Execute query
-            click.echo('Deleting dashboard...', nl=False)
-            self.qs.delete_dashboard(dashboard_id=dashboard_id)
-            print(f'Dashboard {dashboard_id} deleted')
-            self.track('deleted', dashboard_id)
-        except self.qs.client.exceptions.ResourceNotFoundException:
-            print('not found')
-        except Exception as e:
-            # Catch exception and dump a reason
-            logger.debug(e, exc_info=True)
-            print(f'failed with an error message: {e}')
+            dashboard_id = get_parameter(
+                param_name='dashboard-id',
+                message="Please select dashboard from the list",
+                choices=choices,
+                none_as_disabled=True,
+            )
+        except AttributeError as exc:
+            # No updatable dashboards (selection is disabled)
+            logger.debug(exc, exc_info=True)
+        except Exception as exc:
+            logger.exception(exc)
+        finally:
             return dashboard_id
 
-        print('Processing dependencies')
-        for dataset_name, dataset_id in datasets.items():
-            self.delete_dataset(name=dataset_name, id=dataset_id)
-
-        return dashboard_id
-
-    def delete_dataset(self, name: str, id: str=None):
-        if name not in self.resources['datasets']:
-            logger.info(f'Dataset {name} is not managed by CID. Skipping.')
-            print(f'Dataset {name} is not managed by CID. Skipping.')
-            return False
-        for dataset in list(self.qs._datasets.values()) if self.qs._datasets else []:
-            if dataset.id == id or dataset.name == name:
-                # Check if dataset is used in some other dashboard
-                for dashboard in (self.qs.dashboards or {}).values():
-                    if dataset.id in dashboard.datasets.values():
-                        logger.info(f'Dataset {dataset.name} ({dataset.id}) is still used by dashboard "{dashboard.id}". Skipping.')
-                        print      (f'Dataset {dataset.name} ({dataset.id}) is still used by dashboard "{dashboard.id}". Skipping.')
-                        return False
-                else: #not used
-
-                    # try to get the database name from the dataset (might need this for later)
-                    schema = next(iter(dataset.schemas), None) # FIXME: manage choice if multiple data sources
-                    if schema:
-                        self.athena.DatabaseName = schema
-
-                    if get_parameter(
-                        param_name=f'confirm-{dataset.name}',
-                        message=f'Delete QuickSight Dataset {dataset.name}?',
-                        choices=['yes', 'no'],
-                        default='no') == 'yes':
-                        print(f'Deleting dataset {dataset.name} ({dataset.id})')
-                        self.qs.delete_dataset(dataset.id)
-                    else:
-                        logger.info(f'Skipping dataset {dataset.name}')
-                        print      (f'Skipping dataset {dataset.name}')
-                        return False
-                if not dataset.datasources:
-                    continue
-                datasources = dataset.datasources
-                athena_datasource = self.qs.datasources.get(datasources[0])
-                if athena_datasource:
-                    self.athena.WorkGroup = athena_datasource.AthenaParameters.get('WorkGroup')
-                    break
-                logger.debug(f'Cannot find QuickSight DataSource {datasources[0]}. So cannot define Athena WorkGroup')
-                continue
-        else:
-            logger.info(f'Dataset not found for deletion: {name} ({id})')
-        for view_name in list(set(self.resources['datasets'][name].get('dependsOn', {}).get('views', []))):
-            self.delete_view(view_name)
-        return True
-
-    def delete_view(self, view_name):
-        if view_name not in self.resources['views']:
-            logger.info(f'View {view_name} is not managed by CID. Skipping.')
-            return False
-        logger.info(f'Deleting view "{view_name}"')
-        definition = self.get_definition("view", name=view_name)
-        if not definition:
-            logger.info(f'Definition not found for view: "{view_name}"')
-            return False
+    def select_user(self):
+        """ Select a user from the list of users """
+        all_users = []
+        next_token = None
+        try:
+            while True:
+                if next_token:
+                    response = self.identityClient.list_users(AwsAccountId=self.account_id, Namespace='default', NextToken=next_token)
+                else:
+                    response = self.identityClient.list_users(AwsAccountId=self.account_id, Namespace='default')
 
-        for dashboard in (self.qs.dashboards or {}).values():
-            if view_name in dashboard.views:
-                print(f'View {view_name} is used by dashboard "{dashboard.id}". Skipping')
-                return False
+                user_list = response.get('UserList', [])
+                all_users.extend(user_list)
 
-        self.athena.discover_views([view_name])
-        if view_name not in self.athena._metadata.keys():
-            print(f'Table for deletion not found: {view_name}')
-        else:
-            if definition.get('type', '') == 'Glue_Table':
-                print(f'Deleting table: {view_name}')
-                self.athena.delete_table(view_name)
-            else:
-                print(f'Deleting view:  {view_name}')
-                self.athena.delete_view(view_name)
+                next_token = response.get('NextToken')
+                if not next_token:
+                    break
 
-        # manage dependancies
-        for dependancy_view in list(set(definition.get('dependsOn', {}).get('views', []))):
-            self.delete_view(dependancy_view)
-
-        return True
-
-    @command
-    def cleanup(self, **kwargs):
-        """Delete unused resources (QuickSight datasets, Athena views)"""
-
-        self.qs.discover_dashboards()
-        self.qs.discover_datasets()
-        used_datasets = [x for v in self.qs.dashboards.values() for x in v.datasets.values() ]
-        for v in list(self.qs._datasets.values()):
-            if v.arn not in used_datasets and click.confirm(f'Delete unused dataset {v.name}?'):
-                logger.info(f'Deleting dataset {v.name} ({v.arn})')
-                self.qs.delete_dataset(v.id)
-                logger.info(f'Deleted dataset {v.name} ({v.arn})')
-                print(f'Deleted dataset {v.name} ({v.arn})')
-            else:
-                print(f'Dataset {v.name} ({v.arn}) is in use')
+            # Sort the users by UserName
+            user_list = sorted(all_users, key=lambda x: x.get('UserName'))
 
+        except self.client.exceptions.AccessDeniedException as exc:
+            raise CidCritical('AccessDenied for listing users, your can explicitly provide --quicksight-user parameter') from exc
 
-    @command
-    def share(self, dashboard_id, **kwargs):
-        """Share resources (QuickSight datasets, dashboards)"""
-        self._share(dashboard_id, **kwargs)
+        user_name = get_parameter(
+            param_name='quicksight-user',
+            message="Please select QuickSight user to use",
+            choices={f"{user.get('UserName')} ({user.get('Email')}, {user.get('Role')})":user.get('UserName') for user in user_list}
+        )
+        for user in user_list:
+            if user.get('UserName') == user_name:
+                return user
 
+    def select_group(self):
+        """ Select a group from the list of groups """
+        try:
+            groups = self.identityClient.list_groups(AwsAccountId=self.account_id, Namespace='default').get('GroupList')
+        except self.client.exceptions.AccessDeniedException as exc:
+            raise CidCritical('AccessDenied for listing groups, your can explicitly provide --quicksight-group parameter') from exc
+
+        group_name = get_parameter(
+            param_name='quicksight-group',
+            message="Please select QuickSight Group to use",
+            choices={f"{group.get('GroupName')} ({group.get('Description')})":group.get('GroupName') for group in groups}
+        )
+        for group in groups:
+            if group.get('GroupName') == group_name:
+                return group
+
+    def list_data_sets(self):
+        parameters = {
+            'AwsAccountId': self.account_id
+        }
+        try:
+            result = self.client.list_data_sets(**parameters)
+            if result.get('Status') != 200:
+                raise CidCritical(f'list_data_sets: {result}')
+            else:
+                return result.get('DataSetSummaries')
+        except self.client.exceptions.AccessDeniedException:
+            raise
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+            return None
 
-    def _share(self, dashboard_id, **kwargs):
-        """Share resources (QuickSight datasets, dashboards)"""
 
-        if not dashboard_id:
-            if not self.qs.dashboards:
-                print('No deployed dashboards found')
-                return
-            dashboard_id = self.qs.select_dashboard(force=True)
-            if not dashboard_id:
-                return
-        else:
-            # Describe dashboard by the ID given, no discovery
-            self.qs.discover_dashboard(dashboardId=dashboard_id)
+    def list_folders(self) -> list:
+        parameters = {
+            'AwsAccountId': self.account_id
+        }
+        try:
+            result = self.client.list_folders(**parameters)
+            if result.get('Status') != 200:
+                 raise CidCritical(f'list_folders: {result}')
+            else:
+                logger.debug(f"Folder_list: {result.get('FolderSummaryList')}")
+                return result.get('FolderSummaryList')
+        except self.client.exceptions.AccessDeniedException:
+            logger.info('Access denied listing folders')
+            raise
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+            return None
 
-        dashboard = self.qs.dashboards.get(dashboard_id)
 
-        if dashboard is None:
-            print('not deployed.')
-            return
-
-        share_methods = {
-            'Shared Folder (except datasource)': 'folder',
-            'Specific User only': 'user',
-            'Everyone in this account': 'account',
+    def describe_folder(self, folder_id: str) -> dict:
+        parameters = {
+            'AwsAccountId': self.account_id,
+            'FolderId': folder_id
         }
-        share_method = get_parameter(
-            param_name='share-method',
-            message="Please select sharing method",
-            choices=share_methods,
+        try:
+            result = self.client.describe_folder(**parameters)
+            logger.debug(f"DescribeFolder: {result}")
+            if result.get('Status') != 200:
+                raise CidCritical(f'describe_folder : {result}')
+            else:
+                logger.debug(result.get('Folder'))
+                return result.get('Folder')
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+            return None
+
+
+    def select_folder(self):
+        """ Select a folder from the list of folders """
+        try:
+            folder_list = self.list_folders()
+            if not folder_list:
+                return None
+        except self.client.exceptions.AccessDeniedException:
+            logger.error('AccessDeniedException on listing folders')
+            raise
+
+        _folder = get_parameter(
+            param_name='folder-id',
+            message="Please select QuickSight folder to use",
+            choices={f"{folder.get('Name')} ({folder.get('FolderId')})":folder for folder in folder_list}
         )
-        if share_method == 'folder':
-            folder = None
-            folder_methods = {
-                'Select Existing folder': 'existing',
-                'Create New folder': 'new'
-            }
-            folder_method = get_parameter(
-                param_name='folder-method',
-                message="Please select folder method",
-                choices=folder_methods,
-            )
-            if folder_method == 'existing':
-                try:
-                    folder = self.qs.select_folder()
-                except self.qs.client.exceptions.AccessDeniedException:
-                    # If user is not allowed to select folder, prompt for it
-                    print('\nYou are not allowed to select folder, please enter folder ID')
-                    while not folder:
-                        folder_id = get_parameter(
-                            param_name='folder-id',
-                            message='Please enter the folder Id to use'
-                        )
-                        folder = self.qs.describe_folder(folder_id)
-                    print(f'Selected folder {folder.get("Name")} ({folder.get("FolderId")})')
-            elif folder_method == 'new' or not folder:
-                # If user is allowed to select folder, but there is no folder exists, prompt to create one
-                if folder_method != 'new':
-                    print("No folders found, creating one...")
-                while not folder:
-                    try:
-                        folder_name = get_parameter(
-                            param_name='folder-name',
-                            message='Please enter the folder name to create'
-                        )
-                        folder_permissions_tpl = Template(resource_string(
-                            package_or_requirement='cid.builtin.core',
-                            resource_name=f'data/permissions/folder_permissions.json',
-                        ).decode('utf-8'))
-                        columns_tpl = {
-                            'PrincipalArn': self.qs.get_principal_arn()
-                        }
-                        folder_permissions = json.loads(folder_permissions_tpl.safe_substitute(columns_tpl))
-                        folder = self.qs.create_folder(folder_name, **folder_permissions)
-                    except self.qs.client.exceptions.AccessDeniedException:
-                        raise CidError('You are not allowed to create folder, unable to proceed')
-
-            self.qs.create_folder_membership(folder.get('FolderId'), dashboard.id, 'DASHBOARD')
-            for _id in dashboard.datasets.values():
-                self.qs.create_folder_membership(folder.get('FolderId'), _id, 'DATASET')
-            print(f'Sharing complete')
-        elif share_method in ['account', 'user']:
-            if share_method == 'account':
-                principal_arn = f"arn:aws:quicksight:{self.qs.identityRegion}:{self.qs.account_id}:namespace/default"
-                template_filename = 'data/permissions/dashboard_permissions_namespace.json'
-            elif share_method == 'user':
-                template_filename = 'data/permissions/dashboard_permissions.json'
-                user = self.qs.select_user()
-                while not user:
-                    user_name = get_parameter(
-                        param_name='quicksight-user',
-                        message='Please enter the user name to share with'
-                    )
-                    user = self.qs.describe_user(user_name)
-                    if not user:
-                        print(f'QuickSight user {user_name} was not found')
-                        unset_parameter('quicksight-user')
-                principal_arn = user.get('Arn')
-
-            # Update Dashboard permissions
-            columns_tpl = {
-                'PrincipalArn': principal_arn
-            }
-            dashboard_permissions_tpl = Template(resource_string(
-                package_or_requirement='cid.builtin.core',
-                resource_name=template_filename,
-            ).decode('utf-8'))
-            dashboard_permissions = json.loads(dashboard_permissions_tpl.safe_substitute(columns_tpl))
-            dashboard_params = {
-                "GrantPermissions": [
-                    dashboard_permissions
-                ]
-            }
-            if share_method == 'account':
-                dashboard_params.update({
-                    "GrantLinkPermissions": [
-                        dashboard_permissions
-                    ]
-                })
+        return _folder
 
-            logger.info(f'Sharing dashboard {dashboard.name} ({dashboard.id})')
-            try:
-                self.qs.update_dashboard_permissions(DashboardId=dashboard.id, **dashboard_params)
-                logger.info(f'Shared dashboard {dashboard.name} ({dashboard.id})')
-            except self.qs.client.exceptions.AccessDeniedException:
-                logger.error('An error occurred (AccessDeniedException) when calling the UpdateDashboardPermissions operation')
-
-            # Update DataSet permissions
-            if share_method == 'account':
-                logger.info(f'Sharing datasets/datasources with an account is not supported, skipping')
-            else:
-                data_set_permissions_tpl = Template(resource_string(
-                    package_or_requirement='cid.builtin.core',
-                    resource_name=f'data/permissions/data_set_permissions.json',
-                ).decode('utf-8'))
-                data_set_permissions = json.loads(data_set_permissions_tpl.safe_substitute(columns_tpl))
-
-                _datasources: Dict[str, Datasource] = {}
-                for _id in dashboard.datasets.values():
-                    logger.info(f'Sharing dataset {_id}')
-                    self.qs.update_data_set_permissions(DataSetId=_id, GrantPermissions=[data_set_permissions])
-                    logger.info(f'Sharing dataset {_id} complete')
-                    _dataset = self.qs._datasets.get(_id)
-                    # Extract DataSources from DataSet
-                    for v in _dataset.datasources:
-                        _datasource = self.qs.describe_data_source(v)
-                        if not _datasources.get(_datasource.id):
-                            _datasources.update({_datasource.id: _datasource})
-
-                data_source_permissions_tpl = Template(resource_string(
-                    package_or_requirement='cid.builtin.core',
-                    resource_name=f'data/permissions/data_source_permissions.json',
-                ).decode('utf-8'))
-                data_source_permissions = json.loads(data_source_permissions_tpl.safe_substitute(columns_tpl))
-                for k, v in _datasources.items():
-                    logger.info(f'Sharing data source "{v.name}" ({k})')
-                    self.qs.update_data_source_permissions(DataSourceId=k, GrantPermissions=[data_source_permissions])
-                    logger.info(f'Sharing data source "{v.name}" ({k}) complete')
-
-            print(f'Sharing complete')
-
-    @command
-    def update(self, dashboard_id, recursive=False, force=False, **kwargs):
-        """Update Dashboard
-
-        :param dashboard_id: dashboard_id, if None user will be asked to choose
-        :param recursive: Update Datasets and Views as well
-        :param force: allow selection of already updated dashboards in the manual selection mode
-        """
-        if not dashboard_id:
-            if not self.qs.dashboards:
-                print('\nNo deployed dashboards found')
-                return
-            dashboard_id = self.qs.select_dashboard(force)
-            if not dashboard_id:
-                if not force:
-                    print('\nNo updates available or dashboard(s) is/are broken, use --force to allow selection\n')
-                return
 
-        return self._deploy(dashboard_id, recursive=recursive, update=True)
+    def describe_dashboard(self, poll: bool=False, **kwargs) -> Union[None, Dashboard]:
+        """ Describes an AWS QuickSight dashboard
+        Keyword arguments:
+            DashboardId
+            poll_interval
+        """
+        poll_interval = kwargs.get('poll_interval', 5)
+        try:
+            dashboard: Dashboard = None
+            current_status = None
+            # Poll for the current status of query as long as its not finished
+            while current_status in [None, 'CREATION_IN_PROGRESS', 'UPDATE_IN_PROGRESS']:
+                if current_status:
+                    logger.info(f'Dashboard {dashboard.name} status is {current_status}, waiting for {poll_interval} seconds')
+                    # Sleep before polling again
+                    time.sleep(poll_interval)
+                elif poll:
+                    logger.info(f'Polling for dashboard {kwargs.get("DashboardId")}')
+                try:
+                    response = self.client.describe_dashboard(AwsAccountId=self.account_id, **kwargs).get('Dashboard')
+                except self.client.exceptions.ThrottlingException:
+                    logger.debug('Got ThrottlingException will sleep for 5 sec')
+                    time.sleep(5)
+                    continue
+                logger.debug(response)
+                dashboard = Dashboard(response, qs=self)
+                current_status = dashboard.version.get('Status')
+                if not poll:
+                    break
+            logger.info(f'Dashboard {dashboard.name} status is {current_status}')
+            return dashboard
+        except self.client.exceptions.ResourceNotFoundException:
+            return None
+        except self.client.exceptions.UnsupportedUserEditionException as exc:
+            raise CidCritical('Error: AWS QuickSight Enterprise Edition is required') from exc
+        except Exception as exc:
+            logger.error(f'Error in describe_dashboard: {exc}')
+            raise
 
+    def delete_dashboard(self, dashboard_id):
+        """ Deletes an AWS QuickSight dashboard """
+        params = {
+            'AwsAccountId': self.account_id,
+            'DashboardId': dashboard_id
+        }
+        logger.info(f'Deleting dashboard {dashboard_id}')
+        result = self.client.delete_dashboard(**params)
+        del self._dashboards[dashboard_id]
+        return result
 
-    def update_dashboard(self, dashboard_id, recursive=False, required_datasets=None, dashboard_datasets=None, **kwargs):
+    def delete_data_source(self, datasource_id):
+        """ Deletes an AWS QuickSight dashboard """
+        params = {
+            'AwsAccountId': self.account_id,
+            'DataSourceId': datasource_id
+        }
+        logger.info(f'Deleting DataSource {datasource_id}')
+        try:
+            result = self.client.delete_data_source(**params)
+        except self.client.exceptions.ResourceNotFoundException:
+            logger.info(f'Deleting DataSource {datasource_id} not needed as it is does not exist')
+            result = True
+        if datasource_id in (self._datasources or []):
+            del self._datasources[datasource_id]
+        return result
 
-        dashboard = self.qs.dashboards.get(dashboard_id)
-        if not dashboard:
-            print(f'Dashboard "{dashboard_id}" is not deployed')
-            return
+    def delete_dataset(self, id: str) -> bool:
+        """ Deletes an AWS QuickSight dataset """
 
-        print(f'\nChecking for updates...')
-        if isinstance(dashboard.deployedTemplate, CidQsTemplate):
-            print(f'Deployed template: {dashboard.deployedTemplate.arn}')
-        else:
-            print(f'Deployed template: Not available')
-        print(f"Latest template: {dashboard.sourceTemplate.arn}/version/{dashboard.latest_version}")
+        logger.info(f'Deleting dataset {id}')
         try:
-            cid_version = dashboard.deployedTemplate.cid_version
-        except ValueError:
-            logger.debug("The cid version of the deployed dashboard could not be retrieved")
-            cid_version = "N/A"
-
-        try:
-            cid_version_latest = dashboard.sourceTemplate.cid_version if isinstance(dashboard.sourceTemplate, CidQsTemplate) else "N/A"
-        except ValueError:
-            logger.debug("The latest version of the dashboard could not be retrieved")
-            cid_version_latest = "N/A"
-
-        if dashboard.latest:
-            print("You are up to date!")       
-            print(f"  CID Version      {cid_version}")
-            print(f"  TemplateVersion  {dashboard.deployed_version} ")
-
-            logger.debug("The dashboard is up-to-date")
-            logger.debug(f"CID Version      {cid_version}")
-            logger.debug(f"TemplateVersion  {dashboard.deployed_version} ")
+            self.client.delete_data_set(
+                AwsAccountId=self.account_id,
+                DataSetId=id
+            )
+            self.datasets.pop(id)
+        except self.client.exceptions.AccessDeniedException:
+            logger.info('Access denied deleting dataset')
+            return False
+        except self.client.exceptions.ResourceNotFoundException:
+            logger.info('Dataset does not exist')
+            return False
         else:
-            print(f"An update is available:")
-            print("                   Deployed -> Latest")
-            print(f"  CID Version      {str(cid_version): <9}   {str(cid_version_latest): <6}")
-            print(f"  TemplateVersion  {str(dashboard.deployedTemplate.version): <9}   {dashboard.latest_version: <6}")
-
-            logger.debug("An update is available")
-            logger.debug(f"CID Version      {str(cid_version): <9} --> {str(cid_version_latest): <6}")
-            logger.debug(f"TemplateVersion  {str(dashboard.deployedTemplate.version): <9} -->  {dashboard.latest_version: <6}")
-
-        # Check if version are compatible
-        compatible = None
-        try:
-            compatible = dashboard.sourceTemplate.cid_version.compatible_versions(dashboard.deployedTemplate.cid_version)
-        except ValueError as e:
-            logger.info(e)
-        
-        if compatible == False:
-            if get_parameter(
-                    param_name=f'confirm-recursive',
-                    message=f'This is a major update and require recursive action. This could lead to the loss of dataset customization. Continue anyway?',
-                    choices=['yes', 'no'],
-                    default='yes') != 'yes':
-                    return
-            logger.info("Swich to recursive mode")
-            recursive = True
-                            
-        if dashboard.status == 'legacy':
-            if get_parameter(
-                param_name=f'confirm-update',
-                message=f'Dashboard template changed, update it anyway?',
-                choices=['yes', 'no'],
-                default='yes') != 'yes':
-                return
-        elif dashboard.latest:
-            if get_parameter(
-                param_name=f'confirm-update',
-                message=f'No updates available, should I update it anyway?',
-                choices=['yes', 'no'],
-                default='yes') != 'yes':
-                return
+            logger.info(f'Deleted dataset {id}')
+            return True
 
-        # Update dashboard
-        print(f'\nUpdating {dashboard_id}')
-        logger.debug(f"Updating {dashboard_id}")
-        
-        if recursive:
-            logger.debug("Recursive mode is activated")
-            logger.debug("Updating dashboards dataset")
-            self.create_datasets(required_datasets, dashboard_datasets, recursive=recursive, update=True)
-            
-        try:
-            self.qs.update_dashboard(dashboard, **kwargs)
-            print('Update completed\n')
-            dashboard.display_url(self.qs_url, launch=True, **self.qs_url_params)
-            self.track('updated', dashboard_id)
-        except Exception as e:
-            # Catch exception and dump a reason
-            logger.debug(e, exc_info=True)
-            print(f'failed with an error message: {e}')
-
-        return dashboard_id
-
-
-    def create_datasets(self, _datasets: list, known_datasets: dict={}, recursive: bool=True, update: bool=False) -> dict:
-        # Check dependencies
-        required_datasets = sorted(_datasets)
-        print('\nRequired datasets: \n - {}\n'.format('\n - '.join(list(set(required_datasets)))))
-
-        for dataset_name in required_datasets:
-            _ds_id = get_parameters().get(f'{dataset_name.replace("_", "-")}-dataset-id')
-            if _ds_id:
-                self.qs.describe_dataset(_ds_id)
-        
-        found_datasets = utils.intersection(required_datasets, [v.name for v in self.qs.datasets.values()])
-        missing_datasets = utils.difference(required_datasets, found_datasets)
-
-        # Update existing datasets
-        if update:
-            for dataset_name in found_datasets[:]:
-                if dataset_name in known_datasets.keys():
-                    dataset_id = self.qs.get_datasets(id=known_datasets.get(dataset_name))[0].id
-                else:
-                    datasets = self.qs.get_datasets(name=dataset_name)
-                    if not datasets:
-                        continue
-                    elif len(datasets) == 1:
-                        dataset_id = datasets[0].id
-                    else:
-                        dataset_id = get_parameter(
-                            param_name=f'{dataset_name}-dataset-id',
-                            message=f'Multiple "{dataset_name}" datasets detected, please select one',
-                            choices=[v.id for v in datasets],
-                            default=datasets[0].id
-                        )
-                    known_datasets.update({dataset_name: dataset_id})
-                print(f'Updating dataset: "{dataset_name}"')
-                try:
-                    dataset_definition = self.get_definition("dataset", name=dataset_name)
-                    if not dataset_definition:
-                        print(f'Dataset definition not found, skipping {dataset_name}')
-                        continue
-                except Exception as e:
-                    logger.critical('dashboard definition is broken, unable to proceed.')
-                    logger.critical(f'dataset definition not found: {dataset_name}')
-                    logger.critical(e, exc_info=True)
-                    raise
-                try:
-                    if self.create_or_update_dataset(dataset_definition, dataset_id, recursive=recursive, update=update):
-                        print(f'Updated dataset: "{dataset_name}"')
-                    else:
-                        print(f'Dataset "{dataset_name}" update failed, collect debug log for more info')
-                except self.qs.client.exceptions.AccessDeniedException as exc:
-                    print(f'Unable to update, missing permissions: {exc}')
-                except Exception as e:
-                    logger.debug(e, exc_info=True)
-                    raise
 
+    def get_datasets(self, id: str=None, name: str=None) -> List[Dataset]:
+        """ get dataset that match parameters """
+        result = []
+        for dataset in self.datasets.values():
+            if id is not None and dataset.id != id:
+                continue
+            if name is not None and dataset.name != name:
+                continue
+            result.append(dataset)
+        return result
 
-        # Look by DataSetId from dataset_template file
-        if len(missing_datasets):
-            # Look for previously saved deployment info
-            print('\nLooking by DataSetId defined in template...', end='')
-            for dataset_name in missing_datasets[:]:
-                try:
-                    dataset_definition = self.get_definition(type='dataset', name=dataset_name)
-                    raw_template = self.get_dataset_data_from_definition(dataset_definition)
-                    if raw_template:
-                        ds = self.qs.describe_dataset(raw_template.get('DataSetId'))
-                        if isinstance(ds, Dataset) and ds.name == dataset_name:
-                            missing_datasets.remove(dataset_name)
-                            print(f"\n\tFound {dataset_name} as {raw_template.get('DataSetId')}")
-
-                except FileNotFoundError:
-                    logger.info(f'Definitions File for Dataset "{dataset_name}" not found')
-                    pass
-                except self.qs.client.exceptions.ResourceNotFoundException:
-                    logger.info(f'Dataset "{dataset_name}" not found')
-                    pass
-                except self.qs.client.exceptions.AccessDeniedException:
-                    logger.info(f'Access denied trying to find dataset "{dataset_name}"')
-                    pass
-                except Exception as e:
-                    logger.debug(e, exc_info=True)
-            print('complete')
-
-        # If there still datasets missing try automatic creation
-        if len(missing_datasets):
-            missing_str = ', '.join(missing_datasets)
-            print(f'\nThere are still {len(missing_datasets)} datasets missing: {missing_str}')
-            for dataset_name in missing_datasets[:]:
-                dataset_id = known_datasets.get(dataset_name)
-                print(f'Creating dataset: {dataset_name}')
-                try:
-                    dataset_definition = self.get_definition("dataset", name=dataset_name)
-                except Exception as e:
-                    logger.critical('dashboard definition is broken, unable to proceed.')
-                    logger.critical(f'dataset definition not found: {dataset_name}')
-                    logger.critical(e, exc_info=True)
-                    raise
-                try:
-                    if self.create_or_update_dataset(dataset_definition, dataset_id, recursive=recursive, update=update):
-                        missing_datasets.remove(dataset_name)
-                        print(f'Dataset "{dataset_name}" created')
-                    else:
-                        print(f'Dataset "{dataset_name}" creation failed, collect debug log for more info')
-                except self.qs.client.exceptions.AccessDeniedException as e:
-                    print(f'Unable to create dataset  "{dataset_name}", missing permissions')
-                    logger.info(f'Unable to create dataset  "{dataset_name}", missing permissions')
-                    logger.debug(e, exc_info=True)
-                except Exception as e:
-                    logger.debug(e, exc_info=True)
-                    raise
 
-        # Last chance to enter DataSetIds manually by user
-        if len(missing_datasets):
-            missing_str = '\n - '.join(missing_datasets)
-            print(f'\nThere are still {len(missing_datasets)} datasets missing: \n - {missing_str}')
-            print(f"\nCan't move forward without full list, please manually create datasets and provide DataSetIds")
-            # Loop over the list unless we get it empty
-            while len(missing_datasets):
-                # Make a copy and then get an item from the list
-                dataset_name = missing_datasets.copy().pop()
-                _id = get_parameter(
-                    param_name=f'{dataset_name}-dataset-id',
-                    message=f'DataSetId/Arn for {dataset_name}'
-                )
-                id = _id.split('/')[-1]
-                try:
-                    _dataset = self.qs.describe_dataset(id)
-                    if _dataset.name != dataset_name:
-                        print(f"\tFound dataset with a different name: {_dataset.name}, please provide another one")
-                        unset_parameter(f'{dataset_name}-dataset-id')
-                        continue
-                    self.qs._datasets.update({dataset_name: _dataset})
-                    missing_datasets.remove(dataset_name)
-                    print(f'\tFound valid "{_dataset.name}" dataset, using')
-                    logger.info(f'\tFound valid "{_dataset.name}" ({_dataset.id}) dataset, using')
-                except Exception as e:
-                    logger.debug(e, exc_info=True)
-                    print(f"\tProvided DataSetId '{id}' can't be found\n")
-                    unset_parameter(f'{dataset_name}-dataset-id')
-                    continue
-            print('\n')
+    def get_datasources(self, id: str=None, name: str=None, type: str=None, athena_role_arn: str=None, athena_workgroup_name: str=None, healthy: bool=True) -> List[Datasource]:
+        """ get datasource that matches parameters """
+        result = []
+        for datasource in self.datasources.values():
+            if healthy is not None and datasource.is_healthy != healthy:
+                continue
+            if id is not None and datasource.id != id:
+                continue
+            if name is not None and datasource.name != name:
+                continue
+            if type is not None and datasource.type != type:
+                continue
+            if athena_workgroup_name is not None and datasource.AthenaParameters.get('WorkGroup') != athena_workgroup_name:
+                continue
+            if athena_role_arn is not None and datasource.AthenaParameters.get('RoleArn') != athena_role_arn:
+                continue
+            result.append(datasource)
+        return result
 
-    def get_dataset_data_from_definition(self, dataset_definition):
-        raw_template = None
-        dataset_file = dataset_definition.get('File')
-        if dataset_file:
-            raw_template = json.loads(resource_string(
-                dataset_definition.get('providedBy'), f'data/datasets/{dataset_file}'
-            ).decode('utf-8'))
-        elif dataset_definition.get('Data'):
-            raw_template = dataset_definition.get('Data')
-        if raw_template is None:
-            raise CidCritical(f"Error: definition is broken. Cannot find data for {repr(dataset_definition)}. Check resources file.")
-        return raw_template
-
-
-    def create_or_update_dataset(self, dataset_definition: dict, dataset_id: str=None,recursive: bool=True, update: bool=False) -> bool:
-        # Read dataset definition from template
-        data = self.get_dataset_data_from_definition(dataset_definition)
-        template = Template(json.dumps(data))
-        cur_required = dataset_definition.get('dependsOn', dict()).get('cur')
-        athena_datasource = None
-
-        if get_parameters().get('quicksight-datasource-id'):
-            # We have explicit choice of datasource
-            datasource_id = get_parameters().get('quicksight-datasource-id')
 
+    def describe_dataset(self, id, timeout: int=1) -> Dataset:
+        """ Describes an AWS QuickSight dataset """
+        if self._datasets and id in self._datasets:
+            return self._datasets.get(id)
+        self._datasets = self._datasets or {}
+        poll_interval = 1
+        _dataset = None
+        deadline = time.time() + timeout
+        while time.time() <= deadline:
             try:
-                athena_datasource = self.qs.describe_data_source(datasource_id)
-            except self.qs.client.exceptions.AccessDeniedException:
-                # We have access denied on DescribeDataSet but there can be PassDataSet 
-                athena_datasource = Datasource(raw={
-                    'AthenaParameters':{},
-                    "Id": datasource_id,
-                    "Arn": f"arn:aws:quicksight:{self.base.session.region_name}:{self.base.account_id}:datasource/{datasource_id}",
-                })
-            except Exception as exc:
-                raise CidCritical(
-                    f'quicksight-datasource-id={datasource_id} not found or not in a valid state. {exc}'
-            )
+                _dataset = Dataset(self.client.describe_data_set(AwsAccountId=self.account_id, DataSetId=id).get('DataSet'))
+                logger.info(f'Saving dataset details "{_dataset.name}" ({_dataset.id})')
+                self._datasets[_dataset.id] = _dataset
+                break
+            except self.client.exceptions.ResourceNotFoundException:
+                logger.info(f'DataSetId {id} not found')
+                time.sleep(poll_interval)
+                continue
+            except self.client.exceptions.AccessDeniedException:
+                logger.debug(f'No quicksight:DescribeDataSet permission or missing DataSetId {id}')
+                return None
+            except self.client.exceptions.ClientError as exc:
+                logger.error(f'Error when trying to describe dataset {id}: {exc}')
+                return None
 
+        return self._datasets.get(id, None)
 
-        if not athena_datasource and not len(self.qs.athena_datasources):
-            logger.info('No Athena datasources found, attempting to create one')
-            self.qs.AthenaWorkGroup = self.athena.WorkGroup
-            self.qs.create_data_source() # FIXME: we need to use name/id provided by user if any
-            # FIXME: we need to cleanup if datasource creation fails
-
-        if not athena_datasource:
-            if not self.qs.athena_datasources:
-                logger.info('No valid DataSources available, failing')
-                print('No valid DataSources detected and unable to create one. Please create at least one DataSet manually in QuickSight and see why it fails.')
-                # Not failing here to let views creation below
-            else:
-                # Datasources are not obvious for customer so we will try to do our best guess
-                # - if there is just one? -> take that one
-                # - if datasource is references in existing dataset? -> take that one
-                # - if athena workgroup defined -> Try to find a dataset with this workgroup
-                # - and if still nothing -> ask an expicit choice from the user
-                pre_compiled_dataset = json.loads(template.safe_substitute())
-                dataset_name = pre_compiled_dataset.get('Name')
-
-                # let's find the schema/database and workgroup name
-                schemas = []
-                datasources = []
-                if dataset_id:
-                    schemas = self.qs.get_datasets(id=dataset_id)[0].schemas
-                    datasources = self.qs.get_datasets(id=dataset_id)[0].datasources
-                else: # try to find dataset and get athena database
-                    found_datasets = self.qs.get_datasets(name=dataset_name)
-                    if found_datasets:
-                        schemas = list(set(sum([d.schemas for d in found_datasets], [])))
-                        datasources = list(set(sum([d.datasources for d in found_datasets], [])))
-
-                if len(schemas) == 1:
-                    self.athena.DatabaseName = schemas[0]
-                # else user will be suggested to choose database anyway
+    def get_dataset_last_ingestion(self, dataset_id) -> str:
+        """returns human friendly status of the latest ingestion"""
+        try:
+            ingestions = self.client.list_ingestions(
+                DataSetId=dataset_id,
+                AwsAccountId=self.account_id,
+            ).get('Ingestions', [])
+        except self.client.exceptions.ResourceNotFoundException:
+            return '<RED>NotFound<END>'
+        except self.client.exceptions.AccessDeniedException:
+            return '<YELLOW>AccessDenied<END>'
+        if not ingestions:
+            return None
+        last_ingestion = ingestions[0] # Suppose it is the latest
+        status = last_ingestion.get('IngestionStatus')
+        time_ago = ago(last_ingestion.get('CreatedTime'))
+        if last_ingestion.get('ErrorInfo', {}).get('Type') == "DATA_SET_NOT_SPICE":
+            return '<BLUE>DIRECT_QUERY<END>'
+        if status in ('COMPLETED',):
+            status = f'<GREEN>{status}<END>'
+            time_in_mins = int(int(last_ingestion.get('IngestionTimeInSeconds', 0) or 0) / 60)
+            return f"{status} ({time_in_mins} mins, {last_ingestion['RowInfo']['RowsIngested']} rows) {time_ago}"
+        if status in ('FAILED', 'CANCELLED'):
+            status = f'<RED>{status}<END>'
+            return f"{status} ({last_ingestion['ErrorInfo']['Type']} {last_ingestion['ErrorInfo']['Message']}) {time_ago}"
+        return f'{status} {time_ago}'
+
+    def discover_datasets(self, _datasets: list=None):
+        """ Discover datasets in the account """
+
+        logger.info('Discovering datasets')
+        self._datasets =  self._datasets or {}
+        if _datasets:
+            for dataset in _datasets:
+                self.describe_dataset(dataset)
+        try:
+            for dataset in self.list_data_sets():
+                try:
+                    self.describe_dataset(dataset.get('DataSetId'))
+                except Exception as exc:
+                    logger.debug(exc, exc_info=True)
+                    continue
+        except self.client.exceptions.AccessDeniedException:
+            logger.info('Access denied listing datasets')
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+            logger.info('No datasets found')
 
-                if len(datasources) == 1 and datasources[0] in self.qs.athena_datasources:
-                    athena_datasource = self.qs.get_datasources(id=datasources[0])[0]
-                else:
-                    #try to find a datasource with defined workgroup
-                    workgroup = self.athena.WorkGroup
-                    datasources_with_workgroup = self.qs.get_datasources(athena_workgroup_name=workgroup)
-                    if len(datasources_with_workgroup) == 1:
-                        athena_datasource = datasources_with_workgroup[0]
-                    else:
-                        #cannot find the right athena_datasource
-                        logger.info('Multiple DataSources found.')
-                        datasource_choices = {
-                            f"{datasource.name} {datasource.id} (workgroup={datasource.AthenaParameters.get('WorkGroup')})": datasource.id
-                            for datasource in datasources_with_workgroup
-                        }
-                        datasource_id = get_parameter(
-                            param_name='quicksight-datasource-id',
-                            message=f"Please choose DataSource (Choose the first one if not sure).",
-                            choices=datasource_choices,
-                        )
-                        athena_datasource = self.qs.athena_datasources[datasource_id]
-                        logger.info(f'Found {len(datasources)} Athena datasources, not using {athena_datasource.id}')
-        if isinstance(athena_datasource, Datasource) and athena_datasource.AthenaParameters.get('WorkGroup', None):
-            self.athena.WorkGroup = athena_datasource.AthenaParameters.get('WorkGroup')
+    def refresh_dataset(self, dataset_id):
+        """ Refresh the dataset """
+
+        logger.info(f'Starting refresh for dataset: {dataset_id}')
+        status = 'FAILED'
+        try:
+            response = self.client.describe_data_set(
+                AwsAccountId=self.account_id,
+                DataSetId=dataset_id)
+            mode = response.get('DataSet').get('ImportMode')
+            if mode == 'DIRECT_QUERY':
+                return mode, 'DIRECT'
+            response = self.client.create_ingestion(
+                DataSetId=dataset_id,
+                IngestionId=datetime.datetime.now().strftime("%d%m%y-%H%M%S-%f"),
+                AwsAccountId=self.account_id)
+            status = response.get('IngestionStatus')
+        except self.client.exceptions.AccessDeniedException:
+            logger.error(f'Access denied refreshing dataset: {dataset_id}')
+        except Exception as exc:
+            logger.debug(exc, exc_info=True)
+            raise CidError(f'Unable to list refresh dataset {dataset_id}: {str(exc)}') from exc
+        return mode, status
+
+    def describe_data_source(self, id: str, update: bool=False) -> Datasource:
+        """ Describes an AWS QuickSight DataSource """
+        if not update and self.datasources and id in self.datasources:
+            return self.datasources.get(id)
+        try:
+            logger.info(f'Discovering DataSource {id}')
+            result = self.client.describe_data_source(AwsAccountId=self.account_id, DataSourceId=id)
+            logger.debug(result)
+            _datasource = Datasource(result.get('DataSource'))
+            logger.info(f'DataSource "{_datasource.name}" status is {_datasource.status}, saving details')
+            self._datasources.update({_datasource.id: _datasource})
+        except self.client.exceptions.ResourceNotFoundException:
+            logger.info(f'DataSource {id} do not exist')
+            raise
+        except self.client.exceptions.AccessDeniedException:
+            logger.info(f'No quicksight:DescribeDataSource permission or missing DataSetId {id}')
+            raise
+        except Exception as exc:
+            logger.info(exc)
+            logger.debug(exc, exc_info=True)
+            return None
         else:
-            logger.debug('Athena_datasource is not defined. Will only create views')
+            return _datasource
 
-        # Check for required views
-        _views = dataset_definition.get('dependsOn', {}).get('views', [])
-        required_views = [(self.cur.tableName if cur_required and name =='${cur_table_name}' else name) for name in _views]
-
-        self.athena.discover_views(required_views)
-        found_views = utils.intersection(required_views, self.athena._metadata.keys())
-        missing_views = utils.difference(required_views, found_views)
-
-        if recursive:
-            print(f"Detected views: {', '.join(found_views)}")
-            for view_name in found_views:
-                if cur_required and view_name == self.cur.tableName:
-                    logger.debug(f'Dependancy view {view_name} is a CUR. Skip.')
-                    continue
-                if view_name == 'account_map':
-                    logger.debug(f'Dependancy view is {view_name}. Skip.')
-                    continue
-                self.create_or_update_view(view_name, recursive=recursive, update=update)
 
-        # create missing views
-        if len(missing_views):
-            print(f"Missing views: {', '.join(missing_views)}")
-            for view_name in missing_views:
-                self.create_or_update_view(view_name, recursive=recursive, update=update)
+    def describe_template(self, template_id: str, version_number: int=None, account_id: str=None, region: str='us-east-1') -> CidQsTemplate:
+        """ Describes an AWS QuickSight template """
+        if not account_id:
+            account_id=self.cidAccountId
+        if not self._templates.get(f'{account_id}:{region}:{template_id}:{version_number}'):
+            try:
+                client = self.session.client('quicksight', region_name=region)
+                parameters = {
+                    'AwsAccountId': account_id,
+                    'TemplateId': template_id
+                }
+                if version_number:
+                    parameters.update({'VersionNumber': version_number})
+                result = client.describe_template(**parameters)
+                self._templates.update({f'{account_id}:{region}:{template_id}:{version_number}': CidQsTemplate(result.get('Template'))})
+                logger.debug(result)
+            except self.client.exceptions.UnsupportedUserEditionException as exc:
+                raise CidCritical('AWS QuickSight Enterprise Edition is required') from exc
+            except self.client.exceptions.ResourceNotFoundException as exc:
+                raise CidError(f'Error: Template {template_id} is not available in account {account_id} and region {region}') from exc
+            except Exception as exc:
+                logger.debug(exc, exc_info=True)
+                raise CidError(f'Error: {exc} - Cannot find {template_id} in account {account_id}.') from exc
+        return self._templates.get(f'{account_id}:{region}:{template_id}:{version_number}')
+
+    def describe_user(self, username: str) -> dict:
+        """ Describes an AWS QuickSight user """
+        parameters = {
+            'AwsAccountId': self.account_id,
+            'UserName': username,
+            'Namespace': 'default'
+        }
+        try:
+            result = self.identityClient.describe_user(**parameters)
+            logger.debug(result)
+            return result.get('User')
+        except self.client.exceptions.ResourceNotFoundException:
+            logger.info(f'QuickSight user {username} not found.')
+            return None
+        except self.client.exceptions.AccessDeniedException:
+            userList = self.identityClient.list_users(AwsAccountId=self.account_id, Namespace='default').get('UserList')
+            logger.debug(userList)
+            for user in userList:
+                if username.endswith(user.get('UserName')):
+                    logger.info(f'Found user: {user}')
+                    return user
+            logger.info(f'QuickSight user {username} not found.')
+            return None
+
+    def describe_group(self, groupname: str) -> dict:
+        """ Describes an AWS QuickSight Group """
+        try:
+            result = self.identityClient.describe_group(**{
+                'AwsAccountId': self.account_id,
+                'GroupName': groupname,
+                'Namespace': 'default'
+            })
+            logger.debug('group = %s', json.dumps(result))
+            return result.get('Group')
+        except self.client.exceptions.ResourceNotFoundException:
+            logger.error(f'QuickSight group {groupname} not found.')
+            return None
+        except self.client.exceptions.AccessDeniedException:
+            logger.error('AccessDeniedException when trying to DescribeGroup in QuickSight.')
+            return None
+
 
-        if not isinstance(athena_datasource, Datasource): return False
-        # Proceed only if all the parameters are set
+    def create_dataset(self, definition: dict) -> str:
+        """ Creates an AWS QuickSight dataset """
+        poll_interval = 1
+        max_timeout = 60
         columns_tpl = {
-            'athena_datasource_arn': athena_datasource.arn,
-            'athena_database_name': self.athena.DatabaseName,
-            'cur_table_name': self.cur.tableName if cur_required else None
+            'PrincipalArn': self.get_principal_arn()
         }
-
-        compiled_dataset = json.loads(template.safe_substitute(columns_tpl))
-        if dataset_id:
-            compiled_dataset.update({'DataSetId': dataset_id})
-
-        found_dataset = self.qs.describe_dataset(compiled_dataset.get('DataSetId'))
-        if isinstance(found_dataset, Dataset):
-            if update:
-                self.qs.update_dataset(compiled_dataset)
-            elif found_dataset.name != compiled_dataset.get('Name'):
-                print(f"Dataset found with name {found_dataset.name}, but {compiled_dataset.get('Name')} expected. Updating.")
-                self.qs.update_dataset(compiled_dataset)
+        data_set_permissions_tpl = Template(resource_string(
+            package_or_requirement='cid.builtin.core',
+            resource_name='data/permissions/data_set_permissions.json',
+        ).decode('utf-8'))
+        data_set_permissions = json.loads(data_set_permissions_tpl.safe_substitute(columns_tpl))
+        definition.update({
+            'AwsAccountId': self.account_id,
+            'Permissions': [
+                data_set_permissions
+            ]
+        })
+        dataset_id = None
+        try:
+            logger.info(f'Creating dataset {definition.get("Name")} ({dataset_id})')
+            logger.debug(f'Dataset definition: {definition}')
+            response = self.client.create_data_set(**definition)
+            dataset_id = response.get('DataSetId')
+        except self.client.exceptions.ResourceExistsException:
+            dataset_id = definition.get("DataSetId")
+            logger.info(f'Dataset {definition.get("Name")} already exists with DataSetId={dataset_id}')
+        except self.client.exceptions.LimitExceededException as exc:
+            raise CidCritical('Not enough AWS QuickSight SPICE capacity. Add SPICE here https://quicksight.aws.amazon.com/sn/admin#capacity .') from exc
+
+        logger.info(f'Waiting for {definition.get("Name")} to be created')
+        deadline = time.time() + max_timeout
+        while time.time() < deadline:
+            _dataset = self.describe_dataset(dataset_id)
+            if isinstance(_dataset, Dataset):
+                break
             else:
-                print(f'No update requested for dataset {compiled_dataset.get("DataSetId")}')
+                time.sleep(poll_interval)
         else:
-            self.qs.create_dataset(compiled_dataset)
+            logger.info(f'Dataset {definition.get("Name")} is not created before timeout.')
+            return None
+        logger.info(f'Dataset {_dataset.name} is created')
+        return dataset_id
+
+
+    def update_dataset(self, definition: dict) -> Dataset:
+        """ Update an AWS QuickSight dataset """
+        definition.update({'AwsAccountId': self.account_id})
+        logger.info(f'Updating dataset {definition.get("Name")}')
+
+        if "Permissions" in definition:
+            logger.info('Ignoring permissions for dataset update.')
+            del definition['Permissions']
+        response = self.client.update_data_set(**definition)
+        logger.info(f'Dataset {definition.get("Name")} is updated')
+        dataset_id = definition.get('DataSetId')
+        self.datasets.pop(dataset_id, None) # invalidate cache
+        return self.describe_dataset(dataset_id)
 
-        return True
 
+    def get_dataset_refresh_schedules(self, dataset_id):
+        """Returns refresh schedules for given dataset id"""
+        try:
+            refresh_schedules = self.client.list_refresh_schedules(
+                AwsAccountId=self.account_id,
+                DataSetId=dataset_id
+            )
+            return refresh_schedules.get("RefreshSchedules")
+        except self.client.exceptions.ResourceNotFoundException as exc:
+            raise CidError(f'DataSet {dataset_id} does not exist') from exc
+        except self.client.exceptions.AccessDeniedException as exc:
+            raise CidError('AccessDenied on ListRefreshSchedules') from exc
+        except Exception as exc:
+            raise CidError(f'Unable to list refresh schedules for dataset {dataset_id}: {str(exc)}') from exc
 
-    def create_or_update_view(self, view_name: str, recursive: bool=True, update: bool=False) -> None:
-        # For account mappings create a view using a special helper
-        if view_name in self._visited_views: # avoid checking a views multiple times in one cid session
-            return
-        logger.info(f'Processing view: {view_name}')
-        self._visited_views.append(view_name)
 
-        if view_name in ['account_map', 'aws_accounts']:
-            if view_name in self.athena._metadata.keys():
-                print(f'Account map {view_name} exists. Skipping.')
-            else:
-                self.accountMap.create(view_name) #FIXME: add or_update
-            return
+    def ensure_dataset_refresh_schedule(self, dataset_id, schedules: list):
+        """ Ensures that dataset has scheduled refresh """
+        # get all existing schedules for the given dataset
+        try:
+            existing_schedules = self.get_dataset_refresh_schedules(dataset_id)
+        except CidError as exc:
+            # We cannot access schedules, but let's check if there are scheduled ingestions. 
+            ingestions_exist = False
+            try:
+                ingestions_exist = list(
+                    self.client.get_paginator('list_ingestions').paginate(
+                        DataSetId=dataset_id,
+                        AwsAccountId=self.account_id
+                    ).search("Ingestions[?RequestSource=='SCHEDULED']")
+                )
+            except Exception:
+                logger.debug(f'List refresh schedule throws: {exc}')
+                logger.warning(
+                    f'Cannot read dataset schedules for dataset = {dataset_id}. {str(exc)}. Skipping schedule management.'
+                    ' Please make sure scheduled refresh is configured manually.'
+                )
+                return
+            if ingestions_exist:
+                logger.debug(f'We cannot read schedules but there are ingestions. Skipping creation of schedule.')
+                return
+            logger.debug(f'We cannot read schedules but there no ingestions. Continue to creation of schedule.')
+            existing_schedules = []
 
-        # Create a view
-        logger.info(f'Getting view definition')
-        view_definition = self.get_definition("view", name=view_name)
-        if not view_definition and view_name in self.athena._metadata.keys():
-            logger.info(f"Definition is unavailable but view exists: {view_name}, skipping")
-            return
-        logger.debug(f'View definition: {view_definition}')
-
-        if recursive:
-            dependency_views = view_definition.get('dependsOn', dict()).get('views', list())
-            if 'cur' in dependency_views: dependency_views.remove('cur')
-            # Discover dependency views (may not be discovered earlier)
-            self.athena.discover_views(dependency_views)
-            logger.info(f"Dependency views: {', '.join(dependency_views)}" if dependency_views else 'No dependency views')
-            for dep_view_name in dependency_views:
-                if dep_view_name not in self.athena._metadata.keys():
-                    print(f'Missing dependency view: {dep_view_name}, creating')
-                    logger.info(f'Missing dependency view: {dep_view_name}, creating')
-                self.create_or_update_view(dep_view_name, recursive=recursive, update=update)
-        view_query = self.get_view_query(view_name=view_name)
-        logger.debug(f'view_query: {view_query}')
-        if view_name in self.athena._metadata.keys():
-            logger.debug(f'View "{view_name}" exists')
-            if update:
-                logger.info(f'Updating view: "{view_name}"')
-                if view_definition.get('type') == 'Glue_Table':
-                    print(f'Updating table {view_name}')
-                    self.glue.create_or_update_table(view_name, view_query)
-                else:
-                    if 'CREATE OR REPLACE' in view_query.upper():
-                        print(f'Updating view: "{view_name}"')
-                        self.athena.execute_query(view_query)
-                    else:
-                        print(f'View "{view_name}" is not compatible with update. Skipping.')
-                assert self.athena.wait_for_view(view_name), f"Failed to update a view {view_name}"
-                logger.info(f'View "{view_name}" updated')
+        if schedules:
+            if exec_env()['terminal'] in ('lambda'):
+                schedule_frequency_timezone = get_parameters().get("timezone", timezone.get_default_timezone())
             else:
+                default_timezone = timezone.get_default_timezone()
+                schedule_frequency_timezone = get_parameter("timezone",
+                    message='Please select timezone for datasets scheduled refresh.',
+                    choices=sorted(list(set(timezone.get_all_timezones() + [default_timezone]))),
+                    default=default_timezone
+                )
+            if not schedule_frequency_timezone:
+                logger.warning('Cannot get timezone. Please provide --timezone parameter. Please make sure scheduled refresh is configured manually.')
                 return
-        else:
-            logger.info(f'Creating view: "{view_name}"')
-            if view_definition.get('type') == 'Glue_Table':
-                self.glue.create_or_update_table(view_name, view_query)
+
+        for schedule in schedules:
+
+            # Get the list of existing schedules with the same id
+            existing_schedule = None
+            for existing in existing_schedules:
+                if schedule["ScheduleId"] == existing["ScheduleId"]:
+                    existing_schedule = existing
+                    break
+
+            # Verify that all schedule parameters are set
+            schedule["ScheduleId"] = schedule.get("ScheduleId", "cid")
+            if "ScheduleFrequency" not in schedule:
+                schedule["ScheduleFrequency"] = {}
+            schedule["ScheduleFrequency"]["Timezone"] = schedule_frequency_timezone
+            try:
+                schedule["ScheduleFrequency"]["TimeOfTheDay"] = randtime.get_random_time_from_range(
+                    self.account_id + dataset_id,
+                    schedule["ScheduleFrequency"].get("TimeOfTheDay", "")
+                )
+            except Exception as exc:
+                logger.error(
+                    f'Invalid timerange for schedule with id "{schedule["ScheduleId"]}"'
+                    f' and dataset {dataset_id}: {str(exc)} ... skipping.'
+                    f' Please create dataset refresh schedule manually.'
+                )
+                continue
+            schedule["ScheduleFrequency"]["Interval"] = schedule["ScheduleFrequency"].get("Interval", "DAILY")
+            schedule["RefreshType"] = schedule.get("RefreshType", "FULL_REFRESH")
+            if "providedBy" in schedule:
+                del schedule["providedBy"]
+
+            if not existing_schedule:
+                # Avoid adding a new schedule  when customer already has put a schedule manually as this can lead to additional charges.
+                schedules_with_different_id = [existing for existing in existing_schedules if schedule["ScheduleId"] != existing["ScheduleId"] ]
+                if schedules_with_different_id:
+                    logger.info(
+                        f'Found the same schedule {schedule.get("RefreshType")} / {schedule["ScheduleFrequency"].get("Interval")}'
+                        f' but with different id. Skipping to avoid duplication. Please delete all manually created schedules for dataset {dataset_id}'
+                    )
+                    continue
+                logger.debug(f'Creating refresh schedule with id {schedule["ScheduleId"]} for dataset {dataset_id}.')
+                try:
+                    self.client.create_refresh_schedule(
+                        DataSetId=dataset_id,
+                        AwsAccountId=self.account_id,
+                        Schedule=schedule
+                    )
+                    logger.debug(f'Refresh schedule with id {schedule["ScheduleId"]} for dataset {dataset_id} is created.')
+                except self.client.exceptions.ResourceNotFoundException:
+                    logger.error(f'Unable to create refresh schedule with id {schedule["ScheduleId"]}. Dataset {dataset_id} does not exist.')
+                except self.client.exceptions.AccessDeniedException:
+                    logger.error(f'Unable to create refresh schedule with id {schedule["ScheduleId"]}. Please add quicksight:CreateDataSet permission.')
+                except self.client.exceptions.ResourceExistsException:
+                    logger.info(f'Schedule with id {schedule["ScheduleId"]} exists. But can have other settings. You better check.')
+                except Exception as exc:
+                    logger.error(f'Unable to create refresh schedule with id {schedule["ScheduleId"]} for dataset "{dataset_id}": {str(exc)}')
             else:
-                self.athena.execute_query(view_query)
-            assert self.athena.wait_for_view(view_name), f"Failed to create a view {view_name}"
-            logger.info(f'View "{view_name}" created')
-
-
-    def get_view_query(self, view_name: str) -> str:
-        """ Returns a fully compiled AHQ """
-        # View path
-        view_definition = self.get_definition("view", name=view_name)
-        cur_required = view_definition.get('dependsOn', dict()).get('cur')
-        if cur_required and self.cur.hasSavingsPlans and self.cur.hasReservations and view_definition.get('spriFile'):
-            view_file = view_definition.get('spriFile')
-        elif cur_required and self.cur.hasSavingsPlans and view_definition.get('spFile'):
-            view_file = view_definition.get('spFile')
-        elif cur_required and self.cur.hasReservations and view_definition.get('riFile'):
-            view_file = view_definition.get('riFile')
-        elif view_definition.get('File'):
-            view_file = view_definition.get('File')
-        else:
-            logger.critical(f'\nCannot find view {view_name}. View information is incorrect, please check resources.yaml')
-            raise Exception(f'\nCannot find view {view_name}')
+                # schedule exists so we need to update
+                logger.debug(f'Updating refresh schedule with id {schedule["ScheduleId"]} for dataset {dataset_id}.')
+                try:
+                    self.client.update_refresh_schedule(
+                        DataSetId=dataset_id,
+                        AwsAccountId=self.account_id,
+                        Schedule=schedule
+                    )
+                    logger.debug(f'Refresh schedule with id {schedule["ScheduleId"]} for dataset {dataset_id} is updated.')
+                except self.client.exceptions.ResourceNotFoundException:
+                    logger.error(f'Unable to update refresh schedule with id {schedule["ScheduleId"]}. Dataset {dataset_id} does not exist.')
+                except self.client.exceptions.AccessDeniedException:
+                    logger.error(f'Unable to update refresh schedule with id {schedule["ScheduleId"]}. Please add quicksight:UpdqteDataSet permission.')
+                except Exception as exc:
+                    logger.error(f'Unable to update refresh schedule with id {schedule["ScheduleId"]} for dataset "{dataset_id}": {str(exc)}')
 
-        # Load TPL file
-        template = Template(resource_string(
-            view_definition.get('providedBy'),
-            f'data/queries/{view_file}'
+        # Verify if there is at least one schedule and warn user if not
+        try:
+            if not self.get_dataset_refresh_schedules(dataset_id):
+                logger.warning(f'There is no refresh schedule for dataset "{dataset_id}". Please create a refresh schedule manually.' )
+        except CidError:
+            pass
+
+    def create_dashboard(self, definition: dict) -> Dashboard:
+        """ Creates an AWS QuickSight dashboard """
+
+        create_parameters = self._build_params_for_create_update_dash(definition)
+
+        dashboard_permissions_tpl = Template(resource_string(
+            package_or_requirement='cid.builtin.core',
+            resource_name='data/permissions/dashboard_permissions.json',
         ).decode('utf-8'))
-
-        # Prepare template parameters
         columns_tpl = {
-            'cur_table_name': self.cur.tableName if cur_required else None,
-            'athenaTableName': view_name,
-            'athena_database_name': self.athena.DatabaseName,
+            'PrincipalArn': self.get_principal_arn()
         }
+        dashboard_permissions = json.loads(dashboard_permissions_tpl.safe_substitute(columns_tpl))
+        create_parameters['Permissions'] = [ dashboard_permissions ]
 
-        for k, v in view_definition.get('parameters', dict()).items():
-            if isinstance(v, str):
-                param = {k:v}
-            elif isinstance(v, dict):
-                value = v.get('value')
-                while not value:
-                    value = get_parameter(
-                        param_name=f'view-{view_name}-{k}',
-                        message=f"Required parameter: {k} ({v.get('description')})",
-                        default=v.get('default'),
-                        template_variables=dict(account_id=self.base.account_id),
-                    )
-                param = {k:value}
+        try:
+            logger.info(f'Creating dashboard "{definition.get("name")}"')
+            logger.debug(create_parameters)
+            create_status = self.client.create_dashboard(**create_parameters)
+            logger.debug(create_status)
+        except self.client.exceptions.ResourceExistsException:
+            logger.info(f'Dashboard {definition.get("name")} already exists')
+            raise
+        created_version = int(create_status['VersionArn'].split('/')[-1])
+
+        # Poll for the current status of query as long as its not finished
+        describe_parameters = {
+            'DashboardId': definition.get('dashboardId'),
+            'VersionNumber': created_version
+        }
+        dashboard = self.describe_dashboard(poll=True, **describe_parameters)
+        self.discover_dashboard(dashboard.id)
+        if not dashboard.health:
+            failure_reason = dashboard.version.get('Errors')
+            raise Exception(failure_reason)
+
+        return dashboard
+
+
+    def _build_params_for_create_update_dash(self, definition: dict, permissions: bool=True) -> Dict:
+
+        create_parameters = {
+            'AwsAccountId': self.account_id,
+            'DashboardId': definition.get('dashboardId'),
+            'Name': definition.get('name'),
+            'ValidationStrategy': {'Mode': 'LENIENT'},
+        }
+        theme = definition.get('theme')
+        if theme:
+            if not theme.startswith('arn:'):
+                theme_arn = 'arn:aws:quicksight::aws:theme/' + theme
             else:
-                raise CidCritical(f'Unknown parameter type for "{k}". Must be a string or a dict with value or with default key')
-            # Add parameter
-            columns_tpl.update(param)
-        # Compile template
-        compiled_query = template.safe_substitute(columns_tpl)
-
-        return compiled_query
-
-    @command
-    def map(self, **kwargs):
-        """Create account mapping Athena views"""
-        for v in ['account_map', 'aws_accounts']:
-            self.accountMap.create(v)
+                raise NotImplementedError('Only standard themes are supported now.')
+            create_parameters['ThemeArn'] = theme_arn
 
+        if definition.get('sourceTemplate'):
+            dataset_references = [
+                {'DataSetPlaceholder': key, 'DataSetArn': value}
+                for key, value in definition.get('datasets', {}).items()
+            ]
+            create_parameters['SourceEntity'] = {
+                'SourceTemplate': {
+                    'Arn': f"{definition.get('sourceTemplate').arn}/version/{definition.get('sourceTemplate').version}",
+                    'DataSetReferences': dataset_references
+                }
+            }
+        elif definition.get('definition'):
+            create_parameters['Definition'] = definition.get('definition')
+            dataset_references = []
+            for identifier, arn in definition.get('datasets', {}).items():
+                # Fetch dataset by name (preferably) OR by id
+                dataset_declarations = create_parameters['Definition'].get('DataSetIdentifierDeclarations', [])
+                for ds_dec in dataset_declarations:
+                    if identifier == ds_dec['Identifier']:
+                        logger.debug('Dataset {identifier} matched by Name')
+                        break # all good
+                    elif arn.split('/')[-1] == ds_dec['DataSetArn'].split('/')[-1]:
+                        logger.debug('Dataset {identifier} matched by Id')
+                        identifier = ds_dec['Identifier']
+                        break
+                else:
+                    raise CidCritical(f'Unable to match dataset {identifier} / {arn} with any DataSetIdentifierDeclarations of dashboard {repr(dataset_declarations)}')
+
+                dataset_references.append({'Identifier': identifier, 'DataSetArn': arn})
+
+            create_parameters['SourceEntity'] = {}
+            create_parameters['Definition']['DataSetIdentifierDeclarations'] = dataset_references
+        else:
+            logger.debug(f'Definition = {definition}')
+            raise CidCritical('Dashboard definition must contain sourceTemplate or definition')
+        return create_parameters
+
+    def update_dashboard(self, dashboard: Dashboard, definition):
+        """ Updates an AWS QuickSight dashboard """
+        update_parameters = self._build_params_for_create_update_dash(definition)
+        logger.info(f'Updating dashboard "{dashboard.name}"')
+        logger.debug(f"Update parameters: {update_parameters}")
+        update_status = self.client.update_dashboard(**update_parameters)
+        logger.debug(update_status)
+        updated_version = int(update_status['VersionArn'].split('/')[-1])
+
+        dashboard = self.describe_dashboard(poll=True, DashboardId=dashboard.id, VersionNumber=updated_version)
+        if not dashboard.health:
+            failure_reason = dashboard.version.get('Errors')
+            raise Exception(failure_reason)
+
+        update_params = {
+            'AwsAccountId': self.account_id,
+            'DashboardId': dashboard.id,
+            'VersionNumber': updated_version
+        }
+        result = self.client.update_dashboard_published_version(**update_params)
+        logger.debug(result)
+        if result['Status'] != 200:
+            raise Exception(result)
+
+        return result
+
+
+    def update_dashboard_permissions(self, **update_parameters):
+        """ Updates an AWS QuickSight dashboard permissions """
+        logger.debug(f"Updating Dashboard permissions: {update_parameters}")
+        update_parameters.update({'AwsAccountId': self.account_id})
+        update_status = self.client.update_dashboard_permissions(**update_parameters)
+        logger.debug(update_status)
+        return update_status
+
+
+    def update_data_set_permissions(self, **update_parameters):
+        """ Updates an AWS QuickSight dataset permissions """
+        logger.debug(f"Updating DataSet permissions: {update_parameters}")
+        update_parameters.update({'AwsAccountId': self.account_id})
+        update_status = self.client.update_data_set_permissions(**update_parameters)
+        logger.debug(update_status)
+        return update_status
+
+
+    def update_data_source_permissions(self, **update_parameters):
+        """ Updates an AWS QuickSight data source permissions """
+        logger.debug(f"Updating DataSource permissions: {update_parameters}")
+        update_parameters.update({'AwsAccountId': self.account_id})
+        update_status = self.client.update_data_source_permissions(**update_parameters)
+        logger.debug(update_status)
+        return update_status
+
+
+    def update_template_permissions(self, **update_parameters):
+        """ Updates an AWS QuickSight template permissions """
+        logger.debug(f"Updating Template permissions: {update_parameters}")
+        update_parameters.update({'AwsAccountId': self.account_id})
+        update_status = self.client.update_template_permissions(**update_parameters)
+        logger.debug(update_status)
+        return update_status
+
+    def get_dashboard_permissions(self, dashboard_id):
+        """ get_dashboard_permissions """
+        return self.client.describe_dashboard_permissions(AwsAccountId=self.account_id, DashboardId=dashboard_id)['Permissions']
+
+    def dataset_diff(self, raw1, raw2):
+        """ get dataset diff """
+        return diff(
+            Dataset(raw1).to_diffable_structure(),
+            Dataset(raw2).to_diffable_structure(),
+        )
```

### Comparing `cid-cmd-0.2.9/cid/helpers/account_map.py` & `cid_cmd-0.3.0/cid/helpers/account_map.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,76 +1,94 @@
-import csv
+""" Create an Account Map
+
+Account Map is needed for mapping account id to account name and other attributes (Business Unit, Scope, Cost Center or other)
+"""
+import os
 import logging
 from pathlib import Path
+from functools import lru_cache
 
-import click
-from pkg_resources import resource_string
 from string import Template
+from pkg_resources import resource_string
 
 from cid.base import CidBase
 from cid.helpers import Athena, CUR
-from cid.utils import get_parameter
-from cid.exceptions import CidCritical
+from cid.utils import get_parameter, get_parameters, cid_print, unset_parameter
+from cid.exceptions import CidCritical, CidError
+from cid.helpers.csv2view import read_csv
 
 logger = logging.getLogger(__name__)
 
 class AccountMap(CidBase):
+    """
+    Create an account_map view or aws_accounts view with following mandatory fields:
+        account_id
+        account_name
+        parent_account_id (only used in trends)
+        account_status (only used in trends)
+        account_email (only used in trends)
+
+    aws_accounts is only used in trends.
+    """
     defaults = {
         'MetadataTableNames': ['acc_metadata_details', 'organisation_data']
-    } 
-    _clients = dict()
-    _accounts = list()
+    }
+    _clients = {}
+    _accounts = []
     _metadata_source: str = None
-    _AthenaTableName: str = None
+    _athena_table_name: str = None
     mappings = {
         'account_map': {
             'acc_metadata_details': {'account_id': 'account_id', 'account_name': 'account_name'},
             'organisation_data': {'account_id': 'id', 'account_name': 'name', 'email': 'email'}
         },
         'aws_accounts': {
             'acc_metadata_details': {'account_id': 'account_id', 'account_name': 'account_name', 'email': 'email'},
             'organisation_data': { 'account_id': 'id', 'account_name': 'name', 'email': 'email', 'status': 'status'},
             'cur_fields': ['bill_payer_account_id']
         }
     }
 
-    def __init__(self, session) -> None:
-        super().__init__(session)
 
     @property
     def athena(self) -> Athena:
+        """ Getter for Athena """
         if not self._clients.get('athena'):
             self._clients.update({
                 'athena': Athena(self.session)
             })
         return self._clients.get('athena')
-    
+
     @athena.setter
     def athena(self, client) -> Athena:
+        """ Setter for Athena """
         if not self._clients.get('athena'):
             self._clients.update({
                 'athena': client
             })
         return self.athena
 
     @property
     def cur(self) -> CUR:
+        """ Getter for CUR """
         return self._clients.get('cur')
-    
+
     @cur.setter
     def cur(self, client) -> CUR:
+        """ Setter for CUR """
         if not self._clients.get('cur'):
             self._clients.update({
                 'cur': client
             })
         return self.cur
 
     @property
     def accounts(self) -> dict:
-        if self._accounts:            
+        """ Get Accounts with the right mapping """
+        if self._accounts:
             # Required keys mapping, used in renaming below
             key_mapping = {
                 'accountid': 'account_id',
                 'name': 'account_name'
             }
             for account in self._accounts:
                 # Rename required keys according to expected names
@@ -81,145 +99,149 @@
                 # Fill optional keys
                 account.update({
                     'parent_account_id': account.get('parent_account_id', '0'),
                     'account_status': account.get('account_status', 'unknown'),
                     'account_email': account.get('account_email', 'unknown')
                 })
         return self._accounts
-    
+
+    @lru_cache(1000)
+    def detect_metadata_table(self, name):
+        """ detect meta table with the list of accounts """
+        cid_print('Autodiscovering metadata table')
+
+        # FIXME: This will only work for current Athena Database. We might want to check optimization_data base as well
+        tables = self.athena.list_table_metadata()
+        tables = [t for t in tables if t.get('TableType') == 'EXTERNAL_TABLE'] #filter only tables
+        tables = [t for t in tables if t.get('Name') in self.defaults.get('MetadataTableNames')] #filter only with support names
+        if not tables:
+            cid_print('Account metadata not detected')
+            return None
+        for table in tables:
+            table_name = table.get('Name')
+            logger.debug(f"Detected table {table_name}")
+            field_found = [col.get('Name') for col in table.get('Columns')]
+            field_required = list(self.mappings.get(name).get(table_name).values())
+            # Check if we have all the required fields
+            if all(field in field_found for field in field_required):
+                logger.info(f'All required fields found in {table_name} ')
+                return table.get('Name')
+            logger.info('Missing required fields')
+            logger.info(f"Detected fields: {field_found}")
+            logger.info(f"Required fields: {field_required}")
+        return None
+
+
     def create(self, name) -> bool:
         """Create account map"""
-        
-        print(f'\nCreating {name}...')
-        logger.info(f'Creating account mapping "{name}"...')
+
+        cid_print(f'Creating account mapping <BOLD>{name}<END>')
         try:
             if self.accounts:
                 logger.info('Account information found, skipping autodiscovery')
-                raise Exception
-            if not self._AthenaTableName:
-                # Autodiscover
-                print('\tautodiscovering...', end='')
-                logger.info('Autodiscovering metadata table...')
-                tables = self.athena.list_table_metadata()
-                tables = [t for t in tables if t.get('TableType') == 'EXTERNAL_TABLE']
-                tables = [t for t in tables if t.get('Name') in self.defaults.get('MetadataTableNames')]
-                if not len(tables):
-                    logger.info('Metadata table not found')
-                    print('account metadata not detected')
-                    raise Exception
-                table = next(iter(tables))
-                logger.info(f"Detected metadata table {table.get('Name')}")
-                accounts = table.get('Columns')
-                field_found = [v.get('Name') for v in accounts]
-                field_required = list(self.mappings.get(name).get(table.get('Name')).values())
-                logger.info(f"Detected fields: {field_found}")
-                logger.info(f"Required fields: {field_required}")
-                # Check if we have all the required fields
-                if all(v in field_found for v in field_required):
-                    logger.info('All required fields found')
-                    self._AthenaTableName = table.get('Name')
-                else:
-                    logger.info('Missing required fields')
-            if self._AthenaTableName:
-                # Query path
-                view_definition = self.athena._resources.get('views').get(name, dict())
+                raise CidError('Account information found, skipping autodiscovery')
+            if get_parameters().get('account-map-source'):
+                raise CidError('Skipping autodiscovery')
+
+            self._athena_table_name = self.detect_metadata_table(name)
+            if not self._athena_table_name:
+                raise CidError('Metadata table not found')
+
+            # Query path
+            view_definition = self.athena._resources.get('views').get(name, {})
+            if view_definition.get('File'):
                 view_file = view_definition.get('File')
-
                 template = Template(resource_string(view_definition.get('providedBy'), f'data/queries/{view_file}').decode('utf-8'))
-
-                # Fill in TPLs
-                columns_tpl = dict()
-                parameters = {
-                    'metadata_table_name': self._AthenaTableName,
-                    'cur_table_name': self.cur.tableName
-                }
-                columns_tpl.update(**parameters)
-                for k,v in self.mappings.get(name).get(self._AthenaTableName).items():
-                    logger.info(f'Mapping field {k} to {v}')
-                    columns_tpl.update({k: v})
-                compiled_query = template.safe_substitute(columns_tpl)
-                print('compiled view.')
+            elif view_definition.get('data'):
+                template = Template(str(view_definition.get('data')))
             else:
-                logger.info('Metadata table not found')
-                print('account metadata not detected')
-                raise Exception
-        except:
-            # TODO: Handle exceptions
+                raise CidError(f'{name} definition does not contain File or data: {view_definition}')
+
+            # Fill in TPLs
+            columns_tpl = {
+                'metadata_table_name': self._athena_table_name,
+                'cur_table_name': self.cur.table_name # only for trends
+            }
+            for key, val in self.mappings.get(name).get(self._athena_table_name).items():
+                logger.debug(f'Mapping field {key} to {val}')
+                columns_tpl[key] = val
+            compiled_query = template.safe_substitute(columns_tpl)
+            logger.debug('compiled view.')
+
+        except CidError as exc:
+            logger.info(exc)
             compiled_query = self.create_account_mapping_sql(name)
 
         # Execute query
-        click.echo('\tcreating view...', nl=False)
-        query_id = self.athena.execute_query(sql_query=compiled_query)
-        # Get results as list
-        response = self.athena.get_query_results(query_id)
-        click.echo('done')
+        cid_print('Creating Athena view')
+        self.athena.query(compiled_query)
+        cid_print(f'Created account mapping <BOLD>{name}<END>')
 
     def get_dummy_account_mapping_sql(self, name) -> list:
         """Create dummy account mapping"""
         logger.info(f'Creating dummy account mapping for {name}')
         template = Template(resource_string(
             package_or_requirement='cid.builtin.core',
             resource_name='data/queries/shared/account_map_dummy.sql',
         ).decode('utf-8'))
         columns_tpl = {
             'athena_view_name': name,
-            'cur_table_name': self.cur.tableName
+            'cur_table_name': self.cur.table_name
         }
         compiled_query = template.safe_substitute(columns_tpl)
         return compiled_query
 
     def get_organization_accounts(self) -> list:
-        """ Retreive AWS Organization account """
+        """ Retrieve AWS Organization account """
         # Init clients
+        accounts = []
         orgs = self.session.client('organizations')
         try:
-            paginator = orgs.get_paginator('list_accounts')
-            page_iterator = paginator.paginate()
-            accounts = list()
-            for page in page_iterator:
+            for page in orgs.get_paginator('list_accounts').paginate():
                 for account in page['Accounts']:
                     accounts.append({
                         'account_id': account.get('Id'),
                         'account_name': account.get('Name'),
-                        'account_status': account.get('Status'),
-                        'account_email': account.get('Email')
+                        'account_status': account.get('Status'), #Only for Trends
+                        'account_email': account.get('Email'), #Only for Trends
                     })
         except orgs.exceptions.AWSOrganizationsNotInUseException:
-            print('AWS Organization is not enabled')
+            cid_print('AWS Organization is not enabled')
         except orgs.exceptions.AccessDeniedException:
-            print('no access.')
-        except Exception as e:
-            print(e)
-        finally:
-            return accounts
+            cid_print('No access to AWS Organization.')
+        except Exception as exc: #pylint: disable=broad-exception-caught
+            cid_print(exc)
+
+        return accounts
 
     def check_file_exists(self, file_path) -> bool:
-        """ Checks if the givven file exists """
+        """ Checks if the given file exists """
         # Set base paths
         abs_path = Path().absolute()
 
         return Path.is_file(abs_path / file_path)
 
     def get_csv_accounts(self, file_path) -> list:
-        """ Retreive accounts from CSV file """
-        with open(file_path) as f:
-            accounts = [{str(k).lower().replace(" ", "_"): str(v) for k, v in row.items()}
-                        for row in csv.DictReader(f, skipinitialspace=True)]
+        """ Retrieve accounts from CSV file """
+        accounts = [
+            {str(k).lower().replace(" ", "_"): str(v) for k, v in row.items()}
+            for row in read_csv(file_path)
+        ]
 
         return accounts
 
 
     def select_metadata_collection_method(self) -> str:
         """ Selects the method to collect metadata """
         logger.info('Metadata source selection')
-        # Ask user which method to use to retreive account list
+        # Ask user which method to use to retrieve account list
         account_map_sources = {
-            'CSV file (relative path required)': 'csv',
-            'AWS Organizations (one time account listing)': 'organization',
             'Dummy (CUR account data, no names)': 'dummy',
+            'AWS Organizations (one time account listing)': 'organization',
+            'CSV file (relative path required)': 'csv',
         }
         selected_source = get_parameter(
             param_name='account-map-source',
             message="Please select account metadata collection method",
             choices=account_map_sources,
         )
         logger.info(f'Selected {selected_source}')
@@ -229,31 +251,30 @@
         if self._metadata_source == 'csv':
             finished = False
             while not finished:
                 mapping_file = get_parameter(
                     param_name='account-map-file',
                     message="Enter file path",
                 )
+                mapping_file = os.path.expanduser(mapping_file)
                 finished = self.check_file_exists(mapping_file)
                 if not finished:
-                    click.echo('File not found, ', nl=False)
-            click.echo('\nCollecting account info...', nl=False)
+                    cid_print(f'File not found: {mapping_file}')
+                    unset_parameter('account-map-file')
+            cid_print(f'\nReading {mapping_file}')
             self._accounts = self.get_csv_accounts(mapping_file)
-            logger.info(f'Found {len(self._accounts)} accounts')
-            click.echo(f' {len(self.accounts)} collected')
+            cid_print(f'{len(self.accounts)} accounts collected')
         elif self._metadata_source == 'organization':
-            click.echo('\nCollecting account info...', nl=False)
+            cid_print('\nCollecting account info from AWS Organizations')
             self._accounts = self.get_organization_accounts()
-            logger.info(f'Found {len(self._accounts)} accounts')
-            click.echo(f' {len(self.accounts)} collected')
+            cid_print(f'{len(self.accounts)} accounts collected')
         elif self._metadata_source == 'dummy':
-            click.echo('Notice: Dummy account mapping will be created')
+            cid_print('Notice: Dummy account mapping will be created.')
         else:
-            print('Unsupported selection')
-            return False
+            cid_print('Unsupported selection')
 
     def create_account_mapping_sql(self, name) -> str:
         """ Returns account mapping Athena query """
         for attempt in range(3):
             if self.accounts or self._metadata_source == 'dummy':
                 break
             self.select_metadata_collection_method()
@@ -268,20 +289,20 @@
             SELECT
                 *
             FROM
                 ( VALUES ${rows} )
             ignored_table_name (account_id, account_name, parent_account_id, account_status, account_email)
         '''
         template = Template(template_str)
-        accounts_sql = list()
+        accounts_sql = []
+        row_template = """ROW ('{account_id}', '{account_name}:{account_id}', '{parent_account_id}', '{account_status}', '{account_email}')"""
         for account in self.accounts:
             acc = account.copy()
             account_name = acc.pop('account_name').replace("'", "''")
-            accounts_sql.append(
-                """ROW ('{account_id}', '{account_name}:{account_id}', '{parent_account_id}', '{account_status}', '{account_email}')""".format(account_name=account_name, **acc))
+            accounts_sql.append(row_template.format(account_name=account_name, **acc))
         # Fill in TPLs
         columns_tpl = {
             'athena_view_name': name,
             'rows': ','.join(accounts_sql)
         }
         compiled_query = template.safe_substitute(columns_tpl)
```

### Comparing `cid-cmd-0.2.9/cid/helpers/athena.py` & `cid_cmd-0.3.0/cid/helpers/athena.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,32 +1,30 @@
-from io import StringIO
+import re
 import json
+import time
 import logging
-from string import Template
-import time, csv
-
-from pkg_resources import resource_string
 
 from cid.base import CidBase
-from cid.utils import get_parameter, get_parameters
-from cid.exceptions import CidCritical
+from cid.helpers import S3
+from cid.utils import get_parameter, get_parameters, cid_print
+from cid.helpers.diff import diff
+from cid.exceptions import CidCritical, CidError
 
 logger = logging.getLogger(__name__)
 
 class Athena(CidBase):
     # Define defaults
     defaults = {
         'CatalogName': 'AwsDataCatalog',
         'DatabaseName': 'customer_cur_data',
-        'WorkGroup': 'primary'
+        'WorkGroup': 'CID'
     }
     _CatalogName = None
     _DatabaseName = None
     _WorkGroup = None
-    ahq_queries = None
     _metadata = dict()
     _resources = dict()
     _client = None
 
     def __init__(self, session, resources: dict=None) -> None:
         super().__init__(session)
         self._resources = resources
@@ -35,141 +33,217 @@
     def client(self):
         if not self._client:
             self._client = self.session.client('athena', region_name=self.region)
         return self._client
 
     @property
     def CatalogName(self) -> str:
-        """ Check if AWS Datacalog and Athena database exist """
+        """ Check if AWS DataCatalog and Athena database exist """
         if not self._CatalogName:
             # Get AWS Glue DataCatalogs
             glue_data_catalogs = [d for d in self.list_data_catalogs() if d['Type'] == 'GLUE']
             if not len(glue_data_catalogs):
-                logger.error('AWS DataCatog of type GLUE not found!')
-                self._status = 'AWS DataCatog of type GLUE not found'
+                logger.error('AWS DataCatalog of type GLUE not found!')
+                self._status = 'AWS DataCatalog of type GLUE not found'
             if len(glue_data_catalogs) == 1:
                 self._CatalogName = glue_data_catalogs.pop().get('CatalogName')
             elif len(glue_data_catalogs) > 1:
                 # Ask user
                 self._CatalogName = get_parameter(
                     param_name='glue-data-catalog',
                     message="Select AWS DataCatalog to use",
                     choices=[catalog.get('CatalogName') for catalog in glue_data_catalogs],
                 )
-            logger.info(f'Using datacatalog: {self._CatalogName}')
+            logger.info(f'Using DataCatalog: {self._CatalogName}')
         return self._CatalogName
 
     @CatalogName.setter
     def set_catalog_name(self, catalog):
         self._CatalogName = catalog
 
     @property
     def DatabaseName(self) -> str:
         """ Check if Athena database exist """
+        if self._DatabaseName: return self._DatabaseName
 
-        if not self._DatabaseName:
-            if get_parameters().get('athena-database'):
-                self._DatabaseName = get_parameters().get('athena-database')
-                try:
-                    if not self.get_database(self._DatabaseName):
-                        raise CidCritical(f'Database {self._DatabaseName} not found in Athena catalog {self.CatalogName}')
-                except Exception as exc:
-                    if 'AccessDeniedException' in str(exc):
-                        logger.warning(f'{type(exc)} - Missing athena:GetDatabase permission. Cannot verify existance of {self._DatabaseName} in {self.CatalogName}. Hope you have it there.')
-                        return self._DatabaseName
-                    raise
-            # Get AWS Athena databases
-            athena_databases = self.list_databases()
-            if not len(athena_databases):
-                self._status = 'AWS Athena databases not found'
-                raise CidCritical(self._status)
-            if len(athena_databases) == 1:
-                self._DatabaseName = athena_databases.pop().get('Name')
-            elif len(athena_databases) > 1:
-                # Remove empty databases from the list
-                for d in athena_databases:
-                    tables = self.list_table_metadata(
-                        DatabaseName=d.get('Name'),
-                        max_items=1000, # This is an impiric limit. User can have up to 200k tables in one DB we need to draw a line somewhere
-                    )
-                    if not len(tables):
-                        athena_databases.remove(d)
-                # Select default database if present
-                default_database = [d for d in athena_databases if d['Name'] == self.defaults.get('DatabaseName')]
-                if len(default_database):
-                    self._DatabaseName = default_database.pop().get('Name')
-                else:
-                    # Ask user
-                    self._DatabaseName = get_parameter(
-                        param_name='athena-database',
-                        message="Select AWS Athena database to use",
-                        choices=[d['Name'] for d in athena_databases],
-                    )
-            logger.info(f'Using Athena database: {self._DatabaseName}')
+        if get_parameters().get('athena-database'):
+            self._DatabaseName = get_parameters().get('athena-database')
+            try:
+                if not self.get_database(self._DatabaseName):
+                    raise CidCritical(f'Database {self._DatabaseName} not found in Athena catalog {self.CatalogName}')
+            except Exception as exc:
+                if 'AccessDeniedException' in str(exc):
+                    logger.warning(f'{type(exc)} - Missing athena:GetDatabase permission. Cannot verify existence of {self._DatabaseName} in {self.CatalogName}. Hope you have it there.')
+                    return self._DatabaseName
+                raise
+        # Get AWS Athena databases
+        athena_databases = self.list_databases()
+
+        # Select default database if present
+        default_databases = [database for database in athena_databases if database['Name'] == self.defaults.get('DatabaseName')]
+        if len(default_databases):
+            # Silently choose an existing default database
+            self._DatabaseName = default_databases.pop().get('Name')
+        else:
+            # Ask user
+            choices = [d['Name'] for d in athena_databases]
+            if self.defaults.get('DatabaseName') not in choices:
+                choices.append(self.defaults.get('DatabaseName') + ' (CREATE NEW)')
+            self._DatabaseName = get_parameter(
+                param_name='athena-database',
+                message="Select AWS Athena database to use",
+                choices=choices,
+            )
+            if self._DatabaseName.endswith( ' (CREATE NEW)'):
+                self._DatabaseName = self.defaults.get('DatabaseName')
+                self.query(f'CREATE DATABASE {self._DatabaseName}')
+        logger.info(f'Using Athena database: {self._DatabaseName}')
         return self._DatabaseName
 
     @DatabaseName.setter
     def DatabaseName(self, database):
         self._DatabaseName = database
 
     @property
     def WorkGroup(self) -> str:
         """ Select AWS Athena workgroup """
         if not self._WorkGroup:
+            if get_parameters().get('athena-workgroup'):
+                self.WorkGroup = self._ensure_workgroup(name=get_parameters().get('athena-workgroup'))
+                return self._WorkGroup
             logger.info('Selecting Athena workgroup...')
             workgroups = self.list_work_groups()
             logger.info(f'Found {len(workgroups)} workgroups: {", ".join([wg.get("Name") for wg in workgroups])}')
-            if len(workgroups) == 1:
-                self.WorkGroup = workgroups.pop().get('Name')
-            elif len(workgroups) > 1:
-                # Select default workgroup if present
-                default_workgroup = next(iter([wg.get('Name') for wg in workgroups if wg['Name'] == self.defaults.get('WorkGroup')]), None)
-                if default_workgroup: logger.info(f'Found "{default_workgroup}" as a default workgroup')
-                # Ask user
-                self.WorkGroup = get_parameter(
-                    param_name='athena-workgroup',
-                    message="Select AWS Athena workgroup to use",
-                    choices=[d['Name'] for d in workgroups],
-                    default=default_workgroup
-                )
+            # if len(workgroups) == 0:
+            #     self.WorkGroup = self._ensure_workgroup(name=self.defaults.get('WorkGroup'))
+            # elif len(workgroups) == 1:
+            #     # Silently choose the only workgroup that is available
+            #     self.WorkGroup = self._ensure_workgroup(name=workgroups.pop().get('Name'))
+            # else:
+            # Select default workgroup if present
+            if self.defaults.get('WorkGroup') not in {wgr['Name'] for wgr in workgroups}:
+                workgroups.append({'Name': f"{self.defaults.get('WorkGroup')} (create new)"})
+            default_workgroup = next(iter([wgr.get('Name') for wgr in workgroups if  self.defaults.get('WorkGroup') in wgr['Name']]), None)
+            if default_workgroup:
+                logger.info(f'Found "{default_workgroup}" as a default workgroup')
+            # Ask user
+            selected_workgroup = get_parameter(
+                param_name='athena-workgroup',
+                message="Select Amazon Athena workgroup to use",
+                choices=[wgr['Name'] for wgr in workgroups],
+                default=default_workgroup
+            )
+            if ' (create new)' in selected_workgroup:
+                selected_workgroup = selected_workgroup.replace(' (create new)', '')
+            self.WorkGroup = self._ensure_workgroup(name=selected_workgroup)
+
             logger.info(f'Selected workgroup: "{self._WorkGroup}"')
         return self._WorkGroup
 
     @WorkGroup.setter
     def WorkGroup(self, name: str):
         try:
             _workgroup = self.client.get_work_group(WorkGroup=name).get('WorkGroup')
         except self.client.exceptions.InvalidRequestException as e:
             raise CidCritical(e)
         if _workgroup.get('State') == 'DISABLED':
             raise CidCritical(f'Athena Workgroup "{name}" is disabled.')
         if not _workgroup.get('Configuration', {}).get('ResultConfiguration', {}).get('OutputLocation'):
-            raise CidCritical(f'Athena Workgroup "{name}" must have an output location s3 bucket configured in the region {self.region}.')
+            raise CidCritical(f'Athena Workgroup "{name}" must have an output location s3 bucket configured in the region {self.region}. See https://{self.region}.console.aws.amazon.com/athena/home?#/workgroups .')
         self._WorkGroup = name
         logger.info(f'Selected Athena WorkGroup: "{self._WorkGroup}"')
 
+    def workgroup_output_location(self) -> str:
+        workgroup = self.client.get_work_group(WorkGroup=self.WorkGroup)
+        return workgroup.get('WorkGroup', {}).get('Configuration', {}).get('ResultConfiguration', {}).get('OutputLocation', None)
+
+
+    def _ensure_workgroup(self, name: str) -> str:
+        """Ensure a workgroup exists and configured with an S3 bucket"""
+        s3 = S3(session=self.session)
+        if name == 'primary': # QuickSight manages primary wg differently, relying exclusively on bucket with a predefined name
+            bucket_name = f'{self.partition}-athena-query-results-{self.region}-{self.account_id}'
+        else:
+            bucket_name = f'{self.partition}-athena-query-results-cid-{self.account_id}-{self.region}'
+
+        try:
+            workgroup = self.client.get_work_group(WorkGroup=name)
+            if workgroup.get('WorkGroup', {}).get('Configuration', {}).get('ResultConfiguration', {}).get('OutputLocation', None):
+                return name # all good we have Output Bucket Configured.
+
+            # there no result bucket configured for this WG
+            buckets = s3.list_buckets(region_name=self.region)
+            if bucket_name not in buckets:
+                buckets.append(f'{bucket_name} (create new)')
+            bucket_name = get_parameter(
+                param_name='athena-result-bucket',
+                message=f"Select S3 bucket to use with Amazon Athena Workgroup [{name}]",
+                choices=[bucket for bucket in buckets]
+            )
+            if ' (create new)' in bucket_name:
+                bucket_name = bucket_name.replace(' (create new)', '')
+            s3.ensure_bucket(name=bucket_name)
+            self.client.update_work_group(
+                WorkGroup=name,
+                Description='string',
+                ConfigurationUpdates={
+                    'ResultConfigurationUpdates': {
+                        'OutputLocation': f's3://{bucket_name}',
+                        'EncryptionConfiguration': {
+                            'EncryptionOption': 'SSE_S3',
+                        },
+                        'AclConfiguration': {
+                            'S3AclOption': 'BUCKET_OWNER_FULL_CONTROL'
+                        }
+                    }
+                }
+            )
+            return name
+        except self.client.exceptions.InvalidRequestException as exc:
+            # Workgroup does not exist
+            if 'WorkGroup is not found' in exc.response.get('Error', {}).get('Message'):
+                s3.ensure_bucket(name=bucket_name)
+                self.client.create_work_group(
+                    Name=name,
+                    Configuration={
+                        'ResultConfiguration': {
+                            'OutputLocation': f's3://{bucket_name}',
+                            'EncryptionConfiguration': {
+                                'EncryptionOption': 'SSE_S3',
+                            },
+                            'AclConfiguration': {
+                                'S3AclOption': 'BUCKET_OWNER_FULL_CONTROL'
+                            }
+                        },
+                    }
+                )
+                return name
+            else:
+                raise
+        except Exception as exc:
+            logger.exception(exc)
+            raise CidCritical(f'Failed to create Athena work group ({exc})') from exc
+
     def list_data_catalogs(self) -> list:
         return self.client.list_data_catalogs().get('DataCatalogsSummary')
-    
+
     def list_databases(self) -> list:
         return self.client.list_databases(CatalogName=self.CatalogName).get('DatabaseList')
-    
+
     def get_database(self, DatabaseName: str=None) -> bool:
-        """ Check if AWS Datacalog and Athena database exist """
-        if not DatabaseName:
-            DatabaseName=self.DatabaseName
+        """ Check if AWS DataCatalog and Athena database exist """
+        DatabaseName = DatabaseName or self.DatabaseName
         try:
-            self.client.get_database(CatalogName=self.CatalogName, DatabaseName=DatabaseName).get('Database')
-            return True
-        except Exception as exc:
+            return self.client.get_database(CatalogName=self.CatalogName, DatabaseName=DatabaseName).get('Database')
+        except self.client.exceptions.ClientError as exc:
             if 'AccessDeniedException' in str(exc):
                 raise
             else:
-                logger.debug(e, exc_info=True)
-                return False
+                logger.debug(exc, exc_info=True)
+                return None
 
     def list_table_metadata(self, DatabaseName: str=None, max_items: int=None) -> dict:
         params = {
             'CatalogName': self.CatalogName,
             'DatabaseName': DatabaseName or self.DatabaseName,
             'PaginationConfig':{
                 'MaxItems': max_items,
@@ -182,21 +256,21 @@
             for page in response_iterator:
                 table_metadata.extend(page.get('TableMetadataList'))
             logger.debug(f'Table metadata: {table_metadata}')
             logger.info(f'Found {len(table_metadata)} tables in {DatabaseName if DatabaseName else self.DatabaseName}')
         except Exception as e:
             logger.error(f'Failed to list tables in {DatabaseName if DatabaseName else self.DatabaseName}')
             logger.error(e)
-            
+
         return table_metadata
 
     def list_work_groups(self) -> list:
         """ List AWS Athena workgroups """
         result = self.client.list_work_groups()
-        logger.debug(f'Workgroups: {result.get("WorkGroups")}')
+        logger.debug(f'WorkGroups: {result.get("WorkGroups")}')
         return result.get('WorkGroups')
 
     def get_table_metadata(self, TableName: str) -> dict:
         table_metadata = self._metadata.get(TableName)
         params = {
             'CatalogName': self.CatalogName,
             'DatabaseName': self.DatabaseName,
@@ -217,167 +291,86 @@
             'Database': database or self.DatabaseName,
             'Catalog': catalog or self.CatalogName,
         }
 
         try:
             # Start Athena query
             response = self.client.start_query_execution(
-                QueryString=sql_query, 
-                QueryExecutionContext=execution_context, 
+                QueryString=sql_query,
+                QueryExecutionContext=execution_context,
                 WorkGroup=self.WorkGroup
             )
 
             # Get Query ID
             query_id = response.get('QueryExecutionId')
-
-            # Get Query Status
+            if not query_id:
+                logger.debug(f'Full query: {sql_query}')
+                raise CidCritical(f'Athena cannot start query. Answer is: {response}')
+            # Get Query Status for the first time
             query_status = self.client.get_query_execution(QueryExecutionId=query_id)
-        except self.client.exceptions.InvalidRequestException as e:
+        except self.client.exceptions.InvalidRequestException as exc:
             logger.debug(f'Full query: {sql_query}')
-            raise CidCritical(f'InvalidRequestException: {e}')
-        except Exception as e:
+            raise CidCritical(f'InvalidRequestException: {exc}') from exc
+        except Exception as exc:
             logger.debug(f'Full query: {sql_query}')
-            raise CidCritical(f'Athena query failed: {e}')
-
+            raise CidCritical(f'Athena query failed: {exc}') from exc
 
         current_status = query_status['QueryExecution']['Status']['State']
 
         # Poll for the current status of query as long as its not finished
         while current_status in ['SUBMITTED', 'RUNNING', 'QUEUED']:
             response = self.client.get_query_execution(QueryExecutionId=query_id)
             current_status = response['QueryExecution']['Status']['State']
 
             # Sleep before polling again
             time.sleep(sleep_duration)
 
-        # Return result, either positive or negative
-        if (current_status == "SUCCEEDED"):
+        if current_status == "SUCCEEDED":
             return query_id
-        elif not fail:
-            return False
-        else:
-            failure_reason = response['QueryExecution']['Status']['StateChangeReason']
-            logger.error(f'Athena query failed: {failure_reason}')
-            logger.info(f'Full query: {sql_query}')
+        failure_reason = response.get('QueryExecution', {}).get('Status', {}).get('StateChangeReason',repr(response))
+        logger.info(f'Athena query failed: {failure_reason}')
+        logger.debug(f'Full query: {sql_query}')
+        if fail:
             raise CidCritical(f'Athena query failed: {failure_reason}')
+        return False
 
     def get_query_results(self, query_id):
+        """ Get Query Results """
         return self.client.get_query_results(QueryExecutionId=query_id)
-    
-    def get_query_execution(self, query_id):
-        return self.client.get_query_execution(QueryExecutionId=query_id)
-
-    def parse_response_as_list(self, response, include_header=False):
-        data = list()
-
-        # Get results rows, either with or without the header row
-        rows = response['ResultSet']['Rows'] if include_header else response['ResultSet']['Rows'][1:]
-
-        for row in rows:
-            for r in row['Data']:
-                data.append(r['VarCharValue'] if 'VarCharValue' in r else '')
-
-        return data
-
-    def query_results_to_csv(self, query_id, return_header=False):
-        # Get query results
-        response = self.client.get_query_results(QueryExecutionId=query_id)
-
-        # Get results rows, either with or without the header row
-        rows = response['ResultSet']['Rows'] if return_header else response['ResultSet']['Rows'][1:]
-
-        if rows:
-            # Write rows to StringIO in CSV format
-            buf = StringIO()
-            csv_writer = csv.writer(buf, delimiter=',')
-
-            for row in rows:
-                csv_writer.writerow([x['VarCharValue'] if 'VarCharValue' in x else None for x in row['Data']])
-
-            # Strip whitespaces from CSVified string and return it
-            return buf.getvalue().rstrip('\n')
-        else:
-            return None
-
-    def show_columns(self, table_name):
-        sql_query = f'SHOW COLUMNS in {table_name}'
-        query_id = self.execute_query(sql_query=sql_query)
-
-        describe = self.query_results_to_csv(query_id).split('\n')
-
-        # Athena is weird.. Remove whitespaces.
-        result = [elem.rstrip() for elem in describe]
 
+    def parse_response_as_table(self, response, include_header=False):
+        """ Return a query response as a table. """
+        result = []
+        starting_row = 0 if include_header else 1
+        for row in response['ResultSet']['Rows'][starting_row:]:
+            result.append([data.get('VarCharValue', '') for data in row['Data']])
         return result
 
-    def parse_selected_tables(self, month_list):
-        d = {}
-
-        for month in month_list:
-            split = month.split('_')
-
-        payer = split[1]
-        year = split[2][:4]
-        month = split[2][4:]
-
-        if payer in d:
-            d[payer].append((year, month))
-        else:
-            d[payer] = list()
-            d[payer].append((year, month))
-        
-        return d
-
-    # AHQ functions
-    def execute_ahq(self, query_id, **kwargs) -> list:
-        """ Execute Athena Query by name """
-        # Load query
-        query = self.get_ahq(query_id, **kwargs)
-        # Execute query
-        execution_id = self.execute_query(query)
+    def query(self, sql, include_header=False, **kwargs) -> list:
+        """ Execute Athena Query and return a result"""
+        logger.debug(f'query={sql}')
+        execution_id = self.execute_query(sql, **kwargs)
         results = self.get_query_results(execution_id)
-        # Return results as list
-        return self.parse_response_as_list(results)
-
-
-    def get_ahq(self, query_id, **kwargs) -> str:
-        """ Returns a fully compiled AHQ """
-        # Query path
-        query_file = self.get_ahqs().get(query_id).get('File')
-
-        template = Template(resource_string(__name__, f'../queries/{query_file}').decode('utf-8'))
-
-        # Fill in TPLs
-        columns_tpl = dict()
-        columns_tpl.update(**kwargs)
-        compiled_query = template.safe_substitute(columns_tpl)
-
-        return compiled_query
-
-
-    def get_ahqs(self) -> dict:
-        """ Return a list of all availiable AHQs """
-        
-        if not self.ahq_queries:            
-            # Load queries
-            queries_files = resource_string(__name__, '../queries/ahq-queries.json')
-            self.ahq_queries = json.loads(queries_files).get('query_templates')
-
-        return self.ahq_queries
+        #logger.debug(f'results = {json.dumps(results, indent=2)}')
+        parsed = self.parse_response_as_table(results, include_header)
+        logger.debug(f'parsed res = {json.dumps(parsed, indent=2)}')
+        return parsed
 
 
     def discover_views(self, views: dict={}) -> None:
+        """ Discover views from a given list of view names and cache them. """
         for view_name in views:
             try:
                 self.get_table_metadata(TableName=view_name)
             except self.client.exceptions.MetadataException:
                 pass
 
 
     def wait_for_view(self, view_name: str, poll_interval=1, timeout=60) -> None:
+        """ Wait for a View to be created. """
         deadline = time.time() + timeout
         while time.time() <= deadline:
             self.discover_views([view_name])
             if view_name in self._metadata.keys():
                 logger.info(f'view {view_name} exists')
                 return True
             else:
@@ -392,15 +385,15 @@
                 param_name=f'confirm-{name}',
                 message=f'Delete Athena table {name}?',
                 choices=['yes', 'no'],
                 default='no') != 'yes':
             return False
 
         try:
-            res = self.execute_query(
+            self.execute_query(
                 f'DROP TABLE IF EXISTS {name};',
                 catalog=catalog,
                 database=database,
                 fail=False
             )
         except Exception as exc:
             logger.debug(exc, exc_info=True)
@@ -416,21 +409,111 @@
                 param_name=f'confirm-{name}',
                 message=f'Delete Athena view {name}?',
                 choices=['yes', 'no'],
                 default='no') != 'yes':
             return False
 
         try:
-            res = self.execute_query(
+            self.execute_query(
                 f'DROP VIEW IF EXISTS {name};',
                 catalog=catalog,
                 database=database,
                 fail=False
             )
         except Exception as exc:
             logger.debug(exc, exc_info=True)
             logger.info(f'View {name} cannot be deleted: {exc}')
             return False
         else:
             if name in self._metadata: del self._metadata[name]
             logger.info(f'View {name} deleted')
         return True
+
+    def get_view_diff(self, name, sql):
+        """ returns a diff between existing and new views. """
+        tmp_name = 'cid_tmp_deleteme'
+        existing_sql = ''
+        try:
+            existing_sql = self.query(f'SHOW CREATE VIEW {name}', include_header=True)
+            existing_sql = '\n'.join([line[0] for line in existing_sql][1:])
+        except Exception as exc:
+            print(exc)
+            return None
+        try:
+            # Avoid difference in the first line of diff (replace name of the view with the tmp_name)
+            tmp_sql = re.sub(r'(CREATE OR REPLACE VIEW) (.+?) (AS.*)', r'\1 ' + tmp_name +  r' \3', sql)
+
+            if tmp_sql == sql:
+                raise CidError(f"Cannot get diff: same sql {repr(sql)}")
+            self.query(tmp_sql)
+            tmp_sql = self.query(f'SHOW CREATE VIEW {tmp_name}', include_header=True)
+            tmp_sql = '\n'.join([line[0] for line in tmp_sql][1:])
+        except Exception as exc:
+            print(exc)
+            return None
+        finally:
+            try:
+                self.query(f'DROP VIEW IF EXISTS {tmp_name};', fail=False)
+            except Exception as exc:
+                logger.debug(f'Cannot delete temporary view {tmp_name}: {exc}')
+
+        existing_sql = re.sub('"(.+?)"', r'\1', existing_sql) # remove quotes
+        tmp_sql = re.sub('"(.+?)"', r'\1', tmp_sql) # remove quotes
+        return diff(existing_sql, tmp_sql)
+
+
+    def process_views(self, views):
+        """ returns a dict of discovered views. Going to each view and try to discover recursively all "FROM" dependanices
+        """
+        all_views = {}
+        def _recursively_process_view(view):
+            """ process recursively views and add all dependency views to the global dict
+            """
+            athena_type = None
+            if self.query(f"SHOW VIEWS LIKE '{view}'", include_header=True):
+                athena_type = 'view'
+            elif self.query(f"SHOW TABLES LIKE '{view}'", include_header=True):
+                athena_type = 'table'
+            else:
+                logger.debug(f'{view} not a view and not a table. Skipping.')
+                return None
+            cid_print(f"    Processing Athena {athena_type}: <BOLD>{view}<END>")
+
+            all_views[view] = {}
+            if athena_type == 'view':
+                sql = self.query(f'SHOW CREATE VIEW {view}', include_header=True)
+                if not sql:
+                    return
+                sql = '\n'.join([line[0] for line in sql])
+                #print("sql", sql)
+                all_views[view]["dependsOn"] = {}
+                all_views[view]["dependsOn"]['views'] = []
+                deps = re.findall(r'FROM\W+?([\w."]+)', sql)
+                for dep_view in deps:
+                    #FIXME: need to add cross Database Dependencies
+                    if dep_view.upper() in ('SELECT', 'VALUES'): # remove "FROM SELECT" and "FROM VALUES"
+                        continue
+                    dep_view = dep_view.replace('"', '')
+                    if len(dep_view.split('.')) == 2:
+                        dep_database, dep_view_name = dep_view.split('.')
+                        if dep_database != self.DatabaseName:
+                            logger.error(f'The view {view} has a dependency on {dep_view}. CID cannot manage multiple Databases. Please move {dep_view_name} to Database {self.DatabaseName}. Skipping dependency.')
+                            continue
+                    dep_view = dep_view.split('.')[-1]
+                    if dep_view not in all_views:
+                        _recursively_process_view(dep_view)
+                    if dep_view not in all_views[view]["dependsOn"]['views'] and dep_view in all_views:
+                        all_views[view]["dependsOn"]['views'].append(dep_view)
+                if not all_views[view]["dependsOn"]['views']:
+                    del all_views[view]["dependsOn"]
+
+            elif athena_type == 'table':
+                sql = self.query(f'SHOW CREATE TABLE {view}', include_header=True)
+                sql = '\n'.join([line[0] for line in sql])
+
+            all_views[view]['data'] = sql.rstrip()
+            return all_views[view]
+
+        for view in views:
+            _recursively_process_view(view)
+
+        return all_views
```

### Comparing `cid-cmd-0.2.9/cid/helpers/quicksight/datasource.py` & `cid_cmd-0.3.0/cid/helpers/quicksight/datasource.py`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/helpers/quicksight/template.py` & `cid_cmd-0.3.0/cid/helpers/quicksight/template.py`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/logger.py` & `cid_cmd-0.3.0/cid/logger.py`

 * *Files 5% similar despite different names*

```diff
@@ -24,36 +24,35 @@
     if hasattr(logging, name): return # Already set
     logging.addLevelName(num, name)
     setattr(logging, name, num)
     setattr(logging.getLoggerClass(), method, log_method)
     setattr(logging, method, log_to_root)
 
 
-def set_cid_logger(verbosity, log_filename):
+def set_cid_logger(verbosity=2, log_filename=None):
 
     add_logging_level('TRACE', logging.DEBUG - 5)
 
     logger = logging.getLogger('cid')
 
     # File handler logs everything down to DEBUG level
     if log_filename and not os.environ.get('AWS_EXECUTION_ENV', '').startswith('AWS_Lambda'):
         fh = logging.FileHandler(log_filename)
         fh.setLevel(logging.TRACE)
         formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s:%(funcName)s:%(lineno)d - %(message)s')
         fh.setFormatter(formatter)
         logger.addHandler(fh)
 
-    # Console handler logs everything down to ERROR level
+    # Console handler logs everything down to WARNING level
     ch = logging.StreamHandler()
-    ch.setLevel(logging.ERROR)
+    ch.setLevel(logging.WARNING)
     formatter = logging.Formatter('%(levelname)s - %(message)s')
     ch.setFormatter(formatter)
     logger.addHandler(ch)
 
-
     if verbosity:
         # Limit Logging level to DEBUG, base level is WARNING
         verbosity = min(verbosity, 2)
         logger.setLevel(logger.getEffectiveLevel()-10 * verbosity)
         # Logging application start here due to logging configuration
         print(f'Logging level set to: {logging.getLevelName(logger.getEffectiveLevel())}')
```

### Comparing `cid-cmd-0.2.9/cid/plugin.py` & `cid_cmd-0.3.0/cid/plugin.py`

 * *Files identical despite different names*

### Comparing `cid-cmd-0.2.9/cid/utils.py` & `cid_cmd-0.3.0/cid/utils.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,26 +1,43 @@
 import os
 import sys
+import copy
+import math
 import inspect
 import logging
 import platform
+import datetime
+from typing import Any, Dict
 from functools import lru_cache as cache
 from collections.abc import Iterable
 
-from boto3.session import Session
+import requests
 import questionary
+from boto3.session import Session
 from botocore.exceptions import NoCredentialsError, CredentialRetrievalError, NoRegionError, ProfileNotFound
 
 from cid.exceptions import CidCritical
 
 logger = logging.getLogger(__name__)
 
 params = {} # parameters from command line
 _all_yes = False # parameters from command line
 
+PYPI_URL = "https://pypi.org/pypi/cid-cmd/json"
+
+def get_latest_tool_version():
+    res_json = {}
+    try:
+        r = requests.get(PYPI_URL,timeout=3)
+        r.raise_for_status()
+        res_json = r.json()
+    except requests.exceptions as exec:
+        logger.debug(exec, exc_info=True)
+    finally:
+        return res_json.get("info", {}).get("version", "UNDEFINED")
 
 @cache(maxsize=None)
 def isatty():
     """ return True if executed in a Terminal that allows user input """
     if exec_env()['terminal'] == 'gitbash': # We cannot trust isatty on Git Bash on Windows
         return True
     return sys.__stdin__.isatty()
@@ -115,14 +132,15 @@
         violets, roses = 'violets', 'roses'
         cid_print(f'{roses} are <BOLD><RED>red<END>, {violets} are <BLUE><UNDERLINE>blue<END>')
 
     '''
     colors = {
         'PURPLE': '\033[95m',
         'CYAN': '\033[96m',
+        'GREY': '\033[90m',
         'DARKCYAN': '\033[36m',
         'BLUE': '\033[94m',
         'GREEN': '\033[92m',
         'YELLOW': '\033[93m',
         'RED': '\033[91m',
         'BOLD': '\033[1m',
         'UNDERLINE': '\033[4m',
@@ -147,15 +165,15 @@
     for k, v in parameters.items():
         params[k.replace('_', '-')] = v
 
     if all_yes != None:
         global _all_yes
         _all_yes = all_yes
 
-def is_unattendent_mode() -> bool:
+def is_unattended_mode() -> bool:
     return _all_yes
 
 def get_parameters():
     return dict(params)
 
 
 def get_yesno_parameter(param_name, message, default=None, break_on_ctrl_c=True):
@@ -187,16 +205,19 @@
     :returns: a value choosed by user or provided in command line    
     """
     logger.debug(f'getting param {param_name}')
     param_name = param_name.replace('_', '-')
     if params.get(param_name):
         value = params[param_name]
         logger.info(f'Using {param_name}={value}, from parameters')
-        if isinstance(value, str):
-            value = value.format(**template_variables)
+        if isinstance(value, str) and template_variables:
+            try:
+                value = value.format(**template_variables)
+            except KeyError:
+                pass
         return value
 
     if choices is not None:
         if 'yes' in choices and _all_yes:
             return 'yes'
         if isinstance(choices, dict):
             _choices = []
@@ -215,30 +236,77 @@
             raise Exception(f'Please set parameter {param_name}. Unable to request user in environment={exec_env()}')
         result = questionary.select(
             message=f'[{param_name}] {message}:',
             choices=choices,
             default=default,
         ).ask()
     else: # it is a text entry
-        if isinstance(default, str):
+        if isinstance(default, str) and template_variables:
+            print(template_variables)
             default=default.format(**template_variables)
         print()
         if not isatty():
             raise Exception(f'Please set parameter {param_name}. Unable to request user in environment={exec_env()}')
         result = questionary.text(
             message=f'[{param_name}] {message}:' ,
             default=default or '',
         ).ask()
-        if isinstance(result, str):
+        if isinstance(result, str) and template_variables:
             result = result.format(**template_variables)
     if (break_on_ctrl_c and result is None):
         exit(1)
     logger.info(f"(Use \033[1m --{param_name} '{result}'\033[0m next time you run this)")
     params[param_name] = result
     return result
 
 def unset_parameter(param_name):
     param_name = param_name.replace('_', '-')
-    if params.get(param_name):
+    if param_name in params:
         value = params[param_name]
         del params[param_name]
         logger.info(f'Cleared {param_name}={value}, from parameters')
+
+
+def ago(time):
+    """ Calculate a '3 hours ago' type string from a python datetime.
+    credits: https://gist.github.com/tonyblundell/2652369
+    """
+    units = {
+        'days': lambda diff: diff.days,
+        'hours': lambda diff: diff.seconds / 3600,
+        'minutes': lambda diff: diff.seconds % 3600 / 60,
+    }
+    diff = datetime.datetime.now().replace(tzinfo=time.tzinfo) - time
+    for unit in units:
+        dur = math.floor(units[unit](diff)) # Run the lambda function to get a duration
+        if dur > 0:
+            unit = unit[:-dur] if dur == 1 else unit # De-pluralize if duration is 1 ('1 day' vs '2 days')
+            return '%s %s ago' % (dur, unit)
+    return 'just now'
+
+
+class IsolatedParameters:
+    """A context manager to run something in isolated set of parameters"""
+    def __enter__(self):
+        self.backup = copy.deepcopy(params)
+
+    def __exit__(self, exc_type, exc_value, traceback):
+        global params
+        params = self.backup
+
+def merge_objects(obj1, obj2, depth=2):
+    """ merging objects with a depth
+
+    unit tests: cid/test/python/test_merge.py
+    """
+    if isinstance(obj1, dict) and isinstance(obj2, dict):
+        result = obj1.copy()
+        for key, value in obj2.items():
+            if depth > 0 and key in result and isinstance(result[key], (dict, list)) and isinstance(value, (dict, list)):
+                result[key] = merge_objects(result[key], value, depth - 1)
+            else:
+                result[key] = value
+        return result
+    elif isinstance(obj1, list) and isinstance(obj2, list):
+        return obj1 + obj2
+    else:
+        return obj2  # If types don't match or if one of them is not a dict or list, prefer the second object.
```

### Comparing `cid-cmd-0.2.9/cid_cmd.egg-info/SOURCES.txt` & `cid_cmd-0.3.0/cid_cmd.egg-info/SOURCES.txt`

 * *Files 9% similar despite different names*

```diff
@@ -17,14 +17,16 @@
 cid/builtin/core/__init__.py
 cid/builtin/core/data/resources.yaml
 cid/builtin/core/data/datasets/cid/compute.json
 cid/builtin/core/data/datasets/cid/ec2_running_cost.json
 cid/builtin/core/data/datasets/cid/s3_view.json
 cid/builtin/core/data/datasets/cid/summary_view.json
 cid/builtin/core/data/datasets/co/dataset.json
+cid/builtin/core/data/datasets/cudos/hourly_view.json
+cid/builtin/core/data/datasets/cudos/resource_view.json
 cid/builtin/core/data/datasets/kpi/kpi_ebs_snap.json
 cid/builtin/core/data/datasets/kpi/kpi_ebs_storage_all.json
 cid/builtin/core/data/datasets/kpi/kpi_instance_all.json
 cid/builtin/core/data/datasets/kpi/kpi_s3_storage_all.json
 cid/builtin/core/data/datasets/kpi/kpi_tracker.json
 cid/builtin/core/data/datasets/shared/customer_all.json
 cid/builtin/core/data/datasets/tao/dataset.json
@@ -55,14 +57,22 @@
 cid/builtin/core/data/queries/co/auto_scale_options.sql
 cid/builtin/core/data/queries/co/ebs_volume.json
 cid/builtin/core/data/queries/co/ebs_volume_options.sql
 cid/builtin/core/data/queries/co/ec2_instance.json
 cid/builtin/core/data/queries/co/ec2_instance_options.sql
 cid/builtin/core/data/queries/co/lambda.json
 cid/builtin/core/data/queries/co/lambda_options.sql
+cid/builtin/core/data/queries/cudos/hourly_view.sql
+cid/builtin/core/data/queries/cudos/hourly_view_ri.sql
+cid/builtin/core/data/queries/cudos/hourly_view_sp.sql
+cid/builtin/core/data/queries/cudos/hourly_view_sp_ri.sql
+cid/builtin/core/data/queries/cudos/resource_view.sql
+cid/builtin/core/data/queries/cudos/resource_view_ri.sql
+cid/builtin/core/data/queries/cudos/resource_view_sp.sql
+cid/builtin/core/data/queries/cudos/resource_view_sp_ri.sql
 cid/builtin/core/data/queries/kpi/first_kpi_instance_mapping_view.sql
 cid/builtin/core/data/queries/kpi/kpi_ebs_snap_view.sql
 cid/builtin/core/data/queries/kpi/kpi_ebs_storage_view.sql
 cid/builtin/core/data/queries/kpi/kpi_instance_all_view.sql
 cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRI.sql
 cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noRISP.sql
 cid/builtin/core/data/queries/kpi/kpi_instance_all_view_noSP.sql
@@ -70,37 +80,48 @@
 cid/builtin/core/data/queries/kpi/last_kpi_tracker_view.sql
 cid/builtin/core/data/queries/shared/account_map.sql
 cid/builtin/core/data/queries/shared/account_map_dummy.sql
 cid/builtin/core/data/queries/shared/aws_accounts.sql
 cid/builtin/core/data/queries/shared/aws_regions.sql
 cid/builtin/core/data/queries/shared/aws_service_category_map.sql
 cid/builtin/core/data/queries/shared/business_units_map.sql
+cid/builtin/core/data/queries/shared/cur.yaml
 cid/builtin/core/data/queries/shared/payer_account_name_map.sql
 cid/builtin/core/data/queries/shared/ta_descriptions.sql
 cid/builtin/core/data/queries/tao/glue_table.json
 cid/builtin/core/data/queries/tao/ta_org_view.sql
 cid/builtin/core/data/queries/trends/daily_anomaly_detection.sql
 cid/builtin/core/data/queries/trends/monthly_anomaly_detection.sql
 cid/builtin/core/data/queries/trends/monthly_bill_by_account.sql
 cid/builtin/core/data/queries/trends/monthly_bill_by_account_ri.sql
 cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp.sql
 cid/builtin/core/data/queries/trends/monthly_bill_by_account_sp_ri.sql
+cid/commands/__init__.py
+cid/commands/command_base.py
+cid/commands/init_qs.py
 cid/helpers/__init__.py
 cid/helpers/account_map.py
 cid/helpers/athena.py
+cid/helpers/csv2view.py
 cid/helpers/cur.py
+cid/helpers/diff.py
 cid/helpers/glue.py
+cid/helpers/iam.py
+cid/helpers/organizations.py
+cid/helpers/randtime.py
+cid/helpers/s3.py
+cid/helpers/timezone.py
 cid/helpers/quicksight/__init__.py
 cid/helpers/quicksight/dashboard.py
 cid/helpers/quicksight/dataset.py
 cid/helpers/quicksight/datasource.py
 cid/helpers/quicksight/resource.py
 cid/helpers/quicksight/template.py
-cid/queries/ahq-queries.json
-cid/queries/ri_present.sql
-cid/queries/sp_present.sql
+cid/test/python/test_csv2view.py
+cid/test/python/test_isolated_parameters.py
+cid/test/python/test_merge.py
 cid_cmd.egg-info/PKG-INFO
 cid_cmd.egg-info/SOURCES.txt
 cid_cmd.egg-info/dependency_links.txt
 cid_cmd.egg-info/entry_points.txt
 cid_cmd.egg-info/requires.txt
 cid_cmd.egg-info/top_level.txt
```

### Comparing `cid-cmd-0.2.9/setup.cfg` & `cid_cmd-0.3.0/setup.cfg`

 * *Files 5% similar despite different names*

```diff
@@ -11,31 +11,32 @@
 url = https://github.com/aws-samples/aws-cudos-framework-deployment
 author = AWS CUDOS Team
 license = MIT
 classifiers = 
 	Development Status :: 4 - Beta
 	License :: OSI Approved :: MIT License
 	Programming Language :: Python :: 3
-	Programming Language :: Python :: 3.7
-	Programming Language :: Python :: 3.8
 	Programming Language :: Python :: 3.9
 	Programming Language :: Python :: 3.10
+	Programming Language :: Python :: 3.11
+	Programming Language :: Python :: 3.12
 
 [options]
 include_package_data = True
 packages = find_namespace:
 install_requires = 
 	setuptools
-	boto3>=1.26
+	boto3>=1.34.70
 	Click>=8.0
-	deepmerge
 	PyYAML
 	requests
+	tzlocal>=4.0
 	six>=1.15
 	questionary>=1.10
+	tqdm
 
 [options.entry_points]
 console_scripts = 
 	cid-cmd=cid.cli:main
 cid.plugins = 
 	Core = cid.builtin.core
```

