# Comparing `tmp/gaea_paddledet-2.5.0.1-py3-none-any.whl.zip` & `tmp/gaea_paddledet-2.5.0.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,17 +1,17 @@
-Zip file size: 763945 bytes, number of entries: 269
+Zip file size: 765087 bytes, number of entries: 269
 -rw-r--r--  2.0 unx    11357 b- defN 24-Mar-29 15:19 paddledet/LICENSE
 -rw-r--r--  2.0 unx    41596 b- defN 24-Mar-29 15:19 paddledet/README.md
--rw-r--r--  2.0 unx    42889 b- defN 24-Apr-01 11:33 paddledet/gaea_paddledet.egg-info/PKG-INFO
--rw-r--r--  2.0 unx     9045 b- defN 24-Apr-01 11:33 paddledet/gaea_paddledet.egg-info/SOURCES.txt
--rw-r--r--  2.0 unx        1 b- defN 24-Apr-01 11:33 paddledet/gaea_paddledet.egg-info/dependency_links.txt
--rw-r--r--  2.0 unx      158 b- defN 24-Apr-01 11:33 paddledet/gaea_paddledet.egg-info/requires.txt
--rw-r--r--  2.0 unx       10 b- defN 24-Apr-01 11:33 paddledet/gaea_paddledet.egg-info/top_level.txt
+-rw-r--r--  2.0 unx    42889 b- defN 24-Apr-19 06:25 paddledet/gaea_paddledet.egg-info/PKG-INFO
+-rw-r--r--  2.0 unx     9045 b- defN 24-Apr-19 06:25 paddledet/gaea_paddledet.egg-info/SOURCES.txt
+-rw-r--r--  2.0 unx        1 b- defN 24-Apr-19 06:25 paddledet/gaea_paddledet.egg-info/dependency_links.txt
+-rw-r--r--  2.0 unx      158 b- defN 24-Apr-19 06:25 paddledet/gaea_paddledet.egg-info/requires.txt
+-rw-r--r--  2.0 unx       10 b- defN 24-Apr-19 06:25 paddledet/gaea_paddledet.egg-info/top_level.txt
 -rw-r--r--  2.0 unx     1039 b- defN 24-Mar-29 15:19 paddledet/ppdet/__init__.py
--rw-r--r--  2.0 unx      143 b- defN 24-Apr-01 11:33 paddledet/ppdet/version.py
+-rw-r--r--  2.0 unx      143 b- defN 24-Apr-19 06:25 paddledet/ppdet/version.py
 -rw-r--r--  2.0 unx      634 b- defN 24-Mar-29 15:19 paddledet/ppdet/core/__init__.py
 -rw-r--r--  2.0 unx     9214 b- defN 24-Mar-29 15:19 paddledet/ppdet/core/workspace.py
 -rw-r--r--  2.0 unx      610 b- defN 24-Mar-29 15:19 paddledet/ppdet/core/config/__init__.py
 -rw-r--r--  2.0 unx     8066 b- defN 24-Mar-29 15:19 paddledet/ppdet/core/config/schema.py
 -rw-r--r--  2.0 unx     3571 b- defN 24-Mar-29 15:19 paddledet/ppdet/core/config/yaml_helpers.py
 -rw-r--r--  2.0 unx      778 b- defN 24-Mar-29 15:19 paddledet/ppdet/data/__init__.py
 -rw-r--r--  2.0 unx    10576 b- defN 24-Mar-29 15:19 paddledet/ppdet/data/reader.py
@@ -37,21 +37,21 @@
 -rw-r--r--  2.0 unx     2903 b- defN 24-Mar-29 15:19 paddledet/ppdet/data/transform/gridmask_utils.py
 -rw-r--r--  2.0 unx    32641 b- defN 24-Mar-29 15:19 paddledet/ppdet/data/transform/keypoint_operators.py
 -rw-r--r--  2.0 unx    25831 b- defN 24-Mar-29 15:19 paddledet/ppdet/data/transform/mot_operators.py
 -rw-r--r--  2.0 unx    17228 b- defN 24-Mar-29 15:19 paddledet/ppdet/data/transform/op_helper.py
 -rw-r--r--  2.0 unx   168485 b- defN 24-Mar-29 15:19 paddledet/ppdet/data/transform/operators.py
 -rw-r--r--  2.0 unx    19732 b- defN 24-Mar-29 15:19 paddledet/ppdet/data/transform/rotated_operators.py
 -rw-r--r--  2.0 unx      938 b- defN 24-Mar-29 15:19 paddledet/ppdet/engine/__init__.py
--rw-r--r--  2.0 unx    25888 b- defN 24-Apr-01 11:27 paddledet/ppdet/engine/callbacks.py
+-rw-r--r--  2.0 unx    27836 b- defN 24-Apr-19 06:22 paddledet/ppdet/engine/callbacks.py
 -rw-r--r--  2.0 unx     1558 b- defN 24-Mar-29 15:19 paddledet/ppdet/engine/env.py
 -rw-r--r--  2.0 unx     6829 b- defN 24-Mar-29 15:19 paddledet/ppdet/engine/export_utils.py
 -rw-r--r--  2.0 unx    26462 b- defN 24-Mar-29 15:19 paddledet/ppdet/engine/tracker.py
--rw-r--r--  2.0 unx    55251 b- defN 24-Apr-01 11:27 paddledet/ppdet/engine/trainer.py
+-rw-r--r--  2.0 unx    55251 b- defN 24-Apr-19 06:21 paddledet/ppdet/engine/trainer.py
 -rw-r--r--  2.0 unx      983 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/__init__.py
--rw-r--r--  2.0 unx    17546 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/coco_utils.py
+-rw-r--r--  2.0 unx    20865 b- defN 24-Apr-11 02:35 paddledet/ppdet/metrics/coco_utils.py
 -rw-r--r--  2.0 unx     5545 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/json_results.py
 -rw-r--r--  2.0 unx    15446 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/keypoint_metrics.py
 -rw-r--r--  2.0 unx    15486 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/map_utils.py
 -rw-r--r--  2.0 unx    16391 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/mcmot_metrics.py
 -rw-r--r--  2.0 unx    19675 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/metrics.py
 -rw-r--r--  2.0 unx    52006 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/mot_metrics.py
 -rw-r--r--  2.0 unx    13416 b- defN 24-Mar-29 15:19 paddledet/ppdet/metrics/munkres.py
@@ -259,13 +259,13 @@
 -rw-r--r--  2.0 unx     4236 b- defN 24-Mar-29 15:19 paddledet/tools/infer_mot.py
 -rw-r--r--  2.0 unx     8400 b- defN 24-Mar-29 15:19 paddledet/tools/infer_pair.py
 -rw-r--r--  2.0 unx     2708 b- defN 24-Mar-29 15:19 paddledet/tools/post_quant.py
 -rw-r--r--  2.0 unx     2021 b- defN 24-Mar-29 15:19 paddledet/tools/slice_image.py
 -rw-r--r--  2.0 unx     6417 b- defN 24-Mar-29 15:19 paddledet/tools/sniper_params_stats.py
 -rw-r--r--  2.0 unx     4977 b- defN 24-Mar-29 15:19 paddledet/tools/train.py
 -rw-r--r--  2.0 unx    20116 b- defN 24-Mar-29 15:19 paddledet/tools/x2coco.py
--rw-r--r--  2.0 unx    11357 b- defN 24-Apr-01 11:33 gaea_paddledet-2.5.0.1.dist-info/LICENSE
--rw-r--r--  2.0 unx    42892 b- defN 24-Apr-01 11:33 gaea_paddledet-2.5.0.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-01 11:33 gaea_paddledet-2.5.0.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 24-Apr-01 11:33 gaea_paddledet-2.5.0.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    26963 b- defN 24-Apr-01 11:33 gaea_paddledet-2.5.0.1.dist-info/RECORD
-269 files, 2845810 bytes uncompressed, 720245 bytes compressed:  74.7%
+-rw-r--r--  2.0 unx    11357 b- defN 24-Apr-19 06:25 gaea_paddledet-2.5.0.3.dist-info/LICENSE
+-rw-r--r--  2.0 unx    42892 b- defN 24-Apr-19 06:25 gaea_paddledet-2.5.0.3.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-19 06:25 gaea_paddledet-2.5.0.3.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 24-Apr-19 06:25 gaea_paddledet-2.5.0.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    26963 b- defN 24-Apr-19 06:25 gaea_paddledet-2.5.0.3.dist-info/RECORD
+269 files, 2851077 bytes uncompressed, 721387 bytes compressed:  74.7%
```

## zipnote {}

```diff
@@ -786,23 +786,23 @@
 
 Filename: paddledet/tools/train.py
 Comment: 
 
 Filename: paddledet/tools/x2coco.py
 Comment: 
 
-Filename: gaea_paddledet-2.5.0.1.dist-info/LICENSE
+Filename: gaea_paddledet-2.5.0.3.dist-info/LICENSE
 Comment: 
 
-Filename: gaea_paddledet-2.5.0.1.dist-info/METADATA
+Filename: gaea_paddledet-2.5.0.3.dist-info/METADATA
 Comment: 
 
-Filename: gaea_paddledet-2.5.0.1.dist-info/WHEEL
+Filename: gaea_paddledet-2.5.0.3.dist-info/WHEEL
 Comment: 
 
-Filename: gaea_paddledet-2.5.0.1.dist-info/top_level.txt
+Filename: gaea_paddledet-2.5.0.3.dist-info/top_level.txt
 Comment: 
 
-Filename: gaea_paddledet-2.5.0.1.dist-info/RECORD
+Filename: gaea_paddledet-2.5.0.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## paddledet/gaea_paddledet.egg-info/PKG-INFO

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: gaea-paddledet
-Version: 2.5.0.1
+Version: 2.5.0.3
 Summary: Object detection and instance segmentation toolkit based on PaddlePaddle
 Home-page: https://github.com/PaddlePaddle/PaddleDetection
 Download-URL: https://github.com/PaddlePaddle/PaddleDetection.git
 Author: PaddlePaddle
 License: Apache License 2.0
 Keywords: ppdet paddle ppyolo
 Classifier: Intended Audience :: Developers
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: gaea-paddledet Version: 2.5.0.1 Summary: Object
+Metadata-Version: 2.1 Name: gaea-paddledet Version: 2.5.0.3 Summary: Object
 detection and instance segmentation toolkit based on PaddlePaddle Home-page:
 https://github.com/PaddlePaddle/PaddleDetection Download-URL: https://
 github.com/PaddlePaddle/PaddleDetection.git Author: PaddlePaddle License:
 Apache License 2.0 Keywords: ppdet paddle ppyolo Classifier: Intended Audience
 :: Developers Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent Classifier: Natural Language ::
 Chinese (Simplified) Classifier: Programming Language :: Python :: 3
```

## paddledet/ppdet/version.py

```diff
@@ -1,4 +1,4 @@
 # THIS FILE IS GENERATED FROM PADDLEPADDLE SETUP.PY
 #
-full_version    = '2.5.0.1'
-commit          = '29693bae09dd577a15f7480de2dd01869c90f92e'
+full_version    = '2.5.0.3'
+commit          = '2536c8b7a112ca8a47a691bc9521fa9fcd3ee877'
```

## paddledet/ppdet/engine/callbacks.py

```diff
@@ -502,38 +502,54 @@
         self.best_ap = 0.
         self.best_schema_metric: Optional[Dict] = None
         self.training_metric = TrainMetric(metrics=[])
         self.work_dir = os.environ.get('WINDMILL_EXPERIMENT_WORK_DIR', 
                                         os.path.join(self.model.cfg.save_dir, "wwd"))
         self.run_id = os.environ.get('WINDMILL_EXPERIMENT_RUN_ID', '100')
         self.save_dir = self.model.cfg.save_dir
-        if not os.path.exists(self.save_dir):
-            os.makedirs(self.save_dir)
-        if not os.path.exists(self.work_dir):
-            os.makedirs(self.work_dir)
+        _nranks = dist.get_world_size()
+        _local_rank = dist.get_rank()
+        if _nranks < 2 or _local_rank == 0:
+            if not os.path.exists(self.work_dir):
+                os.makedirs(self.work_dir, exist_ok=True)
+            if not os.path.exists(self.save_dir):
+                os.makedirs(self.save_dir, exist_ok=True)
 
     def on_step_end(self, status):
         mode = status['mode']
         if dist.get_world_size() < 2 or dist.get_rank() == 0:
             if mode == 'train':
                 epoch_id = status['epoch_id'] if 'epoch_id' in status else 0
                 step = status['step_id'] + epoch_id * status['steps_per_epoch']
                 self.training_metric.step = step
                 self.training_metric.epoch = None
                 training_staus = status['training_staus'].get()
+                metric_file = os.path.join(self.work_dir, f'{self.run_id}.json')
                 if 'loss' in training_staus:
                     self.training_metric.metrics = []
+                    if os.path.exists(metric_file):
+                        with open(metric_file, 'r', encoding='utf-8') as f:
+                            try:
+                                fcntl.flock(f, fcntl.LOCK_EX)
+                                last_metric = json.load(f)
+                            finally:
+                                fcntl.flock(f, fcntl.LOCK_UN)
+                        self.training_metric.epoch = last_metric['epoch']
+                        for metric in last_metric['metrics']:
+                            if metric['name'] != 'Loss':
+                                self.training_metric.metrics.append(BaseTrainMetric(name=metric['name'],
+                                                                                    result=metric['result']))
                     self.training_metric.metrics.append(BaseTrainMetric(name="Loss", result=training_staus['loss']))
-                    with open(os.path.join(self.work_dir, f'{self.run_id}.json'), 'w', encoding='utf-8') as f:
+                    with open(metric_file, 'w', encoding='utf-8') as f:
                         try:
                             fcntl.flock(f, fcntl.LOCK_EX)
                             json.dump(self.training_metric.dict(), f, indent=2, ensure_ascii=False)
                         finally:
                             fcntl.flock(f, fcntl.LOCK_UN)
-                    logger.info(f"Save training loss to {self.work_dir}/{self.run_id}.json")
+                    logger.info(f"Save training loss to {self.work_dir}/{self.run_id}.json on step {step}")
     
     def on_epoch_end(self, status):
         mode = status['mode']
         if dist.get_world_size() < 2 or dist.get_rank() == 0:
             if mode == 'train':
                 epoch_id = status['epoch_id']
                 self.training_metric.epoch = epoch_id
@@ -551,26 +567,40 @@
                     if map_res[key][0] >= self.best_ap:
                         self.best_ap = map_res[key][0]
                         if curr_epoch_metric is not None:
                             self.best_schema_metric = curr_epoch_metric
                     # 训练过程中指标保存到work_dir
                     curr_train_metric = map_res["GAEA_TRACKER_METRICS"]['train_schema'] \
                                             if "GAEA_TRACKER_METRICS" in map_res else None
+                    metric_file = os.path.join(self.work_dir, f'{self.run_id}.json')
                     if curr_train_metric is not None:
                         self.training_metric.metrics = []
-                        self.training_metric.metrics.append(BaseTrainMetric(name="Loss", result=None))
+                        if os.path.exists(metric_file):
+                            with open(metric_file, 'r', encoding='utf-8') as f:
+                                try:
+                                    fcntl.flock(f, fcntl.LOCK_EX)
+                                    last_metric = json.load(f)
+                                finally:
+                                    fcntl.flock(f, fcntl.LOCK_UN)
+                            self.training_metric.step = last_metric['step']
+                            for sub_metric in last_metric['metrics']:
+                                if sub_metric['name'] == 'Loss':
+                                    self.training_metric.metrics.append(BaseTrainMetric(name=sub_metric['name'],
+                                                                                        result=sub_metric['result']))
+
                         for metric in curr_train_metric["metrics"]:
-                            self.training_metric.metrics.append(BaseTrainMetric(name=metric["name"], result=metric["result"]))
+                            self.training_metric.metrics.append(BaseTrainMetric(name=metric["name"],
+                                                                                result=metric["result"]))
                         with open(os.path.join(self.work_dir, f'{self.run_id}.json'), 'w', encoding='utf-8') as f:
                             try:
                                 fcntl.flock(f, fcntl.LOCK_EX)
                                 json.dump(self.training_metric.dict(), f, indent=2, ensure_ascii=False)
                             finally:
                                 fcntl.flock(f, fcntl.LOCK_UN)
-                        logger.info(f"Save training metric to {self.work_dir}/{self.run_id}.json")
+                        logger.info(f"Save training metric to {self.work_dir}/{self.run_id}.json on epoch {epoch_id}")
 
             elif mode == 'eval':
                 for metric in self.model._metrics:
                     map_res = metric.get_results()
                     if "GAEA_TRACKER_METRICS" in map_res:
                         self.best_schema_metric = map_res["GAEA_TRACKER_METRICS"]['schema']
                         with open(os.path.join(self.save_dir, 'metric.json'), 'w', encoding='utf-8') as f:
```

## paddledet/ppdet/metrics/coco_utils.py

```diff
@@ -29,14 +29,18 @@
     BoundingBoxLabelAveragePrecision, BoundingBoxLabelAveragePrecision, ObjectDetectionMetric, \
     BoundingBoxMeanAveragePrecision, BoundingBoxLabelMetric, BoundingBoxMeanAverageRecall, \
     BoundingBoxLabelAveragePrecisionResult, BoundingBoxLabelConfidenceMetric, BoundingBoxLabelMetricResult, Label
 from gaea_operator.metric.types.metric import ConfusionMatrixMetric, \
     ConfusionMatrixMetricResult, \
     ConfusionMatrixRow, \
     ConfusionMatrixAnnotationSpec
+from collections import defaultdict
+import copy
+from pycocotools import mask as mask_utils
+from pycocotools.coco import COCO
 from ppdet.utils.logger import setup_logger
 logger = setup_logger(__name__)
 
 
 def get_infer_results(outs, catid, bias=0):
     """
     Get result at the stage of inference.
@@ -261,47 +265,18 @@
         results_per_category.append(res_item)
         res_item_iou = [str(nm["name"]), catId, round(float(ap_iou), 4), round(float(rec_iou), 4)]
         results_per_category_iou.append(res_item_iou)
         
         metrics['PR'].append([str(nm["name"]), catId, list(precision_iou), 
             [round(i * 0.01, 2) for i in range(101)]])
 
-    if confusion_matrix:
-        from pycocotools import mask as maskUtils
-        # Compute per-category confusion matrix
-        cm = np.zeros(shape=(max(cat_ids)+1, max(cat_ids)+1), dtype=np.int32)
-        img_ids = coco_gt.getImgIds()
-        for cat_id in cat_ids:
-            for img_id in img_ids:
-                gt_ann_ids = coco_gt.getAnnIds(imgIds=[img_id], catIds=[cat_id])
-                gt = coco_gt.loadAnns(ids=gt_ann_ids)
-                iscrowd = [int(o['iscrowd']) for o in gt]
-                dt_ann_ids = coco_dt.getAnnIds(imgIds=[img_id])
-                dt = coco_dt.loadAnns(ids=dt_ann_ids)
-
-                if style == 'proposal' or style == 'bbox':
-                    gt_box = [g['bbox'] for g in gt]
-                    dt_box = [d['bbox'] for d in dt if d['score'] > score_thrs]
-                    filter_dt = [d for d in dt if d['score'] > score_thrs]
-                elif style == 'segm':
-                    gt_box = [g['segmentation'] for g in gt]
-                    dt_box = [d['segmentation'] for d in dt if d['score'] > score_thrs]
-                    filter_dt = [d for d in dt if d['score'] > score_thrs]
-                else:
-                    raise Exception('iouType not supported')
-                ious = maskUtils.iou(dt_box, gt_box, iscrowd)  # dt_n x gt_n
-                if len(ious) == 0:
-                    continue
-                match_nums = np.sum((np.array(ious) > iou_thrs), axis=1, dtype=np.int32)
-                # print("image_id: {}, cat_id: {}, gt_num: {}, filter_dt_num: {}, match_nums: {}".format(
-                #     img_id, cat_id, len(gt), len(filter_dt), match_nums))
-                for k, d in enumerate(filter_dt):
-                    cm[cat_id, d['category_id']] += match_nums[k]
-        print("Confusion Matrix is: \n {}".format(cm))
-        metrics['ConfusionMatrix'] = cm
+    # if confusion_matrix:
+    cm, cat_id2index = compute_confusion_matrix(coco_gt, coco_dt, score_thrs, iou_thrs)
+    print("Confusion Matrix is: \n {}".format(cm))
+    metrics['ConfusionMatrix'] = cm
     
     bbox_stats = coco_eval.stats
     # 总平均指标
     metrics['mAP'] = bbox_stats[0]
     metrics['mAR'] = bbox_stats[8]
     # 某一IOU阈值下的平均指标
     per_cat_ap_iou = np.array([res_item_iou[2] for res_item_iou in results_per_category_iou], dtype=float)
@@ -342,15 +317,16 @@
     PR_curve = BoundingBoxLabelMetric(name="boundingBoxLabelMetric",
                 displayName= "P-R曲线",
                 result=[])
 
     # ConfusionMatrix
     confusion_matrix = ConfusionMatrixMetric(name="confusionMatrix",
                         displayName="混淆矩阵", 
-                        result=ConfusionMatrixMetricResult(annotationSpecs=[], rows=[]))
+                        result=ConfusionMatrixMetricResult(annotationSpecs=[], rows=[],
+                                lowerBound=cm.min(), upperBound=cm.max()))
 
     for i, res_cat_item in enumerate(results_per_category):
   
         bbox_cat_ap.result.append(BoundingBoxLabelAveragePrecisionResult(
                                     labelName=res_cat_item[0],   
                                     averagePrecision=res_cat_item[2]))
         confidence_metrics = []
@@ -361,21 +337,27 @@
         PR_curve.result.append(BoundingBoxLabelMetricResult(
                                 labelName=res_cat_item[0],
                                 iouThreshold=iou_thrs,
                                 averagePrecision=results_per_category_iou[i][2],
                                 confidenceMetrics=confidence_metrics))
 
         cat_id = int(res_cat_item[1])
+        ind = cat_id2index[cat_id]
         confusion_matrix.result.annotationSpecs.append(ConfusionMatrixAnnotationSpec(
                                                         labelName=res_cat_item[0], id=cat_id))
         confusion_matrix.result.rows.append(ConfusionMatrixRow(
-                                            row=metrics['ConfusionMatrix'][cat_id].tolist()))
+                                            row=metrics['ConfusionMatrix'][ind].tolist()))
 
         cat_name = res_cat_item[0]
         schema_metric.labels.append(Label(name=cat_name, id=cat_id))
+    # 将最后一行加入到混淆矩阵中
+    confusion_matrix.result.rows.append(ConfusionMatrixRow(
+                                        row=metrics['ConfusionMatrix'][-1].tolist()))
+    confusion_matrix.result.annotationSpecs.append(ConfusionMatrixAnnotationSpec(
+                                                    labelName="背景图", id=max(cat_ids)+1))
 
     schema_metric.metrics.append(PR_curve)
     schema_metric.metrics.append(bbox_mean_ap)
     schema_metric.metrics.append(bbox_mean_ar)
     schema_metric.metrics.append(bbox_cat_ap)
     schema_metric.metrics.append(confusion_matrix)
     metrics['schema'] = schema_metric.dict()
@@ -400,7 +382,105 @@
     coco_eval_style = ['proposal', 'bbox', 'segm']
     for i, v_json in enumerate(json_file_list):
         if os.path.exists(v_json):
             # cocoapi_eval(v_json, coco_eval_style[i], anno_file=anno_file)
             cocoapi_detail_eval(v_json, coco_eval_style[i], anno_file=anno_file, confusion_matrix=True)
         else:
             logger.info("{} not exists!".format(v_json))
+
+
+def compute_confusion_matrix(coco_gt: COCO, coco_dt: COCO, conf_threshold: float = 0, iou_threshold: float = 0.5):
+    """
+    compute confusion matrix for each class.
+    Args:
+        coco_gt (pycocotools COCO): ground truth annotations in COCO format.
+        coco_dt (pycocotools COCO): detected results in COCO format.
+    Returns:
+        confusion_matrix (list[np.ndarray]): confusion matrix of each class.
+    """
+    groundths = coco_gt.loadAnns(coco_gt.getAnnIds())
+    predictions = coco_dt.loadAnns(coco_dt.getAnnIds())
+    labels = coco_gt.getCatIds()
+    num_classes = len(labels)
+    label_id2index = {label: index for index, label in enumerate(labels)}
+    img_ids = set()
+    _dts = defaultdict(list)
+    _gts = defaultdict(list)
+
+    gts = copy.deepcopy(groundths)
+    for gt in gts:
+        if gt["image_id"] not in img_ids:
+            img_ids.add(gt["image_id"])
+        if 'bbox' in gt:
+            _gts[(gt['image_id'])].append(gt)
+
+    for pred in predictions:
+        if pred["image_id"] not in img_ids:
+            img_ids.add(pred["image_id"])
+        _dts[(pred["image_id"])].append(pred)
+
+    confusion_matrix = np.zeros(shape=(num_classes+1, num_classes+1), dtype=np.int64)
+    for img_id in img_ids:
+        gt = _gts[img_id]
+        dt = _dts[img_id]
+        dt = [d for d in dt if d['score'] > conf_threshold]
+
+        if len(gt) == 0 and len(dt) == 0:
+            confusion_matrix[num_classes, num_classes] += 1
+        elif len(gt) == 0 and len(dt) > 0:
+            for d in dt:
+                confusion_matrix[num_classes, label_id2index[d['category_id']]] += 1
+        elif len(gt) > 0 and len(dt) == 0:
+            for g in gt:
+                confusion_matrix[label_id2index[g['category_id']], num_classes] += 1
+        else:
+            gt_box = [g['bbox'] for g in gt]
+            dt_box = [d['bbox'] for d in dt]
+
+            iscrowd = [int(o['iscrowd']) if 'iscrowd' in o else 0 for o in gt]
+            ious = mask_utils.iou(dt_box, gt_box, iscrowd)
+
+            gtind = np.argsort([g['ignore'] if 'ignore' in g else 0 for g in gt], kind='mergesort')
+            gt = [gt[i] for i in gtind]
+            dtind = np.argsort([-d['score'] for d in dt], kind='mergesort')
+            dt = [dt[i] for i in dtind]
+
+            iscrowd = [int(o['iscrowd']) if 'iscrowd' in o else 0 for o in gt]
+            gtIg = np.array([g['ignore'] if 'ignore' in g else 0 for g in gt])
+            gt_matched_index = np.ones(len(gt)) * -1
+            for dind, d in enumerate(dt):
+                m = -1
+                label_m = -1
+                for gind, g in enumerate(gt):
+                    if gt_matched_index[gind] > 0 and not iscrowd[gind]:
+                        continue
+                    # if dt matched to reg gt, and on ignore gt, stop
+                    # 如果之前已经匹配上了一个非ignore的GT，并且当前的GT是ignore的，则跳过
+                    # 匹配的情况有两种可能，类别相同(label_m不为-1)，或者类别不同
+                    if m > -1 and gtIg[m] == 0 and gtIg[gind] == 1:
+                        break
+                    # continue to next gt unless better match made
+                    if ious[dind, gind] < iou_threshold:
+                        continue
+                    m = gind
+                    if d["category_id"] == g["category_id"]:
+                        label_m = gind
+                if label_m != -1:
+                    gt_matched_index[label_m] = label_m
+                    index = label_id2index[g["category_id"]]
+                    confusion_matrix[index, index] += 1
+                if m != -1 and label_m < 0:
+                    gt_matched_index[m] = m
+                    g_index = label_id2index[g["category_id"]]
+                    d_index = label_id2index[d["category_id"]]
+                    confusion_matrix[g_index, d_index] += 1
+                if m == -1:
+                    d_index = label_id2index[d["category_id"]]
+                    confusion_matrix[num_classes, d_index] += 1
+
+            gt_matched_index = set(np.asarray(gt_matched_index, dtype=np.int32))
+            for gind, g in enumerate(gt):
+                if gind not in gt_matched_index:
+                    g_index = label_id2index[g["category_id"]]
+                    confusion_matrix[g_index, num_classes] += 1
+
+    return confusion_matrix, label_id2index
```

## Comparing `gaea_paddledet-2.5.0.1.dist-info/LICENSE` & `gaea_paddledet-2.5.0.3.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `gaea_paddledet-2.5.0.1.dist-info/METADATA` & `gaea_paddledet-2.5.0.3.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: gaea-paddledet
-Version: 2.5.0.1
+Version: 2.5.0.3
 Summary: Object detection and instance segmentation toolkit based on PaddlePaddle
 Home-page: https://github.com/PaddlePaddle/PaddleDetection
 Download-URL: https://github.com/PaddlePaddle/PaddleDetection.git
 Author: PaddlePaddle
 License: Apache License 2.0
 Keywords: ppdet paddle ppyolo
 Classifier: Intended Audience :: Developers
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: gaea-paddledet Version: 2.5.0.1 Summary: Object
+Metadata-Version: 2.1 Name: gaea-paddledet Version: 2.5.0.3 Summary: Object
 detection and instance segmentation toolkit based on PaddlePaddle Home-page:
 https://github.com/PaddlePaddle/PaddleDetection Download-URL: https://
 github.com/PaddlePaddle/PaddleDetection.git Author: PaddlePaddle License:
 Apache License 2.0 Keywords: ppdet paddle ppyolo Classifier: Intended Audience
 :: Developers Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent Classifier: Natural Language ::
 Chinese (Simplified) Classifier: Programming Language :: Python :: 3
```

## Comparing `gaea_paddledet-2.5.0.1.dist-info/RECORD` & `gaea_paddledet-2.5.0.3.dist-info/RECORD`

 * *Files 1% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 paddledet/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
 paddledet/README.md,sha256=YgfJxhG7Hf3FGH4GuCztdH3rhaunErqFcYSSMjNKrtg,41596
-paddledet/gaea_paddledet.egg-info/PKG-INFO,sha256=UQQWYNHcv16MAunst2ESzkr-QcrhL1Pa6Zis0dPlNKQ,42889
+paddledet/gaea_paddledet.egg-info/PKG-INFO,sha256=yTNIGwu6fAIOm8zjaHHtmlZIcLbJDrvyjLg9dWGnC6g,42889
 paddledet/gaea_paddledet.egg-info/SOURCES.txt,sha256=vY0dj9MjjqnOjrQEz3WIz4HZ9aHQIgBJCP2qc9bb7Eo,9045
 paddledet/gaea_paddledet.egg-info/dependency_links.txt,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 paddledet/gaea_paddledet.egg-info/requires.txt,sha256=gImDFBHfCGhVCFYPrADJxd1aetUAXEXkoqKerYEfzwg,158
 paddledet/gaea_paddledet.egg-info/top_level.txt,sha256=PvV2jcAw5cfnuDXmEtE7JReExb1OAT_wlcgg5zAVS_g,10
 paddledet/ppdet/__init__.py,sha256=4yDWwPxOR5SQaDjL573DNRVEB_P0P-0m3aS0hlSzIYQ,1039
-paddledet/ppdet/version.py,sha256=tMscVHpJ-2jzZT4lobE3hWvOc5WKXCu13845v-Umsdo,143
+paddledet/ppdet/version.py,sha256=H2thLUN7jwD_bGgeFIFbD_-_InsMguQ6Z89VJpJNqbc,143
 paddledet/ppdet/core/__init__.py,sha256=70ZGqjncpsAD0eZNNaZGvQ5JuOYhLpRQ4Nb6CwCEOL8,634
 paddledet/ppdet/core/workspace.py,sha256=gG72ofRa2_Hoi1SsaDtPv09vyxxQ5Wy8M_WlgV5ckfA,9214
 paddledet/ppdet/core/config/__init__.py,sha256=Wg35JINTwCCrXtg-jyvUmem1FTYSYK5aXrhWRu-nATY,610
 paddledet/ppdet/core/config/schema.py,sha256=U7MgXII8iwvB9NAdK70rSeldPsX4-lM8jmtNlHD38k0,8066
 paddledet/ppdet/core/config/yaml_helpers.py,sha256=syv3GrD5hWOlY4QT7EVRrPSxu4yfuwtFjaY_0-O1mBs,3571
 paddledet/ppdet/data/__init__.py,sha256=Boarjkc45YgkwdN-oLNF64rTiCWTXNXCbzimDnJgVmY,778
 paddledet/ppdet/data/reader.py,sha256=hmPKAG7qd76puG8FgEknSFL_1E_UO4aIEyCfTZsgU74,10576
@@ -36,21 +36,21 @@
 paddledet/ppdet/data/transform/gridmask_utils.py,sha256=brQa-PhPgASPQworA0paKYRjzwrqnl623ZYY9qMGHjk,2903
 paddledet/ppdet/data/transform/keypoint_operators.py,sha256=puGH7DlM8Hog0p9LfwOx0qi9_9Ltf8gDrpd74PYuUro,32641
 paddledet/ppdet/data/transform/mot_operators.py,sha256=b8Zg-szDzs54jm8GQHxMs570OoZqNIl5ubWwvH8C0y0,25831
 paddledet/ppdet/data/transform/op_helper.py,sha256=iloqcZLBdPz4sx5NIre6xlfmFb-S212IIOPYON8Mbws,17228
 paddledet/ppdet/data/transform/operators.py,sha256=_4jhbQaFWrpELW-0hM8TSoCHTuzIDUUBnAKUJrHIaro,168485
 paddledet/ppdet/data/transform/rotated_operators.py,sha256=9-MXZauJI_K4c-TGiz1fRUa_yNSQKag6ua8t3xHMAGI,19732
 paddledet/ppdet/engine/__init__.py,sha256=-uFuHuN6UgZ6XfvQ8877iok_heygt7z6pnoNJFctRsw,938
-paddledet/ppdet/engine/callbacks.py,sha256=oh2eBuQbIGZw-KGQHes1xOL325j5Xrx2J_VQUKQKn0s,25888
+paddledet/ppdet/engine/callbacks.py,sha256=EtdTLEjyo2kdOeMiqkGp4DyN_GDZ3buLntnOLRagwCM,27836
 paddledet/ppdet/engine/env.py,sha256=Al1H9ipkQH9LWkDZn_pLwpxY_OjBiArZSqAwt4BOdPc,1558
 paddledet/ppdet/engine/export_utils.py,sha256=OV_5hMkvgizFyXmJ-6WE6V9OTZYbpDwUU_RWlHdQuhk,6829
 paddledet/ppdet/engine/tracker.py,sha256=EioAeyzoQL1v_Pc9gCQ5m9lMDxmIP3azc_-XMxKtxlI,26462
 paddledet/ppdet/engine/trainer.py,sha256=Y0aFSfy-ur6W6Nsd_XaC_LpfTR8zvMAkVpeey2eTDQo,55251
 paddledet/ppdet/metrics/__init__.py,sha256=JF4Q-E45ImH8oeCA5Yuyrp7OF-z1DY83UEpBPKaIYQY,983
-paddledet/ppdet/metrics/coco_utils.py,sha256=u0YYSys_sYeunJoeZ3pS6WroBg5_ELDbk0N7AH3Y_nY,17546
+paddledet/ppdet/metrics/coco_utils.py,sha256=jcp-ZzzS-5ke_beI3FzKTZr96HjM2TFmvBXwESUb3mk,20865
 paddledet/ppdet/metrics/json_results.py,sha256=_Dy4C9UvqUuO5DRLA_c0naH9NyAVNytU4w1FgwuM3a0,5545
 paddledet/ppdet/metrics/keypoint_metrics.py,sha256=gk-jhnpJVGGY9pyqdFe8WNczabu_O8VXnE-RNCXybNk,15446
 paddledet/ppdet/metrics/map_utils.py,sha256=OZuW3z9zYBS3GxglC72Ozjgl79386Qv36fsJXKmhTn8,15486
 paddledet/ppdet/metrics/mcmot_metrics.py,sha256=RETuD47QZB4dJmR74-blgdVJWlwn1c9guKQNWkkdgQk,16391
 paddledet/ppdet/metrics/metrics.py,sha256=WtTjyCxpWgD1RW6tuTZYrzfbaMQA6aOVtd3WfePQKqM,19675
 paddledet/ppdet/metrics/mot_metrics.py,sha256=1PKs2r3sKfYxOOX5BSUm6E-xi5gbV067ndOf3JwDz1g,52006
 paddledet/ppdet/metrics/munkres.py,sha256=S1dY-eN7BMap7fo97MRqI3tnLnF5PKl3HyINMpYxa_4,13416
@@ -258,12 +258,12 @@
 paddledet/tools/infer_mot.py,sha256=4NQxdj17CH-JfMRYlVsJqTyBr2817DDPp5K4Heo5oyo,4236
 paddledet/tools/infer_pair.py,sha256=Y_RyKwjeqr_9Lkohk-48d-9c8h2LAMVYcC1I-8nyQuM,8400
 paddledet/tools/post_quant.py,sha256=5AfY4azTby0V2AM33kig0LanUqO8KW3qx4f73lxkBas,2708
 paddledet/tools/slice_image.py,sha256=4RMHHuTsQRgfPOSbGVRpfWqxpVIcMi2jbEYhKq6PKdQ,2021
 paddledet/tools/sniper_params_stats.py,sha256=Q4SVm-YPPbPpQR6FnQuv9a4Qejw2jufIpDVCdf4sgVo,6417
 paddledet/tools/train.py,sha256=rWSHWPzL-9joreIy7st-C8H38JPtxrDwcpRCEHqzEKc,4977
 paddledet/tools/x2coco.py,sha256=wgcsYn2GsAzbJI79UFoSRnBEr-ObknY1PA3rX5Y5Hgw,20116
-gaea_paddledet-2.5.0.1.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-gaea_paddledet-2.5.0.1.dist-info/METADATA,sha256=W7RtW-47idmunv99YxLshUIoq-wTu0wl5h38wKftMSM,42892
-gaea_paddledet-2.5.0.1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-gaea_paddledet-2.5.0.1.dist-info/top_level.txt,sha256=PvV2jcAw5cfnuDXmEtE7JReExb1OAT_wlcgg5zAVS_g,10
-gaea_paddledet-2.5.0.1.dist-info/RECORD,,
+gaea_paddledet-2.5.0.3.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+gaea_paddledet-2.5.0.3.dist-info/METADATA,sha256=JaaQ6twsYQLMbTvnvPgwwLvd4Wxhvyl2IHUDUlmMtD4,42892
+gaea_paddledet-2.5.0.3.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+gaea_paddledet-2.5.0.3.dist-info/top_level.txt,sha256=PvV2jcAw5cfnuDXmEtE7JReExb1OAT_wlcgg5zAVS_g,10
+gaea_paddledet-2.5.0.3.dist-info/RECORD,,
```

