# Comparing `tmp/gym_jiminy-1.8.3-py3-none-any.whl.zip` & `tmp/gym_jiminy-1.8.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,32 +1,37 @@
-Zip file size: 100971 bytes, number of entries: 30
--rw-r--r--  2.0 unx      230 b- defN 24-Mar-07 12:04 gym_jiminy/common/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-07 12:04 gym_jiminy/common/py.typed
--rw-r--r--  2.0 unx     1312 b- defN 24-Mar-07 12:04 gym_jiminy/common/bases/__init__.py
--rw-r--r--  2.0 unx    10474 b- defN 24-Mar-07 12:04 gym_jiminy/common/bases/blocks.py
--rw-r--r--  2.0 unx    13795 b- defN 24-Mar-07 12:04 gym_jiminy/common/bases/interfaces.py
--rw-r--r--  2.0 unx    40133 b- defN 24-Mar-07 12:04 gym_jiminy/common/bases/pipeline.py
--rw-r--r--  2.0 unx      357 b- defN 24-Mar-07 12:04 gym_jiminy/common/blocks/__init__.py
--rw-r--r--  2.0 unx    37300 b- defN 24-Mar-07 12:04 gym_jiminy/common/blocks/deformation_estimator.py
--rw-r--r--  2.0 unx    17212 b- defN 24-Mar-07 12:04 gym_jiminy/common/blocks/mahony_filter.py
--rw-r--r--  2.0 unx     9877 b- defN 24-Mar-07 12:04 gym_jiminy/common/blocks/motor_safety_limit.py
--rw-r--r--  2.0 unx    20573 b- defN 24-Mar-07 12:04 gym_jiminy/common/blocks/proportional_derivative_controller.py
--rw-r--r--  2.0 unx      178 b- defN 24-Mar-07 12:04 gym_jiminy/common/envs/__init__.py
--rw-r--r--  2.0 unx    69409 b- defN 24-Mar-07 12:04 gym_jiminy/common/envs/generic.py
--rw-r--r--  2.0 unx    18049 b- defN 24-Mar-07 12:04 gym_jiminy/common/envs/locomotion.py
--rw-r--r--  2.0 unx      118 b- defN 24-Mar-07 12:04 gym_jiminy/common/envs/internal/__init__.py
--rw-r--r--  2.0 unx     9350 b- defN 24-Mar-07 12:04 gym_jiminy/common/envs/internal/play.py
--rw-r--r--  2.0 unx     2194 b- defN 24-Mar-07 12:04 gym_jiminy/common/utils/__init__.py
--rw-r--r--  2.0 unx    19135 b- defN 24-Mar-07 12:04 gym_jiminy/common/utils/math.py
--rw-r--r--  2.0 unx     8954 b- defN 24-Mar-07 12:04 gym_jiminy/common/utils/misc.py
--rw-r--r--  2.0 unx    10189 b- defN 24-Mar-07 12:04 gym_jiminy/common/utils/pipeline.py
--rw-r--r--  2.0 unx    53495 b- defN 24-Mar-07 12:04 gym_jiminy/common/utils/spaces.py
--rw-r--r--  2.0 unx      477 b- defN 24-Mar-07 12:04 gym_jiminy/common/wrappers/__init__.py
--rw-r--r--  2.0 unx     6115 b- defN 24-Mar-07 12:04 gym_jiminy/common/wrappers/flatten.py
--rw-r--r--  2.0 unx     4039 b- defN 24-Mar-07 12:04 gym_jiminy/common/wrappers/normalize.py
--rw-r--r--  2.0 unx     3747 b- defN 24-Mar-07 12:04 gym_jiminy/common/wrappers/observation_filter.py
--rw-r--r--  2.0 unx    10609 b- defN 24-Mar-07 12:04 gym_jiminy/common/wrappers/observation_stack.py
--rw-r--r--  2.0 unx     1606 b- defN 24-Mar-07 12:04 gym_jiminy-1.8.3.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Mar-07 12:04 gym_jiminy-1.8.3.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 24-Mar-07 12:04 gym_jiminy-1.8.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2784 b- defN 24-Mar-07 12:04 gym_jiminy-1.8.3.dist-info/RECORD
-30 files, 371814 bytes uncompressed, 96413 bytes compressed:  74.1%
+Zip file size: 116825 bytes, number of entries: 35
+-rw-r--r--  2.0 unx      230 b- defN 24-Apr-19 21:51 gym_jiminy/common/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-19 21:51 gym_jiminy/common/py.typed
+-rw-r--r--  2.0 unx     1495 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/__init__.py
+-rw-r--r--  2.0 unx    10466 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/blocks.py
+-rw-r--r--  2.0 unx    14577 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/interfaces.py
+-rw-r--r--  2.0 unx    40682 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/pipeline.py
+-rw-r--r--  2.0 unx    18035 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/quantity.py
+-rw-r--r--  2.0 unx      385 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/__init__.py
+-rw-r--r--  2.0 unx    37430 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/deformation_estimator.py
+-rw-r--r--  2.0 unx    17212 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/mahony_filter.py
+-rw-r--r--  2.0 unx    10089 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/motor_safety_limit.py
+-rw-r--r--  2.0 unx    26392 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/proportional_derivative_controller.py
+-rw-r--r--  2.0 unx      178 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/__init__.py
+-rw-r--r--  2.0 unx    69411 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/generic.py
+-rw-r--r--  2.0 unx    18748 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/locomotion.py
+-rw-r--r--  2.0 unx      118 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/internal/__init__.py
+-rw-r--r--  2.0 unx     9350 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/internal/play.py
+-rw-r--r--  2.0 unx      367 b- defN 24-Apr-19 21:51 gym_jiminy/common/quantities/__init__.py
+-rw-r--r--  2.0 unx    11600 b- defN 24-Apr-19 21:51 gym_jiminy/common/quantities/generic.py
+-rw-r--r--  2.0 unx     4496 b- defN 24-Apr-19 21:51 gym_jiminy/common/quantities/locomotion.py
+-rw-r--r--  2.0 unx     7024 b- defN 24-Apr-19 21:51 gym_jiminy/common/quantities/manager.py
+-rw-r--r--  2.0 unx     2263 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/__init__.py
+-rw-r--r--  2.0 unx    21000 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/math.py
+-rw-r--r--  2.0 unx     8972 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/misc.py
+-rw-r--r--  2.0 unx    10189 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/pipeline.py
+-rw-r--r--  2.0 unx    53495 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/spaces.py
+-rw-r--r--  2.0 unx      477 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/__init__.py
+-rw-r--r--  2.0 unx     6115 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/flatten.py
+-rw-r--r--  2.0 unx     4039 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/normalize.py
+-rw-r--r--  2.0 unx     3747 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/observation_filter.py
+-rw-r--r--  2.0 unx    10626 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/observation_stack.py
+-rw-r--r--  2.0 unx     1605 b- defN 24-Apr-19 21:52 gym_jiminy-1.8.4.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-19 21:52 gym_jiminy-1.8.4.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 24-Apr-19 21:52 gym_jiminy-1.8.4.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3266 b- defN 24-Apr-19 21:52 gym_jiminy-1.8.4.dist-info/RECORD
+35 files, 424182 bytes uncompressed, 111497 bytes compressed:  73.7%
```

## zipnote {}

```diff
@@ -12,14 +12,17 @@
 
 Filename: gym_jiminy/common/bases/interfaces.py
 Comment: 
 
 Filename: gym_jiminy/common/bases/pipeline.py
 Comment: 
 
+Filename: gym_jiminy/common/bases/quantity.py
+Comment: 
+
 Filename: gym_jiminy/common/blocks/__init__.py
 Comment: 
 
 Filename: gym_jiminy/common/blocks/deformation_estimator.py
 Comment: 
 
 Filename: gym_jiminy/common/blocks/mahony_filter.py
@@ -42,14 +45,26 @@
 
 Filename: gym_jiminy/common/envs/internal/__init__.py
 Comment: 
 
 Filename: gym_jiminy/common/envs/internal/play.py
 Comment: 
 
+Filename: gym_jiminy/common/quantities/__init__.py
+Comment: 
+
+Filename: gym_jiminy/common/quantities/generic.py
+Comment: 
+
+Filename: gym_jiminy/common/quantities/locomotion.py
+Comment: 
+
+Filename: gym_jiminy/common/quantities/manager.py
+Comment: 
+
 Filename: gym_jiminy/common/utils/__init__.py
 Comment: 
 
 Filename: gym_jiminy/common/utils/math.py
 Comment: 
 
 Filename: gym_jiminy/common/utils/misc.py
@@ -72,20 +87,20 @@
 
 Filename: gym_jiminy/common/wrappers/observation_filter.py
 Comment: 
 
 Filename: gym_jiminy/common/wrappers/observation_stack.py
 Comment: 
 
-Filename: gym_jiminy-1.8.3.dist-info/METADATA
+Filename: gym_jiminy-1.8.4.dist-info/METADATA
 Comment: 
 
-Filename: gym_jiminy-1.8.3.dist-info/WHEEL
+Filename: gym_jiminy-1.8.4.dist-info/WHEEL
 Comment: 
 
-Filename: gym_jiminy-1.8.3.dist-info/top_level.txt
+Filename: gym_jiminy-1.8.4.dist-info/top_level.txt
 Comment: 
 
-Filename: gym_jiminy-1.8.3.dist-info/RECORD
+Filename: gym_jiminy-1.8.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## gym_jiminy/common/bases/__init__.py

```diff
@@ -1,9 +1,12 @@
 # pylint: disable=missing-module-docstring
 
+from .quantity import (SharedCache,
+                       QuantityCreator,
+                       AbstractQuantity)
 from .interfaces import (DT_EPS,
                          ObsT,
                          ActT,
                          BaseObsT,
                          BaseActT,
                          InfoType,
                          SensorMeasurementStackMap,
@@ -19,14 +22,17 @@
                        BaseTransformObservation,
                        BaseTransformAction,
                        ObservedJiminyEnv,
                        ControlledJiminyEnv)
 
 
 __all__ = [
+    'SharedCache',
+    'QuantityCreator',
+    'AbstractQuantity',
     'DT_EPS',
     'ObsT',
     'ActT',
     'BaseObsT',
     'BaseActT',
     'BlockStateT',
     'InfoType',
```

## gym_jiminy/common/bases/blocks.py

```diff
@@ -166,15 +166,15 @@
 
         # Make sure the controller period is lower than environment timestep
         assert self.observe_dt <= self.env.step_dt, (
             "The observer update period must be lower than or equal to the "
             "environment simulation timestep.")
 
     @property
-    def get_fieldnames(self) -> FieldNested:
+    def fieldnames(self) -> FieldNested:
         """Get mapping between each scalar element of the observation space of
         the observer block and the associated fieldname for logging.
 
         It is expected to return an object with the same structure than the
         observation space, but having lists of string as leaves. Generic
         fieldnames are used by default.
         """
@@ -230,15 +230,15 @@
 
         # Make sure the controller period is lower than environment timestep
         assert self.control_dt <= self.env.step_dt, (
             "The controller update period must be lower than or equal to the "
             "environment simulation timestep.")
 
     @property
-    def get_fieldnames(self) -> FieldNested:
+    def fieldnames(self) -> FieldNested:
         """Get mapping between each scalar element of the action space of
         the controller block and the associated fieldname for logging.
 
         It is expected to return an object with the same structure than the
         action space, but having lists of string as leaves. Generic fieldnames
         are used by default.
         """
```

## gym_jiminy/common/bases/interfaces.py

```diff
@@ -1,26 +1,27 @@
 """Controller and observer abstract interfaces from reinforcement learning,
 specifically design for Jiminy engine, and defined as mixin classes. Any
 observer/controller block must inherit and implement those interfaces.
 """
 from abc import abstractmethod, ABC
 from collections import OrderedDict
-from typing import Dict, Any, TypeVar, Generic, no_type_check
+from typing import Dict, Any, TypeVar, Generic, no_type_check, TYPE_CHECKING
 from typing_extensions import TypeAlias
 
 import numpy as np
 import numpy.typing as npt
 import gymnasium as gym
 
 import jiminy_py.core as jiminy
-from jiminy_py.core import array_copyto  # pylint: disable=no-name-in-module
 from jiminy_py.simulator import Simulator
 from jiminy_py.viewer.viewer import is_display_available
 
 from ..utils import DataNested
+if TYPE_CHECKING:
+    from ..quantities import QuantityManager
 
 
 # Temporal resolution of simulator steps
 DT_EPS: float = 1e-6  # 'SIMULATION_MIN_TIMESTEP'
 
 
 ObsT = TypeVar('ObsT', bound=DataNested)
@@ -105,28 +106,28 @@
 
     @abstractmethod
     def _initialize_action_space(self) -> None:
         """Configure the action space.
         """
 
     @abstractmethod
-    def compute_command(self, action: ActT) -> BaseActT:
+    def compute_command(self, action: ActT, command: BaseActT) -> None:
         """Compute the command to send to the subsequent block, based on the
         action and current observation of the environment.
 
         .. note::
             By design, the observation of the environment has been refreshed
             automatically prior to calling this method.
 
         :param action: High-level target to achieve by means of the command.
-
-        :returns: Command to send to the subsequent block. It corresponds to
-                  the target features of another lower-level controller if any,
-                  the target motors efforts of the environment to ultimately
-                  control otherwise.
+        :param command: Command to send to the subsequent block. It corresponds
+                        to the target features of another lower-level
+                        controller if any, the target motors efforts of the
+                        environment to ultimately control otherwise. It must be
+                        updated in-place.
         """
 
     def compute_reward(self,
                        terminated: bool,  # pylint: disable=unused-argument
                        truncated: bool,  # pylint: disable=unused-argument
                        info: InfoType  # pylint: disable=unused-argument
                        ) -> float:
@@ -180,14 +181,16 @@
     simulator: Simulator
     robot: jiminy.Robot
     stepper_state: jiminy.StepperState
     robot_state: jiminy.RobotState
     sensor_measurements: SensorMeasurementStackMap
     is_simulation_running: npt.NDArray[np.bool_]
 
+    quantities: "QuantityManager"
+
     action: ActT
 
     def __init__(self, *args: Any, **kwargs: Any) -> None:
         # Track whether the observation has been refreshed manually since the
         # last called '_controller_handle'. It typically happens at the end of
         # every simulation step to return an observation that is consistent
         # with the updated state of the agent.
@@ -230,19 +233,16 @@
                          ) -> None:
         """Thin wrapper around user-specified `refresh_observation` method.
 
         .. warning::
             This method is not supposed to be called manually nor overloaded.
 
         :param t: Current simulation time.
-        :param q: Current actual configuration of the robot. Note that it is
-                  not the one of the theoretical model even if
-                  'use_theoretical_model' is enabled for the backend Python
-                  `Simulator`.
-        :param v: Current actual velocity vector.
+        :param q: Current extended configuration vector of the robot.
+        :param v: Current extended velocity vector of the robot.
         :param sensor_measurements: Current sensor data.
         """
         # Refresh the observation if not already done but only if a simulation
         # is already running. It would be pointless to refresh the observation
         # at this point since the controller will be called multiple times at
         # start. Besides, it would defeat the purpose `_initialize_buffers`,
         # that is supposed to be executed before `refresh_observation` is being
@@ -268,41 +268,55 @@
                            q: np.ndarray,
                            v: np.ndarray,
                            sensor_measurements: jiminy.SensorMeasurementTree,
                            command: np.ndarray) -> None:
         """Thin wrapper around user-specified `refresh_observation` and
         `compute_command` methods.
 
+        .. note::
+            The internal cache of managed quantities is cleared right away
+            systematically, before anything else.
+
         .. warning::
             This method is not supposed to be called manually nor overloaded.
             It will be used by the base environment to instantiate a
             `jiminy.FunctionalController` responsible for both refreshing
             observations and compute commands of all the way through a given
             pipeline in the correct order of the blocks to finally sends
             command motor torques directly to the robot.
 
         :param t: Current simulation time.
-        :param q: Current actual configuration of the robot. Note that it is
-                  not the one of the theoretical model even if
-                  'use_theoretical_model' is enabled for the backend Python
-                  `Simulator`.
-        :param v: Current actual velocity vector.
+        :param q: Current extended configuration vector of the robot.
+        :param v: Current actual velocity vector of the robot.
         :param sensor_measurements: Current sensor measurements.
         :param command: Output argument corresponding to motors torques to
                         apply on the robot. It must be updated by reference
                         using `[:]` or `np.copyto`.
 
         :returns: Motors torques to apply on the robot.
         """
+        # Reset the quantity manager.
+        # In principle, the internal cache of quantities should be cleared not
+        # each time the state of the robot and/or its derivative changes. This
+        # is hard to do because there is no way to detect this specifically at
+        # the time being. However, `_controller_handle` is never called twice
+        # in the exact same state by the engine, so resetting quantities at the
+        # beginning of the method should cover most cases. Yet, quantities
+        # cannot be used reliably in the definition of profile forces because
+        # they are always updated before the controller gets called, no matter
+        # if either one or the other is time-continuous. Hacking the internal
+        # dynamics to clear quantities does not address this issue either.
+        self.quantities.clear()
+
         # Refresh the observation
         self._observer_handle(t, q, v, sensor_measurements)
 
         # No need to check for breakpoints of the controller because it already
         # matches the update period by design.
-        array_copyto(command, self.compute_command(self.action))
+        self.compute_command(self.action, command)
 
         # Always consider that the observation must be refreshed after calling
         # '_controller_handle' as it is never called more often than necessary.
         self.__is_observation_refreshed = False
 
     @property
     def unwrapped(self) -> "InterfaceJiminyEnv":
```

## gym_jiminy/common/bases/pipeline.py

```diff
@@ -10,18 +10,17 @@
   eventually already wrapped, so that it appears as a black-box environment.
 """
 import math
 from weakref import ref
 from copy import deepcopy
 from abc import abstractmethod
 from collections import OrderedDict
-from itertools import chain
 from typing import (
-    Dict, Any, List, Optional, Tuple, Union, Iterable, Generic, TypeVar,
-    SupportsFloat, Callable, cast)
+    Dict, Any, List, Optional, Tuple, Union, Generic, TypeVar, SupportsFloat,
+    Callable, cast)
 
 import numpy as np
 import gymnasium as gym
 from gymnasium.core import RenderFrame
 from gymnasium.envs.registration import EnvSpec
 
 from .interfaces import (DT_EPS,
@@ -67,14 +66,15 @@
     """
     env: InterfaceJiminyEnv[BaseObsT, BaseActT]
 
     def __init__(self,
                  env: InterfaceJiminyEnv[BaseObsT, BaseActT],
                  **kwargs: Any) -> None:
         """
+        :param env: Base or already wrapped jiminy environment.
         :param kwargs: Extra keyword arguments for multiple inheritance.
         """
         # Initialize some proxies for fast lookup
         self.simulator = env.simulator
         self.stepper_state = env.stepper_state
         self.robot = env.robot
         self.robot_state = env.robot_state
@@ -96,21 +96,21 @@
         """Convenient fallback attribute getter.
 
         It enables to get access to the attribute and methods of the wrapped
         environment directly without having to do it through `env`.
         """
         return getattr(self.__getattribute__('env'), name)
 
-    def __dir__(self) -> Iterable[str]:
+    def __dir__(self) -> List[str]:
         """Attribute lookup.
 
         It is mainly used by autocomplete feature of Ipython. It is overloaded
         to get consistent autocompletion wrt `getattr`.
         """
-        return chain(super().__dir__(), dir(self.env))
+        return [*super().__dir__(), *dir(self.env)]
 
     @property
     def spec(self) -> Optional[EnvSpec]:
         """Random number generator of the base environment.
         """
         return self.env.spec
 
@@ -393,20 +393,20 @@
                 observation['features'] = copy(base_features)
             if base_states := base_observation.get('states'):
                 assert isinstance(observation['states'], dict)
                 observation['states'] = copy(base_states)
         else:
             observation['measurement'] = base_observation
         if (state := self.observer.get_state()) is not None:
-            observation.setdefault(
-                'states', OrderedDict())[  # type: ignore[index]
-                    self.observer.name] = state
-        observation.setdefault(
-            'features', OrderedDict())[  # type: ignore[index]
-                self.observer.name] = self.observer.observation
+            states = observation.setdefault('states', OrderedDict())
+            assert isinstance(states, OrderedDict)
+            states[self.observer.name] = state
+        features = observation.setdefault('features', OrderedDict())
+        assert isinstance(features, OrderedDict)
+        features[self.observer.name] = self.observer.observation
         self.observation = cast(NestedObsT, observation)
 
         # Register the observer's internal state and feature to the telemetry
         if state is not None:
             try:
                 self.env.register_variable(  # type: ignore[attr-defined]
                     'state', state, None, self.observer.name)
@@ -443,20 +443,22 @@
         observation_space: Dict[str, gym.Space[Any]] = OrderedDict()
         base_observation_space = deepcopy(self.env.observation_space)
         if isinstance(base_observation_space, gym.spaces.Dict):
             observation_space.update(base_observation_space)
         else:
             observation_space['measurement'] = base_observation_space
         if self.observer.state_space is not None:
-            observation_space.setdefault(  # type: ignore[index]
-                'states', gym.spaces.Dict())[
-                    self.observer.name] = self.observer.state_space
-        observation_space.setdefault(  # type: ignore[index]
-            'features', gym.spaces.Dict())[
-                self.observer.name] = self.observer.observation_space
+            state_spaces = observation_space.setdefault(
+                'states', gym.spaces.Dict())
+            assert isinstance(state_spaces, gym.spaces.Dict)
+            state_spaces[self.observer.name] = self.observer.state_space
+        feature_spaces = observation_space.setdefault(
+            'features', gym.spaces.Dict())
+        assert isinstance(feature_spaces, gym.spaces.Dict)
+        feature_spaces[self.observer.name] = self.observer.observation_space
         self.observation_space = gym.spaces.Dict(observation_space)
 
     def refresh_observation(self, measurement: EngineObsType) -> None:
         """Compute high-level features based on the current wrapped
         environment's observation.
 
         It gathers the original observation from the environment with the
@@ -473,23 +475,24 @@
         # Get environment observation
         self.env.refresh_observation(measurement)
 
         # Update observed features if necessary
         if is_breakpoint(self.stepper_state.t, self.observe_dt, DT_EPS):
             self.observer.refresh_observation(self.env.observation)
 
-    def compute_command(self, action: ActT) -> np.ndarray:
+    def compute_command(self, action: ActT, command: np.ndarray) -> None:
         """Compute the motors efforts to apply on the robot.
 
         It simply forwards the command computed by the wrapped environment
         without any processing.
 
         :param action: High-level target to achieve by means of the command.
+        :param command: Lower-level command to updated in-place.
         """
-        return self.env.compute_command(action)
+        self.env.compute_command(action, command)
 
 
 class ControlledJiminyEnv(
         BasePipelineWrapper[NestedObsT, ActT, BaseObsT, BaseActT],
         Generic[NestedObsT, ActT, BaseObsT, BaseActT]):
     """Wrap a `BaseJiminyEnv` Gym environment and a single controller.
 
@@ -590,17 +593,14 @@
             elif isinstance(env_unwrapped, ControlledJiminyEnv):
                 assert block_name != env_unwrapped.controller.name
             env_unwrapped = env_unwrapped.env
 
         # Initialize base wrapper
         super().__init__(env, **kwargs)
 
-        # Define specialized operator(s) for efficiency
-        self._copyto_env_action = build_copyto(self.env.action)
-
         # Allocate action buffer
         self.action: ActT = zeros(self.action_space)
 
         # Initialize the observation
         observation: Dict[str, DataNested] = OrderedDict()
         base_observation = self.env.observation
         if isinstance(base_observation, dict):
@@ -610,21 +610,21 @@
                 observation['actions'] = copy(base_actions)
             if base_states := base_observation.get('states'):
                 assert isinstance(observation['states'], dict)
                 observation['states'] = copy(base_states)
         else:
             observation['measurement'] = base_observation
         if (state := self.controller.get_state()) is not None:
-            observation.setdefault(
-                'states', OrderedDict())[  # type: ignore[index]
-                    self.controller.name] = state
+            states = observation.setdefault('states', OrderedDict())
+            assert isinstance(states, OrderedDict)
+            states[self.controller.name] = state
         if self.augment_observation:
-            observation.setdefault(
-                'actions', OrderedDict())[  # type: ignore[index]
-                    self.controller.name] = self.action
+            actions = observation.setdefault('actions', OrderedDict())
+            assert isinstance(actions, OrderedDict)
+            actions[self.controller.name] = self.action
         self.observation = cast(NestedObsT, observation)
 
         # Register the controller's internal state and target to the telemetry
         if state is not None:
             try:
                 self.env.register_variable(  # type: ignore[attr-defined]
                     'state', state, None, self.controller.name)
@@ -667,21 +667,23 @@
         observation_space: Dict[str, gym.Space[Any]] = OrderedDict()
         base_observation_space = deepcopy(self.env.observation_space)
         if isinstance(base_observation_space, gym.spaces.Dict):
             observation_space.update(base_observation_space)
         else:
             observation_space['measurement'] = base_observation_space
         if self.controller.state_space is not None:
-            observation_space.setdefault(  # type: ignore[index]
-                'states', gym.spaces.Dict())[
-                    self.controller.name] = self.controller.state_space
+            state_spaces = observation_space.setdefault(
+                'states', gym.spaces.Dict())
+            assert isinstance(state_spaces, gym.spaces.Dict)
+            state_spaces[self.controller.name] = self.controller.state_space
         if self.augment_observation:
-            observation_space.setdefault(  # type: ignore[index]
-                'actions', gym.spaces.Dict())[
-                    self.controller.name] = self.controller.action_space
+            action_spaces = observation_space.setdefault(
+                'actions', gym.spaces.Dict())
+            assert isinstance(action_spaces, gym.spaces.Dict)
+            action_spaces[self.controller.name] = self.controller.action_space
         self.observation_space = gym.spaces.Dict(observation_space)
 
     def refresh_observation(self, measurement: EngineObsType) -> None:
         """Compute the unified observation based on the current wrapped
         environment's observation and controller's target.
 
         It gathers the actual observation from the environment with the target
@@ -694,39 +696,39 @@
             method multiple times successively.
 
         :param measurement: Low-level measure from the environment to process
                             to get higher-level observation.
         """
         self.env.refresh_observation(measurement)
 
-    def compute_command(self, action: ActT) -> np.ndarray:
+    def compute_command(self, action: ActT, command: np.ndarray) -> None:
         """Compute the motors efforts to apply on the robot.
 
         In practice, it updates whenever necessary:
 
             - the target sent to the subsequent block by the controller
             - the command send to the robot by the environment through the
               subsequent block
 
         :param action: High-level target to achieve by means of the command.
+        :param command: Lower-level command to update in-place.
         """
         # Update the target to send to the subsequent block if necessary.
         # Note that `observation` buffer has already been updated right before
         # calling this method by `_controller_handle`, so it can be used as
         # measure argument without issue.
         if is_breakpoint(self.stepper_state.t, self.control_dt, DT_EPS):
-            target = self.controller.compute_command(action)
-            self._copyto_env_action(target)
+            self.controller.compute_command(action, self.env.action)
 
         # Update the command to send to the actuators of the robot.
         # Note that the environment itself is responsible of making sure to
         # update the command at the right period. Ultimately, this is done
         # automatically by the engine, which is calling `_controller_handle` at
         # the right period.
-        return self.env.compute_command(self.env.action)
+        self.env.compute_command(self.env.action, command)
 
     def compute_reward(self,
                        terminated: bool,
                        truncated: bool,
                        info: InfoType) -> float:
         return self.controller.compute_reward(terminated, truncated, info)
 
@@ -787,23 +789,24 @@
     def _initialize_action_space(self) -> None:
         """Configure the action space.
 
         It simply copy the action space of the wrapped environment.
         """
         self.action_space = self.env.action_space
 
-    def compute_command(self, action: ActT) -> np.ndarray:
+    def compute_command(self, action: ActT, command: np.ndarray) -> None:
         """Compute the motors efforts to apply on the robot.
 
         It simply forwards the command computed by the wrapped environment
         without any processing.
 
         :param action: High-level target to achieve by means of the command.
+        :param command: Lower-level command to update in-place.
         """
-        return self.env.compute_command(action)
+        self.env.compute_command(action, command)
 
     def refresh_observation(self, measurement: EngineObsType) -> None:
         """Compute high-level features based on the current wrapped
         environment's observation.
 
         It calls `transform_observation` at `step_dt` update period, right
         after having refreshed the base observation.
@@ -905,33 +908,36 @@
         without any processing.
 
         :param measurement: Low-level measure from the environment to process
                             to get higher-level observation.
         """
         self.env.refresh_observation(measurement)
 
-    def compute_command(self, action: TransformedActT) -> np.ndarray:
+    def compute_command(self,
+                        action: TransformedActT,
+                        command: np.ndarray) -> None:
         """Compute the motors efforts to apply on the robot.
 
         It calls `transform_action` at `step_dt` update period, which will
         update the environment action. Then, it delegates computation of the
         command to the base environment.
 
         .. warning::
             The method `transform_action` must have been overwritten by the
             user prior to calling this method.
 
         :param action: High-level target to achieve by means of the command.
+        :param command: Lower-level command to update in-place.
         """
         # Transform action at the beginning of the step only
         if is_breakpoint(self.stepper_state.t, self._step_dt, DT_EPS):
             self.transform_action(action)
 
         # Delegate command computation to wrapped environment
-        return self.env.compute_command(self.env.action)
+        self.env.compute_command(self.env.action, command)
 
     @abstractmethod
     def transform_action(self, action: TransformedActT) -> None:
         """Compute the transformed action from the provided wrapped environment
         action.
 
         .. note::
```

## gym_jiminy/common/blocks/__init__.py

```diff
@@ -1,14 +1,15 @@
 # pylint: disable=missing-module-docstring
 
 from .mahony_filter import MahonyFilter
 from .motor_safety_limit import MotorSafetyLimit
-from .proportional_derivative_controller import PDController
+from .proportional_derivative_controller import PDController, PDAdapter
 from .deformation_estimator import DeformationEstimator
 
 
 __all__ = [
     'MahonyFilter',
     'MotorSafetyLimit',
     'PDController',
+    'PDAdapter',
     'DeformationEstimator'
 ]
```

## gym_jiminy/common/blocks/deformation_estimator.py

```diff
@@ -27,16 +27,16 @@
 def _compute_orientation_error(obs_imu_quats: np.ndarray,
                                obs_imu_indices: Tuple[int, ...],
                                inv_obs_imu_quats: np.ndarray,
                                kin_imu_rots: Tuple[np.ndarray, ...],
                                kin_imu_quats: np.ndarray,
                                dev_imu_quats: np.ndarray,
                                ignore_twist: bool) -> None:
-    """Compute total deviation of observed IMU data wrt to rigid model in world
-    frame.
+    """Compute total deviation of observed IMU data wrt to theoretical model in
+    world frame.
     """
     # Re-order IMU data
     for i, imu_index in enumerate(obs_imu_indices):
         inv_obs_imu_quats[:, i] = obs_imu_quats[:, imu_index]
 
     # Compute orientation error
     if ignore_twist:
@@ -47,17 +47,17 @@
         # This approach is equivalent to removing the twist from the exact
         # deviation directly, but much faster as it does not require computing
         # the observed IMU quaternions nor to compose rotations.
 
         # Extract observed tilt: w_R_obs.T @ e_z
         obs_imu_tilts = np.stack(compute_tilt_from_quat(inv_obs_imu_quats), 1)
 
-        # Apply rigid kinematic IMU rotation on observed tilt.
+        # Apply theoretical kinematic IMU rotation on observed tilt.
         # The result can be interpreted as the tilt error between observed
-        # and rigid kinematic IMU orientation in world frame, ie:
+        # and theoretical kinematic IMU orientation in world frame, ie:
         # w_tilt_err = (w_R_kin @ w_R_obs.T) @ e_z
         for i, kin_imu_rot in enumerate(kin_imu_rots):
             obs_imu_tilts[i] = kin_imu_rot @ obs_imu_tilts[i]
 
         # Compute "smallest" rotation that can explain the tilt error.
         swing_from_vector(obs_imu_tilts.T, dev_imu_quats)
 
@@ -66,15 +66,15 @@
     else:
         # Convert kinematic IMU rotation matrices to quaternions
         matrices_to_quat(kin_imu_rots, kin_imu_quats)
 
         # Conjugate quaternion of IMU orientation
         inv_obs_imu_quats[-1] *= -1
 
-        # Compute one-by-one difference between observed and rigid
+        # Compute one-by-one difference between observed and theoretical
         # kinematic IMU orientations.
         quat_multiply(kin_imu_quats,
                       inv_obs_imu_quats,
                       dev_imu_quats)
 
 
 @nb.jit(nopython=True, cache=True, inline='always')
@@ -154,30 +154,29 @@
     """Compute the local deformation at an arbitrary set of flexibility points
     that are presumably responsible for most of the whole deformation of the
     mechanical structure.
 
     .. warning::
         The local deformation at each flexibility frame must be observable, ie
         the flexibility and IMU frames interleave with each others in a unique
-        and contiguous sub-chain in the rigid kinematic tree of the robot.
+        and contiguous sub-chain in theoretical kinematic tree of the robot.
 
     :param obs_imu_quats: Orientation estimates of an unordered arbitrary set
                           of IMUs as a 2D array whose first dimension gathers
                           the 4 quaternion coordinates [qx, qy, qz, qw] while
                           the second corresponds to N independent IMU data.
     :param obs_imu_indices: M-tuple of ordered IMU indices of interest for
                             which the total deviation will be computed.
     :param inv_obs_imu_quats: Pre-allocated memory for storing the inverse of
                               the orientation estimates for an ordered subset
                               of the IMU data `obs_imu_quats` according to
                               `obs_imu_indices`.
     :param kin_imu_rots: Tuple of M kinematic frame orientations corresponding
                          to the ordered subset of IMUs `obs_imu_indices`, for
-                         the rigid configuration of the theoretical model of
-                         the robot.
+                         the configuration of the theoretical robot model.
     :param kin_imu_quats: Pre-allocated memory for storing the kinematic frame
                           orientations of the ordered subset of IMUs of
                           interest as a 2D array whose first dimension gathers
                           the 4 quaternion coordinates while the second
                           corresponds to the M independent IMUs.
     :param kin_flex_rots: Tuple of K kinematic frame orientations for all the
                           flexibility points that interleaves with the ordered
@@ -190,19 +189,19 @@
                            corresponds to the K independent flexibility points.
     :param is_flex_flipped: Whether local deformation estimates for each
                             flexibility point must be inverted to be consistent
                             with standard URDF convention as 1D boolean array.
     :param is_chain_orphan: 2-Tuple stating whether first and last flexibility
                             point is orphan respectively, ie only a single IMU
                             is available for estimating its local deformation.
-    :param dev_imu_quats: Total deviation observed IMU data wrt to rigid model
-                          in world frame for the ordered subset of IMUs of
-                          interest as a 2D array whose first dimension gathers
-                          the 4 quaternion coordinates while the second
-                          corresponds to the M independent IMUs.
+    :param dev_imu_quats: Total deviation of th observed IMU data wrt to the
+                          theoretical model in world frame for the ordered
+                          subset of IMUs of interest, as a 2D array whose first
+                          dimension gathers the 4 quaternion coordinates while
+                          the second corresponds to the M independent IMUs.
     :param inv_child_dev_imu_quats:
         Total deviation observed IMU data in child flexibility frame as a 2D
         array whose first dimension gathers the 4 quaternion coordinates while
         the second corresponds to the K independent flexibility frames.
     :param parent_dev_imu_quats:
         Total deviation observed IMU data in parent flexibility frame as a 2D
         array whose first dimension gathers the 4 quaternion coordinates while
@@ -213,15 +212,15 @@
         dimension gathers the 4 quaternion coordinates while the second
         corresponds to the K independent flexibility points.
     :param ignore_twist: Whether to ignore the twist of the orientation
                          estimates of the ordered subset of IMUs of interest,
                          and incidentally the twist of deformation at the
                          flexibility points.
     """
-    # Compute error between observed and rigid kinematic IMU orientation
+    # Compute error between observed and theoretical kinematic IMU orientation
     _compute_orientation_error(obs_imu_quats,
                                obs_imu_indices,
                                inv_obs_imu_quats,
                                kin_imu_rots,
                                kin_imu_quats,
                                dev_imu_quats,
                                ignore_twist)
@@ -238,19 +237,18 @@
 
 
 def get_flexibility_imu_frame_chains(
         pinocchio_model: pin.Model,
         flex_joint_names: Sequence[str],
         imu_frame_names: Sequence[str]) -> Sequence[Tuple[
             Sequence[str], Sequence[Optional[str]], Sequence[bool]]]:
-    """Extract the minimal set of contiguous sub-chains in the kinematic tree
-    of a given flexible model that goes through all the specified flexibility
-    and IMU frames.
+    """Extract the minimal set of contiguous sub-chains in kinematic tree of a
+    given model that goes through all the specified flexibility and IMU frames.
 
-    :param pinocchio_model: Model for which to extract sub-chains.
+    :param pinocchio_model: Model from which to extract sub-chains.
     :param flex_joint_names: Unordered sequence of joint names that must be
                              considered as associated with flexibility frames.
     :param imu_frame_names: Unordered sequence of frame names that must be
                              considered as associated with IMU frames.
     """
     # Determine the leaf joints of the kinematic tree, ie all the joints that
     # are not parent of any other joint.
@@ -416,81 +414,81 @@
 
 class DeformationEstimator(
         BaseObserverBlock[np.ndarray, np.ndarray, BaseObsT, BaseActT]):
     """Compute the local deformation at an arbitrary set of flexibility points
     that are presumably responsible for most of the whole deformation of the
     mechanical structure.
 
-    .. details::
-        The number of IMU sensors and flexibility frames must be consistent:
-            * If the robot has no freeflyer, there must be as many IMU sensors
-              as flexibility frames (0), ie
-
-              *---o---x---o---x---o---x
-                          |
-                          |
-                          x---o---x
-
-            * Otherwise, it can either have one more IMU than flexibility
-              frames (1), the same number (2), or up to one less IMU per
-              branch in the kinematic tree (3).
-
-              (1) x---o---x---o---x---o---x
-                              |
-                              |
-                              x---o---x
-
-              (2) +---o---x---o---x---o---x
-                              |
-                              |
-                              x---o---x
-
-              (3) +---o---x---o---x---o---+
-                              |
-                              |
-                              x---o---+
-
-        *: Fixed base, +: leaf frame, x: IMU frame, o: flexibility frame
-
-        (1): The pose of the freeflyer is ignored when estimating the
-        deformation at the flexibility frames in local frame. Mathematically,
-        it is the same as (0) when considering a virtual IMU with fixed
-        orientation to identity for the root joint.
-
-        (2): One has to compensate for the missing IMU by providing the
-        configuration of the freeflyer. More precisely, one should ensure that
-        the orientation of the parent frame of the orphan flexibility frame
-        matches the reality for the rigid configuration. This usually requires
-        making some assumptions to guess to pose of the frame that is not
-        directly observable. Any discrepancy will be aggregated to the
-        estimated deformation for the orphan flexibility frame specifically
-        since both cannot be distinguished. This issue typically happens when
-        there is no IMUs in the feet of a legged robot. In such a case, there
-        is no better option than assuming that one of the active contact bodies
-        remains flat on the ground. If the twist of the IMUs are ignored, then
-        the twist of the contact body does not matter either, otherwise it must
-        be set appropriately by the user to get a meaningless estimate for the
-        twist of the deformation. If it cannot be observed by some
-        exteroceptive sensor such as vision, then the most reasonable
-        assumption is to suppose that it matches the twist of the IMU coming
-        right after in the kinematic tree. This way, they will cancel out each
-        other without adding bias to the twist of the orphan flexibility frame.
-
-        (3): This case is basically the same as (2), with the addition that
-        only the deformation of one of the orphan flexibility frames can
-        be estimated at once, namely the one whose parent frame is declared as
-        having known orientation. The other ones will be set to identity. For a
-        legged robot, this corresponds to one of the contact bodies, usually
-        the one holding most of the total weight.
+    The number of IMU sensors and flexibility frames must be consistent:
+        * If the robot has no freeflyer, there must be as many IMU sensors as
+          flexibility frames (0), ie
+
+            *---o---x---o---x---o---x
+                        |
+                        |
+                        x---o---x
+
+        * Otherwise, it can either have one more IMU than flexibility frames
+          (1), the same number (2), or up to one less IMU per branch in the
+          kinematic tree (3).
+
+            (1) x---o---x---o---x---o---x
+                            |
+                            |
+                            x---o---x
+
+            (2) +---o---x---o---x---o---x
+                            |
+                            |
+                            x---o---x
+
+            (3) +---o---x---o---x---o---+
+                            |
+                            |
+                            x---o---+
+
+    *: Fixed base, +: leaf frame, x: IMU frame, o: flexibility frame
+
+    (1): The pose of the freeflyer is ignored when estimating the deformation
+         at the flexibility frames in local frame. Mathematically, it is the
+         same as (0) when considering a virtual IMU with fixed orientation to
+         identity for the root joint.
+
+    (2): One has to compensate for the missing IMU by providing instead the
+         configuration of the freeflyer. More precisely, one should ensure that
+         the orientation of the parent frame of the orphan flexibility frame
+         matches the reality for the theoretical configuration. This usually
+         requires making some assumptions to guess to pose of the frame that is
+         not directly observable. Any discrepancy will be aggregated to the
+         estimated deformation for the orphan flexibility frame specifically
+         since both cannot be distinguished. This issue typically happens when
+         there is no IMUs in the feet of a legged robot. In such a case, there
+         is no better option than assuming that one of the active contact
+         bodies remains flat on the ground. If the twist of the IMUs are
+         ignored, then the twist of the contact body does not matter either,
+         otherwise it must be set appropriately by the user to get a
+         meaningless estimate for the twist of the deformation. If it cannot be
+         observed by some exteroceptive sensor such as vision, then the most
+         reasonable assumption is to suppose that it matches the twist of the
+         IMU coming right after in the kinematic tree. This way, they will
+         cancel out each other without adding bias to the twist of the orphan
+         flexibility frame.
+
+    (3): This case is basically the same as (2), with the addition that only
+         the deformation of one of the orphan flexibility frames can be
+         estimated at once, namely the one whose parent frame is declared as
+         having known orientation. The other ones will be set to identity. For
+         a legged robot, this corresponds to one of the contact bodies, usually
+         the one holding most of the total weight.
 
     .. warning::
         (2) and (3) are not supported for now, as it requires using one
-        additional observation layer responsible for estimating the rigid
-        configuration of the robot including its freeflyer, along with the
-        name of the reference frame, ie the one having known orientation.
+        additional observation layer responsible for estimating the theoretical
+        configuration of the robot including its freeflyer, along with the name
+        of the reference frame, ie the one having known orientation.
 
     .. seealso::
         Matthieu Vigne, Antonio El Khoury, Marine PeÃÅtriaux, Florent Di Meglio,
         and Nicolas Petit "MOVIE: a Velocity-aided IMU Attitude Estimator for
         Observing and Controlling Multiple Deformations on Legged Robots" IEEE
         Robotics and Automation Letters, Institute of Electrical and
         Electronics Engineers, 2022, 7 (2):
@@ -542,65 +540,62 @@
         # Sanitize user argument(s)
         imu_frame_names, flex_frame_names = map(
             list, (imu_frame_names, flex_frame_names))
 
         # Backup some of the user-argument(s)
         self.ignore_twist = ignore_twist
 
-        # Initialize jiminy model
-        self.model = jiminy.Model()
-        self.model.initialize(env.robot.pinocchio_model_th)
-
         # Define proxies for fast access
-        self.pinocchio_model_th = self.model.pinocchio_model_th
-        self.pinocchio_data_th = self.model.pinocchio_data_th
+        self.pinocchio_model_th = env.robot.pinocchio_model_th.copy()
+        self.pinocchio_data_th = env.robot.pinocchio_data_th.copy()
 
-        # Create flexible dynamical model.
+        # Create flexible dynamic model.
         # Dummy physical parameters are specified as they have no effect on
-        # kinematic computations. It is only used for computing the flexible
-        # configuration if requested.
-        options = self.model.get_options()
+        # kinematic computations.
+        model = jiminy.Model()
+        model.initialize(env.robot.pinocchio_model_th)
+        options = model.get_options()
         for frame_name in flex_frame_names:
             options["dynamics"]["flexibilityConfig"].append(
                 {
                     "frameName": frame_name,
                     "stiffness": np.ones(3),
                     "damping": np.ones(3),
                     "inertia": np.ones(3),
                 }
             )
-        self.model.set_options(options)
+        model.set_options(options)
 
         # Extract contiguous chains of flexibility and IMU frames for which
         # computations can be vectorized. It also stores the information of
         # whether or not the sign of the deformation must be reversed to be
         # consistent with standard convention.
-        flexible_joint_names = self.model.flexible_joint_names
+        flexibility_joint_names = model.flexibility_joint_names
         flex_imu_frame_names_chains = get_flexibility_imu_frame_chains(
-            self.model.pinocchio_model, flexible_joint_names, imu_frame_names)
+            model.pinocchio_model, flexibility_joint_names, imu_frame_names)
 
         # Replace actual flex joint name by corresponding rigid frame
         self.flex_imu_frame_names_chains = []
         for flex_frame_names_, imu_frame_names_, is_flipped in (
                 flex_imu_frame_names_chains):
             flex_frame_names_ = [
-                flex_frame_names[flexible_joint_names.index(name)]
+                flex_frame_names[flexibility_joint_names.index(name)]
                 for name in flex_frame_names_]
             self.flex_imu_frame_names_chains.append(
                 (flex_frame_names_, imu_frame_names_, is_flipped))
 
         # Check if a freeflyer estimator is required
-        if self.model.has_freeflyer:
+        if model.has_freeflyer:
             for _, imu_frame_names_, _ in self.flex_imu_frame_names_chains:
                 if None in imu_frame_names_:
                     raise NotImplementedError(
                         "Freeflyer estimator is not supported for now.")
 
         # Backup flexibility frame names
-        self.flexible_frame_names = [
+        self.flexibility_frame_names = [
             name for flex_frame_names, _, _ in self.flex_imu_frame_names_chains
             for name in flex_frame_names]
 
         # Define flexibility and IMU frame orientation proxies for fast access.
         # Note that they will be initialized in `_setup` method.
         self._kin_flex_rots: List[Tuple[np.ndarray, ...]] = []
         self._kin_imu_rots: List[Tuple[np.ndarray, ...]] = []
@@ -642,22 +637,21 @@
         # Get mapping from IMU frame to index
         imu_frame_map: Dict[str, int] = {}
         for sensor_name in env.robot.sensor_names[imu.type]:
             sensor = env.robot.get_sensor(imu.type, sensor_name)
             assert isinstance(sensor, imu)
             imu_frame_map[sensor.frame_name] = sensor.index
 
-        # Make sure that the robot has one encoder per rigid joint
+        # Make sure that the robot has one encoder per mechanical joint
         encoder_sensor_names = env.robot.sensor_names[encoder.type]
-        if len(encoder_sensor_names) < len(self.model.rigid_joint_indices):
+        if len(encoder_sensor_names) < len(model.mechanical_joint_indices):
             raise ValueError(
-                "The robot must have one encoder per joint in theoretical "
-                "model (excluding floating base if any).")
+                "The robot must have one encoder per mechanical joints.")
 
-        # Extract mapping from encoders to rigid configuration.
+        # Extract mapping from encoders to theoretical configuration.
         # Note that revolute unbounded joints are not supported for now.
         self.encoder_to_config = [-1 for _ in range(env.robot.nmotors)]
         for i, sensor_name in enumerate(encoder_sensor_names):
             sensor = env.robot.get_sensor(encoder.type, sensor_name)
             assert isinstance(sensor, encoder)
             if sensor.joint_type == jiminy.JointModelType.ROTARY_UNBOUNDED:
                 raise ValueError(
@@ -665,16 +659,16 @@
             encoder_joint = self.pinocchio_model_th.joints[sensor.joint_index]
             self.encoder_to_config[i] = encoder_joint.idx_q
 
         # Extract measured joint positions for fast access.
         # Note that they will be initialized in `_setup` method.
         self.encoder_data = np.array([])
 
-        # Buffer storing the rigid configuration.
-        self._q_rigid = pin.neutral(self.pinocchio_model_th)
+        # Buffer storing the theoretical configuration.
+        self._q_th = pin.neutral(self.pinocchio_model_th)
 
         # Whether the observer has been compiled already
         self._is_compiled = False
 
         # Initialize the observer
         super().__init__(name, env, update_ratio)
 
@@ -701,14 +695,20 @@
             high=np.full((4, nflex), 1.0 + 1e-9),
             dtype=np.float64)
 
     def _setup(self) -> None:
         # Call base implementation
         super()._setup()
 
+        # Refresh the theoretical model of the robot.
+        # Even if the robot may change, the theoretical model of the robot is
+        # not supposed to change in a way that would break this observer.
+        self.pinocchio_model_th = self.env.robot.pinocchio_model_th
+        self.pinocchio_data_th = self.env.robot.pinocchio_data_th
+
         # Fix initialization of the observation to be valid quaternions
         self.observation[-1] = 1.0
 
         # Refresh flexibility and IMU frame orientation proxies
         self._kin_flex_rots.clear()
         self._kin_imu_rots.clear()
         for flex_frame_names, imu_frame_names_, _ in (
@@ -728,24 +728,24 @@
         # Call `refresh_observation` manually to pre-compile it if necessary
         if not self._is_compiled:
             self.refresh_observation(self.env.observation)
             self._is_compiled = True
 
     @property
     def fieldnames(self) -> List[List[str]]:
-        return [[f"{name}.Quat{e}" for name in self.flexible_frame_names]
+        return [[f"{name}.Quat{e}" for name in self.flexibility_frame_names]
                 for e in ("x", "y", "z", "w")]
 
     def refresh_observation(self, measurement: BaseObsT) -> None:
-        # Estimate the rigid configuration of the robot from encoder data
-        self._q_rigid[self.encoder_to_config] = self.encoder_data
+        # Estimate the theoretical configuration of the robot from encoder data
+        self._q_th[self.encoder_to_config] = self.encoder_data
 
-        # Update kinematic quantities according to estimate rigid configuration
+        # Update kinematic quantities according to the estimated configuration
         pin.framesForwardKinematics(
-            self.pinocchio_model_th, self.pinocchio_data_th, self._q_rigid)
+            self.pinocchio_model_th, self.pinocchio_data_th, self._q_th)
 
         # Estimate all the deformations in their local frame.
         # It loops over each flexibility-imu chain independently.
         for args in zip(
                 self._obs_imu_indices,
                 self._inv_obs_imu_quats,
                 self._kin_imu_rots,
```

## gym_jiminy/common/blocks/motor_safety_limit.py

```diff
@@ -24,16 +24,16 @@
                         q_measured: np.ndarray,
                         v_measured: np.ndarray,
                         kp: np.ndarray,
                         kd: np.ndarray,
                         motors_soft_position_lower: np.ndarray,
                         motors_soft_position_upper: np.ndarray,
                         motors_velocity_limit: np.ndarray,
-                        motors_effort_limit: np.ndarray
-                        ) -> np.ndarray:
+                        motors_effort_limit: np.ndarray,
+                        out: np.ndarray) -> None:
     """Clip the command torque to ensure safe operation.
 
     It acts on each actuator independently and only activate close to the
     position or velocity limits. Basically, the idea to the avoid moving faster
     when some prescribed velocity limit or exceeding soft position bounds by
     forcing the command torque to act against it. Still, it may not be enough
     to prevent such issue in practice as the command torque is bounded.
@@ -56,29 +56,30 @@
         Soft lower position limit of the actuators.
     :param motors_soft_position_upper:
         Soft upper position limit of the actuators.
     :param motors_velocity_limit: Maximum velocity of the actuators.
     :param motors_effort_limit: Maximum effort that the actuators can output.
                                 The command torque cannot exceed this limits,
                                 not even if needed to enforce safe operation.
+    :param out: Pre-allocated memory to store the command motor torques.
     """
     # Computes velocity bounds based on margin from soft joint limit if any
     safe_velocity_lower = motors_velocity_limit * np.minimum(np.maximum(
         -kp * (q_measured - motors_soft_position_lower), -1.0), 1.0)
     safe_velocity_upper = motors_velocity_limit * np.minimum(np.maximum(
         -kp * (q_measured - motors_soft_position_upper), -1.0), 1.0)
 
     # Computes effort bounds based on velocity and effort bounds
     safe_effort_lower = motors_effort_limit * np.minimum(np.maximum(
         -kd * (v_measured - safe_velocity_lower), -1.0), 1.0)
     safe_effort_upper = motors_effort_limit * np.minimum(np.maximum(
         -kd * (v_measured - safe_velocity_upper), -1.0), 1.0)
 
     # Clip command according to safe effort bounds
-    return np.minimum(np.maximum(
+    out[:] = np.minimum(np.maximum(
         command, safe_effort_lower), safe_effort_upper)
 
 
 class MotorSafetyLimit(
         BaseControllerBlock[np.ndarray, np.ndarray, BaseObsT, np.ndarray]):
     """Safety mechanism primarily designed to prevent hardware damage and
     premature wear, but also to temper violent, sporadic and dangerous motions.
@@ -164,15 +165,15 @@
                 "optimal performance.")
 
         # Extract measured motor positions and velocities for fast access.
         # Note that they will be initialized in `_setup` method.
         self.q_measured, self.v_measured = np.array([]), np.array([])
 
         # Initialize the controller
-        super().__init__(name, env, 1)
+        super().__init__(name, env, update_ratio=1)
 
     def _initialize_action_space(self) -> None:
         """Configure the action space of the controller.
 
         The action spaces corresponds to the command motors efforts.
         """
         self.action_space = self.env.action_space
@@ -186,30 +187,34 @@
             self.env.sensor_measurements[encoder.type])
 
     @property
     def fieldnames(self) -> List[str]:
         return [f"currentMotorTorque{name}"
                 for name in self.env.robot.motor_names]
 
-    def compute_command(self, action: np.ndarray) -> np.ndarray:
+    def compute_command(self,
+                        action: np.ndarray,
+                        command: np.ndarray) -> None:
         """Apply safety limits to the desired motor torques right before
         sending it to the robot so as to avoid exceeded prescribed position
         and velocity limits.
 
         :param action: Desired motor torques to apply on the robot.
+        :param command: Current motor torques that will be updated in-place.
         """
         # Extract motor positions and velocity from encoder data
         q_measured, v_measured = self.q_measured, self.v_measured
         if not self._is_same_order:
             q_measured = q_measured[self.encoder_to_motor]
             v_measured = v_measured[self.encoder_to_motor]
 
         # Clip command according to safe effort bounds
-        return apply_safety_limits(action,
-                                   q_measured,
-                                   v_measured,
-                                   self.kp,
-                                   self.kd,
-                                   self.motors_position_lower,
-                                   self.motors_position_upper,
-                                   self.motors_velocity_limit,
-                                   self.motors_effort_limit)
+        apply_safety_limits(action,
+                            q_measured,
+                            v_measured,
+                            self.kp,
+                            self.kd,
+                            self.motors_position_lower,
+                            self.motors_position_upper,
+                            self.motors_velocity_limit,
+                            self.motors_effort_limit,
+                            command)
```

## gym_jiminy/common/blocks/proportional_derivative_controller.py

```diff
@@ -1,185 +1,224 @@
 """Implementation of basic Proportional-Derivative controller block compatible
 with gym_jiminy reinforcement learning pipeline environment design.
 """
-import math
 import warnings
 from typing import List, Union
 
 import numpy as np
 import numba as nb
 import gymnasium as gym
-from numpy.lib.stride_tricks import as_strided
 
 import jiminy_py.core as jiminy
 from jiminy_py.core import (  # pylint: disable=no-name-in-module
     array_copyto,
     EncoderSensor as encoder)
 
 from ..bases import BaseObsT, InterfaceJiminyEnv, BaseControllerBlock
 from ..utils import fill
 
 
-# Pre-computed factorial for small integers
-INV_FACTORIAL_TABLE = tuple(1.0 / math.factorial(i) for i in range(4))
-
 # Name of the n-th position derivative
-N_ORDER_DERIVATIVE_NAMES = ("Position", "Velocity", "Acceleration", "Jerk")
-
-# Command velocity deadband to reduce vibrations and internal efforts
-EVAL_DEADBAND = 5.0e-3
-
-
-@nb.jit(nopython=True, cache=True, inline='always')
-def toeplitz(col: np.ndarray, row: np.ndarray) -> np.ndarray:
-    """Numba-compatible implementation of `scipy.linalg.toeplitz` method.
-
-    .. note:
-        Special cases are ignored for efficiency, hence the input types
-        are more respective than originally.
-
-    .. warning:
-        It returns a strided matrix instead of contiguous copy for efficiency.
-
-    .. seealso::
-        https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.toeplitz.html
-
-    :param col: First column of the matrix.
-    :param row: First row of the matrix.
-    """  # noqa: E501  # pylint: disable=line-too-long
-    vals = np.concatenate((col[::-1], row[1:]))
-    stride = vals.strides[0]  # pylint: disable=E1136
-    return as_strided(vals[len(col)-1:],
-                      shape=(len(col), len(row)),
-                      strides=(-stride, stride))
+N_ORDER_DERIVATIVE_NAMES = ("Position", "Velocity", "Acceleration")
 
 
 @nb.jit(nopython=True, cache=True, inline='always', fastmath=True)
-def integrate_zoh(state_prev: np.ndarray,
+def integrate_zoh(state: np.ndarray,
                   state_min: np.ndarray,
                   state_max: np.ndarray,
-                  dt: float) -> np.ndarray:
-    """N-th order exact integration scheme assuming Zero-Order-Hold for the
-    highest-order derivative, taking state bounds into account.
-
-    .. warning::
-        This method tries its best to keep the state within bounds, but it is
-        not always possible if the order is strictly larger than 1. Indeed, the
-        bounds of different derivative order may be conflicting. In such a
-        case, it gives priority to lower orders.
-
-    :param state_prev: Previous state update, ordered from lowest to highest
-                       derivative order, which means:
-                       s[i](t) = s[i](t-1) + integ_{t-1}^{t}(s[i+1](t))
-    :param state_min: Lower bounds of the state.
-    :param state_max: Upper bounds of the state.
+                  dt: float) -> None:
+    """Second order approximate integration scheme assuming Zero-Order-Hold for
+    the acceleration, taking position, velocity and acceleration bounds into
+    account.
+
+    Internally, it simply chains two first-order integrators in cascade. The
+    acceleration will be updated in-place if clipping is necessary to satisfy
+    bounds.
+
+    :param state: Current state, ordered from lowest to highest derivative
+                  order, ie: s[i](t) = s[i](t-1) + integ_{t-1}^{t}(s[i+1](t)),
+                  as a 2D array whose first dimension gathers the 3 derivative
+                  orders. It will be updated in-place.
+    :param state_min: Lower bounds of the state as a 2D array.
+    :param state_max: Upper bounds of the state as a 2D array.
     :param dt: Integration delta of time since previous state update.
     """
     # Make sure that dt is not negative
-    assert dt >= 0.0, "The integration timestep 'dt' must be positive."
+    assert dt >= 0.0, "Integration backward in time is not supported."
 
-    # Early return if the timestep is too small
+    # Early return if timestep is too small
     if abs(dt) < 1e-9:
-        return state_prev.copy()
+        return
 
-    # Compute integration matrix
-    dim, size = state_prev.shape
-    integ_coeffs = np.array([
-        pow(dt, k) * INV_FACTORIAL_TABLE[k] for k in range(dim)])
-    integ_matrix = toeplitz(integ_coeffs, np.zeros(dim)).T
-    integ_zero = integ_matrix[:, :-1].copy() @ state_prev[:-1]
-    integ_drift = integ_matrix[:, -1:]
-
-    # Propagate derivative bounds to compute highest-order derivative bounds
-    deriv_min_stack = (state_min - integ_zero) / integ_drift
-    deriv_max_stack = (state_max - integ_zero) / integ_drift
-    deriv_min, deriv_max = np.full((size,), -np.inf), np.full((size,), np.inf)
-    for deriv_min_i, deriv_max_i in zip(deriv_min_stack, deriv_max_stack):
-        for k, (deriv_min_k, deriv_max_k) in enumerate(zip(
-                deriv_min, deriv_max)):
-            if deriv_min_k < deriv_min_i[k] < deriv_max_k:
-                deriv_min[k] = deriv_min_i[k]
-            if deriv_min_k < deriv_max_i[k] < deriv_max_k:
-                deriv_max[k] = deriv_max_i[k]
-
-    # Clip highest-order derivative to ensure every derivative are within
-    # bounds if possible, lowest orders in priority otherwise.
-    deriv = np.minimum(np.maximum(state_prev[-1], deriv_min), deriv_max)
+    # Split position, velocity and acceleration orders for convenience
+    position, velocity, acceleration = state
+    position_min, velocity_min, acceleration_min = state_min
+    position_max, velocity_max, acceleration_max = state_max
+
+    # Clip acceleration
+    acceleration[:] = np.minimum(
+        np.maximum(acceleration, acceleration_min), acceleration_max)
+
+    # Backup the initial velocity to later compute the clipped acceleration
+    velocity_prev = velocity.copy()
+
+    # Integrate acceleration 1-step ahead
+    velocity += acceleration * dt
+
+    # Make sure that "true" velocity bounds are satisfied
+    velocity[:] = np.minimum(np.maximum(velocity, velocity_min), velocity_max)
+
+    # Force slowing down early enough to avoid violating acceleration limits
+    # when hitting position bounds.
+    horizon = np.maximum(
+        np.floor(np.abs(velocity_prev) / acceleration_max / dt) * dt, dt)
+    position_min_delta = position_min - position
+    position_max_delta = position_max - position
+    drift = 0.5 * (horizon[horizon > dt] * (horizon[horizon > dt] - dt))
+    position_min_delta[horizon > dt] -= drift * acceleration_max[horizon > dt]
+    position_max_delta[horizon > dt] += drift * acceleration_max[horizon > dt]
+    velocity_min = position_min_delta / horizon
+    velocity_max = position_max_delta / horizon
+    velocity[:] = np.minimum(np.maximum(velocity, velocity_min), velocity_max)
+
+    # Velocity after hitting bounds must be cancellable in a single time step
+    velocity_mask = np.abs(velocity) > dt * acceleration_max
+    velocity_min = - np.maximum(
+        position_min_delta[velocity_mask] / velocity[velocity_mask], dt
+        ) * acceleration_max[velocity_mask]
+    velocity_max = np.maximum(
+        position_max_delta[velocity_mask] / velocity[velocity_mask], dt
+        ) * acceleration_max[velocity_mask]
+    velocity[velocity_mask] = np.minimum(
+        np.maximum(velocity[velocity_mask], velocity_min), velocity_max)
 
-    # Integrate, taking into account clipped highest derivative
-    return integ_zero + integ_drift * deriv
+    # Back-propagate velocity clipping at the acceleration-level
+    acceleration[:] = (velocity - velocity_prev) / dt
+
+    # Integrate position 1-step ahead
+    position += dt * velocity
 
 
 @nb.jit(nopython=True, cache=True, fastmath=True)
 def pd_controller(q_measured: np.ndarray,
                   v_measured: np.ndarray,
                   command_state: np.ndarray,
                   command_state_lower: np.ndarray,
                   command_state_upper: np.ndarray,
                   kp: np.ndarray,
                   kd: np.ndarray,
                   motors_effort_limit: np.ndarray,
-                  control_dt: float) -> np.ndarray:
-    """Compute command under discrete-time proportional-derivative feedback
-    control.
-
-    Internally, it integrates the command state over the controller update
-    period in order to obtain the desired motor positions 'q_desired' and
-    velocities 'v_desired'. By computing them this way, the desired motor
-    positions and velocities can be interpreted as targets should be reached
-    right before updating the command once again. The integration takes into
-    account some lower and upper bounds that ideally should not be exceeded.
-    If not possible, priority is given to consistency of the integration, so
-    no clipping of the command state ever occurs. The lower order bounds will
-    be satisfied first, which means that position limits are the only one to be
-    guaranteed to never be violated.
+                  control_dt: float,
+                  out: np.ndarray) -> None:
+    """Compute command torques under discrete-time proportional-derivative
+    feedback control.
+
+    Internally, it integrates the command state (position, velocity and
+    acceleration) at controller update period in order to obtain the desired
+    motor positions 'q_desired' and velocities 'v_desired', takes into account
+    some lower and upper bounds. By computing them this way, the target motor
+    positions and velocities can be interpreted as targets that has be to reach
+    right before updating the command once again. Enforcing consistency between
+    target position and velocity in such a way is a necessary but insufficient
+    condition for the motors to be able to track them.
 
     The command effort is computed as follows:
 
         tau = - kp * ((q_measured - q_desired) + kd * (v_measured - v_desired))
 
     The torque will be held constant until the next controller update.
 
     .. seealso::
         See `PDController` documentation to get more information, and
         `integrate_zoh` documentation for details about the state integration.
 
     :param q_measured: Current position of the actuators.
     :param v_measured: Current velocity of the actuators.
     :param command_state: Current command state, namely, all the derivatives of
-                          the target motors positions up to order N. The order
-                          must be larger than 2 but can be arbitrarily large.
-    :param command_state_lower: Lower bound of the command state that should be
-                                satisfied if possible, prioritizing lower order
-                                derivatives.
-    :param command_state_upper: Upper bound of the command state that should be
-                                satisfied if possible, prioritizing lower order
-                                derivatives.
+                          the target motors positions up to acceleration order.
+    :param command_state_lower: Lower bound of the command state that must be
+                                satisfied at all cost.
+    :param command_state_upper: Upper bound of the command state that must be
+                                satisfied at all cost.
     :param kp: PD controller position-proportional gain in motor order.
     :param kd: PD controller velocity-proportional gain in motor order.
     :param motors_effort_limit: Maximum effort that the actuators can output.
     :param control_dt: Controller update period. It will be involved in the
                        integration of the command state.
+    :param out: Pre-allocated memory to store the command motor torques.
     """
-    # Integrate command state
-    command_state[:] = integrate_zoh(
-        command_state, command_state_lower, command_state_upper, control_dt)
+    # Integrate target motor positions and velocities
+    integrate_zoh(command_state,
+                  command_state_lower,
+                  command_state_upper,
+                  control_dt)
 
     # Extract targets motors positions and velocities from command state
-    q_target, v_target = command_state[:2]
+    q_target, v_target, _ = command_state
 
     # Compute the joint tracking error
     q_error, v_error = q_target - q_measured, v_target - v_measured
 
     # Compute PD command
-    u_command = kp * (q_error + kd * v_error)
+    out[:] = kp * (q_error + kd * v_error)
 
     # Clip the command motors torques before returning
-    return np.minimum(np.maximum(
-        u_command, -motors_effort_limit), motors_effort_limit)
+    out[:] = np.minimum(np.maximum(
+        out, -motors_effort_limit), motors_effort_limit)
+
+
+@nb.jit(nopython=True, cache=True, fastmath=True)
+def pd_adapter(action: np.ndarray,
+               order: int,
+               command_state: np.ndarray,
+               command_state_lower: np.ndarray,
+               command_state_upper: np.ndarray,
+               dt: float,
+               out: np.ndarray) -> None:
+    """Compute the target motor accelerations that must be held constant for a
+    given time interval in order to reach the desired value of some derivative
+    of the target motor positions at the end of that interval if possible.
+
+    Internally, it applies backward in time the same integration scheme as the
+    PD controller. Knowing the initial and final value of the derivative over
+    the time interval, constant target motor accelerations can be uniquely
+    deduced. In practice, it consists in successive clipped finite difference
+    of that derivative up to acceleration-level.
+
+    :param action: Desired value of the n-th derivative of the command motor
+                   positions at the end of the controller update.
+    :param order: Derivative order of the position associated with the action.
+    :param command_state: Current command state, namely, all the derivatives of
+                          the target motors positions up to acceleration order.
+    :param command_state_lower: Lower bound of the command state that must be
+                                satisfied at all cost.
+    :param command_state_upper: Upper bound of the command state that must be
+                                satisfied at all cost.
+    :param dt: Time interval during which the target motor accelerations will
+               be held constant.
+    :param out: Pre-allocated memory to store the target motor accelerations.
+    """
+    # Update command accelerations based on the action and its derivative order
+    if order == 2:
+        # The action corresponds to the command motor accelerations
+        out[:] = action
+    else:
+        if order == 0:
+            # Compute command velocity
+            velocity = (action - command_state[0]) / dt
+
+            # Clip command velocity
+            velocity = np.minimum(np.maximum(
+                velocity, command_state_lower[1]), command_state_upper[1])
+        else:
+            # The action corresponds to the command motor velocities
+            velocity = action
+
+        # Compute command acceleration
+        out[:] = (velocity - command_state[1]) / dt
 
 
 def get_encoder_to_motor_map(robot: jiminy.Robot) -> Union[slice, List[int]]:
     """Get the mapping from encoder sensors to motors.
 
     .. warning::
         If reordering is necessary, then a list of indices is returned, which
@@ -216,65 +255,63 @@
     return encoder_to_motor
 
 
 class PDController(
         BaseControllerBlock[np.ndarray, np.ndarray, BaseObsT, np.ndarray]):
     """Low-level Proportional-Derivative controller.
 
-    The action corresponds to a given derivative of the target motors
-    positions. All the lower-order derivatives are obtained by integration,
-    considering that the action is constant until the next controller update.
+    The action are the target motors accelerations. The latter are integrated
+    twice using two first-order integrators in cascade, considering that the
+    acceleration is constant until the next controller update:
 
-    .. note::
-        The higher the derivative order of the action, the smoother the command
-        motors torques. Thus, a high order is generally beneficial for robotic
-        applications. However, it introduces some kind of delay between the
-        action and its effects. This phenomenon makes learning more difficult
-        but most importantly, it limits the responsiveness of the agent
-        and therefore impedes its optimal performance.
+        v_{t+1} = v_{t} + dt * a_{t}
+        q_{t+1} = q_{t} + dt * v_{t+1}
 
     .. note::
         The position and velocity bounds on the command corresponds to the
         joint limits specified by the dynamical model of the robot. Then, lax
-        higher-order bounds are extrapolated. In a single timestep of the
-        environment, they are chosen to be sufficient either to span the whole
-        range of the state derivative directly preceding (ie acceleration
-        bounds are inferred from velocity bounds) or to allow reaching the
-        command effort limits depending on what is the most restrictive.
+        default acceleration bounds are extrapolated. More precisely, they are
+        chosen to be sufficient either to span the whole range of velocity or
+        to allow reaching the command effort limits depending on what is the
+        most restrictive. Position, velocity and acceleration.
 
     .. warning::
-        It must be connected directly to the environment to control without
-        any intermediary controllers altering the action space.
+        It must be connected directly to the base environment to control
+        without any intermediary controllers altering its action space.
     """
     def __init__(self,
                  name: str,
                  env: InterfaceJiminyEnv[BaseObsT, np.ndarray],
                  *,
                  update_ratio: int = 1,
-                 order: int,
                  kp: Union[float, List[float], np.ndarray],
                  kd: Union[float, List[float], np.ndarray],
                  target_position_margin: float = 0.0,
-                 target_velocity_limit: float = float("inf")) -> None:
+                 target_velocity_limit: float = float("inf"),
+                 target_acceleration_limit: float = float("inf")) -> None:
         """
         :param name: Name of the block.
         :param env: Environment to connect with.
         :param update_ratio: Ratio between the update period of the controller
                              and the one of the subsequent controller. -1 to
                              match the simulation timestep of the environment.
-        :param order: Derivative order of the action.
+                             Optional: 1 by default.
         :param kp: PD controller position-proportional gains in motor order.
         :param kd: PD controller velocity-proportional gains in motor order.
         :param target_position_margin: Minimum distance of the motor target
                                        positions from their respective bounds.
-        :param target_velocity_limit: Maximum motor target velocities.
+                                       Optional: 0.0 by default.
+        :param target_velocity_limit: Restrict maximum motor target velocities
+                                      wrt their hardware specifications.
+                                      Optional: "inf" by default.
+        :param target_acceleration_limit:
+            Restrict maximum motor target accelerations wrt their hardware
+            specifications.
+            Optional: "inf" by default.
         """
-        # Make sure that the specified derivative order is valid
-        assert (0 < order < 4), "Derivative order of command out-of-bounds"
-
         # Make sure the action space of the environment has not been altered
         if env.action_space is not env.unwrapped.action_space:
             raise RuntimeError(
                 "Impossible to connect this block on an environment whose "
                 "action space has been altered.")
 
         # Make sure that the number of PD gains matches the number of motors
@@ -282,15 +319,14 @@
             kp = np.broadcast_to(kp, (env.robot.nmotors,))
             kd = np.broadcast_to(kd, (env.robot.nmotors,))
         except ValueError as e:
             raise TypeError(
                 "PD gains inconsistent with number of motors.") from e
 
         # Backup some user argument(s)
-        self.order = order
         self.kp = kp
         self.kd = kd
 
         # Mapping from motors to encoders
         self.encoder_to_motor = get_encoder_to_motor_map(env.robot)
 
         # Whether stored reference to encoder measurements are already in the
@@ -305,85 +341,82 @@
         # Note that even if the robot instance may change from one simulation
         # to another, the observation and action spaces are required to stay
         # the same the whole time. This induces that the motors effort limit
         # must not change unlike the mapping from full state to motors.
         self.motors_effort_limit = env.robot.command_limit[
             env.robot.motor_velocity_indices]
 
-        # Extract the motors target position and velocity bounds from the model
+        # Extract the motors target position bounds from the model
         motors_position_lower: List[float] = []
         motors_position_upper: List[float] = []
         for motor_name in env.robot.motor_names:
             motor = env.robot.get_motor(motor_name)
             joint_type = jiminy.get_joint_type(
                 env.robot.pinocchio_model, motor.joint_index)
             if joint_type == jiminy.JointModelType.ROTARY_UNBOUNDED:
                 lower, upper = float("-inf"), float("inf")
             else:
                 motor_position_index = motor.joint_position_index
                 lower = env.robot.position_limit_lower[motor_position_index]
                 upper = env.robot.position_limit_upper[motor_position_index]
             motors_position_lower.append(lower + target_position_margin)
             motors_position_upper.append(upper - target_position_margin)
+
+        # Extract the motors target velocity bounds
         motors_velocity_limit = np.minimum(
             env.robot.velocity_limit[env.robot.motor_velocity_indices],
             target_velocity_limit)
-        command_state_lower = [
-            np.array(motors_position_lower), -motors_velocity_limit]
-        command_state_upper = [
-            np.array(motors_position_upper), motors_velocity_limit]
-
-        # Try to infers bounds for higher-order derivatives if necessary.
-        # They are tuned to allow for bang-bang control without restriction.
-        step_dt = env.step_dt
-        for i in range(2, order + 1):
-            range_limit = (
-                command_state_upper[-1] - command_state_lower[-1]) / step_dt
-            effort_limit = self.motors_effort_limit / (
-                self.kp * step_dt ** (i - 1) * INV_FACTORIAL_TABLE[i - 1] *
-                np.maximum(step_dt / i, self.kd))
-            n_order_limit = np.minimum(range_limit, effort_limit)
-            command_state_lower.append(-n_order_limit)
-            command_state_upper.append(n_order_limit)
-        self._command_state_lower = np.stack(command_state_lower, axis=0)
-        self._command_state_upper = np.stack(command_state_upper, axis=0)
+
+        # Compute acceleration bounds allowing unrestricted bang-bang control
+        range_limit = 2 * motors_velocity_limit / env.step_dt
+        effort_limit = self.motors_effort_limit / (
+            self.kp * env.step_dt * np.maximum(env.step_dt / 2, self.kd))
+        acceleration_limit = np.minimum(
+            np.minimum(range_limit, effort_limit), target_acceleration_limit)
+
+        # Compute command state bounds
+        self._command_state_lower = np.stack([np.array(motors_position_lower),
+                                              -motors_velocity_limit,
+                                              -acceleration_limit], axis=0)
+        self._command_state_upper = np.stack([np.array(motors_position_upper),
+                                              motors_velocity_limit,
+                                              acceleration_limit], axis=0)
 
         # Extract measured motor positions and velocities for fast access.
         # Note that they will be initialized in `_setup` method.
         self.q_measured, self.v_measured = np.array([]), np.array([])
 
         # Allocate memory for the command state
-        self._command_state = np.zeros((order + 1, env.robot.nmotors))
+        self._command_state = np.zeros((3, env.robot.nmotors))
 
         # Initialize the controller
         super().__init__(name, env, update_ratio)
 
-        # Reference to highest-order derivative for fast access
-        self._action = self._command_state[-1]
+        # References to command acceleration for fast access
+        self._command_acceleration = self._command_state[2]
 
     def _initialize_state_space(self) -> None:
         """Configure the state space of the controller.
 
-        The state spaces corresponds to all the derivatives of the target
-        motors positions up to order N-1.
+        The state spaces corresponds to the target motors positions and
+        velocities.
         """
         self.state_space = gym.spaces.Box(
-            low=self._command_state_lower[:-1],
-            high=self._command_state_upper[:-1],
+            low=self._command_state_lower[:2],
+            high=self._command_state_upper[:2],
             dtype=np.float64)
 
     def _initialize_action_space(self) -> None:
         """Configure the action space of the controller.
 
-        The action spaces corresponds to the N-th order derivative of the
-        target motors positions.
+        The action spaces corresponds to the target motors accelerations.
         """
         self.action_space = gym.spaces.Box(
-            low=self._command_state_lower[-1],
-            high=self._command_state_upper[-1],
+            low=self._command_state_lower[2],
+            high=self._command_state_upper[2],
             dtype=np.float64)
 
     def _setup(self) -> None:
         # Call base implementation
         super()._setup()
 
         # Make sure control update is discrete-time
@@ -396,63 +429,162 @@
             self.env.sensor_measurements[encoder.type])
 
         # Reset the command state
         fill(self._command_state, 0)
 
     @property
     def fieldnames(self) -> List[str]:
-        return [f"target{N_ORDER_DERIVATIVE_NAMES[self.order]}{name}"
+        return [f"currentTarget{N_ORDER_DERIVATIVE_NAMES[2]}{name}"
                 for name in self.env.robot.motor_names]
 
     def get_state(self) -> np.ndarray:
-        return self._command_state[:-1]
+        return self._command_state[:2]
 
-    def compute_command(self, action: np.ndarray) -> np.ndarray:
-        """Compute the motor torques using a PD controller.
+    def compute_command(self, action: np.ndarray, command: np.ndarray) -> None:
+        """Compute the target motor torques using a PD controller.
 
         It is proportional to the error between the observed motors positions/
         velocities and the target ones.
 
         .. warning::
             Calling this method manually while a simulation is running is
             forbidden, because it would mess with the controller update period.
 
-        :param action: Desired N-th order deriv. of the target motor positions.
+        :param action: Desired target motor acceleration.
+        :param command: Current motor torques that will be updated in-place.
         """
         # Re-initialize the command state to the current motor state if the
         # simulation is not running. This must be done here because the
         # command state must be valid prior to calling `refresh_observation`
         # for the first time, which happens at `reset`.
         is_simulation_running = self.env.is_simulation_running
         if not is_simulation_running:
             for i, value in enumerate((self.q_measured, self.v_measured)):
                 np.clip(value,
                         self._command_state_lower[i],
                         self._command_state_upper[i],
                         out=self._command_state[i])
 
-        # Update the highest order derivative of the target motor positions to
-        # match the provided action.
-        array_copyto(self._action, action)
-
-        # Dead band to avoid slow drift of target at rest for evaluation only
-        if not self.env.is_training:
-            self._action[np.abs(self._action) > EVAL_DEADBAND] = 0.0
-
         # Extract motor positions and velocity from encoder data
         q_measured, v_measured = self.q_measured, self.v_measured
         if not self._is_same_order:
             q_measured = q_measured[self.encoder_to_motor]
             v_measured = v_measured[self.encoder_to_motor]
 
+        # Update target motor accelerations
+        array_copyto(self._command_acceleration, action)
+
         # Compute the motor efforts using PD control.
         # The command state must not be updated if no simulation is running.
-        return pd_controller(
+        pd_controller(
             q_measured,
             v_measured,
             self._command_state,
             self._command_state_lower,
             self._command_state_upper,
             self.kp,
             self.kd,
             self.motors_effort_limit,
-            self.control_dt if is_simulation_running else 0.0)
+            self.control_dt if is_simulation_running else 0.0,
+            command)
+
+
+class PDAdapter(
+        BaseControllerBlock[np.ndarray, np.ndarray, BaseObsT, np.ndarray]):
+    """Adapt the action of a lower-level Proportional-Derivative controller
+    to be the target motor positions or velocities rather than accelerations.
+
+    The action is the desired value of some derivative of the target motor
+    positions. The target motor accelerations are then deduced so as to reach
+    this value by the next update of this controller if possible without
+    exceeding the position, velocity and acceleration bounds. Finally, these
+    target position accelerations are passed to a lower-level PD controller,
+    usually running at a higher frequency.
+
+    .. note::
+        The higher the derivative order of the action, the smoother the command
+        motor torques. Thus, a high order is generally beneficial for robotic
+        applications. However, it introduces some kind of delay between the
+        action and its effects. This phenomenon limits the responsiveness of
+        the agent and therefore impedes its optimal performance. Besides, it
+        introduces addition layer of indirection between the action and its
+        effect which may be difficult to grasp for the agent. Finally,
+        exploration usually consists in addition temporally uncorrelated
+        gaussian random process at action-level. The effect of such random
+        processes tends to vanish when integrated, making exploration very
+        inefficient.
+    """
+    def __init__(self,
+                 name: str,
+                 env: InterfaceJiminyEnv[BaseObsT, np.ndarray],
+                 *,
+                 update_ratio: int = -1,
+                 order: int = 1) -> None:
+        """
+        :param update_ratio: Ratio between the update period of the controller
+                             and the one of the subsequent controller. -1 to
+                             match the simulation timestep of the environment.
+                             Optional: -1 by default.
+        :param order: Derivative order of the action. It accepts position or
+                      velocity (respectively 0 or 1).
+                      Optional: 1 by default.
+        """
+        # Make sure that the specified derivative order is valid
+        assert order in (0, 1), "Derivative order out-of-bounds"
+
+        # Make sure that a PD controller block is already connected
+        controller = env.controller  # type: ignore[attr-defined]
+        if not isinstance(controller, PDController):
+            raise RuntimeError(
+                "This block must be directly connected to a lower-level "
+                "`PDController` block.")
+
+        # Backup some user argument(s)
+        self.order = order
+
+        # Define some proxies for convenience
+        self._pd_controller = controller
+
+        # Allocate memory for the target motor accelerations
+        self._target_accelerations = np.zeros((env.robot.nmotors,))
+
+        # Initialize the controller
+        super().__init__(name, env, update_ratio)
+
+    def _initialize_action_space(self) -> None:
+        """Configure the action space of the controller.
+
+        The action spaces corresponds to the N-th order derivative of the
+        target motors positions.
+        """
+        self.action_space = gym.spaces.Box(
+            low=self._pd_controller._command_state_lower[self.order],
+            high=self._pd_controller._command_state_upper[self.order],
+            dtype=np.float64)
+
+    def _setup(self) -> None:
+        # Call base implementation
+        super()._setup()
+
+        # Reset the target motor accelerations
+        fill(self._target_accelerations, 0)
+
+    @property
+    def fieldnames(self) -> List[str]:
+        return [f"nextTarget{N_ORDER_DERIVATIVE_NAMES[self.order]}{name}"
+                for name in self.env.robot.motor_names]
+
+    def compute_command(self, action: np.ndarray, command: np.ndarray) -> None:
+        """Compute the target motor accelerations from the desired value of
+        some derivative of the target motor positions.
+
+        :param action: Desired target motor acceleration.
+        :param command: Current motor torques that will be updated in-place.
+        """
+        pd_adapter(
+            action,
+            self.order,
+            self._pd_controller._command_state,
+            self._pd_controller._command_state_lower,
+            self._pd_controller._command_state_upper,
+            self.control_dt,
+            command)
```

## gym_jiminy/common/envs/generic.py

```diff
@@ -6,19 +6,18 @@
 import math
 import weakref
 import logging
 import tempfile
 from copy import deepcopy
 from collections import OrderedDict
 from collections.abc import Mapping
-from itertools import chain
 from functools import partial
 from typing import (
-    Dict, Any, List, cast, no_type_check, Optional, Tuple, Callable, Iterable,
-    Union, SupportsFloat, Iterator,  Generic, Sequence, Mapping as MappingT,
+    Dict, Any, List, cast, no_type_check, Optional, Tuple, Callable, Union,
+    SupportsFloat, Iterator,  Generic, Sequence, Mapping as MappingT,
     MutableMapping as MutableMappingT)
 
 import numpy as np
 from gymnasium import spaces
 from gymnasium.core import RenderFrame
 
 import jiminy_py.core as jiminy
@@ -52,14 +51,15 @@
                      register_variables)
 from ..bases import (ObsT,
                      ActT,
                      InfoType,
                      SensorMeasurementStackMap,
                      EngineObsType,
                      InterfaceJiminyEnv)
+from ..quantities import QuantityManager
 
 from .internal import loop_interactive
 
 
 # Maximum realtime slowdown of simulation steps before triggering timeout error
 TIMEOUT_RATIO = 10
 
@@ -148,14 +148,19 @@
                               the viewer when calling `render` method, unlike
                               `replay` which forwards extra keyword arguments.
                               Optional: None by default.
         :param kwargs: Extra keyword arguments that may be useful for derived
                        environments with multiple inheritance, and to allow
                        automatic pipeline wrapper generation.
         """
+        # Make sure that the simulator is single-robot
+        if tuple(robot.name for robot in simulator.robots) != ("",):
+            raise ValueError(
+                "`BaseJiminyEnv` only supports single-robot simulators.")
+
         # Handling of default rendering mode
         viewer_backend = (simulator.viewer or Viewer).backend
         if render_mode is None:
             # 'rgb_array' by default if the backend is or will be
             # 'panda3d-sync', otherwise 'human' if available.
             backend = (kwargs.get('backend') or viewer_backend or
                        simulator.viewer_kwargs.get('backend') or
@@ -183,15 +188,16 @@
         self.stepper_state = self.simulator.stepper_state
         self.is_simulation_running = self.simulator.is_simulation_running
         self.robot = self.simulator.robot
         self.robot_state = self.simulator.robot_state
         self._robot_state_q = np.array([])
         self._robot_state_v = np.array([])
         self._robot_state_a = np.array([])
-        self.sensor_measurements: SensorMeasurementStackMap = OrderedDict()
+        self.sensor_measurements: SensorMeasurementStackMap = OrderedDict(
+            self.robot.sensor_measurements)
 
         # Top-most block of the pipeline to which the environment is part of
         self._env_derived: InterfaceJiminyEnv = self
 
         # Store references to the variables to register to the telemetry
         self._registered_variables: MutableMappingT[
             str, Tuple[FieldNested, DataNested]] = {}
@@ -233,14 +239,17 @@
         if (BaseJiminyEnv.compute_command is type(self).compute_command and
                 BaseJiminyEnv._initialize_action_space is not
                 type(self)._initialize_action_space):
             raise NotImplementedError(
                 "`BaseJiminyEnv.compute_command` must be overloaded in case "
                 "of custom action spaces.")
 
+        # Initialize a quantity manager for later use
+        self.quantities = QuantityManager(self)
+
         # Define specialized operators for efficiency.
         # Note that a partial view of observation corresponding to measurement
         # must be extracted since only this one must be updated during refresh.
         self._copyto_action = build_copyto(self.action)
         self._contains_observation = build_contains(
             self.observation, self.observation_space, tol_rel=OBS_CONTAINS_TOL)
         self._contains_action = build_contains(self.action, self.action_space)
@@ -286,21 +295,21 @@
         Simulator directly, without having to do it through `simulator`.
 
         .. note::
             This method is not meant to be called manually.
         """
         return getattr(self.__getattribute__('simulator'), name)
 
-    def __dir__(self) -> Iterable[str]:
+    def __dir__(self) -> List[str]:
         """Attribute lookup.
 
         It is mainly used by autocomplete feature of Ipython. It is overloaded
         to get consistent autocompletion wrt `getattr`.
         """
-        return chain(super().__dir__(), dir(self.simulator))
+        return [*super().__dir__(), *dir(self.simulator)]
 
     def __del__(self) -> None:
         try:
             self.close()
         except Exception:   # pylint: disable=broad-except
             # This method must not fail under any circumstances
             pass
@@ -309,69 +318,47 @@
         """Get time space.
         """
         return spaces.Box(low=0.0,
                           high=self.simulation_duration_max,
                           shape=(),
                           dtype=np.float64)
 
-    def _get_agent_state_space(self,
-                               use_theoretical_model: Optional[bool] = None
-                               ) -> spaces.Dict:
+    def _get_agent_state_space(self) -> spaces.Dict:
         """Get state space.
 
         This method is not meant to be overloaded in general since the
         definition of the state space is mostly consensual. One must rather
         overload `_initialize_observation_space` to customize the observation
         space as a whole.
-
-        :param use_theoretical_model: Whether to compute the state space
-                                      corresponding to the theoretical model to
-                                      the actual one. `None` to use internal
-                                      value 'simulator.use_theoretical_model'.
-                                      Optional: `None` by default.
-        """
-        # Handling of default argument
-        if use_theoretical_model is None:
-            use_theoretical_model = self.simulator.use_theoretical_model
-
+        """
         # Define some proxies for convenience
         model_options = self.robot.get_model_options()
-        joint_position_indices = self.robot.rigid_joint_position_indices
-        joint_velocity_indices = self.robot.rigid_joint_velocity_indices
+        joint_velocity_indices = self.robot.mechanical_joint_velocity_indices
         position_limit_upper = self.robot.position_limit_upper
         position_limit_lower = self.robot.position_limit_lower
         velocity_limit = self.robot.velocity_limit
 
         # Replace inf bounds of the state space if requested
         if self.enforce_bounded_spaces:
             if self.robot.has_freeflyer:
                 position_limit_lower[:3] = -FREEFLYER_POS_TRANS_MAX
                 position_limit_upper[:3] = +FREEFLYER_POS_TRANS_MAX
                 velocity_limit[:3] = FREEFLYER_VEL_LIN_MAX
                 velocity_limit[3:6] = FREEFLYER_VEL_ANG_MAX
 
-            for joint_index in self.robot.flexible_joint_indices:
+            for joint_index in self.robot.flexibility_joint_indices:
                 joint_velocity_index = (
                     self.robot.pinocchio_model.joints[joint_index].idx_v)
                 velocity_limit[
                     joint_velocity_index + np.arange(3)] = FLEX_VEL_ANG_MAX
 
-            if not model_options['joints']['enablePositionLimit']:
-                position_limit_lower[joint_position_indices] = -JOINT_POS_MAX
-                position_limit_upper[joint_position_indices] = JOINT_POS_MAX
-
             if not model_options['joints']['enableVelocityLimit']:
                 velocity_limit[joint_velocity_indices] = JOINT_VEL_MAX
 
-        # Define bounds of the state space
-        if use_theoretical_model:
-            position_limit_lower = position_limit_lower[joint_position_indices]
-            position_limit_upper = position_limit_upper[joint_position_indices]
-            velocity_limit = velocity_limit[joint_velocity_indices]
-
+        # Aggregate position and velocity bounds to define state space
         return spaces.Dict(OrderedDict(
             q=spaces.Box(low=position_limit_lower,
                          high=position_limit_upper,
                          dtype=np.float64),
             v=spaces.Box(low=-velocity_limit,
                          high=velocity_limit,
                          dtype=np.float64)))
@@ -404,16 +391,15 @@
             definition of the sensor space is mostly consensual. One must
             rather overload `_initialize_observation_space` to customize the
             observation space as a whole.
         """
         # Define some proxies for convenience
         sensor_measurements = self.robot.sensor_measurements
         command_limit = self.robot.command_limit
-        position_space, velocity_space = self._get_agent_state_space(
-            use_theoretical_model=False).values()
+        position_space, velocity_space = self._get_agent_state_space().values()
         assert isinstance(position_space, spaces.Box)
         assert isinstance(velocity_space, spaces.Box)
 
         # Replace inf bounds of the action space
         for motor_name in self.robot.motor_names:
             motor = self.robot.get_motor(motor_name)
             motor_options = motor.get_options()
@@ -684,14 +670,15 @@
         if self.engine is not self.simulator.engine:
             raise RuntimeError(
                 "Changing the memory address of the low-level jiminy engine "
                 "is an undefined behavior.")
 
         # Re-initialize some shared memories.
         # It is necessary because the robot may have changed.
+        self.robot = self.simulator.robot
         self.robot_state = self.simulator.robot_state
         self.sensor_measurements = OrderedDict(self.robot.sensor_measurements)
 
         # Enforce the low-level controller.
         # The robot may have changed, for example it could be randomly
         # generated, which would corrupt the old controller. As a result, it is
         # necessary to either instantiate a new low-level controller and to
@@ -713,15 +700,15 @@
         if self.debug:
             fd, self.log_path = tempfile.mkstemp(suffix=".data")
             os.close(fd)
 
         # Extract the observer/controller update period.
         # The controller update period is used by default for the observer if
         # it was not specify by the user in `_setup`.
-        engine_options = self.simulator.engine.get_options()
+        engine_options = self.simulator.get_options()
         self.control_dt = float(
             engine_options['stepper']['controllerUpdatePeriod'])
         if self.observe_dt < 0.0:
             self.observe_dt = self.control_dt
 
         # Make sure that both the observer and the controller are running
         # faster than the environment to which it is attached for the action to
@@ -739,16 +726,15 @@
             control_update_ratio = round(self.step_dt / self.control_dt, 10)
             assert round(control_update_ratio) == control_update_ratio, (
                 "Controller update period must be a divisor of environment "
                 "simulation timestep")
 
         # Sample the initial state and reset the low-level engine
         q_init, v_init = self._sample_state()
-        if not jiminy.is_position_valid(
-                self.simulator.pinocchio_model, q_init):
+        if not jiminy.is_position_valid(self.robot.pinocchio_model, q_init):
             raise RuntimeError(
                 "The initial state provided by `_sample_state` is "
                 "inconsistent with the dimension or types of joints of the "
                 "model.")
 
         # Set robot in initial configuration
         pin.framesForwardKinematics(
@@ -760,14 +746,20 @@
         # computations may require valid sensor data, such as normalized
         # quaternion or non-zero linear acceleration.
         a_init, u_motor = (np.zeros(self.robot.nv),) * 2
         f_external = [pin.Force.Zero(),] * self.robot.pinocchio_model.njoints
         self.robot.compute_sensor_measurements(
             0.0, q_init, v_init, a_init, u_motor, f_external)
 
+        # Re-initialize the quantity manager.
+        # Note that computation graph tracking is never reset automatically.
+        # It is the responsibility of the practitioner implementing a derived
+        # environment whenever it makes sense for its specific use-case.
+        self.quantities.reset(reset_tracking=False)
+
         # Run the reset hook if any.
         # Note that the reset hook must be called after `_setup` because it
         # expects that the robot is not going to change anymore at this point.
         # Similarly, the observer and controller update periods must be set.
         reset_hook: Optional[Callable[[], InterfaceJiminyEnv]] = (
             options or {}).get("reset_hook")
         env: InterfaceJiminyEnv = self
@@ -787,16 +779,15 @@
         self.max_steps = int(self.simulation_duration_max // self.step_dt)
 
         # Register user-specified variables to the telemetry
         for header, value in self._registered_variables.values():
             register_variables(self.robot.controller, header, value)
 
         # Start the engine
-        self.simulator.start(
-            q_init, v_init, None, self.simulator.use_theoretical_model)
+        self.simulator.start(q_init, v_init)
 
         # Refresh robot_state proxies. It must be done here because memory is
         # only allocated by the engine when starting a simulation.
         self._robot_state_q = self.robot_state.q
         self._robot_state_v = self.robot_state.v
         self._robot_state_a = self.robot_state.a
 
@@ -842,17 +833,19 @@
 
         # Reset cumulative reward
         self.total_reward = 0.0
 
         # Note that the viewer must be reset if available, otherwise it would
         # keep using the old robot model for display, which must be avoided.
         if self.simulator.is_viewer_available:
-            self.simulator.viewer._setup(self.robot)
-            if self.simulator.viewer.has_gui():
-                self.simulator.viewer.refresh()
+            viewer = self.simulator.viewer
+            assert viewer is not None  # Assert(s) for type checker
+            viewer._setup(self.robot)  # type: ignore[attr-defined]
+            if viewer.has_gui():
+                viewer.refresh()
 
         return obs, deepcopy(self._info)
 
     def close(self) -> None:
         """Clean up the environment after the user has finished using it.
 
         It terminates the Python Jiminy engine.
@@ -1004,61 +997,70 @@
         if self.render_mode == 'human' and viewer_backend == "panda3d-sync":
             Viewer.close()
 
         # Call base implementation
         return self.simulator.render(  # type: ignore[return-value]
             return_rgb_array=self.render_mode == 'rgb_array')
 
-    def plot(self, **kwargs: Any) -> TabbedFigure:
+    def plot(self,
+             enable_block_states: bool = False,
+             **kwargs: Any) -> TabbedFigure:
         """Display common simulation data and action over time.
 
         .. Note:
-            It adds "Action" tab on top of original `Simulator.plot`.
+            It adds tabs for the base environment action plus all blocks
+            ((state, action) for controllers and (state, features) for
+            observers) on top of original `Simulator.plot`.
 
+        :param enable_block_states: Whether to display the internal state of
+                                    all blocks.
         :param kwargs: Extra keyword arguments to forward to `simulator.plot`.
         """
         # Call base implementation
         figure = self.simulator.plot(**kwargs)
 
         # Extract log data
         log_vars = self.simulator.log_data.get("variables", {})
         if not log_vars:
             raise RuntimeError(
                 "Nothing to plot. Please run a simulation before calling "
                 "`plot` method.")
 
-        # Extract action.
-        # If telemetry action fieldnames is a dictionary, it cannot be nested.
-        # In such a case, keys corresponds to subplots, and values are
-        # individual scalar data over time to be displayed to the same subplot.
-        t = log_vars["Global.Time"]
-        tab_data: Dict[str, Union[np.ndarray, Dict[str, np.ndarray]]] = {}
-        action_fieldnames = self.log_fieldnames.get("action")
-        if action_fieldnames is None:
-            # It was impossible to register the action to the telemetry, likely
-            # because of incompatible dtype. Early return without adding tab.
-            return figure
-        if isinstance(action_fieldnames, dict):
-            for group, fieldnames in action_fieldnames.items():
-                if not isinstance(fieldnames, list):
-                    LOGGER.error(
-                        "Action space not supported by this method.")
-                    return figure
-                tab_data[group] = {
+        # Plot all registered variables
+        for key, fieldnames in self.log_fieldnames.items():
+            # Filter state if requested
+            if not enable_block_states and key.endswith(".state"):
+                continue
+
+            # Extract action hierarchical time series.
+            # Fieldnames stored in a dictionary cannot be nested. In such a
+            # case, keys corresponds to subplots, and values are individual
+            # scalar data over time to be displayed to the same subplot.
+            t = log_vars["Global.Time"]
+            tab_data: Dict[str, Union[np.ndarray, Dict[str, np.ndarray]]] = {}
+            if isinstance(fieldnames, dict):
+                for group, subfieldnames in fieldnames.items():
+                    if not isinstance(subfieldnames, list):
+                        LOGGER.error(
+                            "Action space not supported by this method.")
+                        return figure
+                    value_map = extract_variables_from_log(
+                        log_vars, subfieldnames, "controller", as_dict=True)
+                    tab_data[group] = {
+                        key.split(".", 2)[2]: value
+                        for key, value in value_map.items()}
+            elif isinstance(fieldnames, list):
+                value_map = extract_variables_from_log(
+                    log_vars, fieldnames, "controller", as_dict=True)
+                tab_data.update({
                     key.split(".", 2)[2]: value
-                    for key, value in extract_variables_from_log(
-                        log_vars, fieldnames, as_dict=True).items()}
-        elif isinstance(action_fieldnames, list):
-            tab_data.update({
-                key.split(".", 2)[2]: value
-                for key, value in extract_variables_from_log(
-                    log_vars, action_fieldnames, as_dict=True).items()})
+                    for key, value in value_map.items()})
 
-        # Add action tab
-        figure.add_tab(" ".join(("Env", "Action")), t, tab_data)
+            # Add action tab
+            figure.add_tab(key.replace(".", " "), t, tab_data)
 
         # Return figure for convenience and consistency with Matplotlib
         return figure
 
     def replay(self, **kwargs: Any) -> None:
         """Replay the current episode until now.
 
@@ -1128,34 +1130,37 @@
         is_training = self.is_training
         self._is_interactive = True
         if is_training:
             self.eval()
 
         # Make sure viewer gui is open, so that the viewer will shared external
         # forces with the robot automatically.
-        if not (self.simulator.is_viewer_available and
-                self.simulator.viewer.has_gui()):
+        viewer = self.simulator.viewer
+        if viewer is None or not viewer.has_gui():
             self.simulator.render(update_ground_profile=False)
 
         # Reset the environnement
         self.reset()
         obs = self.observation
         reward = None
 
         # Refresh the ground profile
         self.simulator.render(update_ground_profile=True)
+        viewer = self.simulator.viewer
+        assert viewer is not None  # Assert(s) for type checker
 
         # Enable travelling
         if enable_travelling is None:
-            enable_travelling = \
-                self.simulator.viewer.backend.startswith('panda3d')
+            backend = viewer.backend
+            assert backend is not None  # Assert(s) for type checker
+            enable_travelling = backend.startswith('panda3d')
         enable_travelling = enable_travelling and self.robot.has_freeflyer
         if enable_travelling:
             tracked_frame = self.robot.pinocchio_model.frames[2].name
-            self.simulator.viewer.attach_camera(tracked_frame)
+            viewer.attach_camera(tracked_frame)
 
         # Refresh the scene once again to update camera placement
         self.render()
 
         # Define interactive loop
         def _interact(key: Optional[str] = None) -> bool:
             nonlocal obs, reward, enable_is_done
@@ -1174,15 +1179,15 @@
         # Run interactive loop
         loop_interactive(max_rate=self.step_dt,
                          start_paused=start_paused,
                          verbose=verbose)(_interact)()
 
         # Disable travelling if it enabled
         if enable_travelling:
-            self.simulator.viewer.detach_camera()
+            viewer.detach_camera()
 
         # Stop the simulation to unlock the robot.
         # It will enable to display contact forces for replay.
         if self.simulator.is_simulation_running:
             self.simulator.stop()
 
         # Disable play interactive mode flag and restore training flag
@@ -1306,15 +1311,15 @@
         .. note::
             This method is called internally by `reset` methods.
         """
         # Call base implementation
         super()._setup()
 
         # Configure the low-level integrator
-        engine_options = self.simulator.engine.get_options()
+        engine_options = self.simulator.get_options()
         engine_options["stepper"]["iterMax"] = 0
         if self.debug:
             engine_options["stepper"]["verbose"] = True
             engine_options["stepper"]["logInternalStepperSteps"] = True
 
         # Set maximum computation time for single internal integration steps
         engine_options["stepper"]["timeout"] = self.step_dt * TIMEOUT_RATIO
@@ -1322,15 +1327,15 @@
             engine_options["stepper"]["timeout"] = 0.0
 
         # Force disabling logging of geometries unless in debug or eval modes
         if self.is_training and not self.debug:
             engine_options["telemetry"]["isPersistent"] = False
 
         # Update engine options
-        self.simulator.engine.set_options(engine_options)
+        self.simulator.set_options(engine_options)
 
     def _initialize_observation_space(self) -> None:
         """Configure the observation of the environment.
 
         By default, the observation is a dictionary gathering the current
         simulation time, the real agent state, and the sensors data.
 
@@ -1362,25 +1367,21 @@
             This method is called internally by '_sample_state' to generate the
             initial state. It can be overloaded to ensure static stability of
             the configuration.
         """
         # Get the neutral configuration of the actual model
         q = pin.neutral(self.robot.pinocchio_model)
 
-        # Make sure it is not out-of-bounds
+        # Make sure it is not out-of-bounds before returning
         position_limit_lower = self.robot.position_limit_lower
         position_limit_upper = self.robot.position_limit_upper
         for idx, val in enumerate(q):
             lo, hi = position_limit_lower[idx], position_limit_upper[idx]
             if hi < val or val < lo:
                 q[idx] = 0.5 * (lo + hi)
-
-        # Return rigid/flexible configuration
-        if self.simulator.use_theoretical_model:
-            return q[self.robot.rigid_joint_position_indices]
         return q
 
     def _sample_state(self) -> Tuple[np.ndarray, np.ndarray]:
         """Returns a randomized yet valid configuration and velocity for the
         robot.
 
         The default implementation returns the neutral configuration and zero
@@ -1402,30 +1403,30 @@
                out=q)
 
         # Make sure the configuration is normalized
         q = pin.normalize(self.robot.pinocchio_model, q)
 
         # Make sure the robot impacts the ground
         if self.robot.has_freeflyer:
-            engine_options = self.simulator.engine.get_options()
+            engine_options = self.simulator.get_options()
             ground_fun = engine_options['world']['groundProfile']
             compute_freeflyer_state_from_fixed_body(
                 self.robot, q, ground_profile=ground_fun)
 
         # Zero velocity
         v = np.zeros(self.robot.pinocchio_model.nv)
 
         return q, v
 
     def _initialize_buffers(self) -> None:
         """Initialize internal buffers for fast access to shared memory or to
         avoid redundant computations.
 
         .. note::
-            This method is called at `reset`, right after
+            This method is called at every `reset`, right after
             `self.simulator.start`. At this point, the simulation is running
             but `refresh_observation` has never been called, so that it can be
             used to initialize buffers involving the engine state but required
             to refresh the observation.
 
         .. note::
             Buffers requiring manual update must be refreshed using
@@ -1493,36 +1494,36 @@
         array_copyto(agent_state_out['q'], agent_state_in['q'])
         array_copyto(agent_state_out['v'], agent_state_in['v'])
         sensors_out = observation['measurements']
         sensors_in = measurement['measurements']
         for sensor_type in self._sensors_types:
             array_copyto(sensors_out[sensor_type], sensors_in[sensor_type])
 
-    def compute_command(self, action: ActT) -> np.ndarray:
+    def compute_command(self, action: ActT, command: np.ndarray) -> None:
         """Compute the motors efforts to apply on the robot.
 
-        By default, it is forward the input action as is, without performing
-        any processing. One is responsible of overloading this method if the
-        action space has been customized, or just to clip the action to make
-        sure it is never out-of-bounds if necessary.
+        By default, all it does is forwarding the input action as is, without
+        performing any processing. One is responsible of overloading this
+        method if the action space has been customized, or just to clip the
+        action to make sure it is never out-of-bounds if necessary.
 
         .. warning::
             There is not good place to initialize buffers that are necessary to
             compute the command. The only solution for now is to define
             initialization inside this method itself, using the safeguard
             `if not self.is_simulation_running:`.
 
         :param action: High-level target to achieve by means of the command.
         """
         # Check if the action is out-of-bounds, in debug mode only
         if self.debug and not self._contains_action():
             LOGGER.warning("The action is out-of-bounds.")
 
         assert isinstance(action, np.ndarray)
-        return action
+        array_copyto(command, action)
 
     def has_terminated(self) -> Tuple[bool, bool]:
         """Determine whether the episode is over, because a terminal state of
         the underlying MDP has been reached or an aborting condition outside
         the scope of the MDP has been triggered.
 
         By default, it always returns `terminated=False`, and `truncated=True`
```

## gym_jiminy/common/envs/locomotion.py

```diff
@@ -1,22 +1,25 @@
 """Generic environment to learn locomotion skills for legged robots using
 Jiminy simulator as physics engine.
 """
+import os
+import pathlib
 from typing import Optional, Dict, Union, Any, Type, Sequence, Tuple
 
 import numpy as np
 
 from jiminy_py.core import (  # pylint: disable=no-name-in-module
     EncoderSensor as encoder,
     EffortSensor as effort,
     ContactSensor as contact,
     ForceSensor as force,
     ImuSensor as imu,
     PeriodicGaussianProcess,
     Robot)
+from jiminy_py.robot import BaseJiminyRobot
 from jiminy_py.simulator import Simulator
 
 import pinocchio as pin
 
 from ..utils import sample
 from ..bases import InfoType
 from .generic import BaseJiminyEnv
@@ -175,20 +178,35 @@
                 hardware_path=self.hardware_path,
                 mesh_path_dir=self.mesh_path_dir,
                 config_path=self.config_path,
                 avoid_instable_collisions=self.avoid_instable_collisions,
                 debug=debug,
                 viewer_kwargs=viewer_kwargs,
                 **{**dict(
-                    has_freeflyer=True,
-                    use_theoretical_model=False),
+                    has_freeflyer=True),
                     **kwargs})
         else:
-            # Instantiate a simulator and load the options
+            # Instantiate a simulator
             simulator = Simulator(robot, viewer_kwargs=viewer_kwargs, **kwargs)
+
+            # Load engine and robot options
+            if config_path is None:
+                if isinstance(robot, BaseJiminyRobot):
+                    urdf_path = (
+                        robot._urdf_path_orig)  # type: ignore[attr-defined]
+                else:
+                    urdf_path = robot.urdf_path
+                if not urdf_path:
+                    raise ValueError(
+                        "'config_path' must be provided if the robot is not "
+                        "associated with any URDF.")
+                config_path = str(pathlib.Path(
+                    urdf_path).with_suffix('')) + '_options.toml'
+                if not os.path.exists(config_path):
+                    config_path = ""
             simulator.import_options(config_path)
 
         # Initialize base class
         super().__init__(
             simulator, step_dt, enforce_bounded_spaces, debug, **kwargs)
 
     def _setup(self) -> None:
@@ -225,15 +243,15 @@
         # Compute the height of the freeflyer in neutral configuration
         # TODO: Take into account the ground profile.
         q_init, _ = self._sample_state()
         self._height_neutral = q_init[2]
 
         # Get the options of robot and engine
         robot_options = self.robot.get_options()
-        engine_options = self.simulator.engine.get_options()
+        engine_options = self.simulator.get_options()
 
         # Make sure to log at least the required data for terminal reward
         # computation and log replay.
         engine_options['telemetry']['enableConfiguration'] = True
         engine_options['telemetry']['enableVelocity'] = True
         engine_options['telemetry']['enableForceExternal'] = \
             'disturbance' in self.std_ratio.keys()
@@ -268,15 +286,15 @@
                             scale=(self.std_ratio['sensors'] *
                                    SENSOR_NOISE_SCALE[sensor.type]),
                             shape=(len(sensor.fieldnames),),
                             rg=self.np_random)
 
         # Randomize the flexibility parameters
         if 'model' in self.std_ratio.keys():
-            if self.robot.is_flexible:
+            if self.robot.is_flexibility_enabled:
                 dynamics_options = robot_options["model"]["dynamics"]
                 for flexibility in dynamics_options["flexibilityConfig"]:
                     flexibility['stiffness'] += FLEX_STIFFNESS_SCALE * sample(
                         scale=self.std_ratio['model'], rg=self.np_random)
                     flexibility['damping'] += FLEX_DAMPING_SCALE * sample(
                         scale=self.std_ratio['model'], rg=self.np_random)
 
@@ -312,15 +330,15 @@
             for func in self._f_xy_profile:
                 func.reset(self.np_random)
             self.simulator.register_profile_force(
                 frame_name, self._force_external_profile)
 
         # Set the options, finally
         self.robot.set_options(robot_options)
-        self.simulator.engine.set_options(engine_options)
+        self.simulator.set_options(engine_options)
 
     def _force_external_profile(self,
                                 t: float,
                                 q: np.ndarray,
                                 v: np.ndarray,
                                 wrench: np.ndarray) -> None:
         """User-specified processing of external force profiles.
@@ -402,16 +420,16 @@
             if 'failure' in reward_mixture_keys:
                 reward_dict['failure'] = - 1.0
 
             # Add a negative reward proportional to the average deviation on
             # Y-axis. It is equal to 0.0 if the frontal displacement is
             # perfectly symmetric wrt Y-axis over the whole trajectory.
             if 'direction' in reward_mixture_keys:
-                frontal_displacement = abs(np.mean(self.log_data[
-                    'HighLevelController.currentFreeflyerPositionTransY']))
+                frontal_displacement = abs(np.mean(
+                    self.log_data['currentFreeflyerPositionTransY']))
                 reward_dict['direction'] = - frontal_displacement
 
         # Compute the total reward
         reward_total = sum(self.reward_mixture[name] * value
                            for name, value in reward_dict.items())
 
         return reward_total
```

## gym_jiminy/common/utils/__init__.py

```diff
@@ -9,14 +9,15 @@
                    quat_to_rpy,
                    quat_to_yaw,
                    quat_to_yaw_cos_sin,
                    quat_multiply,
                    quat_average,
                    rpy_to_matrix,
                    rpy_to_quat,
+                   transforms_to_vector,
                    compute_tilt_from_quat,
                    swing_from_vector,
                    remove_twist_from_quat)
 from .spaces import (DataNested,
                      FieldNested,
                      ArrayOrScalar,
                      get_bounds,
@@ -51,14 +52,15 @@
     'quat_to_rpy',
     'quat_to_yaw',
     'quat_to_yaw_cos_sin',
     'quat_multiply',
     'quat_average',
     'rpy_to_matrix',
     'rpy_to_quat',
+    'transforms_to_vector',
     'compute_tilt_from_quat',
     'swing_from_vector',
     'remove_twist_from_quat',
     'DataNested',
     'FieldNested',
     'ArrayOrScalar',
     'get_bounds',
```

## gym_jiminy/common/utils/math.py

```diff
@@ -20,23 +20,35 @@
     """Fast implementation of the sum of squared array elements, optimized for
     small to medium size 1D arrays.
     """
     return np.sum(np.square(array))
 
 
 @nb.jit(nopython=True, cache=True)
-def matrix_to_yaw(mat: np.ndarray) -> float:
+def matrix_to_yaw(mat: np.ndarray,
+                  out: Optional[np.ndarray] = None
+                  ) -> Union[float, np.ndarray]:
     """Compute the yaw from Yaw-Pitch-Roll Euler angles representation of a
     rotation matrix in 3D Euclidean space.
 
     :param mat: N-dimensional array whose first and second dimensions gathers
                 the 3-by-3 rotation matrix elements.
     """
     assert mat.ndim >= 2
-    return np.arctan2(mat[1, 0], mat[0, 0])
+
+    # Allocate memory for the output array
+    if out is None:
+        out_ = np.empty(mat.shape[2:])
+    else:
+        assert out.shape == mat.shape[2:]
+        out_ = out
+
+    out_[:] = np.arctan2(mat[1, 0], mat[0, 0])
+
+    return out_
 
 
 @nb.jit(nopython=True, cache=True, inline='always')
 def quat_to_yaw_cos_sin(quat: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
     """Compute cosine and sine of the yaw from Yaw-Pitch-Roll Euler angles
     representation of a single or a batch of quaternions.
 
@@ -212,14 +224,53 @@
                 out_[2][i] = mat[1, 0] - mat[0, 1]
                 out_[3][i] = t[i]
     out_ /= 2 * np.sqrt(t)
     return out_
 
 
 @nb.jit(nopython=True, cache=True)
+def transforms_to_vector(
+        transform_list: Tuple[Tuple[np.ndarray, np.ndarray], ...],
+        out: Optional[np.ndarray] = None) -> np.ndarray:
+    """Stack the translation vector [x, y, z] and the quaternion representation
+    [qx, qy, qz, qw] of the orientation of multiple transform tuples.
+
+    .. note::
+        Internally, it copies the translation unaffected and convert rotation
+        matrices to quaternions using `matrices_to_quat`.
+
+    :param transform_list: Tuple of N transforms, each of which represented as
+                           pairs gathering the translation as a vector and the
+                           orientation as a 3D rotation matrix.
+    :param out: A pre-allocated array into which the result is stored. If not
+                provided, a new array is freshly-allocated, which is slower.
+    """
+    # Allocate memory if necessart
+    if out is None:
+        out_ = np.empty((7, len(transform_list)))
+    else:
+        out2d = out[:, np.newaxis] if out.ndim == 1 else out
+        assert out2d.shape == (7, len(transform_list))
+        out_ = out2d
+
+    # Simply copy the translation
+    for i, (translation, _) in enumerate(transform_list):
+        out_[:3, i] = translation
+
+    # Convert all rotation matrices to quaternions at once
+    rotation_list = [rotation for _, rotation in transform_list]
+    matrices_to_quat(rotation_list, out_[-4:])
+
+    # Revel extra dimension before returning if not present initially
+    if out is not None and out.ndim == 1:
+        return out_[:, 0]
+    return out_
+
+
+@nb.jit(nopython=True, cache=True)
 def rpy_to_matrix(rpy: np.ndarray,
                   out: Optional[np.ndarray] = None) -> np.ndarray:
     """Compute the Rotation Matrix representation of a single or a
     batch of Yaw-Pitch-Roll Euler angles.
 
     :param rpy: N-dimensional array whose first dimension gathers the 3
                 Yaw-Pitch-Roll Euler angles [Roll, Pitch, Yaw].
```

## gym_jiminy/common/utils/misc.py

```diff
@@ -22,16 +22,16 @@
 
 
 FieldNestedSequence = Sequence[Union['FieldNestedSequence', str]]
 FieldNestedList = List[Union[FieldNestedSequence, str]]
 
 
 class RandomDistribution(Protocol):
-    """Protocol to be satisfied when passing generic statistical distribution
-    callable to `sample` method.
+    """Protocol that must be satisfied for passing a generic callable as
+    custom statistical distribution to `sample` method.
     """
     def __call__(self, rg: np.random.Generator, *args: Any, **kwargs: Any
                  ) -> ArrayOrScalar:
         ...
 
 
 @nb.jit(nopython=True, cache=True, inline='always')
@@ -91,15 +91,15 @@
             fieldname = []
         elif data.size == 1:
             # Scalar: fieldname path is enough
             fieldname = [".".join(map(str, filter(None, fieldname_path)))]
         else:
             # Tensor: basic numbering
             fieldname = np.array([
-                ".".join(map(str, filter(None, (*fieldname_path, i))))
+                ".".join(map(str, (*filter(None, fieldname_path), i)))
                 for i in range(data.size)]).reshape(data.shape).tolist()
         fieldnames.append(fieldname)
 
     return tree.unflatten_as(structure, fieldnames)
 
 
 def register_variables(controller: jiminy.AbstractController,
```

## gym_jiminy/common/wrappers/observation_stack.py

```diff
@@ -246,16 +246,16 @@
         if self.is_simulation_running and is_breakpoint(
                 self.stepper_state.t, self.env.observe_dt, DT_EPS):
             self.__n_last_stack += 1
         if self.__n_last_stack == self.skip_frames_ratio:
             self.__n_last_stack = -1
             self.wrapper.refresh_observation(self.env.observation)
 
-    def compute_command(self, action: ActT) -> np.ndarray:
+    def compute_command(self, action: ActT, command: np.ndarray) -> None:
         """Compute the motors efforts to apply on the robot.
 
         It simply forwards the command computed by the wrapped environment
         without any processing.
 
         :param action: High-level target to achieve by means of the command.
         """
-        return self.env.compute_command(action)
+        self.env.compute_command(action, command)
```

## Comparing `gym_jiminy-1.8.3.dist-info/METADATA` & `gym_jiminy-1.8.4.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 Metadata-Version: 2.1
 Name: gym-jiminy
-Version: 1.8.3
+Version: 1.8.4
 Summary: Python-native OpenAI Gym interface between Jiminy open-source simulator and Reinforcement Learning frameworks.
 Home-page: https://github.com/duburcqa/jiminy
-Download-URL: https://github.com/duburcqa/jiminy/archive/1.8.3.tar.gz
+Download-URL: https://github.com/duburcqa/jiminy/archive/1.8.4.tar.gz
 Author: Alexis Duburcq
 Author-email: alexis.duburcq@gmail.com
 Maintainer: Alexis Duburcq
 License: MIT
 Keywords: reinforcement-learning robotics gym jiminy
 Classifier: Development Status :: 3 - Alpha
 Classifier: Intended Audience :: Science/Research
@@ -16,23 +16,23 @@
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: 3.12
 Requires-Python: >=3.8,<3.13
-Requires-Dist: jiminy-py ~=1.8.3
+Requires-Dist: jiminy-py ~=1.8.4
 Requires-Dist: numpy
 Requires-Dist: numba >=0.54.0
-Requires-Dist: gymnasium <0.29,>=0.26
+Requires-Dist: gymnasium <1.0,>=0.28
 Requires-Dist: typing-extensions
 Provides-Extra: all
-Requires-Dist: gym-jiminy-zoo ~=1.8.3 ; extra == 'all'
-Requires-Dist: gym-jiminy-toolbox ~=1.8.3 ; extra == 'all'
-Requires-Dist: gym-jiminy-rllib ~=1.8.3 ; extra == 'all'
+Requires-Dist: gym-jiminy-zoo ~=1.8.4 ; extra == 'all'
+Requires-Dist: gym-jiminy-rllib ~=1.8.4 ; extra == 'all'
+Requires-Dist: gym-jiminy-toolbox ~=1.8.4 ; extra == 'all'
 Provides-Extra: rllib
-Requires-Dist: gym-jiminy-rllib ~=1.8.3 ; extra == 'rllib'
+Requires-Dist: gym-jiminy-rllib ~=1.8.4 ; extra == 'rllib'
 Provides-Extra: toolbox
-Requires-Dist: gym-jiminy-toolbox ~=1.8.3 ; extra == 'toolbox'
+Requires-Dist: gym-jiminy-toolbox ~=1.8.4 ; extra == 'toolbox'
 Provides-Extra: zoo
-Requires-Dist: gym-jiminy-zoo ~=1.8.3 ; extra == 'zoo'
+Requires-Dist: gym-jiminy-zoo ~=1.8.4 ; extra == 'zoo'
```

## Comparing `gym_jiminy-1.8.3.dist-info/RECORD` & `gym_jiminy-1.8.4.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,30 +1,35 @@
 gym_jiminy/common/__init__.py,sha256=8BemhrCxALdOEEKFpFRutfsu4t2guZIMIIpjx0bIU08,230
 gym_jiminy/common/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-gym_jiminy/common/bases/__init__.py,sha256=l09iWLyhcOE2k7b0NfUBlHmfFIQ92DlgT7ibCNP9Iww,1312
-gym_jiminy/common/bases/blocks.py,sha256=6V1GtSWv9_w9HXEZzDsnmXJMQcbiJX1pRn9zntXeYMQ,10474
-gym_jiminy/common/bases/interfaces.py,sha256=Jce5oDh5HHBVFJq9YLXMPiVldlAQT0NfC3BaTF11D8A,13795
-gym_jiminy/common/bases/pipeline.py,sha256=gk8Ewg0dq5XWBg3Qj_XybdrO7M9JsJ8GOfEqLhptTEY,40133
-gym_jiminy/common/blocks/__init__.py,sha256=Gj0FfXqNoK6T8kGkmOdzA8wAYZY8wQ8WjkFW9XqUIEM,357
-gym_jiminy/common/blocks/deformation_estimator.py,sha256=EcRXsJ_dfC0WZMVCqFO__j0bYodwOAtBb8KOywZBerY,37300
+gym_jiminy/common/bases/__init__.py,sha256=RZQ8V3sEuFqAv3hiNE71FklTWTfAU6cXi57To6fo2Eg,1495
+gym_jiminy/common/bases/blocks.py,sha256=jYyInWm3d2LWrBDmO1wh2TsTnrzJ1lYANIdpPlxoURw,10466
+gym_jiminy/common/bases/interfaces.py,sha256=yXvuXZDSi3HBo51EG-SVd_drMMNiq59ZZqsk4Ls7XSM,14577
+gym_jiminy/common/bases/pipeline.py,sha256=KWt2hGT6gsl3qSI0IhpF1kzFl2Ya1Yrdp_Mgbho7Qmg,40682
+gym_jiminy/common/bases/quantity.py,sha256=HWSSByxc1RPQReCZqTgQi2pQpOcUBBH1jduwPdiPraY,18035
+gym_jiminy/common/blocks/__init__.py,sha256=zpuD5GgmxEUAAWih0H-Zwy_JF8BlouStEAAPKQ5koWc,385
+gym_jiminy/common/blocks/deformation_estimator.py,sha256=1T1ZAvaqOdwl6mKQ3jZ0jFxgQ7SWQnT3sP56GWl2ekY,37430
 gym_jiminy/common/blocks/mahony_filter.py,sha256=3JwBb1ushRwOXKPvbitbYVlqwU-Pooth-sgCJQbJvoY,17212
-gym_jiminy/common/blocks/motor_safety_limit.py,sha256=B3Wr_WuB8RhSxweQ8negM3RrAPe0XRz1fM0v-A14y0I,9877
-gym_jiminy/common/blocks/proportional_derivative_controller.py,sha256=6Pm-OotSQU4pex5r_Undgof2wqLfnTJohvD9sxEUQjI,20573
+gym_jiminy/common/blocks/motor_safety_limit.py,sha256=3H_6gzkXTbM-nYyTYiVh3I4BP25DXFKci6dhXMNd0EA,10089
+gym_jiminy/common/blocks/proportional_derivative_controller.py,sha256=fQN0XUvBXdDgJpLMHxMs0TEqtmkE3oNSc84v5nid-oI,26392
 gym_jiminy/common/envs/__init__.py,sha256=A5GYVURVmtE_IIPZfBliGhvfwSvifbZmkNWlLClRUO4,178
-gym_jiminy/common/envs/generic.py,sha256=PvdK1IrZ9MjNNgGcEdTJxRsaTgCECvRHuYE4Rax2AQw,69409
-gym_jiminy/common/envs/locomotion.py,sha256=CdFaY-1NKBAYrm8mcEn412F0Y18bIQHyj8U0NHag1VE,18049
+gym_jiminy/common/envs/generic.py,sha256=jWXuImtGi8JqGG90GBV-SMNyhND5eowWo5Br2FIoeX8,69411
+gym_jiminy/common/envs/locomotion.py,sha256=iU2-3bYCtGV70QxymSESW99oD-bHIvv8Q8UDKv9yO4w,18748
 gym_jiminy/common/envs/internal/__init__.py,sha256=TKkRy9iC7oL2yPlYzQBPXeJ5h7yEVbJlOfR2-ZKkcKw,118
 gym_jiminy/common/envs/internal/play.py,sha256=Rh87t2tL4HzpON0fihDwxYIMEK-w5xWjoVi_VYwsFsI,9350
-gym_jiminy/common/utils/__init__.py,sha256=FQSLifJqLYyoZgguUH-p4p2jGnV4sHLHPMX0hNGQlOI,2194
-gym_jiminy/common/utils/math.py,sha256=UY5xM0VrsfDROY7-KZV5kBKPInPJoUw3_Dnc-qNTvYk,19135
-gym_jiminy/common/utils/misc.py,sha256=3qJZAtdGEkchi3C1pskhNDZy1gE4TlKZ2DOQ8guwC4s,8954
+gym_jiminy/common/quantities/__init__.py,sha256=YtyCZAotxhOJzwFKyXvlKIbJteTLgvvtqIfIuxtUS6E,367
+gym_jiminy/common/quantities/generic.py,sha256=aIn-mHJEmAuai75SeSM2yt7_3VxBdBxu62Hw9PNW-iU,11600
+gym_jiminy/common/quantities/locomotion.py,sha256=7LV4FiJ978gdK7TGV7VR-B02vBTkOrwXYvl8TD3Ma0k,4496
+gym_jiminy/common/quantities/manager.py,sha256=AG7BGubkqaIq1uEqF6qfXdG3CSVv4S31MdFXVnqADBo,7024
+gym_jiminy/common/utils/__init__.py,sha256=3i9o-zWgW24CWIDEwoT6BVj8hEUFZ_vEWBmiqriNggc,2263
+gym_jiminy/common/utils/math.py,sha256=XjP4Gx1CGqfmjPaeEBCje_lUXs65_s6bJcDgGmKTWfQ,21000
+gym_jiminy/common/utils/misc.py,sha256=-om0HJumO-7aj3XayVSgDTNwG9-o-TmuY5ZZk5_TpX4,8972
 gym_jiminy/common/utils/pipeline.py,sha256=Zf8WlE3nux5rt7c-OQ6-4taMSj5f-81q3J-fM1u1u_o,10189
 gym_jiminy/common/utils/spaces.py,sha256=A5-_tuNr7wdY7XxEIhmP5agGbUZ5VZNVSskG_EIzj_o,53495
 gym_jiminy/common/wrappers/__init__.py,sha256=vdX9DeoMfipj4XDVuG7muM6uXo3YZrIGb-d9Lfr3-ys,477
 gym_jiminy/common/wrappers/flatten.py,sha256=5lsmOdTE3hZCJMRNcHGQOnsrBI6I05Hb1ESpbKqqxxA,6115
 gym_jiminy/common/wrappers/normalize.py,sha256=TD3SnkMDydC2688ozpnNR7Y2_BIOEYcAIa6OtSb11B8,4039
 gym_jiminy/common/wrappers/observation_filter.py,sha256=qYrRM8eKV7HJ1_-CWwuUauTVTf8TalHq2JsBaHrQdPQ,3747
-gym_jiminy/common/wrappers/observation_stack.py,sha256=L3zznK2jNDwBrW7RkY4qcONu9HXI63G0gy2EJYkVBSQ,10609
-gym_jiminy-1.8.3.dist-info/METADATA,sha256=0ynNrrnbvDulI4f7WPQ5_uF0WEIT46E3j69rPl-cKSk,1606
-gym_jiminy-1.8.3.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-gym_jiminy-1.8.3.dist-info/top_level.txt,sha256=c6Ipde11Sivat1D9sNj6sn3TCpadD0Qqk9fMzWYQLko,11
-gym_jiminy-1.8.3.dist-info/RECORD,,
+gym_jiminy/common/wrappers/observation_stack.py,sha256=9rUAi-ZGI8pLF2niK2A06-VmvLe7GDuUwlhwhe-H7H8,10626
+gym_jiminy-1.8.4.dist-info/METADATA,sha256=BrG6uFOcL8cohu21Q0ICYqEenAULNnKNDBayR4-QVII,1605
+gym_jiminy-1.8.4.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+gym_jiminy-1.8.4.dist-info/top_level.txt,sha256=c6Ipde11Sivat1D9sNj6sn3TCpadD0Qqk9fMzWYQLko,11
+gym_jiminy-1.8.4.dist-info/RECORD,,
```

